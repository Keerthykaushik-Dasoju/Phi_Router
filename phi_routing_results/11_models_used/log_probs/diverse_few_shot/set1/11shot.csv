sample_id,phi_prediction,phi_response,oracle_model_to_route
mmlu-high-school-macroeconomics.val.127,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.82,meta/code-llama-instruct-34b-chat,D) (∀x)[Bx ⊃ (∃y)(Ny • Lxy)],claude-instant-v1
hellaswag.val.7968,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4037,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-global-facts.val.6,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1409,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-high-school-microeconomics.val.133,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3926,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.389,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3378,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
winogrande.dev.647,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.180,meta/llama-2-70b-chat,B) All of these options,mistralai/mixtral-8x7b-chat
arc-challenge.test.959,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.558,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview
mmlu-high-school-psychology.val.109,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5826,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.206,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.763,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6880,claude-v1,A) title,zero-one-ai/Yi-34B-Chat
hellaswag.val.6222,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-microeconomics.val.49,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.59,WizardLM/WizardLM-13B-V1.2,A) NaCl + H_{2}O,mistralai/mistral-7b-chat
mmlu-high-school-psychology.val.532,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.72,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
arc-challenge.val.125,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.581,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
hellaswag.val.9534,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3972,claude-v1,gpt-3.5-turbo-1106,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1172,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
grade-school-math.dev.1844,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2702,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.6893,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2730,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4709,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,WizardLM/WizardLM-13B-V1.2
mmlu-elementary-mathematics.val.360,claude-v2,claude-v2,mistralai/mistral-7b-chat
mmlu-human-sexuality.val.63,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-college-medicine.val.154,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.6302,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.2020,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-world-history.val.163,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-econometrics.val.76,claude-v1,B) (ii) and (iv) only,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.13,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v1
hellaswag.val.10012,claude-v1,"A) title: Present the soccer ball to your child on a special day, maybe their birthday. [step] This will help your child to associate it with a fun occasion, seeing it as a gift and an opportunity to learn something",mistralai/mistral-7b-chat
arc-challenge.val.282,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.93,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-world-religions.val.11,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
winogrande.dev.742,claude-v1,A) Samuel,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.135,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-elementary-mathematics.val.233,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,no_model_correct
mmlu-world-religions.val.44,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
consensus_summary.dev.292,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
mmlu-clinical-knowledge.val.142,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-high-school-geography.val.73,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5893,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1110,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-business-ethics.val.77,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.138,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4374,gpt-4-1106-preview,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1169,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.278,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-psychology.val.475,meta/code-llama-instruct-34b-chat,B) DSM-5,WizardLM/WizardLM-13B-V1.2
bias_detection.dev.62,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence provided is a direct quote from President Biden, which is a clear example of a quote. It does not contain any personal view, judgement",mistralai/mixtral-8x7b-chat
arc-challenge.test.667,claude-v1,claude-v1,mistralai/mistral-7b-chat
accounting_audit.dev.6,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.7030,meta/llama-2-70b-chat,"B) [substeps] Ask yourself how much time you spend with your spouse, then compare that to the amount of time you spend at work (excluding the time you must spend working), with friends, with family, or online. E",zero-one-ai/Yi-34B-Chat
hellaswag.val.8370,claude-v1,A) Choose the type and size of machines that best meet your location needs.,mistralai/mistral-7b-chat
mmlu-international-law.val.119,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.602,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.498,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1023,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.3857,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,claude-instant-v1
hellaswag.val.1881,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
mmlu-college-chemistry.val.80,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,no_model_correct
hellaswag.val.325,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1113,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-prehistory.val.36,claude-v2,B) Aztec; Tenochtitlán.,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2065,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7399,gpt-4-1106-preview,claude-v2,gpt-3.5-turbo-1106
mmlu-high-school-us-history.val.104,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-nutrition.val.45,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
arc-challenge.test.986,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.846,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-anatomy.val.29,WizardLM/WizardLM-13B-V1.2,meta/llama-2-70b-chat,claude-v2
mmlu-professional-law.val.1523,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.785,zero-one-ai/Yi-34B-Chat,"D) Wrong, Not wrong",zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2940,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.3806,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.192,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-management.val.57,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
mmlu-human-sexuality.val.62,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-psychology.val.444,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.362,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,gpt-4-1106-preview
mmlu-professional-law.val.997,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7413,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7488,claude-v2,claude-v2,claude-instant-v1
grade-school-math.dev.4320,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-philosophy.val.96,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
grade-school-math.dev.1249,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-miscellaneous.val.515,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.3235,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.1344,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
arc-challenge.val.249,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.5107,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,mistralai/mistral-7b-chat
hellaswag.val.9635,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-econometrics.val.62,WizardLM/WizardLM-13B-V1.2,"C) (i), (ii), (iii), and (iv)",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.618,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.674,claude-v1,claude-v1,gpt-4-1106-preview
mmlu-professional-law.val.708,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.7853,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-security-studies.val.98,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.9812,claude-v1,"B) Your domain name represents the url (or permanent web address) of your website. Therefore, when anyone types in "" yourdomain.com "" or "" www.yourdomain.com "", they will see your website.",mistralai/mixtral-8x7b-chat
mmlu-clinical-knowledge.val.137,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.4419,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-microeconomics.val.171,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.564,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.7887,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1526,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.278,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2210,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mbpp.dev.175,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
grade-school-math.dev.3037,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4522,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.7739,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-anatomy.val.26,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.406,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-accounting.val.45,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1740,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.416,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-abstract-algebra.val.48,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
mmlu-professional-law.val.107,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.109,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-moral-scenarios.val.27,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-astronomy.val.17,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.7261,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4133,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.335,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.1202,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.5461,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.4468,claude-v1,claude-v1,gpt-3.5-turbo-1106
consensus_summary.dev.189,zero-one-ai/Yi-34B-Chat,N-A,WizardLM/WizardLM-13B-V1.2
hellaswag.val.883,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-chemistry.val.171,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
arc-challenge.val.72,WizardLM/WizardLM-13B-V1.2,claude-v2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3385,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.293,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mbpp.dev.110,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1374,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-machine-learning.val.66,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-elementary-mathematics.val.292,gpt-3.5-turbo-1106,B) gpt-3.5-turbo-1106,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6867,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-european-history.val.63,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.907,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.1064,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
arc-challenge.test.989,claude-v2,claude-v2,mistralai/mistral-7b-chat
hellaswag.val.1289,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.139,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.5011,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.71,gpt-4-1106-preview,gpt-3.5-turbo-1106,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-chemistry.val.57,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8945,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
arc-challenge.test.1065,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-astronomy.val.100,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7804,claude-v2,claude-v2,no_model_correct
mmlu-high-school-mathematics.val.171,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-3.5-turbo-1106
hellaswag.val.2593,mistralai/mixtral-8x7b-chat,"B) , a woman rises the left hand and touches her head.",mistralai/mixtral-8x7b-chat
hellaswag.val.7573,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-macroeconomics.val.329,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.1927,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.1531,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
mmlu-high-school-psychology.val.358,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.1241,claude-v1,A) Michael,mistralai/mistral-7b-chat
grade-school-math.dev.2865,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-college-medicine.val.100,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.446,claude-v1,A) Ian,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.29,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.3025,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5081,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
arc-challenge.test.604,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-computer-science.val.94,claude-v1,claude-v1,claude-v2
winogrande.dev.235,claude-v1,A) Lawrence,meta/llama-2-70b-chat
grade-school-math.dev.3864,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.229,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,claude-v2
mmlu-high-school-macroeconomics.val.6,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.915,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.3802,claude-v1,claude-v1,gpt-3.5-turbo-1106
winogrande.dev.1234,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.7039,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-professional-law.val.1026,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1294,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.436,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
consensus_summary.dev.32,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8261,claude-v1,"A) title: Gently rub your hunter boots with the wet washcloth. [step] Work in a circular pattern to most effectively wipe away dirt and grime.

The best-suited model for this",mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6364,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-jurisprudence.val.19,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.241,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.6960,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-statistics.val.193,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
mmlu-medical-genetics.val.94,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.298,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.60,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.4368,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.742,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.62,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-virology.val.77,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.2072,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-macroeconomics.val.378,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.1022,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6258,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-psychology.val.66,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.3292,claude-v1,A) claude-instant-v1,mistralai/mistral-7b-chat
grade-school-math.dev.4377,claude-v1,claude-v1,claude-instant-v1
mmlu-professional-law.val.735,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5658,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.7557,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.102,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6108,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.4426,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.3043,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.704,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6244,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2021,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.2798,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.927,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.96,claude-v1,B) H ∨ ~R,claude-instant-v1
mmlu-human-aging.val.180,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.1955,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1614,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5958,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.1554,claude-v1,A),mistralai/mistral-7b-chat
hellaswag.val.128,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
consensus_summary.dev.105,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
hellaswag.val.6255,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.335,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-computer-security.val.58,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1258,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1226,claude-v1,"C) Yes, because a challenge to jurisdiction can be made at any time, even after judgment has been entered, and here the jurisdictional requirement was missing.",mistralai/mistral-7b-chat
hellaswag.val.1535,claude-v2,claude-v2,mistralai/mistral-7b-chat
mmlu-professional-law.val.590,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,no_model_correct
grade-school-math.dev.6105,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,meta/llama-2-70b-chat
mmlu-management.val.93,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
hellaswag.val.978,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.276,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.101,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.460,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3331,gpt-4-1106-preview,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-medicine.val.137,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.1183,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.1326,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4090,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,mistralai/mistral-7b-chat
mmlu-human-aging.val.104,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.219,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.9743,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-prehistory.val.75,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.290,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3889,claude-v1,"A) Ladybugs can be sold as small boxes, pots, or bowls.",no_model_correct
hellaswag.val.3173,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.35,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-clinical-knowledge.val.193,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2319,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.5933,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.6724,claude-v2,claude-v2,mistralai/mistral-7b-chat
grade-school-math.dev.6764,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.391,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9660,claude-v1,claude-v1,mistralai/mistral-7b-chat
abstract2title.test.100,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.636,zero-one-ai/Yi-34B-Chat,"B) Wrong, Not wrong",gpt-4-1106-preview
mbpp.dev.241,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-human-sexuality.val.127,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.6672,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.873,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
hellaswag.val.4415,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
consensus_summary.dev.305,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.1429,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
winogrande.dev.454,claude-v1,B) Randy,mistralai/mistral-7b-chat
mmlu-professional-law.val.1469,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-management.val.92,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4509,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.36,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.302,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
hellaswag.val.5413,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-clinical-knowledge.val.46,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.723,WizardLM/WizardLM-13B-V1.2,A) Greenware,mistralai/mistral-7b-chat
mmlu-college-biology.val.63,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.1509,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
hellaswag.val.4033,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-physics.val.100,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-psychology.val.446,claude-v1,claude-v1,no_model_correct
hellaswag.val.4102,claude-v1,A) meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
hellaswag.val.7289,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.9705,claude-v1,claude-v1,claude-instant-v1
mmlu-philosophy.val.289,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1359,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.285,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4461,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,claude-instant-v1
mmlu-logical-fallacies.val.98,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
arc-challenge.val.203,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.4,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.950,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,no_model_correct
winogrande.dev.172,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.769,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.837,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.9978,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
abstract2title.test.74,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-statistics.val.53,claude-v1,B) H0: p ≤ 0.60 and Ha: p > 0.60,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.597,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-machine-learning.val.103,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
mmlu-professional-law.val.1430,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-jurisprudence.val.33,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-prehistory.val.37,meta/llama-2-70b-chat,D) diffusionism,mistralai/mixtral-8x7b-chat
mmlu-high-school-world-history.val.146,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.4260,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4167,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.2125,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-philosophy.val.105,claude-v1,claude-v1,claude-instant-v1
mmlu-high-school-microeconomics.val.4,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.36,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
arc-challenge.test.289,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-security-studies.val.8,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.100,meta/llama-2-70b-chat,D) All of these options,WizardLM/WizardLM-13B-V1.2
mmlu-virology.val.13,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1069,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
grade-school-math.dev.5990,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.6941,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.714,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.142,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6826,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-marketing.val.47,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2795,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.79,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-logical-fallacies.val.105,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7041,claude-v2,A) WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-sociology.val.134,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.3902,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat,claude-v1
hellaswag.val.9991,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.641,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat
mmlu-jurisprudence.val.54,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
hellaswag.val.9361,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.1394,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.6078,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-european-history.val.2,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-high-school-psychology.val.456,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.1049,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
hellaswag.val.8239,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,gpt-3.5-turbo-1106
mmlu-global-facts.val.38,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4324,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.105,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.611,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1010,claude-v1,C) it is necessary to show that every reasonable effort has been made to procure his attendance.,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.218,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.3579,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4543,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7054,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.184,claude-v1,claude-v1,claude-v2
mmlu-high-school-chemistry.val.140,gpt-4-1106-preview,WizardLM/WizardLM-113B-V1.2,mistralai/mixtral-8x7b-chat
hellaswag.val.8898,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.584,claude-v1,claude-v1,no_model_correct
grade-school-math.dev.919,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-college-biology.val.50,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.756,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.222,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1234,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.143,claude-v1,claude-v1,gpt-4-1106-preview
mmlu-professional-law.val.424,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-philosophy.val.290,meta/llama-2-70b-chat,D) All of the above,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.17,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-microeconomics.val.218,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.236,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.46,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2592,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-professional-law.val.388,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1332,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.121,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2598,claude-v1,mistralai/mistral-7b-chat,gpt-4-1106-preview
hellaswag.val.8132,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.9655,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-econometrics.val.96,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-conceptual-physics.val.105,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
hellaswag.val.2437,claude-v1,mistralai/mistral-7b-chat,no_model_correct
mmlu-college-mathematics.val.60,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6052,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.22,claude-v1,meta/code-llama-instruct-34b-chat,claude-instant-v1
mmlu-high-school-world-history.val.129,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.3189,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-professional-law.val.1056,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
arc-challenge.test.701,meta/code-llama-instruct-34b-chat,C) meters,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.218,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.814,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,claude-instant-v1
arc-challenge.test.826,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-philosophy.val.91,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
arc-challenge.test.854,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6543,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2112,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
arc-challenge.test.767,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2919,WizardLM/WizardLM-13B-V1.2,A),claude-instant-v1
mmlu-moral-scenarios.val.650,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-professional-law.val.267,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.239,claude-v2,claude-v2,gpt-4-1106-preview
mmlu-professional-law.val.1124,meta/code-llama-instruct-34b-chat,D) an installment contract.,gpt-3.5-turbo-1106
grade-school-math.dev.2573,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3100,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-psychology.val.538,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1567,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.1638,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9236,claude-v2,B) claude-v2,gpt-3.5-turbo-1106
mmlu-abstract-algebra.val.46,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
arc-challenge.test.534,meta/llama-2-70b-chat,B) universal systems model,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1703,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mbpp.dev.68,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.557,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1092,claude-v2,claude-v2,gpt-3.5-turbo-1106
mmlu-professional-law.val.1129,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mbpp.dev.60,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat
grade-school-math.dev.179,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
winogrande.dev.1155,claude-v2,A) Benjamin,mistralai/mistral-7b-chat
mmlu-moral-disputes.val.187,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.266,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-professional-medicine.val.133,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.2065,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,gpt-4-1106-preview
grade-school-math.dev.1915,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1401,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.281,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
winogrande.dev.1151,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3420,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
winogrande.dev.479,meta/llama-2-70b-chat,B) Instrument,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3134,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.309,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.9164,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1328,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.1303,claude-v1,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1207,claude-v1,claude-v1,no_model_correct
winogrande.dev.533,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8992,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.672,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.78,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,claude-instant-v1
mmlu-prehistory.val.22,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.187,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v1
mmlu-professional-psychology.val.410,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3476,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-prehistory.val.179,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-business-ethics.val.64,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.211,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-mathematics.val.34,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,gpt-3.5-turbo-1106
mmlu-high-school-us-history.val.133,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
arc-challenge.test.687,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-machine-learning.val.63,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
winogrande.dev.825,claude-v1,A) monogram,mistralai/mistral-7b-chat
mmlu-professional-law.val.594,zero-one-ai/Yi-34B-Chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.154,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-government-and-politics.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6902,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.372,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-medicine.val.90,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mbpp.dev.276,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.4538,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-sociology.val.120,claude-v1,claude-v1,mistralai/mistral-7b-chat
consensus_summary.dev.266,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.6634,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.4809,claude-v1,"A) title ""Read about the denomination that a particular congregation belongs to."" step ""Some are evangelical (such as the evangelical lutheran church in america), and others are more conservative (such as the l",mistralai/mistral-7b-chat
bias_detection.dev.191,claude-v1,"D) True, True\n\nReasoning: The sentence ""at some point Ukraine will likely seize the initiative"" is a speculation because it expresses an assumption or theory about a future event that has not yet occurred and",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1159,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.391,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,no_model_correct
mmlu-professional-law.val.798,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4979,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.417,claude-v1,"B) Yes, because it is prior testimony of an unavailable declarant.",WizardLM/WizardLM-13B-V1.2
mmlu-sociology.val.85,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.185,claude-v1,claude-v1,gpt-4-1106-preview
grade-school-math.dev.3263,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.9260,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1076,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.489,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-computer-security.val.48,meta/code-llama-instruct-34b-chat,B) A piece of software that intercepts and possibly modifies requests (and responses) between a web browser and web server,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-european-history.val.151,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.3327,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
arc-challenge.test.1012,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8506,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2904,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5860,claude-v2,claude-v2,claude-v1
hellaswag.val.7221,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-marketing.val.163,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.148,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.80,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3954,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.65,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4906,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2799,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-marketing.val.134,meta/llama-2-70b-chat,Porter's Five Forces model,mistralai/mixtral-8x7b-chat
hellaswag.val.9497,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.8171,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-nutrition.val.225,WizardLM/WizardLM-13B-V1.2,A) All of the above were among the causes.,mistralai/mistral-7b-chat
grade-school-math.dev.1805,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.5381,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1016,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.1363,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,claude-instant-v1
grade-school-math.dev.5413,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.8950,claude-v1,claude-v1,meta/llama-2-70b-chat
hellaswag.val.8835,claude-v1,"B) [step] If your diamante started off with "" home, "" you might choose two adjectives like "" safe "" and "" warm. "" these adjectives describe feelings associated with home.",claude-instant-v1
mmlu-prehistory.val.134,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5353,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.6666,claude-v1,claude-v1,meta/llama-2-70b-chat
mbpp.dev.63,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-3.5-turbo-1106
grade-school-math.dev.3322,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4060,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.153,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3275,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1767,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/llama-2-70b-chat
accounting_audit.dev.25,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.2325,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
winogrande.dev.1092,mistralai/mistral-7b-chat,B) Erin,mistralai/mistral-7b-chat
mmlu-security-studies.val.113,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.538,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
hellaswag.val.4707,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.2271,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.15,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.720,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.3092,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-high-school-statistics.val.104,mistralai/mixtral-8x7b-chat,B) matched pairs t-test,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.130,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-psychology.val.276,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3818,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-international-law.val.27,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.6,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.307,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.254,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3124,meta/llama-2-70b-chat,claude-v2,meta/llama-2-70b-chat
consensus_summary.dev.216,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.744,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
grade-school-math.dev.5577,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.9039,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2482,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
consensus_summary.dev.179,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-v1
winogrande.dev.528,claude-v1,A) Laura,mistralai/mistral-7b-chat
grade-school-math.dev.4571,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8600,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.281,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.7893,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.2763,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/llama-2-70b-chat
grade-school-math.dev.6413,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
mmlu-us-foreign-policy.val.7,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v1
grade-school-math.dev.5824,meta/llama-2-70b-chat,claude-v1,mistralai/mistral-7b-chat
winogrande.dev.82,claude-v1,A) Brett,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.476,claude-v1,claude-v1,gpt-3.5-turbo-1106
grade-school-math.dev.5041,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-high-school-us-history.val.28,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6754,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7190,claude-v2,A) meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
mmlu-nutrition.val.222,claude-v1,claude-v1,no_model_correct
mmlu-miscellaneous.val.70,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.225,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.234,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7707,claude-v2,A) claude-v2,mistralai/mistral-7b-chat
hellaswag.val.6260,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4389,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-elementary-mathematics.val.7,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-miscellaneous.val.742,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1170,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.760,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2701,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1486,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.565,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.650,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6352,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.375,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,mistralai/mistral-7b-chat
hellaswag.val.8001,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.7042,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.218,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-security-studies.val.6,meta/llama-2-70b-chat,B) Nationalization: state enterprises should be protected.,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9903,claude-v1,B) Substeps,WizardLM/WizardLM-13B-V1.2
mtbench-math.dev.17,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
consensus_summary.dev.4,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2764,claude-v2,claude-v2,mistralai/mistral-7b-chat
mmlu-high-school-chemistry.val.120,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview
winogrande.dev.569,mistralai/mistral-7b-chat,B) Laura,mistralai/mistral-7b-chat
grade-school-math.dev.4207,gpt-3.5-turbo-1106,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-college-physics.val.70,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.9251,claude-v1,"B) True, False",claude-instant-v1
hellaswag.val.1324,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
arc-challenge.val.4,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.156,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9051,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-elementary-mathematics.val.252,mistralai/mixtral-8x7b-chat,C) 4(x – 22),WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1118,claude-v1,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
hellaswag.val.2979,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6403,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.4083,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,claude-v2
mmlu-high-school-mathematics.val.25,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview
mmlu-professional-law.val.373,claude-v1,claude-v1,no_model_correct
mbpp.dev.329,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat
mtbench.dev.11,WizardLM/WizardLM-13B-V1.2,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.74,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-professional-law.val.135,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-nutrition.val.6,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.536,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.293,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.7036,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.8764,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7434,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6211,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-european-history.val.5,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.5883,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-statistics.val.156,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
arc-challenge.val.147,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.48,WizardLM/WizardLM-13B-V1.2,A) All of the above,gpt-3.5-turbo-1106
mmlu-jurisprudence.val.72,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.263,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6188,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.463,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.5044,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.1935,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6199,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-human-sexuality.val.52,meta/llama-2-70b-chat,D) a and b only,mistralai/mixtral-8x7b-chat
hellaswag.val.1188,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-microeconomics.val.63,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-prehistory.val.309,WizardLM/WizardLM-13B-V1.2,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7184,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-business-ethics.val.6,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.790,claude-v1,claude-v1,mistralai/mistral-7b-chat
winogrande.dev.14,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.4973,claude-v2,claude-v2,mistralai/mistral-7b-chat
arc-challenge.val.286,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.val.229,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.5617,claude-v1,claude-v1,gpt-3.5-turbo-1106
grade-school-math.dev.2309,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.2550,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-marketing.val.6,meta/code-llama-instruct-34b-chat,B) Gatekeepers,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5231,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-microeconomics.val.173,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1081,claude-v1,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.923,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2275,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1847,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3933,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4666,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.75,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mbpp.dev.259,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat,no_model_correct
hellaswag.val.8816,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.10,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.863,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.3733,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.523,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
arc-challenge.val.37,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.7254,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.4043,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
hellaswag.val.9382,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.7332,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.8211,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-psychology.val.212,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.216,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1203,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-moral-disputes.val.252,claude-v1,claude-v1,gpt-4-1106-preview
hellaswag.val.3480,claude-v2,claude-v2,no_model_correct
mmlu-college-biology.val.8,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.972,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-chemistry.val.59,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.3228,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,WizardLM/WizardLM-13B-V1.2
mmlu-machine-learning.val.50,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-medicine.val.154,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.66,claude-v1,claude-v1,no_model_correct
mmlu-high-school-government-and-politics.val.59,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1113,claude-v1,claude-v1,claude-v1
grade-school-math.dev.4814,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-clinical-knowledge.val.65,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.653,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mbpp.dev.122,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6276,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.5657,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.3013,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.496,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.777,meta/llama-2-70b-chat,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.1740,claude-v1,claude-v1,meta/llama-2-70b-chat
hellaswag.val.6582,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.2211,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,no_model_correct
hellaswag.val.2767,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,no_model_correct
hellaswag.val.4667,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-world-history.val.105,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-security-studies.val.133,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3392,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-astronomy.val.82,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9435,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.7064,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.3232,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,gpt-3.5-turbo-1106
mmlu-high-school-geography.val.81,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.4450,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.798,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-elementary-mathematics.val.222,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1316,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1491,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,mistralai/mistral-7b-chat
mmlu-medical-genetics.val.61,claude-v2,claude-v2,mistralai/mistral-7b-chat
hellaswag.val.8426,claude-v1,claude-v1 or claude-v2,claude-instant-v1
mmlu-high-school-chemistry.val.54,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-prehistory.val.90,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2688,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5533,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5776,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6632,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.86,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.481,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
grade-school-math.dev.5160,claude-v2,claude-v2,mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.49,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1842,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-physics.val.67,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5193,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8699,claude-v1,claude-v1,no_model_correct
hellaswag.val.5211,claude-v2,B) claude-v2,claude-instant-v1
grade-school-math.dev.1009,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-accounting.val.59,claude-v2,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.153,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.144,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
abstract2title.test.104,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.8980,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-public-relations.val.85,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-medical-genetics.val.52,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-government-and-politics.val.11,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
bias_detection.dev.284,claude-v1,"WizardLM/WizardLM-12B-V1.2 — correctness: 1.0, cost: 0.00012345678901234e-0",claude-v1
bias_detection.dev.161,meta/llama-2-70b-chat,"meta/llama-2-70b-chat — The sentence ""Ukrainian leaders won't want to rush into their own mistake just when Russia is making a lot of its own"" is classified as an opinion.",WizardLM/WizardLM-13B-V1.2
hellaswag.val.10010,claude-v1,"A) Tap the "" menu "" tab to open up the options.",mistralai/mistral-7b-chat
grade-school-math.dev.4245,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.2557,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.186,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6509,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-jurisprudence.val.107,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-european-history.val.11,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.7994,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,gpt-3.5-turbo-1106
mbpp.dev.384,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1272,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-international-law.val.12,meta/llama-2-70b-chat,"B) No, all States are considered equal as sovereign States (the principle of sovereign equality, enshrined in article 2, para 1 UN Charter)",WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.403,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.489,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.234,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.4466,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-macroeconomics.val.316,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
bias_detection.dev.27,meta/code-llama-instruct-34b-chat,"meta/code-llama-instruct-34b-chat

Reasoning: The sentence provided is a factual statement that directly presents information about the 2005 Protection of Lawful Commerce in Arms",no_model_correct
mmlu-moral-scenarios.val.391,WizardLM/WizardLM-13B-V1.2,"D) Wrong, Not wrong",zero-one-ai/Yi-34B-Chat
mmlu-professional-psychology.val.123,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.390,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6830,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-us-foreign-policy.val.62,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
winogrande.dev.95,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,claude-instant-v1
grade-school-math.dev.3870,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.870,gpt-4-1106-preview,B) gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-clinical-knowledge.val.8,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
mmlu-high-school-geography.val.98,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
bias_detection.dev.140,meta/llama-2-70b-chat,"meta/llama-2-70b-chat — The sentence is expressing a viewpoint and a hope for future political action, which is an opinion. It includes a direct reference to what ""Proudman hopes"" and what needs",WizardLM/WizardLM-13B-V1.2
hellaswag.val.9123,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.24,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
mmlu-high-school-us-history.val.54,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.551,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-formal-logic.val.61,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-management.val.48,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
abstract2title.test.133,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.857,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-logical-fallacies.val.88,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
grade-school-math.dev.5394,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-us-history.val.26,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
arc-challenge.test.698,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.73,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.105,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-professional-law.val.1446,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.4297,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-macroeconomics.val.138,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.179,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.371,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview
grade-school-math.dev.155,claude-v2,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-high-school-physics.val.132,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.164,mistralai/mixtral-8x7b-chat,D) Submit an affidavit from the patient's expert radiologist with findings that contradict the report of the hospital's radiologist.,WizardLM/WizardLM-13B-V1.2
bias_detection.dev.209,WizardLM/WizardLM-13B-V1.2,"WizardLM/WizardLM-13B-V1.2 — This sentence is presenting a factual information about an event that took place, specifically Moscow declaring a state of emergency and attempting to stop the advance of Prig",no_model_correct
mmlu-professional-law.val.1061,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-college-mathematics.val.52,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.444,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.105,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.923,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5486,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.8591,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.2128,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3783,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2924,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mtbench.dev.37,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.515,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-jurisprudence.val.95,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2467,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.446,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1087,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.104,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5064,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.4387,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-mathematics.val.46,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-4-1106-preview
arc-challenge.test.598,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.4724,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7164,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.1868,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-high-school-european-history.val.13,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-computer-security.val.50,claude-v2,"C) C, C++",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1377,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.3481,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-business-ethics.val.62,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.8999,claude-v1,claude-v1,no_model_correct
arc-challenge.val.48,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-professional-medicine.val.161,WizardLM/WizardLM-13B-V1.2,C) Crossover,mistralai/mistral-7b-chat
mmlu-college-biology.val.97,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.7010,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
abstract2title.test.28,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.214,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.442,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3284,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
mmlu-moral-scenarios.val.810,claude-v1,"B) Not wrong, Wrong",WizardLM/WizardLM-13B-V1.2
hellaswag.val.1696,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6477,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-statistics.val.50,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7806,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1218,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6534,claude-v2,B) claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.465,claude-v1,claude-v1,no_model_correct
hellaswag.val.4161,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-college-biology.val.40,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
hellaswag.val.2026,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1067,claude-v1,"A) denied, because double jeopardy rights do not attach unless there has been an acquittal or conviction.",no_model_correct
mmlu-miscellaneous.val.131,meta/llama-2-70b-chat,B) 50,mistralai/mixtral-8x7b-chat
hellaswag.val.8944,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.3283,claude-v1,claude-v1,meta/llama-2-70b-chat
mmlu-professional-law.val.1521,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2789,meta/llama-2-70b-chat,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.5947,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-elementary-mathematics.val.298,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4366,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-international-law.val.92,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5668,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-anatomy.val.127,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.408,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-anatomy.val.57,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.23,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.156,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.807,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.265,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,gpt-4-1106-preview
mmlu-high-school-macroeconomics.val.285,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.1916,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-mathematics.val.133,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.81,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1130,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-machine-learning.val.41,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3784,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.3353,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.5036,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5183,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4728,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-abstract-algebra.val.50,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.288,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4811,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mbpp.dev.43,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.252,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
accounting_audit.dev.5,WizardLM/WizardLM-13B-V1.2,A,zero-one-ai/Yi-34B-Chat
hellaswag.val.1952,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,claude-v1
grade-school-math.dev.5514,claude-v2,claude-v2,mistralai/mistral-7b-chat
hellaswag.val.4792,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-european-history.val.65,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-mathematics.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
arc-challenge.test.367,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.384,gpt-4-1106-preview,B) Sensation,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.430,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-marketing.val.180,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.61,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3744,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-4-1106-preview
grade-school-math.dev.2702,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.3386,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-moral-scenarios.val.112,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9644,claude-v1,claude-v1,mistralai/mistral-7b-chat
winogrande.dev.513,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1338,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-abstract-algebra.val.58,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
mmlu-professional-psychology.val.437,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.790,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.725,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
arc-challenge.test.1081,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
grade-school-math.dev.2999,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2883,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.654,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.83,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-world-religions.val.84,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
consensus_summary.dev.290,zero-one-ai/Yi-34B-Chat,"N-A (The provided claims do not directly address the question of whether high school should be free for everyone, and none of the models are specified to be best suited for this particular question.)",WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.83,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.543,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.8,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,meta/llama-2-70b-chat
grade-school-math.dev.3865,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7191,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.301,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-medicine.val.236,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
arc-challenge.test.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5832,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
hellaswag.val.4965,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.2215,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1244,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3376,claude-v1,claude-v1,claude-instant-v1
mmlu-miscellaneous.val.660,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6695,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.845,claude-v1,"B) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
hellaswag.val.5829,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-miscellaneous.val.493,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.63,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.35,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.953,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.6584,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1937,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8977,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-philosophy.val.189,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.6160,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.7074,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-global-facts.val.77,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7917,claude-v2,"A) Pack a couple sandwiches, take the kids into the woods and hike a deer trail through the woods. As you go : [substeps] Let the kids ask questions.",mistralai/mistral-7b-chat
mmlu-high-school-biology.val.289,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-international-law.val.94,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
winogrande.dev.1014,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.6587,claude-v1,claude-v1,claude-instant-v1
hellaswag.val.2461,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,meta/llama-2-70b-chat
grade-school-math.dev.6641,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.1799,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-computer-science.val.54,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3174,claude-v1,meta/llama-2-70b-chat,claude-instant-v1
mmlu-high-school-microeconomics.val.59,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.5984,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.592,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-moral-disputes.val.144,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2560,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.144,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3455,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.5557,claude-v1,claude-v1,mistralai/mistral-7b-chat
consensus_summary.dev.213,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.6989,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.250,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-clinical-knowledge.val.104,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5450,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2797,gpt-3.5-turbo-1106,gpt-3.5-turbo-1106,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2760,claude-v1,claude-v1,gpt-4-1106-preview
grade-school-math.dev.4473,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-4-1106-preview
hellaswag.val.5949,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.188,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.252,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8592,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-college-physics.val.94,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
grade-school-math.dev.2318,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-global-facts.val.99,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.9608,claude-v2,A) claude-instant-v1,mistralai/mistral-7b-chat
hellaswag.val.886,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,claude-instant-v1
grade-school-math.dev.617,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
grade-school-math.dev.1245,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
grade-school-math.dev.136,claude-v2,claude-v2,meta/code-llama-instruct-34b-chat
mmlu-college-mathematics.val.50,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
arc-challenge.test.506,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.816,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.156,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.0,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-european-history.val.163,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3702,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.3781,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mtbench-reference.dev.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,gpt-3.5-turbo-1106
mmlu-high-school-macroeconomics.val.332,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.5627,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3848,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.5919,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.514,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.209,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.7791,claude-v2,claude-v2,mistralai/mixtral-8x7b-chat
mmlu-human-sexuality.val.26,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-nutrition.val.22,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.4039,claude-v2,claude-v2,claude-instant-v1
arc-challenge.test.709,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2905,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.328,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
hellaswag.val.8690,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-jurisprudence.val.44,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7593,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.119,claude-v1,claude-v1,claude-instant-v1
bias_detection.dev.77,mistralai/mixtral-8x7b-chat,"mistralai/mixtral-8x7b-chat — The sentence provided is a direct quote from a person expressing their belief about the percentage of energy produced by solar and wind due to cost. It does not present raw data,",mistralai/mixtral-8x7b-chat
arc-challenge.test.635,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.210,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.3963,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.2713,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-macroeconomics.val.35,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mbpp.dev.298,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat
grade-school-math.dev.3536,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-college-medicine.val.168,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.638,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.5922,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-nutrition.val.220,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-sexuality.val.33,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
winogrande.dev.129,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.122,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-physics.val.103,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.156,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.285,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
winogrande.dev.361,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-mathematics.val.229,claude-v1,claude-v1,no_model_correct
grade-school-math.dev.7065,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-elementary-mathematics.val.218,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat
winogrande.dev.1012,claude-v1,B) Justin,mistralai/mistral-7b-chat
hellaswag.val.8217,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.209,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-mathematics.val.142,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.180,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-logical-fallacies.val.100,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.178,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
