sample_id,phi_prediction,phi_response,oracle_model_to_route
mmlu-high-school-macroeconomics.val.127,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.82,meta/code-llama-instruct-34b-chat,D,claude-instant-v1
hellaswag.val.7968,claude-v1,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4037,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-global-facts.val.6,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1409,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-microeconomics.val.133,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3926,claude-v2,claude-v2,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.389,claude-v1,"B) Not wrong, Wrong",WizardLM/WizardLM-13B-V1.2
hellaswag.val.3378,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
winogrande.dev.647,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.180,gpt-4-1106-preview,B) All of these options.,mistralai/mixtral-8x7b-chat
arc-challenge.test.959,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.558,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
mmlu-high-school-psychology.val.109,gpt-4-1106-preview,D) Mania,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5826,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.206,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.763,claude-v1,C) overrule the objection on the grounds that the former girlfriend qualifies as an authenticating witness.,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6880,claude-v1,A),zero-one-ai/Yi-34B-Chat
hellaswag.val.6222,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-microeconomics.val.49,WizardLM/WizardLM-13B-V1.2,A),mistralai/mistral-7b-chat
arc-challenge.test.59,WizardLM/WizardLM-13B-V1.2,A) NaCl + H_{2}O,mistralai/mistral-7b-chat
mmlu-high-school-psychology.val.532,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.72,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
arc-challenge.val.125,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.581,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
hellaswag.val.9534,claude-v1,C) meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3972,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1172,meta/llama-2-70b-chat,B) Interstate travel,claude-instant-v1
grade-school-math.dev.1844,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2702,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.6893,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2730,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4709,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-elementary-mathematics.val.360,claude-v2,claude-v1,mistralai/mistral-7b-chat
mmlu-human-sexuality.val.63,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-college-medicine.val.154,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6302,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/llama-2-70b-chat
grade-school-math.dev.2020,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-world-history.val.163,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-econometrics.val.76,meta/llama-2-70b-chat,B) (ii) and (iv) only,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.13,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
hellaswag.val.10012,claude-v1,"A) title: Present the soccer ball to your child on a special day, maybe their birthday. [step] This will help your child to associate it with a fun occasion, seeing it as a gift and an opportunity to learn something",mistralai/mistral-7b-chat
arc-challenge.val.282,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.93,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-world-religions.val.11,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
winogrande.dev.742,claude-v1,A) Samuel,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.135,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-elementary-mathematics.val.233,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
mmlu-world-religions.val.44,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
consensus_summary.dev.292,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
mmlu-clinical-knowledge.val.142,meta/llama-2-70b-chat,D) calcium binding to troponin,mistralai/mixtral-8x7b-chat
mmlu-high-school-geography.val.73,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5893,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1110,WizardLM/WizardLM-13B-V1.2,"A) The statement should be allowed, because the driver was not in custody for Miranda purposes when the admission was made.",no_model_correct
mmlu-business-ethics.val.77,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.138,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4374,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1169,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.278,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-psychology.val.475,claude-v1,B) DSM-5,WizardLM/WizardLM-13B-V1.2
bias_detection.dev.62,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence provided is a direct quote from a political figure (Biden) at a campaign rally, which is a factual statement about an event that occurred",mistralai/mixtral-8x7b-chat
arc-challenge.test.667,claude-v1,claude-v1,mistralai/mistral-7b-chat
accounting_audit.dev.6,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.7030,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.8370,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-international-law.val.119,meta/llama-2-70b-chat,B) Implied are those powers which are necessary in order for an organisation to carry out the tasks conferred upon it and which are not stipulated in its charter,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.602,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.498,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1023,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.3857,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.1881,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-college-chemistry.val.80,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
hellaswag.val.325,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1113,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-prehistory.val.36,claude-v1,B) Aztec; Tenochtitlán.,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2065,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7399,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
mmlu-high-school-us-history.val.104,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-nutrition.val.45,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
arc-challenge.test.986,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.846,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
mmlu-anatomy.val.29,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v2
mmlu-professional-law.val.1523,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.785,WizardLM/WizardLM-13B-V1.2,"D) Wrong, Not wrong",zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2940,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.3806,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.192,claude-v1,"C) The cousin, based on necessity",mistralai/mixtral-8x7b-chat
mmlu-management.val.57,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-human-sexuality.val.62,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-psychology.val.444,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.362,claude-v1,"C) Wrong, Not wrong",gpt-4-1106-preview
mmlu-professional-law.val.997,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7413,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7488,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.4320,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-philosophy.val.96,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
grade-school-math.dev.1249,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-miscellaneous.val.515,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.3235,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1344,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
arc-challenge.val.249,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.5107,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9635,claude-v1,"A) All operating systems are designed to automatically download the required drivers, but if you have no internet connection, or if the instructions specify to install the driver manually, you should do so. [substeps] The driver will generally be included on a",mistralai/mistral-7b-chat
mmlu-econometrics.val.62,meta/code-llama-instruct-34b-chat,"C) (i), (ii), (iii), and (iv)",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.618,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.674,claude-v1,"D) Wrong, Not wrong",gpt-4-1106-preview
mmlu-professional-law.val.708,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.7853,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-security-studies.val.98,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.9812,meta/llama-2-70b-chat,B) meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-clinical-knowledge.val.137,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.4419,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-microeconomics.val.171,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.564,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.7887,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1526,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.278,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2210,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mbpp.dev.175,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
grade-school-math.dev.3037,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4522,claude-v1,"A) """,mistralai/mistral-7b-chat
hellaswag.val.7739,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-anatomy.val.26,meta/llama-2-70b-chat,D) Nephrolithiasis,mistralai/mistral-7b-chat
mmlu-professional-law.val.406,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-accounting.val.45,claude-v1,B) One.,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1740,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.416,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-abstract-algebra.val.48,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
mmlu-professional-law.val.107,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.109,gpt-4-1106-preview,D) Selling Treasury securities to commercial banks.,zero-one-ai/Yi-34B-Chat
mmlu-moral-scenarios.val.27,claude-v1,"C) Not wrong, Wrong",zero-one-ai/Yi-34B-Chat
mmlu-astronomy.val.17,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.7261,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4133,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.335,gpt-4-1106-preview,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.1202,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.5461,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.4468,claude-v1,claude-v1,gpt-3.5-turbo-1106
consensus_summary.dev.189,meta/llama-2-70b-chat,N-A,WizardLM/WizardLM-13B-V1.2
hellaswag.val.883,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-chemistry.val.171,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
arc-challenge.val.72,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3385,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.293,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mbpp.dev.110,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1374,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-machine-learning.val.66,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-elementary-mathematics.val.292,claude-v1,B) 42 ÷ 7,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6867,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-european-history.val.63,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.907,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.1064,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
arc-challenge.test.989,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.1289,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.139,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.5011,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.71,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-chemistry.val.57,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8945,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
arc-challenge.test.1065,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-astronomy.val.100,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7804,claude-v1,claude-v1,no_model_correct
mmlu-high-school-mathematics.val.171,claude-v1,claude-v1,gpt-3.5-turbo-1106
hellaswag.val.2593,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.7573,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-macroeconomics.val.329,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.1927,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.1531,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
mmlu-high-school-psychology.val.358,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.1241,claude-v1,A) Michael,mistralai/mistral-7b-chat
grade-school-math.dev.2865,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-college-medicine.val.100,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.446,claude-v1,A) Ian,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.29,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-113B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.3025,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5081,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
arc-challenge.test.604,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-computer-science.val.94,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
winogrande.dev.235,claude-v1,A) Lawrence,meta/llama-2-70b-chat
grade-school-math.dev.3864,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.229,meta/llama-2-70b-chat,D) zero-one-ai/Yi-34B-Chat,claude-v2
mmlu-high-school-macroeconomics.val.6,claude-v1,A) implies that resources are used to produce the goods and services society desires in just the right amounts.,mistralai/mistral-7b-chat
grade-school-math.dev.915,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.3802,claude-v1,claude-v1,gpt-3.5-turbo-1106
winogrande.dev.1234,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.7039,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-professional-law.val.1026,gpt-4-1106-preview,"B) Yes, the injunctive restriction was a content-neutral restriction that burdened no more speech than was necessary.",WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1294,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.436,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
consensus_summary.dev.32,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8261,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6364,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-jurisprudence.val.19,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.241,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,claude-instant-v1
grade-school-math.dev.6960,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-statistics.val.193,gpt-4-1106-preview,"D) .5, 0.44, 0.3",no_model_correct
mmlu-medical-genetics.val.94,meta/llama-2-70b-chat,D) meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.298,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.60,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.4368,claude-v2,claude-v2,zero-one-ai/Yi-34B-Chat
hellaswag.val.742,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.62,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-virology.val.77,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.2072,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-macroeconomics.val.378,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1022,gpt-4-1106-preview,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6258,claude-v1,C) You should also run the mashed potatoes through a strainer if they seem lumpy. [substeps] Avoid using mashed potatoes that have bits of the potato peel in them.,zero-one-ai/Yi-34B-Chat
mmlu-high-school-psychology.val.66,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
hellaswag.val.3292,claude-v1,A) claude-instant-v1,mistralai/mistral-7b-chat
grade-school-math.dev.4377,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
mmlu-professional-law.val.735,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5658,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.7557,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.102,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6108,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.4426,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.3043,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.704,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6244,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2021,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.2798,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.927,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.96,gpt-4-1106-preview,B) H ∨ ~R,claude-instant-v1
mmlu-human-aging.val.180,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.1955,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1614,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5958,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.1554,claude-v1,A),mistralai/mistral-7b-chat
hellaswag.val.128,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
consensus_summary.dev.105,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.6255,claude-v1,"B) Before you buy the car, it is owned by the dealership or the manufacturer. Once you purchase the vehicle, title needs to be transferred into your name.",zero-one-ai/Yi-34B-Chat
hellaswag.val.335,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-computer-security.val.58,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1258,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1226,claude-v1,C) Yes,mistralai/mistral-7b-chat
hellaswag.val.1535,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.590,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
grade-school-math.dev.6105,gpt-4-1106-preview,meta/llama-2-70b-chat,meta/llama-2-70b-chat
mmlu-management.val.93,claude-v2,claude-v2,mistralai/mistral-7b-chat
hellaswag.val.978,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.276,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.101,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.460,claude-v1,"D) Wrong, Wrong",mistralai/mixtral-8x7b-chat
grade-school-math.dev.3331,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Explanation: The problem involves basic arithmetic and understanding of weight conversion (from ounces to pounds). The model meta/llama-2-70b-chat",zero-one-ai/Yi-34B-Chat
mmlu-professional-medicine.val.137,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.1183,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.1326,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4090,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-human-aging.val.104,meta/llama-2-70b-chat,D,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.219,meta/llama-2-70b-chat,D) Anarchy is an inescapable feature of the international system.,mistralai/mixtral-8x7b-chat
hellaswag.val.9743,claude-v1,A) Begin by identifying the reason you don't have a job or why you don't make enough to pay child support : [substeps] Medical illness disability layoff imprisonment other reason,mistralai/mistral-7b-chat
mmlu-prehistory.val.75,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.290,mistralai/mistral-7b-chat,C) plasmolysis,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3889,claude-v1,"A) Ladybugs can be sold as small boxes, pots, or bowls.",no_model_correct
hellaswag.val.3173,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.35,WizardLM/WizardLM-13B-V1.2,"C) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
mmlu-clinical-knowledge.val.193,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2319,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.5933,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.6724,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.6764,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.391,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9660,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
abstract2title.test.100,WizardLM/WizardLM-13B-V1.2,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.636,WizardLM/WizardLM-13B-V1.2,"C) Wrong, Wrong",gpt-4-1106-preview
mbpp.dev.241,gpt-4-1106-preview,"gpt-4-1106-preview — This model has demonstrated high correctness scores and relatively low cost, indicating it is well-suited for generating code and text-based solutions, including writing a function to match words containing '",mistralai/mixtral-8x7b-chat
mmlu-human-sexuality.val.127,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.6672,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.873,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.4415,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
consensus_summary.dev.305,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.1429,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
winogrande.dev.454,claude-v1,B) Randy,mistralai/mistral-7b-chat
mmlu-professional-law.val.1469,WizardLM/WizardLM-13B-V1.2,A) Negligence and battery.,zero-one-ai/Yi-34B-Chat
mmlu-management.val.92,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4509,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.36,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.302,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
hellaswag.val.5413,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-clinical-knowledge.val.46,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.723,WizardLM/WizardLM-13B-V1.2,A) Greenware,mistralai/mistral-7b-chat
mmlu-college-biology.val.63,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.1509,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4033,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-physics.val.100,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-psychology.val.446,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
hellaswag.val.4102,claude-v1,A),mistralai/mistral-7b-chat
hellaswag.val.7289,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.9705,claude-v1,claude-v1,claude-instant-v1
mmlu-philosophy.val.289,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.1359,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.285,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4461,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-logical-fallacies.val.98,zero-one-ai/Yi-34B-Chat,D) common person appeal,mistralai/mixtral-8x7b-chat
arc-challenge.val.203,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.4,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.950,zero-one-ai/Yi-34B-Chat,"B) Yes, because the law burdens the woman's fundamental right to health care.",no_model_correct
winogrande.dev.172,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.769,claude-v1,"C) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.837,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9978,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
abstract2title.test.74,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-statistics.val.53,claude-v1,B) H0: p ≤ 0.60 and Ha: p > 0.60,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.597,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-machine-learning.val.103,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-instant-v1
mmlu-professional-law.val.1430,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-jurisprudence.val.33,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-prehistory.val.37,meta/llama-2-70b-chat,D) diffusionism,mistralai/mixtral-8x7b-chat
mmlu-high-school-world-history.val.146,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.4260,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4167,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.2125,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-philosophy.val.105,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-microeconomics.val.4,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.36,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
arc-challenge.test.289,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-security-studies.val.8,claude-v1,C) All of these options,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.100,meta/llama-2-70b-chat,D) All of these options,WizardLM/WizardLM-13B-V1.2
mmlu-virology.val.13,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1069,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
grade-school-math.dev.5990,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.6941,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.714,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.142,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6826,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-marketing.val.47,meta/llama-2-70b-chat,B) Value,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2795,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.79,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-logical-fallacies.val.105,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7041,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-sociology.val.134,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.3902,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v1
hellaswag.val.9991,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.641,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-jurisprudence.val.54,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
hellaswag.val.9361,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.1394,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.6078,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-european-history.val.2,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-psychology.val.456,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.1049,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.8239,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,gpt-3.5-turbo-1106
mmlu-global-facts.val.38,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4324,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.105,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.611,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1010,claude-v1,C) meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.218,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.3579,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4543,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7054,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.184,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-v2
mmlu-high-school-chemistry.val.140,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.8898,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.584,claude-v1,"B) ""unethical because it violates the prohibition against “fee splitting.""""",no_model_correct
grade-school-math.dev.919,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

The prompt is a simple arithmetic problem involving addition and subtraction. The model meta/llama-2-70b-chat is a language model trained on a diverse",zero-one-ai/Yi-34B-Chat
mmlu-college-biology.val.50,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.756,claude-v1,"C) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.222,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1234,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.143,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,gpt-4-1106-preview
mmlu-professional-law.val.424,claude-v1,A) admissible as secondary evidence under the circumstances.,mistralai/mistral-7b-chat
mmlu-philosophy.val.290,meta/llama-2-70b-chat,D,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.17,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-microeconomics.val.218,claude-v1,A),mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.236,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.46,gpt-4-1106-preview,B) gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2592,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-professional-law.val.388,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1332,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.121,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2598,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,gpt-4-1106-preview
hellaswag.val.8132,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.9655,meta/code-llama-instruct-34b-chat,D) meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-econometrics.val.96,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-conceptual-physics.val.105,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
hellaswag.val.2437,claude-v1,claude-v1,no_model_correct
mmlu-college-mathematics.val.60,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6052,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-formal-logic.val.22,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-world-history.val.129,claude-v1,A) The fight for independence in South America,mistralai/mistral-7b-chat
grade-school-math.dev.3189,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-professional-law.val.1056,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
arc-challenge.test.701,meta/code-llama-instruct-34b-chat,C) meters,WizardLM/WizardLM-13B-V1.2
mmlu-security-studies.val.218,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.814,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,claude-instant-v1
arc-challenge.test.826,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-philosophy.val.91,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
arc-challenge.test.854,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6543,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2112,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
arc-challenge.test.767,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2919,mistralai/mistral-7b-chat,"A) (The prompt describes a scene where Hannah is interacting with a hula hoop, which aligns with option A) showing then sets the toy part of the hula hoop towards the camera and a person comes on the",claude-instant-v1
mmlu-moral-scenarios.val.650,claude-v1,"C) Not wrong, Wrong",gpt-3.5-turbo-1106
mmlu-professional-law.val.267,claude-v1,"C) Yes, because they were trade fixtures.",WizardLM/WizardLM-13B-V1.2
mmlu-professional-accounting.val.239,gpt-4-1106-preview,C) Increase Increase,gpt-4-1106-preview
mmlu-professional-law.val.1124,meta/llama-2-70b-chat,D) an installment contract.,gpt-3.5-turbo-1106
grade-school-math.dev.2573,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3100,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-psychology.val.538,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1567,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.1638,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9236,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-abstract-algebra.val.46,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
arc-challenge.test.534,meta/llama-2-70b-chat,B) universal systems model,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1703,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mbpp.dev.68,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.557,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1092,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-professional-law.val.1129,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mbpp.dev.60,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
grade-school-math.dev.179,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
winogrande.dev.1155,claude-v1,A) Benjamin,mistralai/mistral-7b-chat
mmlu-moral-disputes.val.187,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.266,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-professional-medicine.val.133,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.2065,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-4-1106-preview
grade-school-math.dev.1915,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.1401,claude-v1,claude-v1,mistralai/mistral-7b-chat
arc-challenge.test.281,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
winogrande.dev.1151,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3420,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
winogrande.dev.479,claude-v1,B) Instrument,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3134,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.309,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9164,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1328,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.1303,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1207,claude-v1,claude-v1,no_model_correct
winogrande.dev.533,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8992,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.672,claude-v1,"C) Wrong, Wrong",WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.78,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,claude-instant-v1
mmlu-prehistory.val.22,gpt-4-1106-preview,B) all of the above,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.187,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,claude-v1
mmlu-professional-psychology.val.410,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3476,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-prehistory.val.179,claude-v1,C) megafauna,mistralai/mistral-7b-chat
mmlu-business-ethics.val.64,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.211,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-mathematics.val.34,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,gpt-3.5-turbo-1106
mmlu-high-school-us-history.val.133,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
arc-challenge.test.687,gpt-4-1106-preview,D) evaporation,mistralai/mistral-7b-chat
mmlu-machine-learning.val.63,claude-v1,B) All the examples that have a non-zero weight αk in a SVM.,claude-instant-v1
winogrande.dev.825,claude-v1,A) monogram,mistralai/mistral-7b-chat
mmlu-professional-law.val.594,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.154,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-government-and-politics.val.140,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6902,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.372,claude-v1,C) The ex post facto clause,mistralai/mixtral-8x7b-chat
mmlu-professional-medicine.val.90,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mbpp.dev.276,gpt-4-1106-preview,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.4538,claude-v1,B) WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-sociology.val.120,meta/llama-2-70b-chat,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
consensus_summary.dev.266,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
hellaswag.val.6634,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.4809,claude-v1,"A) title: Read about the denomination that a particular congregation belongs to. [step] Some are evangelical (such as the evangelical lutheran church in america), and others are more conservative (such as the",mistralai/mistral-7b-chat
bias_detection.dev.191,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence ""at some point Ukraine will likely seize the initiative"" is an expression of a future event that is not certain but speculated upon. It",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1159,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.391,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,no_model_correct
mmlu-professional-law.val.798,mistralai/mixtral-8x7b-chat,C) Equitable servitude(s),WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4979,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.417,claude-v1,"B) Yes, because it is prior testimony of an unavailable declarant.",WizardLM/WizardLM-13B-V1.2
mmlu-sociology.val.85,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.185,claude-v1,claude-v1,gpt-4-1106-preview
grade-school-math.dev.3263,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9260,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1076,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.489,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-computer-security.val.48,WizardLM/WizardLM-13B-V1.2,B) WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-european-history.val.151,claude-v1,A) J.P. Taylor,mistralai/mistral-7b-chat
hellaswag.val.3327,claude-v1,mistralai/mixtral-8x7b-chat,zero-one-ai/Yi-34B-Chat
arc-challenge.test.1012,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8506,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2904,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5860,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
hellaswag.val.7221,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-marketing.val.163,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.148,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.80,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3954,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.65,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4906,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2799,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-marketing.val.134,meta/code-llama-instruct-34b-chat,Porter's Five Forces model,mistralai/mixtral-8x7b-chat
hellaswag.val.9497,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.8171,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-nutrition.val.225,WizardLM/WizardLM-13B-V1.2,A) All of the above were among the causes.,mistralai/mistral-7b-chat
grade-school-math.dev.1805,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.5381,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1016,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.1363,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,claude-instant-v1
grade-school-math.dev.5413,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.8950,claude-v1,claude-v1,meta/llama-2-70b-chat
hellaswag.val.8835,claude-v1,"B) [step] If your diamante started off with "" home, "" you might choose two adjectives like "" safe "" and "" warm. "" these adjectives describe feelings associated with home.",claude-instant-v1
mmlu-prehistory.val.134,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5353,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
hellaswag.val.6666,claude-v1,claude-v1,meta/llama-2-70b-chat
mbpp.dev.63,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
grade-school-math.dev.3322,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4060,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.153,claude-v1,A) South American temperate plants are more similar to the tropical plants of South America than to the temperate plants of Europe.,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3275,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1767,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/llama-2-70b-chat
accounting_audit.dev.25,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.2325,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
winogrande.dev.1092,claude-v1,B) Erin,mistralai/mistral-7b-chat
mmlu-security-studies.val.113,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.538,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.4707,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.2271,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.15,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.720,claude-v1,"B) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
hellaswag.val.3092,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-high-school-statistics.val.104,mistralai/mixtral-8x7b-chat,B) A matched pairs t-test,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.130,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-psychology.val.276,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3818,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-international-law.val.27,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.6,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.307,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.254,claude-v1,B) Yes,mistralai/mistral-7b-chat
grade-school-math.dev.3124,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/llama-2-70b-chat
consensus_summary.dev.216,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.744,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.5577,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.9039,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2482,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
consensus_summary.dev.179,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,claude-v1
winogrande.dev.528,claude-v1,A) Laura,mistralai/mistral-7b-chat
grade-school-math.dev.4571,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8600,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.281,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.7893,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.2763,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/llama-2-70b-chat
grade-school-math.dev.6413,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
mmlu-us-foreign-policy.val.7,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-v1
grade-school-math.dev.5824,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
winogrande.dev.82,claude-v1,A) Brett,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.476,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
grade-school-math.dev.5041,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-high-school-us-history.val.28,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6754,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7190,claude-v1,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-nutrition.val.222,claude-v1,claude-v1,no_model_correct
mmlu-miscellaneous.val.70,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.225,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-psychology.val.234,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7707,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.6260,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4389,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
mmlu-elementary-mathematics.val.7,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-miscellaneous.val.742,mistralai/mixtral-8x7b-chat,D) electric guitar,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1170,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-moral-scenarios.val.760,claude-v1,"C) Not wrong, Wrong",WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2701,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1486,claude-v1,"A) Yes, because the boy was the true owner of the card and was entitled to the benefit of the bargain.",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.565,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.650,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6352,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.375,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.8001,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.7042,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.218,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-security-studies.val.6,claude-v2,B) Nationalization: state enterprises should be protected.,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9903,claude-v1,"B) [substeps] If it sounds too good to be true, it almost certainly is. If someone claims they have an inheritance from a long lost relative, a high-paying-do-nothing job, or unclaimed lottery",WizardLM/WizardLM-13B-V1.2
mtbench-math.dev.17,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
consensus_summary.dev.4,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2764,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-high-school-chemistry.val.120,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
winogrande.dev.569,claude-v1,B) Laura,mistralai/mistral-7b-chat
grade-school-math.dev.4207,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-college-physics.val.70,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.9251,claude-v1,"B) Even though the pain can be intense during the first few minutes, by avoiding any touching or rubbing, you may prevent the pain from lingering for days. [substeps] The chemical irritants from the plant can",claude-instant-v1
hellaswag.val.1324,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
arc-challenge.val.4,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.156,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.9051,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-elementary-mathematics.val.252,mistralai/mixtral-8x7b-chat,C) 4(x – 22),WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1118,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.2979,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6403,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
grade-school-math.dev.4083,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
mmlu-high-school-mathematics.val.25,claude-v1,claude-v1,gpt-4-1106-preview
mmlu-professional-law.val.373,claude-v1,claude-v1,no_model_correct
mbpp.dev.329,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,meta/code-llama-instruct-34b-chat
mtbench.dev.11,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.74,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-professional-law.val.135,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-nutrition.val.6,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.536,gpt-4-1106-preview,D) recover against either the husband and wife or the carpeting company.,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.293,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.7036,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.8764,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.7434,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6211,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-european-history.val.5,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.5883,claude-v1,B) meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-high-school-statistics.val.156,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
arc-challenge.val.147,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.48,WizardLM/WizardLM-13B-V1.2,A) All of the above,gpt-3.5-turbo-1106
mmlu-jurisprudence.val.72,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.263,mistralai/mixtral-8x7b-chat,mistralai/mixtral-8x7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6188,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-law.val.463,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.5044,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.1935,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6199,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-human-sexuality.val.52,meta/llama-2-70b-chat,D,mistralai/mixtral-8x7b-chat
hellaswag.val.1188,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-microeconomics.val.63,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-prehistory.val.309,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7184,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-business-ethics.val.6,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.790,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
winogrande.dev.14,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.4973,claude-v1,claude-v1,mistralai/mistral-7b-chat
arc-challenge.val.286,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.val.229,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.5617,claude-v1,claude-v1,gpt-3.5-turbo-1106
grade-school-math.dev.2309,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.2550,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-marketing.val.6,meta/code-llama-instruct-34b-chat,B) Gatekeepers,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5231,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-microeconomics.val.173,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1081,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.923,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2275,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1847,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3933,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.4666,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.75,meta/code-llama-instruct-34b-chat,D) check to see which diagram shows a nucleus,WizardLM/WizardLM-13B-V1.2
mbpp.dev.259,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
hellaswag.val.8816,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.10,gpt-4-1106-preview,B) claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.863,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.3733,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.523,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
arc-challenge.val.37,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.7254,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.4043,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
hellaswag.val.9382,claude-v1,A) Men who don't want to compromise their fertility may increase their chances by switching to boxers. [substeps] The research shows that boxers can positively affect sperm quality.,mistralai/mistral-7b-chat
hellaswag.val.7332,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.8211,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-psychology.val.212,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.216,gpt-4-1106-preview,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.1203,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-moral-disputes.val.252,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
hellaswag.val.3480,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-college-biology.val.8,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.972,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-chemistry.val.59,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.3228,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-machine-learning.val.50,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-medicine.val.154,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.66,claude-v1,"D) Wrong, Not wrong",no_model_correct
mmlu-high-school-government-and-politics.val.59,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.1113,gpt-4-1106-preview,gpt-4-1106-preview,claude-v1
grade-school-math.dev.4814,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-clinical-knowledge.val.65,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.653,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mbpp.dev.122,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6276,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.5657,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.3013,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.496,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.777,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.1740,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,meta/llama-2-70b-chat
hellaswag.val.6582,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
hellaswag.val.2211,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,no_model_correct
hellaswag.val.2767,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,no_model_correct
hellaswag.val.4667,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-world-history.val.105,meta/llama-2-70b-chat,C) The ways of Heaven are not invariable: on the good-doer it sends down all blessings.,mistralai/mistral-7b-chat
mmlu-security-studies.val.133,zero-one-ai/Yi-34B-Chat,D) A decrease in the arms trade,WizardLM/WizardLM-13B-V1.2
hellaswag.val.3392,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-astronomy.val.82,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.9435,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
hellaswag.val.7064,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.3232,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,gpt-3.5-turbo-1106
mmlu-high-school-geography.val.81,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.4450,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.798,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-elementary-mathematics.val.222,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1316,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.1491,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-medical-genetics.val.61,claude-v1,A) Monozygotic twins,mistralai/mistral-7b-chat
hellaswag.val.8426,claude-v1,claude-v1,claude-instant-v1
mmlu-high-school-chemistry.val.54,claude-v1,claude-v1,no_model_correct
mmlu-prehistory.val.90,claude-v1,C) catastrophist,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2688,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5533,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5776,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.6632,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.86,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-professional-law.val.481,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
grade-school-math.dev.5160,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-clinical-knowledge.val.49,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1842,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-physics.val.67,claude-v1,C) Increased voltage and decreased resistance,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5193,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8699,claude-v1,claude-v1,no_model_correct
hellaswag.val.5211,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.1009,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-accounting.val.59,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.153,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.144,meta/code-llama-instruct-34b-chat,D) includes both measured (observed) attributes and latent traits.,WizardLM/WizardLM-13B-V1.2
abstract2title.test.104,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.8980,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-public-relations.val.85,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-medical-genetics.val.52,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-government-and-politics.val.11,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
bias_detection.dev.284,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence provided is a direct quote from a person, which is a clear indication that it is a quote. It does not contain any unverified information",claude-v1
bias_detection.dev.161,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence provided is an opinion, as it expresses a viewpoint or judgement about the potential actions of Ukrainian leaders without presenting verifiable facts",WizardLM/WizardLM-13B-V1.2
hellaswag.val.10010,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.4245,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
hellaswag.val.2557,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-psychology.val.186,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.6509,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-jurisprudence.val.107,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-european-history.val.11,gpt-4-1106-preview,gpt-4-1106-preview,claude-v2
hellaswag.val.7994,claude-v1,claude-v1,gpt-3.5-turbo-1106
mbpp.dev.384,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1272,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
mmlu-international-law.val.12,claude-v1,B) claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.403,meta/llama-2-70b-chat,D,mistralai/mixtral-8x7b-chat
hellaswag.val.489,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.234,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.4466,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-macroeconomics.val.316,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
bias_detection.dev.27,meta/code-llama-instruct-34b-chat,"meta/code-llama-instruct-34b-chat

Reasoning: The sentence provided is a statement of fact regarding a specific law, the 2005 Protection of Lawful Commerce in Arms",no_model_correct
mmlu-moral-scenarios.val.391,meta/llama-2-70b-chat,"D) Wrong, Not wrong",zero-one-ai/Yi-34B-Chat
mmlu-professional-psychology.val.123,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.390,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.6830,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-us-foreign-policy.val.62,WizardLM/WizardLM-13B-V1.2,D) WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
winogrande.dev.95,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.3870,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.870,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-clinical-knowledge.val.8,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
mmlu-high-school-geography.val.98,meta/llama-2-70b-chat,A) Origin point,mistralai/mistral-7b-chat
bias_detection.dev.140,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The sentence provided is an expression of a viewpoint or intention (""Proudman hopes"") and an assertion about current events or opinions (""decriminalization on the",WizardLM/WizardLM-13B-V1.2
hellaswag.val.9123,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.24,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-high-school-us-history.val.54,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.551,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-formal-logic.val.61,meta/llama-2-70b-chat,C) gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-management.val.48,claude-v1,B) Routine and non-complex,WizardLM/WizardLM-13B-V1.2
abstract2title.test.133,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.857,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-logical-fallacies.val.88,meta/llama-2-70b-chat,D) irrelevant conclusion,no_model_correct
grade-school-math.dev.5394,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-us-history.val.26,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
arc-challenge.test.698,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.73,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-electrical-engineering.val.105,meta/llama-2-70b-chat,meta/llama-2-70b-chat,no_model_correct
mmlu-professional-law.val.1446,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.4297,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-high-school-macroeconomics.val.138,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-human-aging.val.179,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.371,WizardLM/WizardLM-13B-V1.2,"D) Wrong, Not wrong",gpt-4-1106-preview
grade-school-math.dev.155,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-high-school-physics.val.132,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.164,mistralai/mixtral-8x7b-chat,D) Submit an affidavit from the patient's expert radiologist with findings that contradict the report of the hospital's radiologist.,WizardLM/WizardLM-13B-V1.2
bias_detection.dev.209,meta/code-llama-instruct-34b-chat,"meta/code-llama-instruct-34b-chat

Reasoning: The sentence provided is a statement of fact, reporting an action taken by Moscow without any personal opinion, interpretation, or sensationalism. It is",no_model_correct
mmlu-professional-law.val.1061,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-college-mathematics.val.52,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.444,claude-v1,"C) Wrong, Not wrong",WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.105,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.923,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5486,gpt-4-1106-preview,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.8591,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.2128,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3783,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.2924,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mtbench.dev.37,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
mmlu-professional-law.val.515,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-jurisprudence.val.95,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2467,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.446,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1087,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-professional-medicine.val.104,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5064,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
hellaswag.val.4387,claude-v1,A) WizardLM/WizardLM-13B-V1.2,zero-one-ai/Yi-34B-Chat
mmlu-high-school-mathematics.val.46,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-4-1106-preview
arc-challenge.test.598,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.4724,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7164,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Explanation: The prompt requires a simple calculation based on the given information about the English alphabet, which consists of 26 letters with 5 vowels and 2",mistralai/mistral-7b-chat
grade-school-math.dev.1868,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-high-school-european-history.val.13,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,no_model_correct
mmlu-computer-security.val.50,WizardLM/WizardLM-13B-V1.2,"C) C, C++",mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1377,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.3481,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-business-ethics.val.62,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.8999,claude-v1,claude-v1,no_model_correct
arc-challenge.val.48,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-professional-medicine.val.161,WizardLM/WizardLM-13B-V1.2,C) Crossover,mistralai/mistral-7b-chat
mmlu-college-biology.val.97,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.7010,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
abstract2title.test.28,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.214,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.442,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3284,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
mmlu-moral-scenarios.val.810,claude-v1,"B) Not wrong, Wrong",WizardLM/WizardLM-13B-V1.2
hellaswag.val.1696,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.6477,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-statistics.val.50,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.7806,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.1218,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.6534,claude-v1,B) claude-v2,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.465,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
hellaswag.val.4161,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-college-biology.val.40,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.2026,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.1067,claude-v1,"A) denied, because double jeopardy rights do not attach unless there has been an acquittal or conviction.",no_model_correct
mmlu-miscellaneous.val.131,meta/llama-2-70b-chat,B) 50,mistralai/mixtral-8x7b-chat
hellaswag.val.8944,claude-v1,"B) This is a good choice for heavy eye makeup--just make sure you shake the bottle thoroughly before use, as the formula tends to separate. [substeps] If you use waterproof mascara and liner or very",zero-one-ai/Yi-34B-Chat
hellaswag.val.3283,claude-v1,claude-v1,meta/llama-2-70b-chat
mmlu-professional-law.val.1521,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2789,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.5947,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-elementary-mathematics.val.298,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4366,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-international-law.val.92,meta/llama-2-70b-chat,D,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5668,claude-v1,A) claude-instant-v1,mistralai/mistral-7b-chat
mmlu-anatomy.val.127,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.408,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-anatomy.val.57,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-electrical-engineering.val.23,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.156,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.807,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.265,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,gpt-4-1106-preview
mmlu-high-school-macroeconomics.val.285,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.1916,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-mathematics.val.133,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
mmlu-international-law.val.81,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-professional-law.val.1130,WizardLM/WizardLM-13B-V1.2,"A) No, the statute violates the First Amendment right to publish protected commercial speech.",mistralai/mistral-7b-chat
mmlu-machine-learning.val.41,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3784,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.3353,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
grade-school-math.dev.5036,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.5183,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.4728,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-abstract-algebra.val.50,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-nutrition.val.288,meta/llama-2-70b-chat,D) Chylomicrons,mistralai/mixtral-8x7b-chat
grade-school-math.dev.4811,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mbpp.dev.43,WizardLM/WizardLM-13B-V1.2,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.252,WizardLM/WizardLM-13B-V1.2,"A) Wrong, Not wrong",zero-one-ai/Yi-34B-Chat
accounting_audit.dev.5,WizardLM/WizardLM-13B-V1.2,A,zero-one-ai/Yi-34B-Chat
hellaswag.val.1952,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,claude-v1
grade-school-math.dev.5514,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
hellaswag.val.4792,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-high-school-european-history.val.65,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-mathematics.val.140,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
arc-challenge.test.367,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-miscellaneous.val.384,gpt-4-1106-preview,B) Sensation,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.430,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-marketing.val.180,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-miscellaneous.val.61,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3744,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
grade-school-math.dev.2702,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.3386,gpt-4-1106-preview,gpt-4-1106-preview,gpt-3.5-turbo-1106
mmlu-moral-scenarios.val.112,WizardLM/WizardLM-13B-V1.2,"B) Wrong, Wrong",WizardLM/WizardLM-13B-V1.2
hellaswag.val.9644,claude-v1,claude-v1,mistralai/mistral-7b-chat
winogrande.dev.513,claude-v1,A) television,mistralai/mistral-7b-chat
mmlu-professional-law.val.1338,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-abstract-algebra.val.58,gpt-4-1106-preview,gpt-4-1106-preview,no_model_correct
mmlu-professional-psychology.val.437,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.790,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
arc-challenge.test.725,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
arc-challenge.test.1081,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,mistralai/mistral-7b-chat
grade-school-math.dev.2999,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2883,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.654,zero-one-ai/Yi-34B-Chat,zero-one-ai/Yi-34B-Chat,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-world-history.val.83,meta/llama-2-70b-chat,meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-world-religions.val.84,meta/llama-2-70b-chat,B) Correct knowledge,no_model_correct
consensus_summary.dev.290,meta/llama-2-70b-chat,N-A,WizardLM/WizardLM-13B-V1.2
mmlu-conceptual-physics.val.83,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
hellaswag.val.543,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
consensus_summary.dev.8,gpt-4-1106-preview,gpt-4-1106-preview,meta/llama-2-70b-chat
grade-school-math.dev.3865,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.7191,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-psychology.val.301,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-medicine.val.236,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
arc-challenge.test.2,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.5832,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
hellaswag.val.4965,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.2215,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.1244,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.3376,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
mmlu-miscellaneous.val.660,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.6695,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.845,claude-v1,"B) Wrong, Not wrong",mistralai/mixtral-8x7b-chat
hellaswag.val.5829,claude-v1,claude-v1,gpt-3.5-turbo-1106
mmlu-miscellaneous.val.493,WizardLM/WizardLM-13B-V1.2,B) hygrometer,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.63,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-miscellaneous.val.35,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
winogrande.dev.953,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.6584,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
hellaswag.val.1937,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8977,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-philosophy.val.189,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.6160,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.7074,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-global-facts.val.77,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7917,claude-v1,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-biology.val.289,WizardLM/WizardLM-13B-V1.2,A) WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-international-law.val.94,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
winogrande.dev.1014,claude-v1,A) Rachel,mistralai/mistral-7b-chat
hellaswag.val.6587,claude-v1,claude-v1,claude-instant-v1
hellaswag.val.2461,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,meta/llama-2-70b-chat
grade-school-math.dev.6641,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.1799,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-high-school-computer-science.val.54,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
grade-school-math.dev.3174,meta/llama-2-70b-chat,meta/llama-2-70b-chat,claude-instant-v1
mmlu-high-school-microeconomics.val.59,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,mistralai/mistral-7b-chat
grade-school-math.dev.5984,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.592,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-moral-disputes.val.144,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.2560,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-macroeconomics.val.144,WizardLM/WizardLM-13B-V1.2,A) The consumer price index,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3455,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.5557,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
consensus_summary.dev.213,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
grade-school-math.dev.6989,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-professional-law.val.250,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-clinical-knowledge.val.104,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
grade-school-math.dev.5450,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2797,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.2760,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
grade-school-math.dev.4473,gpt-4-1106-preview,gpt-4-1106-preview,gpt-4-1106-preview
hellaswag.val.5949,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
grade-school-math.dev.188,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-biology.val.252,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.8592,claude-v1,claude-v1,zero-one-ai/Yi-34B-Chat
mmlu-college-physics.val.94,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
grade-school-math.dev.2318,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-global-facts.val.99,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.9608,claude-v1,"A) [substeps] Use wire or a head pin depending on how you want your nose ring to look. For example, do you want your hoop to be thick (head pin) or thin (wire), gold or silver.",mistralai/mistral-7b-chat
hellaswag.val.886,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,claude-instant-v1
grade-school-math.dev.617,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
grade-school-math.dev.1245,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
grade-school-math.dev.136,meta/llama-2-70b-chat,meta/llama-2-70b-chat,meta/code-llama-instruct-34b-chat
mmlu-college-mathematics.val.50,gpt-4-1106-preview,gpt-4-1106-preview,claude-instant-v1
arc-challenge.test.506,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
arc-challenge.test.816,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.156,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.0,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-european-history.val.163,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
grade-school-math.dev.3702,gpt-4-1106-preview,gpt-4-1106-preview,zero-one-ai/Yi-34B-Chat
hellaswag.val.3781,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mtbench-reference.dev.2,meta/llama-2-70b-chat,meta/llama-2-70b-chat,gpt-3.5-turbo-1106
mmlu-high-school-macroeconomics.val.332,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.5627,claude-v1,claude-v1,mistralai/mistral-7b-chat
grade-school-math.dev.3848,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.5919,claude-v1,claude-v1,claude-instant-v1
grade-school-math.dev.514,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-moral-disputes.val.209,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
hellaswag.val.7791,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
mmlu-human-sexuality.val.26,WizardLM/WizardLM-13B-V1.2,A) corpus luteum,mistralai/mistral-7b-chat
mmlu-nutrition.val.22,WizardLM/WizardLM-13B-V1.2,A) Both of the options given are correct.,mistralai/mistral-7b-chat
hellaswag.val.4039,claude-v1,claude-v1,claude-instant-v1
arc-challenge.test.709,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
hellaswag.val.2905,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat
mmlu-moral-scenarios.val.328,WizardLM/WizardLM-13B-V1.2,"D) Wrong, Wrong",zero-one-ai/Yi-34B-Chat
hellaswag.val.8690,meta/code-llama-instruct-34b-chat,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-jurisprudence.val.44,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
hellaswag.val.7593,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.119,claude-v1,C) The doctrine of worthier title,claude-instant-v1
bias_detection.dev.77,meta/llama-2-70b-chat,"meta/llama-2-70b-chat

Reasoning: The given sentence includes a direct quote from a person, which is a clear indication that this is a quote. The quote, ""I think it's",mistralai/mixtral-8x7b-chat
arc-challenge.test.635,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.210,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
hellaswag.val.3963,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
hellaswag.val.2713,claude-v1,claude-v1,mistralai/mistral-7b-chat
mmlu-high-school-macroeconomics.val.35,meta/code-llama-instruct-34b-chat,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mbpp.dev.298,gpt-4-1106-preview,gpt-4-1106-preview,meta/code-llama-instruct-34b-chat
grade-school-math.dev.3536,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mixtral-8x7b-chat
mmlu-college-medicine.val.168,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-professional-law.val.638,claude-v1,claude-v1,mistralai/mixtral-8x7b-chat
hellaswag.val.5922,claude-v1,meta/code-llama-instruct-34b-chat,zero-one-ai/Yi-34B-Chat
mmlu-nutrition.val.220,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
mmlu-human-sexuality.val.33,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
winogrande.dev.129,claude-v1,claude-v1,WizardLM/WizardLM-13B-V1.2
mmlu-prehistory.val.122,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mistral-7b-chat
mmlu-high-school-physics.val.103,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
mmlu-nutrition.val.156,WizardLM/WizardLM-13B-V1.2,WizardLM/WizardLM-13B-V1.2,mistralai/mixtral-8x7b-chat
mmlu-moral-scenarios.val.285,claude-v1,"B) Not wrong, Wrong",zero-one-ai/Yi-34B-Chat
winogrande.dev.361,mistralai/mistral-7b-chat,mistralai/mistral-7b-chat,mistralai/mixtral-8x7b-chat
mmlu-high-school-mathematics.val.229,claude-v1,claude-v1,no_model_correct
grade-school-math.dev.7065,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mistral-7b-chat
mmlu-elementary-mathematics.val.218,meta/llama-2-70b-chat,meta/llama-2-70b-chat,mistralai/mixtral-8x7b-chat
winogrande.dev.1012,claude-v1,claude-v1,mistralai/mistral-7b-chat
hellaswag.val.8217,claude-v1,B) meta/llama-2-70b-chat,zero-one-ai/Yi-34B-Chat
mmlu-professional-law.val.209,gpt-4-1106-preview,gpt-4-1106-preview,WizardLM/WizardLM-13B-V1.2
mmlu-high-school-mathematics.val.142,WizardLM/WizardLM-13B-V1.2,A),mistralai/mistral-7b-chat
grade-school-math.dev.180,gpt-4-1106-preview,gpt-4-1106-preview,mistralai/mistral-7b-chat
mmlu-logical-fallacies.val.100,meta/llama-2-70b-chat,B) Prejudicial Language,mistralai/mistral-7b-chat
hellaswag.val.178,meta/llama-2-70b-chat,meta/llama-2-70b-chat,WizardLM/WizardLM-13B-V1.2
