sample_id,phi_prediction,phi_correctness,phi_cost,mistralai/mistral-7b-chat_correctness,mistralai/mistral-7b-chat_cost,WizardLM/WizardLM-13B-V1.2_correctness,WizardLM/WizardLM-13B-V1.2_cost,mistralai/mixtral-8x7b-chat_correctness,mistralai/mixtral-8x7b-chat_cost,meta/code-llama-instruct-34b-chat_correctness,meta/code-llama-instruct-34b-chat_cost,gpt-4-1106-preview_correctness,gpt-4-1106-preview_cost
mmlu-professional-law.val.1247,WizardLM/WizardLM-13B-V1.2,1.0,0.0001766999999999,0.0,0.0001178,1.0,0.0001766999999999,0.0,0.0003533999999999,0.0,0.000457064,1.0,0.0059
mmlu-international-law.val.89,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.4617,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.5357,WizardLM/WizardLM-13B-V1.2,0.25,0.0001317,0.25,8.68e-05,0.25,0.0001317,0.25,0.0002526,0.5,0.00030652,0.5,0.00626
hellaswag.val.2731,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.9797,WizardLM/WizardLM-13B-V1.2,0.0,7.619999999999998e-05,0.0,5.1000000000000006e-05,0.0,7.619999999999998e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-professional-law.val.570,WizardLM/WizardLM-13B-V1.2,0.0,9.54e-05,0.0,6.36e-05,0.0,9.54e-05,0.0,0.0001908,0.0,0.000246768,1.0,0.00319
hellaswag.val.1836,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.2769,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,1.0,7.2168e-05,1.0,0.00097
mmlu-professional-law.val.485,WizardLM/WizardLM-13B-V1.2,0.0,5.55e-05,0.0,3.7000000000000005e-05,0.0,5.55e-05,0.0,0.000111,0.0,0.00014356,1.0,0.00186
hellaswag.val.2850,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-business-ethics.val.54,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
bias_detection.dev.265,mistralai/mixtral-8x7b-chat,0.0,0.0001817999999999,0.0,6.54e-05,0.0,0.0001085999999999,0.0,0.0001817999999999,0.0,0.000270048,0.0,0.01179
consensus_summary.dev.5,mistralai/mistral-7b-chat,0.75,8.740000000000001e-05,0.75,8.740000000000001e-05,0.75,0.0002274,0.75,0.0002136,0.75,0.000335232,0.75,0.00886
hellaswag.val.3051,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00099
hellaswag.val.5313,mistralai/mixtral-8x7b-chat,0.0,0.0001806,0.0,6.0200000000000006e-05,1.0,9.03e-05,0.0,0.0001806,0.0,0.000233576,1.0,0.00302
mmlu-miscellaneous.val.737,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.3702,meta/code-llama-instruct-34b-chat,0.25,0.000415936,0.25,0.0001055999999999,0.25,0.0001869,0.25,0.0003072,0.25,0.000415936,0.5,0.0102
hellaswag.val.6662,mistralai/mixtral-8x7b-chat,1.0,0.0001392,1.0,4.64e-05,1.0,6.96e-05,1.0,0.0001392,1.0,0.000180032,1.0,0.00233
grade-school-math.dev.5353,mistralai/mistral-7b-chat,0.25,8.78e-05,0.25,8.78e-05,0.25,0.0001311,0.25,0.0002286,0.75,0.000294104,0.75,0.00763
grade-school-math.dev.7313,mistralai/mistral-7b-chat,0.25,8.280000000000001e-05,0.25,8.280000000000001e-05,0.25,0.0001539,0.25,0.0002838,0.75,0.0002669439999999,0.75,0.00835
mmlu-high-school-biology.val.90,mistralai/mixtral-8x7b-chat,1.0,6.96e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-professional-law.val.73,WizardLM/WizardLM-13B-V1.2,0.0,5.76e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00193
mmlu-business-ethics.val.77,WizardLM/WizardLM-13B-V1.2,1.0,2.37e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.7889,mistralai/mixtral-8x7b-chat,0.0,0.0001404,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.715,mistralai/mistral-7b-chat,0.75,8.94e-05,0.75,8.94e-05,0.75,0.0001578,0.75,0.0002808,0.25,0.000284792,0.75,0.00757
mmlu-jurisprudence.val.67,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.2580,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.5091,WizardLM/WizardLM-13B-V1.2,0.5,0.0001844999999999,0.75,0.0001016,0.5,0.0001844999999999,0.25,0.0003012,0.25,0.000383344,0.75,0.01166
grade-school-math.dev.7398,mistralai/mistral-7b-chat,0.25,8.340000000000001e-05,0.25,8.340000000000001e-05,0.75,0.0001656,0.75,0.0002418,0.25,0.000312728,0.75,0.00753
hellaswag.val.8841,mistralai/mixtral-8x7b-chat,0.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.0027
mmlu-college-mathematics.val.52,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,0.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
mmlu-professional-law.val.1513,WizardLM/WizardLM-13B-V1.2,0.0,6.66e-05,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00223
hellaswag.val.6403,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.1515,mistralai/mistral-7b-chat,0.5,6.900000000000001e-05,0.5,6.900000000000001e-05,0.75,0.0001293,0.25,0.0002021999999999,0.75,0.000250648,0.75,0.00579
hellaswag.val.8810,mistralai/mixtral-8x7b-chat,0.0,0.0001662,1.0,5.5400000000000005e-05,1.0,8.31e-05,0.0,0.0001662,1.0,0.000214952,1.0,0.00281
mmlu-professional-law.val.1365,mistralai/mistral-7b-chat,1.0,4.380000000000001e-05,1.0,4.380000000000001e-05,0.0,6.57e-05,0.0,0.0001314,0.0,0.0001699439999999,0.0,0.0022
hellaswag.val.9743,mistralai/mistral-7b-chat,1.0,5.280000000000001e-05,1.0,5.280000000000001e-05,1.0,7.89e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00268
hellaswag.val.4227,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.5e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00255
grade-school-math.dev.3650,WizardLM/WizardLM-13B-V1.2,0.25,0.0001416,0.25,6.2e-05,0.25,0.0001416,0.5,0.0002694,0.5,0.000351528,0.75,0.0083
grade-school-math.dev.7183,WizardLM/WizardLM-13B-V1.2,0.25,0.0001353,0.25,9.44e-05,0.25,0.0001353,0.25,0.000282,0.25,0.000339888,0.75,0.00779
grade-school-math.dev.2573,mistralai/mixtral-8x7b-chat,0.75,0.0002676,0.25,0.0001122,0.75,0.0001566,0.75,0.0002676,0.25,0.000585104,0.75,0.00777
hellaswag.val.1662,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,0.0,0.00105
mmlu-miscellaneous.val.235,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.2161,WizardLM/WizardLM-13B-V1.2,0.25,0.0001842,0.25,8.16e-05,0.25,0.0001842,0.25,0.0002988,0.25,0.000394984,0.5,0.0106
hellaswag.val.5410,mistralai/mixtral-8x7b-chat,0.0,0.0001326,1.0,4.420000000000001e-05,1.0,6.599999999999999e-05,0.0,0.0001326,1.0,0.000171496,1.0,0.00222
hellaswag.val.551,mistralai/mixtral-8x7b-chat,1.0,7.86e-05,0.0,2.62e-05,0.0,3.9e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-high-school-geography.val.58,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.03e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-professional-law.val.1203,WizardLM/WizardLM-13B-V1.2,0.0,0.0001257,0.0,8.38e-05,0.0,0.0001257,0.0,0.0002514,0.0,0.000325144,1.0,0.0042
hellaswag.val.867,mistralai/mixtral-8x7b-chat,0.0,6.96e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
winogrande.dev.569,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
mmlu-professional-law.val.1091,WizardLM/WizardLM-13B-V1.2,0.0,0.0001269,1.0,8.46e-05,0.0,0.0001269,1.0,0.0002532,0.0,0.000328248,1.0,0.00427
mmlu-elementary-mathematics.val.144,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
winogrande.dev.43,mistralai/mixtral-8x7b-chat,0.0,3.6e-05,0.0,1.2e-05,1.0,1.8e-05,0.0,3.6e-05,0.0,4.656e-05,1.0,0.00064
mmlu-high-school-microeconomics.val.129,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
grade-school-math.dev.6486,WizardLM/WizardLM-13B-V1.2,0.25,0.0001314,0.75,8.44e-05,0.25,0.0001314,0.75,0.0002304,0.75,0.00036084,0.75,0.0095
mmlu-professional-law.val.185,mistralai/mistral-7b-chat,0.0,3.980000000000001e-05,0.0,3.980000000000001e-05,0.0,5.97e-05,0.0,0.0001193999999999,0.0,0.000154424,1.0,0.002
hellaswag.val.7802,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,0.0,0.00258
arc-challenge.test.635,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
hellaswag.val.6944,mistralai/mixtral-8x7b-chat,1.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,0.0,0.0027
hellaswag.val.2947,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
grade-school-math.dev.915,WizardLM/WizardLM-13B-V1.2,0.25,0.0001706999999999,0.25,6.620000000000001e-05,0.25,0.0001706999999999,0.25,0.000249,0.25,0.000311176,0.25,0.01329
grade-school-math.dev.5638,WizardLM/WizardLM-13B-V1.2,0.75,0.0001356,0.25,5.440000000000001e-05,0.75,0.0001356,0.75,0.0002663999999999,0.5,0.000292552,0.75,0.00724
grade-school-math.dev.3680,mistralai/mixtral-8x7b-chat,0.5,0.0002784,0.5,0.000102,0.25,0.0001977,0.5,0.0002784,0.75,0.00028324,0.75,0.00885
mmlu-human-aging.val.134,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.3806,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,0.0,0.00275
grade-school-math.dev.5827,WizardLM/WizardLM-13B-V1.2,0.25,0.0001668,0.75,6.98e-05,0.25,0.0001668,0.75,0.0002663999999999,0.75,0.000361616,0.5,0.0085799999999999
grade-school-math.dev.5807,mistralai/mistral-7b-chat,0.25,7.26e-05,0.25,7.26e-05,0.5,0.0001713,0.75,0.0002502,0.75,0.000357736,0.5,0.00909
grade-school-math.dev.1333,WizardLM/WizardLM-13B-V1.2,0.25,0.0001692,0.25,8.460000000000001e-05,0.25,0.0001692,0.75,0.0003455999999999,0.25,0.000388,0.5,0.00797
hellaswag.val.9260,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00233
mmlu-professional-law.val.598,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
winogrande.dev.171,mistralai/mixtral-8x7b-chat,0.0,3.4200000000000005e-05,0.0,1.14e-05,1.0,1.7100000000000002e-05,0.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00061
hellaswag.val.3234,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-miscellaneous.val.551,mistralai/mistral-7b-chat,1.0,1.44e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
grade-school-math.dev.5221,mistralai/mistral-7b-chat,0.25,8.340000000000001e-05,0.25,8.340000000000001e-05,0.75,0.0001368,0.25,0.0002352,0.75,0.000264616,0.75,0.0051199999999999
winogrande.dev.229,mistralai/mistral-7b-chat,0.0,8.999999999999999e-06,0.0,8.999999999999999e-06,1.0,1.35e-05,0.0,2.7e-05,0.0,3.4920000000000004e-05,1.0,0.00049
mmlu-high-school-macroeconomics.val.189,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,0.0,0.00147
hellaswag.val.5038,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.739999999999998e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
grade-school-math.dev.5894,WizardLM/WizardLM-13B-V1.2,0.25,0.0001662,0.25,9.44e-05,0.25,0.0001662,1.0,0.000204,0.25,0.000384896,0.75,0.01289
mmlu-formal-logic.val.96,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
hellaswag.val.3283,mistralai/mixtral-8x7b-chat,0.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.0027
grade-school-math.dev.4791,WizardLM/WizardLM-13B-V1.2,0.75,0.0001640999999999,0.75,7.38e-05,0.75,0.0001640999999999,0.75,0.0002778,0.5,0.000273152,0.75,0.00847
hellaswag.val.1801,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,1.0,6.5184e-05,1.0,0.00088
mmlu-professional-law.val.698,WizardLM/WizardLM-13B-V1.2,0.0,0.0001092,0.0,7.280000000000001e-05,0.0,0.0001092,0.0,0.0002184,0.0,0.000282464,1.0,0.00365
hellaswag.val.5145,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00235
hellaswag.val.3321,mistralai/mistral-7b-chat,1.0,5.660000000000001e-05,1.0,5.660000000000001e-05,1.0,8.49e-05,1.0,0.0001698,1.0,0.000219608,1.0,0.00287
hellaswag.val.6136,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.769999999999999e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
hellaswag.val.2065,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
arc-challenge.test.250,mistralai/mistral-7b-chat,1.0,1.3e-05,1.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
hellaswag.val.5815,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00257
mmlu-high-school-psychology.val.64,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-high-school-government-and-politics.val.59,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.4385,mistralai/mixtral-8x7b-chat,0.0,0.000327,0.75,0.0001216,0.25,0.0001647,0.0,0.000327,0.25,0.0004462,0.75,0.01077
grade-school-math.dev.2688,mistralai/mixtral-8x7b-chat,0.25,0.0003017999999999,0.25,0.0001154,0.75,0.0001532999999999,0.25,0.0003017999999999,0.5,0.000303416,0.75,0.00865
mmlu-high-school-world-history.val.198,mistralai/mixtral-8x7b-chat,1.0,0.0002082,0.0,6.939999999999999e-05,0.0,0.0001041,1.0,0.0002082,0.0,0.000269272,1.0,0.00348
grade-school-math.dev.3972,WizardLM/WizardLM-13B-V1.2,0.5,0.0001392,0.5,7.840000000000001e-05,0.5,0.0001392,0.5,0.0002766,0.25,0.000303416,0.5,0.00593
hellaswag.val.5922,WizardLM/WizardLM-13B-V1.2,0.0,7.08e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.0024
arc-challenge.test.472,mistralai/mixtral-8x7b-chat,1.0,3.3e-05,0.0,1.1e-05,1.0,1.65e-05,1.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00056
hellaswag.val.1654,mistralai/mixtral-8x7b-chat,1.0,7.62e-05,1.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,1.0,9.8552e-05,0.0,0.00131
grade-school-math.dev.2397,WizardLM/WizardLM-13B-V1.2,0.25,0.0001643999999999,0.75,6.82e-05,0.25,0.0001643999999999,0.5,0.0002166,0.5,0.000281688,0.75,0.01042
grade-school-math.dev.25,mistralai/mistral-7b-chat,0.75,9.06e-05,0.75,9.06e-05,0.25,0.0001482,0.5,0.0003426,0.25,0.000413608,0.75,0.00874
mmlu-high-school-mathematics.val.171,mistralai/mixtral-8x7b-chat,0.0,7.32e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
grade-school-math.dev.4915,mistralai/mistral-7b-chat,0.25,0.0001,0.25,0.0001,0.75,0.0001331999999999,0.75,0.0002544,0.25,0.000329024,0.75,0.00628
mmlu-miscellaneous.val.545,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,1.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
winogrande.dev.1064,mistralai/mixtral-8x7b-chat,1.0,2.7e-05,1.0,8.999999999999999e-06,1.0,1.35e-05,1.0,2.7e-05,1.0,3.4920000000000004e-05,0.0,0.00046
mmlu-college-chemistry.val.6,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.1740,WizardLM/WizardLM-13B-V1.2,0.0,3.12e-05,0.0,2.1e-05,0.0,3.12e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
mmlu-professional-law.val.1314,WizardLM/WizardLM-13B-V1.2,0.0,6.989999999999999e-05,1.0,4.660000000000001e-05,0.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
mmlu-philosophy.val.134,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
grade-school-math.dev.5890,WizardLM/WizardLM-13B-V1.2,0.25,0.0001409999999999,0.25,8.32e-05,0.25,0.0001409999999999,0.25,0.0002862,0.25,0.000335232,0.25,0.0112699999999999
hellaswag.val.1813,mistralai/mistral-7b-chat,1.0,1.92e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.4241,mistralai/mixtral-8x7b-chat,0.25,0.0003876,0.25,0.0001024,0.25,0.0002132999999999,0.25,0.0003876,0.25,0.000394984,0.75,0.01047
mmlu-high-school-european-history.val.14,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,0.0,0.000202536,1.0,0.00262
grade-school-math.dev.3587,mistralai/mistral-7b-chat,0.5,7.04e-05,0.5,7.04e-05,0.75,0.0001293,0.75,0.0002394,0.25,0.00031428,0.75,0.0086
hellaswag.val.501,mistralai/mistral-7b-chat,1.0,1.92e-05,1.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,1.0,7.4496e-05,1.0,0.001
mmlu-miscellaneous.val.355,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-college-computer-science.val.7,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00108
hellaswag.val.7848,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,0.0,0.00261
hellaswag.val.7409,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
hellaswag.val.3592,WizardLM/WizardLM-13B-V1.2,1.0,7.110000000000001e-05,1.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,1.0,0.000183912,1.0,0.00241
hellaswag.val.3009,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.2827,meta/code-llama-instruct-34b-chat,0.25,0.000247544,0.25,9.54e-05,0.25,0.0001086,0.25,0.0003072,0.25,0.000247544,0.75,0.0076
grade-school-math.dev.5004,mistralai/mixtral-8x7b-chat,0.75,0.0002034,0.5,7.1e-05,0.75,0.0001317,0.75,0.0002034,0.5,0.000311176,0.75,0.00613
grade-school-math.dev.6728,WizardLM/WizardLM-13B-V1.2,0.75,0.0001233,0.25,7e-05,0.75,0.0001233,0.75,0.0002267999999999,0.75,0.000260736,0.75,0.00592
mmlu-professional-law.val.409,mistralai/mistral-7b-chat,1.0,7.06e-05,1.0,7.06e-05,0.0,0.0001059,0.0,0.0002118,0.0,0.000273928,0.0,0.00354
grade-school-math.dev.2746,meta/code-llama-instruct-34b-chat,0.25,0.000397312,0.25,8.640000000000001e-05,0.25,0.0001425,0.5,0.0002544,0.25,0.000397312,0.75,0.0095
grade-school-math.dev.3184,meta/code-llama-instruct-34b-chat,0.75,0.000305744,0.75,8.5e-05,0.5,0.0001593,0.75,0.0002556,0.75,0.000305744,0.5,0.0098999999999999
hellaswag.val.2498,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,1.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-high-school-world-history.val.81,WizardLM/WizardLM-13B-V1.2,0.0,0.0001286999999999,0.0,8.58e-05,0.0,0.0001286999999999,1.0,0.0002573999999999,0.0,0.000332904,1.0,0.0043
mmlu-computer-security.val.46,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-high-school-mathematics.val.156,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,1.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,0.0,0.00121
mmlu-public-relations.val.103,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
hellaswag.val.10012,mistralai/mistral-7b-chat,1.0,5.84e-05,1.0,5.84e-05,1.0,8.73e-05,1.0,0.0001752,1.0,0.000226592,1.0,0.00296
mmlu-miscellaneous.val.461,WizardLM/WizardLM-13B-V1.2,1.0,2.31e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.4666,mistralai/mistral-7b-chat,0.0,4.2600000000000005e-05,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00217
mmlu-virology.val.8,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
grade-school-math.dev.5907,WizardLM/WizardLM-13B-V1.2,0.25,0.0001677,0.75,9.74e-05,0.25,0.0001677,0.25,0.0002982,0.75,0.000370152,0.75,0.0121999999999999
hellaswag.val.8409,mistralai/mixtral-8x7b-chat,0.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.19e-05,0.0,0.0001638,0.0,0.0002118479999999,0.0,0.00277
hellaswag.val.5798,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.319999999999999e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00245
mbpp.dev.134,mistralai/mixtral-8x7b-chat,0.0,0.0002538,0.0,0.0003504,0.0,0.0001619999999999,0.0,0.0002538,0.0,0.000288672,0.0,0.0135
hellaswag.val.2555,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-high-school-european-history.val.92,mistralai/mixtral-8x7b-chat,1.0,0.0001602,1.0,5.34e-05,1.0,8.01e-05,1.0,0.0001602,0.0,0.000207192,1.0,0.00268
mmlu-high-school-macroeconomics.val.266,WizardLM/WizardLM-13B-V1.2,0.0,2.94e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
hellaswag.val.1791,WizardLM/WizardLM-13B-V1.2,0.0,3.96e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,1.0,0.00133
grade-school-math.dev.4541,WizardLM/WizardLM-13B-V1.2,0.25,0.0001305,0.5,7.2e-05,0.25,0.0001305,0.25,0.0002208,0.75,0.000289448,0.5,0.00698
mmlu-professional-law.val.113,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
grade-school-math.dev.4857,mistralai/mixtral-8x7b-chat,0.25,0.0002789999999999,0.25,8.38e-05,0.25,0.0001373999999999,0.25,0.0002789999999999,0.25,0.000290224,0.75,0.00925
hellaswag.val.7301,mistralai/mixtral-8x7b-chat,0.0,0.0001494,1.0,4.980000000000001e-05,1.0,7.47e-05,0.0,0.0001494,1.0,0.0001932239999999,1.0,0.0025
hellaswag.val.5604,WizardLM/WizardLM-13B-V1.2,0.0,7.529999999999999e-05,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
mmlu-professional-law.val.1067,WizardLM/WizardLM-13B-V1.2,0.0,9.99e-05,0.0,6.659999999999999e-05,0.0,9.99e-05,0.0,0.0001998,0.0,0.0002584079999999,0.0,0.00334
mmlu-miscellaneous.val.185,mistralai/mixtral-8x7b-chat,1.0,8.879999999999999e-05,0.0,2.96e-05,1.0,4.44e-05,1.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
hellaswag.val.5790,mistralai/mistral-7b-chat,1.0,4.600000000000001e-05,1.0,4.600000000000001e-05,1.0,6.869999999999999e-05,1.0,0.000138,1.0,0.0001784799999999,1.0,0.00234
hellaswag.val.2697,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.06e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-elementary-mathematics.val.244,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.66e-05,0.0,8.6912e-05,1.0,0.00116
grade-school-math.dev.733,mistralai/mixtral-8x7b-chat,0.5,0.0002975999999999,0.75,7.240000000000001e-05,0.25,0.0001479,0.5,0.0002975999999999,0.25,0.000365496,0.75,0.01545
mmlu-moral-scenarios.val.493,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
mmlu-high-school-mathematics.val.229,mistralai/mixtral-8x7b-chat,0.0,7.32e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
mmlu-high-school-world-history.val.83,mistralai/mixtral-8x7b-chat,0.0,0.0003365999999999,0.0,0.0001122,0.0,0.0001682999999999,0.0,0.0003365999999999,0.0,0.000435336,0.0,0.00562
mmlu-professional-medicine.val.180,WizardLM/WizardLM-13B-V1.2,0.0,6.12e-05,1.0,4.080000000000001e-05,0.0,6.12e-05,1.0,0.0001224,0.0,0.000158304,1.0,0.00208
hellaswag.val.4332,WizardLM/WizardLM-13B-V1.2,0.0,8.099999999999999e-05,0.0,5.420000000000001e-05,0.0,8.099999999999999e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
mmlu-security-studies.val.9,WizardLM/WizardLM-13B-V1.2,0.0,7.08e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,1.0,0.0001416,0.0,0.000183136,1.0,0.00237
accounting_audit.dev.9,mistralai/mistral-7b-chat,0.0,3.68e-05,0.0,3.68e-05,0.0,4.14e-05,1.0,8.280000000000001e-05,0.0,0.000113296,1.0,0.0014
mmlu-professional-law.val.778,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-astronomy.val.74,mistralai/mixtral-8x7b-chat,0.0,5.46e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
grade-school-math.dev.6804,WizardLM/WizardLM-13B-V1.2,0.75,0.0001641,0.25,8.960000000000001e-05,0.75,0.0001641,0.25,0.0002676,0.25,0.000402744,0.75,0.0098
mmlu-nutrition.val.91,mistralai/mixtral-8x7b-chat,1.0,0.000102,0.0,3.4000000000000007e-05,0.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
winogrande.dev.377,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
mmlu-prehistory.val.90,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.2128,WizardLM/WizardLM-13B-V1.2,0.75,0.0001442999999999,0.25,0.0001032,0.75,0.0001442999999999,0.75,0.0002639999999999,0.75,0.000339112,0.75,0.00806
mbpp.dev.241,mistralai/mistral-7b-chat,0.0,2.48e-05,0.0,2.48e-05,0.0,7.469999999999999e-05,1.0,8.64e-05,0.0,6.2856e-05,1.0,0.0107
mmlu-college-computer-science.val.70,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
arc-challenge.test.54,mistralai/mistral-7b-chat,1.0,3.02e-05,1.0,3.02e-05,0.0,4.53e-05,1.0,9.06e-05,1.0,0.000117176,1.0,0.00152
mmlu-high-school-biology.val.138,mistralai/mistral-7b-chat,1.0,1.62e-05,1.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
grade-school-math.dev.5026,mistralai/mistral-7b-chat,0.75,7.82e-05,0.75,7.82e-05,0.75,0.0001311,0.75,0.0002333999999999,0.75,0.00029876,0.75,0.00684
mmlu-philosophy.val.119,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00076
hellaswag.val.697,mistralai/mixtral-8x7b-chat,0.0,8.58e-05,1.0,2.8600000000000004e-05,1.0,4.26e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
hellaswag.val.3480,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.74e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,0.0,0.00289
mmlu-professional-law.val.1010,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-professional-psychology.val.296,WizardLM/WizardLM-13B-V1.2,0.0,3.27e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-high-school-macroeconomics.val.138,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
winogrande.dev.1029,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00051
mmlu-moral-scenarios.val.105,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.00153
mmlu-professional-law.val.1440,WizardLM/WizardLM-13B-V1.2,0.0,7.02e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00235
mmlu-professional-accounting.val.110,WizardLM/WizardLM-13B-V1.2,1.0,3.27e-05,1.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
mmlu-college-computer-science.val.48,mistralai/mistral-7b-chat,0.0,4.1800000000000006e-05,0.0,4.1800000000000006e-05,0.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
grade-school-math.dev.1703,mistralai/mistral-7b-chat,0.25,6.840000000000001e-05,0.25,6.840000000000001e-05,0.5,0.0001491,0.25,0.0002154,0.25,0.000268496,0.75,0.00936
hellaswag.val.4855,WizardLM/WizardLM-13B-V1.2,1.0,7.62e-05,0.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
mmlu-professional-medicine.val.129,mistralai/mixtral-8x7b-chat,1.0,0.0001494,0.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
mmlu-moral-scenarios.val.212,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
mmlu-professional-psychology.val.298,mistralai/mistral-7b-chat,1.0,2.08e-05,1.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.9913,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
mmlu-international-law.val.34,mistralai/mixtral-8x7b-chat,1.0,8.04e-05,0.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-high-school-european-history.val.102,WizardLM/WizardLM-13B-V1.2,0.0,0.0001481999999999,0.0,9.88e-05,0.0,0.0001481999999999,0.0,0.0002963999999999,0.0,0.000383344,0.0,0.0049499999999999
mmlu-moral-scenarios.val.459,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-high-school-biology.val.122,mistralai/mixtral-8x7b-chat,1.0,8.46e-05,1.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-professional-law.val.1399,WizardLM/WizardLM-13B-V1.2,1.0,0.0001011,0.0,6.74e-05,1.0,0.0001011,0.0,0.0002022,0.0,0.000261512,1.0,0.00341
winogrande.dev.485,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.00058
mmlu-moral-scenarios.val.515,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-abstract-algebra.val.99,mistralai/mixtral-8x7b-chat,0.0,5.8200000000000005e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
grade-school-math.dev.3933,WizardLM/WizardLM-13B-V1.2,0.5,0.0001722,0.5,8.76e-05,0.5,0.0001722,0.5,0.0002634,0.5,0.000343768,0.75,0.00881
mmlu-jurisprudence.val.14,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.312,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.0011899999999999
mmlu-high-school-statistics.val.170,mistralai/mixtral-8x7b-chat,0.0,7.740000000000001e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.00133
mmlu-professional-law.val.1179,WizardLM/WizardLM-13B-V1.2,0.0,6.9e-05,0.0,4.600000000000001e-05,0.0,6.9e-05,0.0,0.000138,0.0,0.0001784799999999,0.0,0.00231
consensus_summary.dev.351,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.75,4.1e-05,1.0,0.000288,0.0,0.0001434,0.75,0.0001823599999999,0.75,0.00368
mmlu-college-physics.val.59,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
bias_detection.dev.110,mistralai/mistral-7b-chat,0.0,4.84e-05,0.0,4.84e-05,0.0,9.57e-05,0.0,0.0001734,0.0,0.000207968,0.0,0.00647
hellaswag.val.6042,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
mmlu-security-studies.val.87,mistralai/mixtral-8x7b-chat,1.0,0.0001476,0.0,4.920000000000001e-05,1.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.3903,mistralai/mistral-7b-chat,0.75,0.0001462,0.75,0.0001462,0.25,0.0001908,0.5,0.0003168,0.25,0.000374808,0.75,0.00991
grade-school-math.dev.6111,WizardLM/WizardLM-13B-V1.2,0.25,0.0001719,0.25,8.879999999999999e-05,0.25,0.0001719,0.75,0.000339,0.25,0.0004322319999999,0.75,0.00874
mmlu-professional-accounting.val.52,mistralai/mistral-7b-chat,1.0,2.46e-05,1.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-professional-psychology.val.461,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00108
mtbench.dev.36,mistralai/mistral-7b-chat,0.8,0.0001828,0.8,0.0001828,0.8,0.0002948999999999,0.9,0.0006377999999999,0.9,0.000696848,1.0,0.0373
winogrande.dev.646,mistralai/mixtral-8x7b-chat,0.0,3.06e-05,0.0,1.04e-05,1.0,1.56e-05,0.0,3.06e-05,0.0,4.0352e-05,1.0,0.00053
hellaswag.val.8571,mistralai/mixtral-8x7b-chat,1.0,0.0001728,0.0,5.76e-05,0.0,8.609999999999999e-05,1.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
hellaswag.val.2255,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00131
arc-challenge.test.534,WizardLM/WizardLM-13B-V1.2,1.0,5.43e-05,0.0,3.6200000000000006e-05,1.0,5.43e-05,1.0,0.0001086,0.0,0.0001404559999999,1.0,0.00182
hellaswag.val.678,mistralai/mixtral-8x7b-chat,1.0,7.86e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-jurisprudence.val.69,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-professional-psychology.val.570,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
consensus_summary.dev.43,mistralai/mistral-7b-chat,0.75,7.400000000000001e-05,0.75,7.400000000000001e-05,1.0,6.69e-05,1.0,0.000132,0.75,0.000234352,1.0,0.00229
hellaswag.val.1535,mistralai/mixtral-8x7b-chat,0.0,6.54e-05,1.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,1.0,8.4584e-05,0.0,0.0011
grade-school-math.dev.1949,mistralai/mistral-7b-chat,0.25,5.860000000000001e-05,0.25,5.860000000000001e-05,0.75,0.0001463999999999,0.25,0.000279,0.75,0.000311176,0.75,0.0077
hellaswag.val.8156,mistralai/mistral-7b-chat,0.0,4.420000000000001e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00225
bias_detection.dev.243,mistralai/mixtral-8x7b-chat,0.0,0.0001944,0.0,6.38e-05,0.0,0.0001166999999999,0.0,0.0001944,0.0,0.00028712,0.0,0.00963
mmlu-prehistory.val.58,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
mmlu-anatomy.val.32,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-prehistory.val.156,WizardLM/WizardLM-13B-V1.2,0.0,3.09e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
arc-challenge.test.1160,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,1.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-college-chemistry.val.80,mistralai/mixtral-8x7b-chat,0.0,4.6200000000000005e-05,0.0,1.54e-05,0.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,0.0,0.00078
hellaswag.val.2669,mistralai/mistral-7b-chat,1.0,3.520000000000001e-05,1.0,3.520000000000001e-05,1.0,5.25e-05,1.0,0.0001055999999999,0.0,0.000136576,1.0,0.00177
grade-school-math.dev.2371,WizardLM/WizardLM-13B-V1.2,0.25,0.0001626,0.25,0.0001194,0.25,0.0001626,0.25,0.0002352,0.25,0.000443872,0.25,0.00987
mmlu-professional-law.val.594,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,1.0,0.0001776,0.0,0.000229696,1.0,0.00297
mmlu-virology.val.58,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.2975,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.88e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
hellaswag.val.5368,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
hellaswag.val.5149,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,0.0,0.00238
hellaswag.val.4715,mistralai/mistral-7b-chat,0.0,4.4000000000000006e-05,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,0.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
winogrande.dev.1092,mistralai/mistral-7b-chat,1.0,1.2e-05,1.0,1.2e-05,0.0,1.77e-05,1.0,3.6e-05,0.0,4.5784e-05,0.0,0.00064
mmlu-astronomy.val.105,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-prehistory.val.316,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-miscellaneous.val.209,mistralai/mistral-7b-chat,1.0,2.64e-05,1.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
arc-challenge.val.113,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,1.0,5.354400000000001e-05,1.0,0.00073
grade-school-math.dev.6529,WizardLM/WizardLM-13B-V1.2,0.75,0.0001464,0.25,8.64e-05,0.75,0.0001464,0.75,0.0002562,0.75,0.0003298,0.75,0.0091399999999999
mmlu-college-physics.val.70,WizardLM/WizardLM-13B-V1.2,0.0,4.29e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
mmlu-miscellaneous.val.621,mistralai/mistral-7b-chat,1.0,1.28e-05,1.0,1.28e-05,1.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
grade-school-math.dev.2760,meta/code-llama-instruct-34b-chat,0.25,0.0002716,0.25,0.0005054,0.25,0.0001581,0.25,0.0002274,0.25,0.0002716,0.75,0.00874
arc-challenge.val.190,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,1.0,7.2944e-05,1.0,0.00095
hellaswag.val.6240,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,0.0,6.22e-05,0.0,9.3e-05,0.0,0.0001866,0.0,0.000241336,1.0,0.00315
mmlu-world-religions.val.4,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
grade-school-math.dev.1249,WizardLM/WizardLM-13B-V1.2,0.5,0.0002103,0.25,0.000103,0.5,0.0002103,0.25,0.0002982,0.25,0.000270048,0.75,0.00909
mmlu-high-school-geography.val.40,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
mmlu-moral-disputes.val.13,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
mmlu-professional-law.val.1121,mistralai/mistral-7b-chat,1.0,6.659999999999999e-05,1.0,6.659999999999999e-05,0.0,9.99e-05,0.0,0.0001998,0.0,0.0002584079999999,1.0,0.00334
mmlu-miscellaneous.val.594,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.4239,WizardLM/WizardLM-13B-V1.2,0.75,0.0001751999999999,0.25,9.5e-05,0.75,0.0001751999999999,0.25,0.0002868,0.25,0.000367824,0.75,0.00862
winogrande.dev.533,mistralai/mistral-7b-chat,0.0,1.16e-05,0.0,1.16e-05,1.0,1.7400000000000003e-05,0.0,3.4800000000000006e-05,0.0,4.500800000000001e-05,1.0,0.0005899999999999
hellaswag.val.7141,mistralai/mistral-7b-chat,0.0,5.580000000000001e-05,0.0,5.580000000000001e-05,0.0,8.34e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.00283
hellaswag.val.7755,mistralai/mixtral-8x7b-chat,0.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
bias_detection.dev.59,mistralai/mistral-7b-chat,0.0,6.64e-05,0.0,6.64e-05,0.0,0.0001319999999999,0.0,0.0002519999999999,0.0,0.000274704,0.0,0.0075899999999999
grade-school-math.dev.6332,mistralai/mixtral-8x7b-chat,0.75,0.0002573999999999,0.75,8.04e-05,0.25,0.0001458,0.75,0.0002573999999999,0.5,0.000336008,0.5,0.00819
mmlu-high-school-world-history.val.170,mistralai/mixtral-8x7b-chat,1.0,0.0002543999999999,1.0,8.48e-05,1.0,0.0001271999999999,1.0,0.0002543999999999,0.0,0.000329024,1.0,0.0042499999999999
mmlu-human-sexuality.val.63,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-high-school-microeconomics.val.104,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.6831,WizardLM/WizardLM-13B-V1.2,0.5,0.0001704,0.75,8.86e-05,0.5,0.0001704,0.5,0.0003144,0.25,0.000328248,0.5,0.00878
hellaswag.val.9491,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
grade-school-math.dev.5748,WizardLM/WizardLM-13B-V1.2,0.25,0.0001634999999999,0.25,0.0001022,0.25,0.0001634999999999,0.25,0.0003089999999999,0.25,0.000464824,0.75,0.0108
grade-school-math.dev.7238,mistralai/mistral-7b-chat,0.25,0.0001256,0.25,0.0001256,0.25,0.0002021999999999,0.25,0.0003101999999999,0.25,0.0003918799999999,0.25,0.0113
hellaswag.val.8893,WizardLM/WizardLM-13B-V1.2,0.0,8.46e-05,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00287
mmlu-moral-scenarios.val.557,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
mmlu-professional-law.val.818,mistralai/mixtral-8x7b-chat,1.0,0.0001818,0.0,6.06e-05,1.0,9.09e-05,1.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
mmlu-human-aging.val.138,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-professional-law.val.105,WizardLM/WizardLM-13B-V1.2,0.0,6.24e-05,0.0,4.160000000000001e-05,0.0,6.24e-05,0.0,0.0001248,0.0,0.0001614079999999,0.0,0.00209
grade-school-math.dev.3380,WizardLM/WizardLM-13B-V1.2,0.5,0.0001788,0.25,0.0001012,0.5,0.0001788,0.25,0.0002045999999999,0.75,0.00029876,0.75,0.00881
mmlu-jurisprudence.val.76,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-nutrition.val.292,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-philosophy.val.153,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.3520,WizardLM/WizardLM-13B-V1.2,0.25,0.0001685999999999,0.25,6.86e-05,0.25,0.0001685999999999,0.75,0.0003059999999999,0.25,0.000336008,0.75,0.01036
grade-school-math.dev.428,mistralai/mistral-7b-chat,0.25,9.28e-05,0.25,9.28e-05,0.25,0.0001496999999999,0.25,0.0002826,0.25,0.000327472,0.5,0.00983
mmlu-moral-scenarios.val.266,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00141
mmlu-conceptual-physics.val.209,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,1.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00108
hellaswag.val.8097,mistralai/mixtral-8x7b-chat,0.0,0.0001698,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00284
hellaswag.val.4408,mistralai/mixtral-8x7b-chat,0.0,0.0001368,1.0,4.56e-05,1.0,6.84e-05,0.0,0.0001368,1.0,0.000176928,1.0,0.00229
hellaswag.val.5188,mistralai/mixtral-8x7b-chat,0.0,0.0001332,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,1.0,0.00223
mmlu-professional-law.val.820,WizardLM/WizardLM-13B-V1.2,1.0,7.59e-05,1.0,5.06e-05,1.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-professional-law.val.1106,WizardLM/WizardLM-13B-V1.2,0.0,0.0001101,1.0,7.34e-05,0.0,0.0001101,1.0,0.0002202,0.0,0.000284792,0.0,0.00368
grade-school-math.dev.6004,mistralai/mistral-7b-chat,0.75,0.0001074,0.75,0.0001074,0.25,0.0001692,0.75,0.000231,0.5,0.000278584,0.5,0.00886
hellaswag.val.9961,WizardLM/WizardLM-13B-V1.2,0.0,6.239999999999999e-05,0.0,4.1800000000000006e-05,0.0,6.239999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
grade-school-math.dev.1253,WizardLM/WizardLM-13B-V1.2,0.25,0.0001836,1.0,7.26e-05,0.25,0.0001836,0.25,0.000267,0.25,0.000547856,0.75,0.01031
mmlu-college-medicine.val.142,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.5515,WizardLM/WizardLM-13B-V1.2,0.0,7.74e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,0.0,0.00262
mmlu-virology.val.3,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-college-physics.val.36,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-clinical-knowledge.val.156,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,0.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
mmlu-world-religions.val.83,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
grade-school-math.dev.2254,WizardLM/WizardLM-13B-V1.2,0.25,0.0001338,0.75,6.24e-05,0.25,0.0001338,0.75,0.000216,0.75,0.000256856,0.5,0.00588
mmlu-professional-law.val.57,mistralai/mistral-7b-chat,0.0,6.0200000000000006e-05,0.0,6.0200000000000006e-05,1.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
winogrande.dev.1169,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,1.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00051
hellaswag.val.4243,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
mmlu-high-school-european-history.val.57,mistralai/mixtral-8x7b-chat,1.0,0.0002909999999999,0.0,9.7e-05,0.0,0.0001454999999999,1.0,0.0002909999999999,0.0,0.0003763599999999,1.0,0.00489
mmlu-professional-law.val.245,WizardLM/WizardLM-13B-V1.2,0.0,0.0002297999999999,0.0,0.0001532,0.0,0.0002297999999999,1.0,0.0004595999999999,0.0,0.000594416,1.0,0.00767
mmlu-miscellaneous.val.641,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,0.0,7.83e-05,1.0,0.0001566,0.0,0.000202536,1.0,0.00262
hellaswag.val.9786,WizardLM/WizardLM-13B-V1.2,0.0,8.280000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.0028
bias_detection.dev.171,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,9.36e-05,0.0,0.0001787999999999,0.0,0.000211848,1.0,0.0101
mmlu-international-law.val.18,mistralai/mistral-7b-chat,1.0,2.92e-05,1.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
mmlu-college-medicine.val.38,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
hellaswag.val.114,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,1.0,6.751200000000001e-05,1.0,0.00091
mmlu-nutrition.val.130,mistralai/mixtral-8x7b-chat,1.0,8.1e-05,1.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00139
mmlu-college-physics.val.52,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-professional-law.val.571,WizardLM/WizardLM-13B-V1.2,0.0,8.730000000000001e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
mmlu-philosophy.val.187,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
hellaswag.val.7241,mistralai/mixtral-8x7b-chat,1.0,0.00015,0.0,5e-05,0.0,7.5e-05,1.0,0.00015,0.0,0.000194,1.0,0.00254
mmlu-high-school-psychology.val.67,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
mmlu-high-school-macroeconomics.val.175,mistralai/mistral-7b-chat,1.0,1.64e-05,1.0,1.64e-05,1.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,0.0,0.00083
hellaswag.val.4972,mistralai/mistral-7b-chat,0.0,5.160000000000001e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,1.0,0.0001548,0.0,0.000200208,1.0,0.00262
mmlu-nutrition.val.285,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00138
hellaswag.val.3441,mistralai/mistral-7b-chat,0.0,4.460000000000001e-05,0.0,4.460000000000001e-05,0.0,6.69e-05,0.0,0.0001338,0.0,0.000173048,1.0,0.00224
mmlu-miscellaneous.val.285,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
hellaswag.val.3889,mistralai/mistral-7b-chat,0.0,4.0400000000000006e-05,0.0,4.0400000000000006e-05,0.0,6.06e-05,0.0,0.0001212,0.0,0.000156752,0.0,0.00206
mmlu-global-facts.val.70,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,1.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,0.0,0.00092
mmlu-nutrition.val.74,mistralai/mixtral-8x7b-chat,0.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.4009,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.28e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-security-studies.val.173,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,0.0,0.00264
winogrande.dev.599,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,1.0,1.56e-05,0.0,3.12e-05,0.0,4.0352e-05,0.0,0.00056
mmlu-sociology.val.140,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-professional-psychology.val.214,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,0.0,0.0008
mmlu-high-school-mathematics.val.222,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.0012599999999999
mmlu-professional-medicine.val.171,mistralai/mixtral-8x7b-chat,1.0,8.22e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-professional-medicine.val.140,WizardLM/WizardLM-13B-V1.2,1.0,3.45e-05,0.0,2.3e-05,1.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.0011899999999999
mmlu-professional-law.val.336,WizardLM/WizardLM-13B-V1.2,0.0,6.3e-05,0.0,4.2e-05,0.0,6.3e-05,0.0,0.000126,0.0,0.00016296,0.0,0.00211
grade-school-math.dev.4928,mistralai/mistral-7b-chat,0.25,8.920000000000001e-05,0.25,8.920000000000001e-05,0.25,0.0001281,0.25,0.0002778,0.5,0.000295656,0.75,0.00755
grade-school-math.dev.4543,mistralai/mistral-7b-chat,0.5,9.84e-05,0.5,9.84e-05,0.75,0.0001512,0.5,0.0002729999999999,0.75,0.000312728,0.5,0.00799
mmlu-professional-law.val.983,mistralai/mistral-7b-chat,1.0,3.2200000000000003e-05,1.0,3.2200000000000003e-05,1.0,4.83e-05,0.0,9.66e-05,0.0,0.000124936,1.0,0.00165
hellaswag.val.2795,WizardLM/WizardLM-13B-V1.2,1.0,3.84e-05,0.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
hellaswag.val.9818,WizardLM/WizardLM-13B-V1.2,1.0,5.73e-05,1.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,1.0,0.000148216,1.0,0.00195
mmlu-professional-psychology.val.601,mistralai/mixtral-8x7b-chat,1.0,8.46e-05,0.0,2.82e-05,0.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-moral-scenarios.val.660,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00146
mmlu-professional-law.val.1428,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
grade-school-math.dev.280,mistralai/mistral-7b-chat,0.75,9.72e-05,0.75,9.72e-05,0.75,0.0001446,0.75,0.0002418,0.75,0.000292552,0.75,0.00861
hellaswag.val.5050,mistralai/mixtral-8x7b-chat,1.0,0.000156,0.0,5.2e-05,1.0,7.8e-05,1.0,0.000156,0.0,0.00020176,1.0,0.00261
mmlu-high-school-macroeconomics.val.39,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,0.0,0.00108
grade-school-math.dev.6510,WizardLM/WizardLM-13B-V1.2,0.25,0.0001818,0.25,7.000000000000001e-05,0.25,0.0001818,0.25,0.0002646,0.25,0.00037248,0.75,0.01103
hellaswag.val.856,mistralai/mistral-7b-chat,1.0,2.78e-05,1.0,2.78e-05,0.0,4.14e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
mmlu-logical-fallacies.val.151,mistralai/mistral-7b-chat,0.0,3.04e-05,0.0,3.04e-05,1.0,4.56e-05,1.0,9.12e-05,0.0,0.000117952,1.0,0.00153
arc-challenge.test.530,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
mmlu-moral-scenarios.val.352,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,0.0,0.0015
mmlu-moral-scenarios.val.30,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,1.0,0.00154
mmlu-professional-law.val.622,mistralai/mistral-7b-chat,0.0,4.84e-05,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00243
mmlu-professional-law.val.267,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,1.0,7.02e-05,1.0,0.0001404,0.0,0.000181584,1.0,0.00235
winogrande.dev.540,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
mmlu-high-school-us-history.val.33,mistralai/mixtral-8x7b-chat,1.0,0.0002525999999999,1.0,8.420000000000001e-05,1.0,0.0001262999999999,1.0,0.0002525999999999,0.0,0.000326696,1.0,0.00422
grade-school-math.dev.258,meta/code-llama-instruct-34b-chat,0.25,0.000336784,0.25,9.5e-05,0.5,0.0001554,0.25,0.0002664,0.25,0.000336784,0.75,0.01036
mmlu-professional-law.val.89,WizardLM/WizardLM-13B-V1.2,0.0,0.0001782,1.0,0.0001188,0.0,0.0001782,0.0,0.0003564,0.0,0.0004609439999999,0.0,0.00598
mmlu-high-school-psychology.val.212,mistralai/mistral-7b-chat,1.0,2.4800000000000003e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.9827,mistralai/mixtral-8x7b-chat,1.0,0.0001338,1.0,4.460000000000001e-05,1.0,6.69e-05,1.0,0.0001338,1.0,0.000173048,1.0,0.00227
hellaswag.val.2722,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
hellaswag.val.1170,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00143
hellaswag.val.4877,mistralai/mistral-7b-chat,1.0,4.460000000000001e-05,1.0,4.460000000000001e-05,1.0,6.659999999999999e-05,1.0,0.0001338,1.0,0.000173048,1.0,0.00227
mmlu-moral-scenarios.val.330,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-medical-genetics.val.80,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.519,WizardLM/WizardLM-13B-V1.2,0.0,4.05e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
winogrande.dev.633,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,1.0,3.8024e-05,0.0,0.00053
mbpp.dev.58,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.769999999999999e-05,0.0,0.0001602,1.0,0.000107864,0.0,0.00598
consensus_summary.dev.161,WizardLM/WizardLM-13B-V1.2,0.75,0.0001010999999999,1.0,5.1800000000000005e-05,0.75,0.0001010999999999,0.75,0.0001733999999999,0.0,0.000231248,0.0,0.00247
hellaswag.val.969,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-computer-security.val.60,WizardLM/WizardLM-13B-V1.2,1.0,3.51e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
grade-school-math.dev.5533,mistralai/mistral-7b-chat,0.0,7.620000000000001e-05,0.0,7.620000000000001e-05,0.5,0.0001437,0.75,0.0002184,0.25,0.000346872,0.5,0.00739
mbpp.dev.212,mistralai/mistral-7b-chat,0.0,5.42e-05,0.0,5.42e-05,1.0,4.5e-05,1.0,0.0001715999999999,1.0,9.7e-05,0.0,0.00849
mmlu-miscellaneous.val.244,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-professional-law.val.965,mistralai/mistral-7b-chat,0.0,7.02e-05,0.0,7.02e-05,1.0,0.0001053,1.0,0.0002106,0.0,0.000272376,1.0,0.00352
grade-school-math.dev.1434,mistralai/mistral-7b-chat,0.75,0.0001058,0.75,0.0001058,0.25,0.0001659,0.5,0.0003132,0.5,0.000441544,0.5,0.00836
grade-school-math.dev.20,mistralai/mistral-7b-chat,0.25,8.580000000000001e-05,0.25,8.580000000000001e-05,0.75,0.000156,0.25,0.0001848,0.5,0.000328248,0.75,0.0073
mmlu-logical-fallacies.val.54,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.8660,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001547999999999,0.0,0.000200984,1.0,0.00263
mmlu-philosophy.val.154,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
mmlu-miscellaneous.val.740,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-philosophy.val.297,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-human-sexuality.val.9,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-astronomy.val.147,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
arc-challenge.val.97,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-sociology.val.85,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.607,WizardLM/WizardLM-13B-V1.2,0.0,3.39e-05,1.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00117
hellaswag.val.2469,WizardLM/WizardLM-13B-V1.2,0.0,2.55e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-miscellaneous.val.591,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-moral-disputes.val.32,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,1.0,3.18e-05,0.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-conceptual-physics.val.163,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
hellaswag.val.7963,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,0.0,5.800000000000001e-05,1.0,8.699999999999999e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
mmlu-high-school-chemistry.val.198,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
arc-challenge.test.264,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-high-school-statistics.val.173,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00129
mmlu-elementary-mathematics.val.51,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.68e-05,0.0,6.1304e-05,0.0,0.0007999999999999
mmlu-human-sexuality.val.56,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mbpp.dev.60,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,6.599999999999999e-05,0.0,0.0001962,1.0,0.0001047599999999,1.0,0.01117
bias_detection.dev.108,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,9.48e-05,0.0,0.000156,0.0,0.0002374559999999,1.0,0.00714
mmlu-professional-law.val.1482,WizardLM/WizardLM-13B-V1.2,1.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-prehistory.val.86,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.00075
mmlu-professional-law.val.722,WizardLM/WizardLM-13B-V1.2,0.0,0.0001187999999999,0.0,7.920000000000001e-05,0.0,0.0001187999999999,0.0,0.0002375999999999,0.0,0.000307296,0.0,0.00397
grade-school-math.dev.191,mistralai/mistral-7b-chat,0.25,0.0001074,0.25,0.0001074,0.25,0.0001701,0.25,0.000348,0.25,0.000280136,0.25,0.01103
mmlu-professional-law.val.1171,WizardLM/WizardLM-13B-V1.2,1.0,6.149999999999999e-05,0.0,4.100000000000001e-05,1.0,6.149999999999999e-05,1.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-professional-law.val.856,WizardLM/WizardLM-13B-V1.2,1.0,8.07e-05,0.0,5.380000000000001e-05,1.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
grade-school-math.dev.2883,WizardLM/WizardLM-13B-V1.2,0.75,0.0001241999999999,0.25,9.04e-05,0.75,0.0001241999999999,0.25,0.0001644,0.75,0.000249872,0.75,0.00558
hellaswag.val.9332,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.829999999999999e-05,0.0,0.0001572,0.0,0.000203312,0.0,0.00266
mmlu-nutrition.val.236,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
hellaswag.val.9809,mistralai/mistral-7b-chat,0.0,4.720000000000001e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-us-foreign-policy.val.94,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,0.0,1.98e-05,1.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
grade-school-math.dev.3953,WizardLM/WizardLM-13B-V1.2,0.75,0.0001383,0.25,0.000101,0.75,0.0001383,0.75,0.0002688,0.25,0.000327472,0.75,0.00673
hellaswag.val.2709,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
hellaswag.val.8132,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
arc-challenge.val.207,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-high-school-chemistry.val.173,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-psychology.val.605,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mbpp.dev.330,mistralai/mistral-7b-chat,1.0,2.48e-05,1.0,2.48e-05,1.0,4.95e-05,1.0,0.000162,1.0,0.000128816,1.0,0.0037199999999999
mmlu-electrical-engineering.val.132,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-medical-genetics.val.54,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
hellaswag.val.3831,mistralai/mistral-7b-chat,0.0,4.64e-05,0.0,4.64e-05,0.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00233
hellaswag.val.8081,mistralai/mistral-7b-chat,1.0,4.860000000000001e-05,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00247
grade-school-math.dev.4267,WizardLM/WizardLM-13B-V1.2,0.5,0.0001626,0.25,9.120000000000002e-05,0.5,0.0001626,1.0,0.0002333999999999,0.25,0.00034532,0.5,0.00834
mmlu-professional-law.val.645,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-elementary-mathematics.val.74,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.7380,mistralai/mistral-7b-chat,0.0,4.7e-05,0.0,4.7e-05,1.0,7.019999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
mmlu-medical-genetics.val.70,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
grade-school-math.dev.1618,WizardLM/WizardLM-13B-V1.2,0.25,0.0001701,0.25,0.0001056,0.25,0.0001701,0.25,0.0002844,0.25,0.000422144,0.25,0.0104
grade-school-math.dev.1845,mistralai/mistral-7b-chat,0.75,9.5e-05,0.75,9.5e-05,0.75,0.0001905,0.75,0.0002748,0.75,0.000422144,0.5,0.0093899999999999
winogrande.dev.1136,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,0.0,1.3799999999999998e-05,1.0,2.76e-05,1.0,3.5696e-05,1.0,0.0005
grade-school-math.dev.5944,mistralai/mistral-7b-chat,0.25,0.0001258,0.25,0.0001258,0.5,0.0002063999999999,0.5,0.0002934,0.5,0.000392656,0.75,0.00787
mmlu-high-school-statistics.val.119,WizardLM/WizardLM-13B-V1.2,1.0,4.86e-05,1.0,3.24e-05,1.0,4.86e-05,1.0,9.72e-05,0.0,0.000125712,1.0,0.00163
mmlu-professional-accounting.val.51,mistralai/mistral-7b-chat,0.0,3.180000000000001e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,0.0,9.54e-05,0.0,0.000123384,0.0,0.0016
mmlu-abstract-algebra.val.97,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.86e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-miscellaneous.val.139,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,0.0,4.08e-05,0.0,5.2768e-05,0.0,0.00069
hellaswag.val.7247,mistralai/mixtral-8x7b-chat,0.0,0.0001836,0.0,6.120000000000001e-05,0.0,9.15e-05,0.0,0.0001836,0.0,0.0002374559999999,1.0,0.00307
grade-school-math.dev.4515,mistralai/mistral-7b-chat,0.5,9.52e-05,0.5,9.52e-05,0.5,0.0001695,0.5,0.0002898,0.75,0.000346872,0.75,0.009
grade-school-math.dev.6007,WizardLM/WizardLM-13B-V1.2,0.75,0.0001959,0.75,0.0001222,0.75,0.0001959,0.25,0.000267,0.75,0.0003298,0.75,0.00779
mmlu-management.val.69,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
grade-school-math.dev.4130,mistralai/mistral-7b-chat,0.75,7.26e-05,0.75,7.26e-05,0.75,0.000147,0.25,0.0002466,0.75,0.000377912,0.25,0.01055
grade-school-math.dev.7184,mistralai/mistral-7b-chat,0.25,9.34e-05,0.25,9.34e-05,0.25,0.000156,0.25,0.0003558,0.25,0.000374808,0.75,0.01001
hellaswag.val.7106,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
mmlu-professional-law.val.465,mistralai/mistral-7b-chat,0.0,6.38e-05,0.0,6.38e-05,0.0,9.57e-05,0.0,0.0001914,0.0,0.000247544,0.0,0.0032
hellaswag.val.9914,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00252
grade-school-math.dev.7195,mistralai/mistral-7b-chat,0.25,7.32e-05,0.25,7.32e-05,0.75,0.0001296,0.25,0.0002658,0.75,0.000336784,0.75,0.00618
grade-school-math.dev.978,mistralai/mistral-7b-chat,0.75,7.94e-05,0.75,7.94e-05,0.75,0.0001397999999999,0.5,0.0002586,0.5,0.000370152,0.75,0.00703
grade-school-math.dev.675,WizardLM/WizardLM-13B-V1.2,0.5,0.0002028,0.75,0.0001234,0.5,0.0002028,0.25,0.0003834,0.25,0.00045784,0.5,0.01196
grade-school-math.dev.6672,WizardLM/WizardLM-13B-V1.2,0.75,0.0001761,0.75,0.0001086,0.75,0.0001761,0.75,0.000267,0.5,0.000375584,0.25,0.01047
grade-school-math.dev.1824,mistralai/mistral-7b-chat,0.5,0.0001286,0.5,0.0001286,0.5,0.0001820999999999,0.5,0.0003366,0.25,0.000637096,0.5,0.0106
grade-school-math.dev.10,mistralai/mixtral-8x7b-chat,0.75,0.0003252,0.75,0.0001046,0.25,0.0002228999999999,0.75,0.0003252,0.75,0.0003492,0.5,0.0085
hellaswag.val.3954,mistralai/mixtral-8x7b-chat,0.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-high-school-statistics.val.140,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
mmlu-world-religions.val.27,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,1.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
hellaswag.val.76,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
winogrande.dev.897,mistralai/mistral-7b-chat,0.0,1.14e-05,0.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00058
mmlu-miscellaneous.val.276,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-high-school-psychology.val.499,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
mmlu-high-school-psychology.val.189,mistralai/mixtral-8x7b-chat,1.0,7.86e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.0013499999999999
grade-school-math.dev.1359,mistralai/mistral-7b-chat,0.25,7.920000000000001e-05,0.25,7.920000000000001e-05,0.25,0.0001563,0.75,0.0002352,0.25,0.000352304,0.5,0.00798
grade-school-math.dev.2493,mistralai/mistral-7b-chat,0.75,8.980000000000001e-05,0.75,8.980000000000001e-05,0.75,0.0001431,0.25,0.000228,0.25,0.000252976,0.5,0.00678
hellaswag.val.8714,mistralai/mixtral-8x7b-chat,0.0,0.0001824,0.0,6.080000000000001e-05,0.0,9.12e-05,0.0,0.0001824,0.0,0.000235904,1.0,0.00308
grade-school-math.dev.6260,WizardLM/WizardLM-13B-V1.2,0.75,0.0001997999999999,0.25,9.54e-05,0.75,0.0001997999999999,0.5,0.0003101999999999,0.0,0.000289448,0.75,0.00805
mmlu-high-school-psychology.val.109,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-professional-law.val.517,WizardLM/WizardLM-13B-V1.2,1.0,9.06e-05,0.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
grade-school-math.dev.327,mistralai/mixtral-8x7b-chat,0.75,0.0002658,0.25,8.98e-05,0.75,0.0001578,0.75,0.0002658,0.75,0.000348424,0.5,0.00816
mmlu-high-school-us-history.val.100,WizardLM/WizardLM-13B-V1.2,1.0,9.9e-05,1.0,6.6e-05,1.0,9.9e-05,1.0,0.000198,0.0,0.00025608,1.0,0.00331
grade-school-math.dev.1566,WizardLM/WizardLM-13B-V1.2,0.25,0.0001581,0.25,8.400000000000001e-05,0.25,0.0001581,0.25,0.0002358,0.25,0.000315056,0.75,0.0104099999999999
winogrande.dev.408,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,0.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
hellaswag.val.9396,WizardLM/WizardLM-13B-V1.2,0.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
hellaswag.val.5350,mistralai/mixtral-8x7b-chat,0.0,0.0001656,1.0,5.520000000000001e-05,1.0,8.280000000000001e-05,0.0,0.0001656,1.0,0.0002141759999999,1.0,0.0028
arc-challenge.test.602,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
grade-school-math.dev.3407,WizardLM/WizardLM-13B-V1.2,0.5,0.000165,0.25,9.52e-05,0.5,0.000165,0.25,0.0001967999999999,0.25,0.0003786879999999,0.75,0.00715
mmlu-moral-scenarios.val.868,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-high-school-statistics.val.104,mistralai/mixtral-8x7b-chat,1.0,0.0001038,0.0,3.460000000000001e-05,1.0,5.19e-05,1.0,0.0001038,0.0,0.0001342479999999,1.0,0.00174
consensus_summary.dev.213,mistralai/mixtral-8x7b-chat,0.75,0.0002021999999999,0.75,4.86e-05,0.25,0.000111,0.75,0.0002021999999999,0.25,0.000264616,0.75,0.004
grade-school-math.dev.2281,WizardLM/WizardLM-13B-V1.2,0.25,0.000183,0.25,0.0001048,0.25,0.000183,0.75,0.0002772,0.25,0.000401192,0.75,0.00867
hellaswag.val.7145,mistralai/mixtral-8x7b-chat,0.0,0.0001272,0.0,4.24e-05,0.0,6.36e-05,0.0,0.0001272,0.0,0.0001645119999999,1.0,0.00213
mmlu-logical-fallacies.val.98,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-high-school-computer-science.val.54,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,1.0,0.0001446,0.0,0.00018624,1.0,0.00242
mmlu-high-school-microeconomics.val.151,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-law.val.1053,WizardLM/WizardLM-13B-V1.2,1.0,0.0001038,0.0,6.919999999999999e-05,1.0,0.0001038,0.0,0.0002076,0.0,0.000268496,1.0,0.00347
arc-challenge.test.367,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,1.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,1.0,5.6648e-05,0.0,0.00074
hellaswag.val.5061,mistralai/mixtral-8x7b-chat,0.0,0.0001722,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00288
hellaswag.val.7404,mistralai/mixtral-8x7b-chat,1.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
grade-school-math.dev.2783,mistralai/mistral-7b-chat,0.25,9.28e-05,0.25,9.28e-05,0.25,0.0001719,0.25,0.0002615999999999,0.25,0.000600624,0.5,0.0093999999999999
grade-school-math.dev.7442,WizardLM/WizardLM-13B-V1.2,0.75,0.0001389,0.25,9.26e-05,0.75,0.0001389,0.5,0.0002441999999999,0.75,0.000329024,0.75,0.00875
hellaswag.val.7970,WizardLM/WizardLM-13B-V1.2,0.0,0.0001023,0.0,6.819999999999999e-05,0.0,0.0001023,0.0,0.0002046,0.0,0.000264616,1.0,0.00342
grade-school-math.dev.6381,mistralai/mixtral-8x7b-chat,0.75,0.0002573999999999,0.75,8.36e-05,0.75,0.0001508999999999,0.75,0.0002573999999999,0.75,0.000336784,0.75,0.00718
mmlu-prehistory.val.189,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,1.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
grade-school-math.dev.807,mistralai/mistral-7b-chat,0.75,7.04e-05,0.75,7.04e-05,0.25,0.0001671,0.25,0.0002322,0.75,0.000270824,0.75,0.00668
mmlu-professional-law.val.480,mistralai/mistral-7b-chat,0.0,5.8200000000000005e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
hellaswag.val.2275,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.09e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
mmlu-professional-law.val.959,WizardLM/WizardLM-13B-V1.2,1.0,6.42e-05,0.0,4.280000000000001e-05,1.0,6.42e-05,0.0,0.0001284,0.0,0.000166064,0.0,0.00218
mmlu-professional-law.val.1311,WizardLM/WizardLM-13B-V1.2,0.0,0.0001064999999999,0.0,7.1e-05,0.0,0.0001064999999999,0.0,0.0002129999999999,0.0,0.00027548,0.0,0.00356
grade-school-math.dev.5942,mistralai/mixtral-8x7b-chat,0.25,0.0002184,0.25,0.0001066,0.75,0.0001376999999999,0.25,0.0002184,0.75,0.000321264,0.5,0.00821
mmlu-business-ethics.val.52,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
mmlu-moral-scenarios.val.252,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.00133
mmlu-jurisprudence.val.25,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
hellaswag.val.7471,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
grade-school-math.dev.5284,mistralai/mistral-7b-chat,0.25,8.54e-05,0.25,8.54e-05,0.25,0.0001889999999999,0.5,0.0003149999999999,0.25,0.0003298,0.75,0.00944
grade-school-math.dev.5697,mistralai/mistral-7b-chat,0.75,7.54e-05,0.75,7.54e-05,0.75,0.0001479,0.25,0.0002099999999999,0.75,0.000291,0.75,0.00683
grade-school-math.dev.4419,WizardLM/WizardLM-13B-V1.2,0.75,0.0001944,0.25,0.0001076,0.75,0.0001944,0.25,0.0002904,0.25,0.00038024,0.75,0.01116
grade-school-math.dev.3492,WizardLM/WizardLM-13B-V1.2,0.5,0.000195,0.25,5.9e-05,0.5,0.000195,0.25,0.000288,0.25,0.00035308,0.75,0.01119
mmlu-anatomy.val.83,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
grade-school-math.dev.4577,mistralai/mistral-7b-chat,0.5,8.840000000000001e-05,0.5,8.840000000000001e-05,0.75,0.0001709999999999,0.75,0.0002136,0.5,0.000276256,0.75,0.00789
grade-school-math.dev.1218,WizardLM/WizardLM-13B-V1.2,0.75,0.000147,0.25,8.22e-05,0.75,0.000147,0.75,0.0002454,0.5,0.000303416,0.75,0.00875
hellaswag.val.8689,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
mmlu-professional-psychology.val.546,mistralai/mixtral-8x7b-chat,0.0,7.92e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,0.0,0.00133
hellaswag.val.4468,mistralai/mixtral-8x7b-chat,0.0,0.000177,0.0,5.9e-05,0.0,8.85e-05,0.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
hellaswag.val.9605,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,1.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.0026
grade-school-math.dev.5831,mistralai/mistral-7b-chat,0.25,8.3e-05,0.25,8.3e-05,0.25,0.0001515,0.25,0.0002622,0.25,0.000311952,0.75,0.0102399999999999
mmlu-electrical-engineering.val.100,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.1464,mistralai/mistral-7b-chat,0.25,8.08e-05,0.25,8.08e-05,0.25,0.0001434,0.25,0.0002388,0.25,0.000335232,0.25,0.00823
grade-school-math.dev.1827,mistralai/mistral-7b-chat,0.25,0.0001168,0.25,0.0001168,0.25,0.0001623,0.75,0.0002639999999999,0.25,0.000378688,0.75,0.01014
mmlu-high-school-european-history.val.2,mistralai/mixtral-8x7b-chat,1.0,0.0002189999999999,0.0,7.3e-05,0.0,0.0001094999999999,1.0,0.0002189999999999,0.0,0.00028324,1.0,0.00366
mmlu-conceptual-physics.val.219,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-professional-psychology.val.186,mistralai/mixtral-8x7b-chat,1.0,7.2e-05,0.0,2.4e-05,0.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-professional-law.val.627,mistralai/mistral-7b-chat,0.0,3.4000000000000007e-05,0.0,3.4000000000000007e-05,0.0,5.1e-05,0.0,0.000102,0.0,0.0001319199999999,0.0,0.00174
mmlu-high-school-microeconomics.val.8,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
arc-challenge.test.567,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.9168,mistralai/mixtral-8x7b-chat,0.0,0.0001422,1.0,4.74e-05,1.0,7.110000000000001e-05,0.0,0.0001422,1.0,0.000183912,1.0,0.00241
grade-school-math.dev.5404,WizardLM/WizardLM-13B-V1.2,0.5,0.0001608,1.0,5.9600000000000005e-05,0.5,0.0001608,0.5,0.0002963999999999,0.25,0.000321264,0.5,0.00764
mmlu-miscellaneous.val.64,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
grade-school-math.dev.179,mistralai/mixtral-8x7b-chat,0.75,0.0003174,0.25,8.060000000000001e-05,0.25,0.0001820999999999,0.75,0.0003174,0.25,0.000355408,0.5,0.0101
mmlu-nutrition.val.161,mistralai/mistral-7b-chat,1.0,1.5e-05,1.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mbpp.dev.392,mistralai/mistral-7b-chat,1.0,5.2400000000000007e-05,1.0,5.2400000000000007e-05,1.0,8.639999999999999e-05,1.0,0.0001416,1.0,0.000166064,1.0,0.0064
mmlu-prehistory.val.271,mistralai/mixtral-8x7b-chat,1.0,7.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-college-biology.val.92,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,1.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-high-school-us-history.val.119,mistralai/mixtral-8x7b-chat,1.0,0.0001446,1.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,1.0,0.0001446,0.0,0.000187016,1.0,0.00242
hellaswag.val.5867,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,0.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-professional-accounting.val.261,WizardLM/WizardLM-13B-V1.2,0.0,2.97e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
mmlu-high-school-macroeconomics.val.69,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.2002,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00143
mmlu-professional-law.val.679,mistralai/mistral-7b-chat,0.0,3.8400000000000005e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00193
grade-school-math.dev.3607,WizardLM/WizardLM-13B-V1.2,0.75,0.0001406999999999,0.75,8.42e-05,0.75,0.0001406999999999,0.75,0.0002382,0.75,0.000316608,0.75,0.00586
hellaswag.val.9902,mistralai/mixtral-8x7b-chat,1.0,0.0001572,1.0,5.24e-05,1.0,7.86e-05,1.0,0.0001572,1.0,0.000203312,1.0,0.00266
hellaswag.val.1281,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
hellaswag.val.8791,mistralai/mixtral-8x7b-chat,0.0,0.0001404,1.0,4.6800000000000006e-05,1.0,7.02e-05,0.0,0.0001404,1.0,0.000181584,1.0,0.00235
hellaswag.val.6927,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
mmlu-international-law.val.81,WizardLM/WizardLM-13B-V1.2,0.0,3.84e-05,0.0,2.56e-05,0.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-miscellaneous.val.493,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-high-school-government-and-politics.val.151,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
grade-school-math.dev.4785,WizardLM/WizardLM-13B-V1.2,0.25,0.0001773,0.25,7.78e-05,0.25,0.0001773,0.75,0.000225,0.5,0.000313504,0.75,0.00688
hellaswag.val.3579,mistralai/mixtral-8x7b-chat,1.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.739999999999998e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
hellaswag.val.3361,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
winogrande.dev.224,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.56e-05,0.0,3.12e-05,1.0,4.0352e-05,1.0,0.00056
mmlu-high-school-world-history.val.113,mistralai/mixtral-8x7b-chat,1.0,0.0001553999999999,0.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
hellaswag.val.1316,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.52e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
bias_detection.dev.77,mistralai/mistral-7b-chat,0.0,4.86e-05,0.0,4.86e-05,0.0,9.33e-05,1.0,0.0001776,1.0,0.000233576,1.0,0.00825
hellaswag.val.4906,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
grade-school-math.dev.5653,meta/code-llama-instruct-34b-chat,0.5,0.000273152,0.75,6.1e-05,0.75,0.0001293,0.0,0.0001853999999999,0.5,0.000273152,0.5,0.00516
mmlu-professional-psychology.val.565,mistralai/mixtral-8x7b-chat,1.0,0.0001002,0.0,3.3400000000000005e-05,1.0,5.01e-05,1.0,0.0001002,0.0,0.000129592,1.0,0.00168
grade-school-math.dev.790,mistralai/mistral-7b-chat,0.75,8.300000000000001e-05,0.75,8.300000000000001e-05,0.25,0.0001602,0.75,0.0002208,0.75,0.0003429919999999,0.5,0.00772
grade-school-math.dev.31,WizardLM/WizardLM-13B-V1.2,0.75,0.0001638,0.75,8.2e-05,0.75,0.0001638,0.75,0.0002766,0.25,0.000335232,0.75,0.00712
hellaswag.val.9443,mistralai/mixtral-8x7b-chat,0.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
mmlu-professional-law.val.1181,mistralai/mistral-7b-chat,0.0,6.36e-05,0.0,6.36e-05,1.0,9.54e-05,1.0,0.0001908,0.0,0.000246768,1.0,0.00319
mmlu-professional-law.val.1359,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-sociology.val.170,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-law.val.9,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,1.0,6.2e-05,0.0,9.3e-05,1.0,0.000186,0.0,0.00024056,0.0,0.00311
hellaswag.val.8898,mistralai/mistral-7b-chat,0.0,4.420000000000001e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,1.0,0.0001326,0.0,0.000171496,1.0,0.00225
grade-school-math.dev.103,WizardLM/WizardLM-13B-V1.2,0.25,0.0001785,0.25,6.82e-05,0.25,0.0001785,0.25,0.0003342,0.25,0.000390328,0.5,0.00995
mmlu-professional-law.val.734,mistralai/mistral-7b-chat,1.0,4.080000000000001e-05,1.0,4.080000000000001e-05,0.0,6.12e-05,1.0,0.0001224,0.0,0.000158304,0.0,0.00208
hellaswag.val.2915,WizardLM/WizardLM-13B-V1.2,0.0,3.78e-05,1.0,2.52e-05,0.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.0013
mmlu-college-medicine.val.104,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.00075
arc-challenge.test.694,mistralai/mixtral-8x7b-chat,0.0,4.98e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
mmlu-professional-law.val.225,WizardLM/WizardLM-13B-V1.2,0.0,5.88e-05,0.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,1.0,0.00197
mmlu-high-school-statistics.val.171,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-marketing.val.133,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.255,WizardLM/WizardLM-13B-V1.2,0.75,0.0001347,0.75,7.9e-05,0.75,0.0001347,0.25,0.0002436,0.75,0.000251424,0.75,0.00436
hellaswag.val.7615,WizardLM/WizardLM-13B-V1.2,0.0,6.149999999999999e-05,0.0,4.100000000000001e-05,0.0,6.149999999999999e-05,0.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-human-aging.val.193,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-law.val.1487,WizardLM/WizardLM-13B-V1.2,1.0,0.0001250999999999,1.0,8.34e-05,1.0,0.0001250999999999,1.0,0.0002496,0.0,0.000323592,1.0,0.00418
grade-school-math.dev.4517,mistralai/mistral-7b-chat,0.25,8.26e-05,0.25,8.26e-05,0.25,0.0001991999999999,0.25,0.0003017999999999,0.25,0.000320488,0.75,0.00949
hellaswag.val.1772,mistralai/mistral-7b-chat,1.0,2.88e-05,1.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-professional-psychology.val.557,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.1743,mistralai/mistral-7b-chat,0.25,8.16e-05,0.25,8.16e-05,0.5,0.0001593,0.5,0.0002802,0.75,0.000331352,0.5,0.00815
winogrande.dev.1101,mistralai/mistral-7b-chat,1.0,1.12e-05,1.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,1.0,0.0006
grade-school-math.dev.996,WizardLM/WizardLM-13B-V1.2,0.25,0.0001682999999999,0.25,9.18e-05,0.25,0.0001682999999999,0.25,0.0003635999999999,0.25,0.00035696,0.5,0.01258
hellaswag.val.4965,WizardLM/WizardLM-13B-V1.2,0.0,8.04e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-marketing.val.113,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-virology.val.113,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-marketing.val.47,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00076
grade-school-math.dev.5272,mistralai/mistral-7b-chat,0.25,0.0001366,0.25,0.0001366,0.5,0.0001497,0.5,0.0002808,0.25,0.000384896,0.5,0.0075499999999999
mmlu-moral-disputes.val.73,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.6113,mistralai/mistral-7b-chat,0.75,8.660000000000002e-05,0.75,8.660000000000002e-05,0.75,0.0001347,0.75,0.0002766,0.75,0.000295656,0.75,0.00599
mmlu-high-school-macroeconomics.val.213,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00121
mmlu-nutrition.val.105,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-high-school-government-and-politics.val.104,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-high-school-european-history.val.88,mistralai/mixtral-8x7b-chat,1.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
consensus_summary.dev.259,mistralai/mixtral-8x7b-chat,0.75,0.0002988,0.75,9.3e-05,0.75,0.0001728,0.75,0.0002988,0.75,0.0004275759999999,1.0,0.00408
grade-school-math.dev.5036,mistralai/mixtral-8x7b-chat,0.25,0.0002868,0.25,8.400000000000001e-05,0.75,0.0001706999999999,0.25,0.0002868,0.75,0.000308848,0.75,0.0070999999999999
mmlu-high-school-microeconomics.val.4,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-clinical-knowledge.val.84,mistralai/mixtral-8x7b-chat,1.0,7.02e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
mmlu-international-law.val.29,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-professional-law.val.1224,mistralai/mistral-7b-chat,1.0,4.9600000000000006e-05,1.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
mmlu-econometrics.val.84,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
hellaswag.val.7253,mistralai/mixtral-8x7b-chat,1.0,0.0001704,1.0,5.680000000000001e-05,1.0,8.52e-05,1.0,0.0001704,1.0,0.0002203839999999,1.0,0.00285
arc-challenge.test.843,mistralai/mistral-7b-chat,1.0,1.22e-05,1.0,1.22e-05,1.0,1.83e-05,1.0,3.66e-05,1.0,4.7336e-05,1.0,0.00062
hellaswag.val.2162,WizardLM/WizardLM-13B-V1.2,0.0,3.3e-05,1.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,1.0,8.536000000000001e-05,1.0,0.00114
mmlu-high-school-mathematics.val.27,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,0.0,0.00131
mmlu-high-school-government-and-politics.val.180,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-professional-law.val.1370,WizardLM/WizardLM-13B-V1.2,0.0,7.83e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,1.0,0.0001566,0.0,0.000202536,1.0,0.00262
hellaswag.val.8175,mistralai/mixtral-8x7b-chat,0.0,0.0001733999999999,0.0,5.780000000000001e-05,0.0,8.669999999999999e-05,0.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
hellaswag.val.1461,mistralai/mistral-7b-chat,1.0,1.82e-05,1.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,1.0,7.0616e-05,1.0,0.00095
hellaswag.val.7101,mistralai/mixtral-8x7b-chat,1.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
hellaswag.val.7094,mistralai/mixtral-8x7b-chat,1.0,0.0001584,1.0,5.280000000000001e-05,1.0,7.92e-05,1.0,0.0001584,1.0,0.000204864,1.0,0.00268
hellaswag.val.6880,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
hellaswag.val.7526,mistralai/mixtral-8x7b-chat,0.0,0.000144,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.000144,0.0,0.000187016,1.0,0.00242
mmlu-professional-accounting.val.127,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
hellaswag.val.3883,mistralai/mixtral-8x7b-chat,0.0,0.0001758,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00297
hellaswag.val.1616,WizardLM/WizardLM-13B-V1.2,0.0,2.97e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
mmlu-professional-law.val.1192,WizardLM/WizardLM-13B-V1.2,1.0,9.84e-05,0.0,6.56e-05,1.0,9.84e-05,0.0,0.0001961999999999,0.0,0.000254528,0.0,0.00329
grade-school-math.dev.3937,mistralai/mistral-7b-chat,0.75,7.84e-05,0.75,7.84e-05,0.75,0.0001539,0.75,0.000225,0.75,0.000294104,0.75,0.00946
hellaswag.val.8909,WizardLM/WizardLM-13B-V1.2,0.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
grade-school-math.dev.1,WizardLM/WizardLM-13B-V1.2,0.75,0.0001173,0.75,7.460000000000001e-05,0.75,0.0001173,0.75,0.0002357999999999,0.25,0.000284016,0.75,0.00685
hellaswag.val.614,mistralai/mixtral-8x7b-chat,1.0,6.3e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00109
grade-school-math.dev.180,mistralai/mistral-7b-chat,0.75,7.24e-05,0.75,7.24e-05,0.5,0.0001557,0.75,0.0002304,0.75,0.000256856,0.5,0.00621
hellaswag.val.7099,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
hellaswag.val.3207,WizardLM/WizardLM-13B-V1.2,0.0,3.69e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-professional-law.val.1402,WizardLM/WizardLM-13B-V1.2,0.0,0.0001356,1.0,9.04e-05,0.0,0.0001356,1.0,0.0002712,0.0,0.0003507519999999,1.0,0.0045299999999999
mmlu-professional-law.val.102,WizardLM/WizardLM-13B-V1.2,1.0,9.39e-05,0.0,6.26e-05,1.0,9.39e-05,1.0,0.0001877999999999,0.0,0.000242888,1.0,0.00314
mmlu-professional-law.val.443,WizardLM/WizardLM-13B-V1.2,0.0,8.64e-05,1.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,0.0,0.00289
mmlu-high-school-microeconomics.val.113,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.3409,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
hellaswag.val.7858,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00244
hellaswag.val.6298,WizardLM/WizardLM-13B-V1.2,0.0,7.859999999999999e-05,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.4730,mistralai/mistral-7b-chat,0.25,0.0001118,0.25,0.0001118,0.5,0.0001788,0.75,0.000312,0.25,0.000290224,0.5,0.01184
hellaswag.val.4683,WizardLM/WizardLM-13B-V1.2,0.0,8.34e-05,0.0,5.56e-05,0.0,8.34e-05,1.0,0.0001668,0.0,0.000215728,1.0,0.00282
mmlu-clinical-knowledge.val.83,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.1992,mistralai/mistral-7b-chat,0.25,0.0001206,0.25,0.0001206,0.25,0.0002175,0.25,0.0003666,0.25,0.000486552,0.25,0.00939
hellaswag.val.883,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00142
hellaswag.val.3703,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
mmlu-sociology.val.50,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.7600,mistralai/mixtral-8x7b-chat,1.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00237
hellaswag.val.2589,WizardLM/WizardLM-13B-V1.2,1.0,3.09e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
grade-school-math.dev.4732,WizardLM/WizardLM-13B-V1.2,0.25,0.0002148,0.75,0.0001052,0.25,0.0002148,0.5,0.0002975999999999,0.25,0.000329024,0.75,0.01182
hellaswag.val.2978,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.49e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
hellaswag.val.2972,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-electrical-engineering.val.33,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.86e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.7241,mistralai/mistral-7b-chat,0.25,9.78e-05,0.25,9.78e-05,0.75,0.0001743,0.75,0.0002658,0.75,0.000357736,0.5,0.00874
grade-school-math.dev.6854,WizardLM/WizardLM-13B-V1.2,0.75,0.0001701,0.25,9.46e-05,0.75,0.0001701,0.75,0.0002927999999999,0.5,0.000353856,0.5,0.00812
hellaswag.val.8193,WizardLM/WizardLM-13B-V1.2,0.0,8.01e-05,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-security-studies.val.11,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,1.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-high-school-government-and-politics.val.168,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.759999999999999e-05,1.0,0.00102
mmlu-formal-logic.val.40,mistralai/mixtral-8x7b-chat,1.0,0.0001242,0.0,4.14e-05,0.0,6.21e-05,1.0,0.0001242,0.0,0.000160632,1.0,0.00208
hellaswag.val.440,mistralai/mixtral-8x7b-chat,1.0,8.159999999999999e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.5509,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-moral-disputes.val.252,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
winogrande.dev.1081,mistralai/mistral-7b-chat,0.0,1.1e-05,0.0,1.1e-05,1.0,1.65e-05,1.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00056
hellaswag.val.8125,mistralai/mistral-7b-chat,1.0,5.7400000000000006e-05,1.0,5.7400000000000006e-05,1.0,8.61e-05,1.0,0.0001722,1.0,0.000222712,1.0,0.00291
mmlu-professional-law.val.814,mistralai/mistral-7b-chat,0.0,7.08e-05,0.0,7.08e-05,0.0,0.0001061999999999,1.0,0.0002123999999999,0.0,0.0002747039999999,1.0,0.00355
winogrande.dev.797,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.00053
mmlu-security-studies.val.219,mistralai/mixtral-8x7b-chat,1.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
winogrande.dev.925,mistralai/mixtral-8x7b-chat,0.0,3e-05,0.0,1e-05,0.0,1.47e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00051
grade-school-math.dev.2268,mistralai/mistral-7b-chat,0.25,0.000112,0.25,0.000112,0.25,0.0001722,0.75,0.0002658,0.75,0.000425248,0.75,0.0094799999999999
arc-challenge.test.181,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.5257,mistralai/mixtral-8x7b-chat,0.0,0.0001452,1.0,4.84e-05,1.0,7.23e-05,0.0,0.0001452,1.0,0.000187792,1.0,0.00246
mmlu-professional-psychology.val.266,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-professional-accounting.val.61,WizardLM/WizardLM-13B-V1.2,0.0,3.84e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
grade-school-math.dev.1571,WizardLM/WizardLM-13B-V1.2,0.25,0.000153,0.25,8.120000000000001e-05,0.25,0.000153,0.5,0.000252,0.25,0.000291,0.5,0.0080299999999999
mmlu-marketing.val.31,WizardLM/WizardLM-13B-V1.2,1.0,3.09e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
hellaswag.val.374,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,0.0,0.0014
mmlu-professional-law.val.101,WizardLM/WizardLM-13B-V1.2,0.0,5.97e-05,0.0,3.980000000000001e-05,0.0,5.97e-05,0.0,0.0001193999999999,0.0,0.000154424,0.0,0.002
mmlu-professional-law.val.379,WizardLM/WizardLM-13B-V1.2,0.0,5.79e-05,0.0,3.86e-05,0.0,5.79e-05,0.0,0.0001158,0.0,0.000149768,1.0,0.00197
hellaswag.val.5562,mistralai/mixtral-8x7b-chat,1.0,0.0001608,1.0,5.360000000000001e-05,1.0,8.01e-05,1.0,0.0001608,1.0,0.0002079679999999,1.0,0.00269
mmlu-marketing.val.79,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
grade-school-math.dev.4598,WizardLM/WizardLM-13B-V1.2,0.25,0.0001820999999999,0.25,0.0001331999999999,0.25,0.0001820999999999,0.25,0.0003954,0.25,0.000388776,0.5,0.01326
mmlu-professional-law.val.1475,WizardLM/WizardLM-13B-V1.2,1.0,9.06e-05,0.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
mmlu-college-mathematics.val.48,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,0.0,0.00132
mmlu-high-school-geography.val.173,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.26,mistralai/mixtral-8x7b-chat,0.75,0.0002189999999999,0.5,8.180000000000001e-05,0.75,0.0001521,0.75,0.0002189999999999,0.5,0.000339888,0.5,0.00716
grade-school-math.dev.1031,WizardLM/WizardLM-13B-V1.2,0.75,0.0001848,0.75,0.0001236,0.75,0.0001848,0.75,0.000279,0.25,0.000385672,0.5,0.00917
mmlu-professional-law.val.716,mistralai/mistral-7b-chat,0.0,4.600000000000001e-05,0.0,4.600000000000001e-05,0.0,6.9e-05,0.0,0.000138,0.0,0.0001784799999999,0.0,0.00231
grade-school-math.dev.4922,WizardLM/WizardLM-13B-V1.2,0.5,0.0001785,0.75,6.74e-05,0.5,0.0001785,0.25,0.000243,0.25,0.00045008,0.75,0.00869
grade-school-math.dev.896,WizardLM/WizardLM-13B-V1.2,0.25,0.0001799999999999,0.25,6.98e-05,0.25,0.0001799999999999,0.5,0.0002724,0.5,0.00032592,0.5,0.00741
grade-school-math.dev.842,mistralai/mistral-7b-chat,0.75,9.1e-05,0.75,9.1e-05,0.25,0.000198,0.75,0.0002898,0.75,0.000332904,0.75,0.00766
grade-school-math.dev.6775,WizardLM/WizardLM-13B-V1.2,0.25,0.0001371,0.25,6.04e-05,0.25,0.0001371,0.25,0.000255,0.25,0.000304968,0.5,0.00778
hellaswag.val.8220,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,1.0,0.00232
hellaswag.val.4018,mistralai/mixtral-8x7b-chat,1.0,0.0001698,0.0,5.660000000000001e-05,0.0,8.49e-05,1.0,0.0001698,0.0,0.000219608,1.0,0.00287
hellaswag.val.9341,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-professional-law.val.912,mistralai/mistral-7b-chat,1.0,3.1e-05,1.0,3.1e-05,1.0,4.65e-05,1.0,9.3e-05,0.0,0.00012028,1.0,0.00156
hellaswag.val.1847,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
arc-challenge.test.818,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,1.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.6415,WizardLM/WizardLM-13B-V1.2,0.25,0.0001626,0.25,9.72e-05,0.25,0.0001626,0.25,0.0002958,0.25,0.000384896,0.25,0.0102499999999999
mmlu-elementary-mathematics.val.305,mistralai/mixtral-8x7b-chat,0.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
grade-school-math.dev.917,WizardLM/WizardLM-13B-V1.2,0.75,0.0001719,0.75,7.98e-05,0.75,0.0001719,0.25,0.0002544,0.75,0.000317384,0.75,0.00734
grade-school-math.dev.1891,WizardLM/WizardLM-13B-V1.2,0.25,0.0001208999999999,0.25,5.580000000000001e-05,0.25,0.0001208999999999,0.25,0.0002118,0.25,0.000297208,0.5,0.00584
mmlu-professional-law.val.210,WizardLM/WizardLM-13B-V1.2,0.0,7.680000000000001e-05,0.0,5.12e-05,0.0,7.680000000000001e-05,1.0,0.0001536,0.0,0.000198656,1.0,0.00257
grade-school-math.dev.4461,WizardLM/WizardLM-13B-V1.2,0.25,0.000141,0.5,8.280000000000001e-05,0.25,0.000141,0.25,0.0003414,0.25,0.000394208,0.5,0.0096
grade-school-math.dev.7433,mistralai/mistral-7b-chat,0.25,7.34e-05,0.25,7.34e-05,0.25,0.0001416,0.25,0.0002658,0.75,0.000292552,0.75,0.00687
hellaswag.val.308,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.51e-05,0.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
mmlu-human-aging.val.76,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.1063,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,0.0,0.00102
bias_detection.dev.119,mistralai/mistral-7b-chat,1.0,5.640000000000001e-05,1.0,5.640000000000001e-05,0.0,0.0001059,1.0,0.0001529999999999,0.0,0.0002064159999999,0.0,0.0078
hellaswag.val.7967,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
hellaswag.val.9851,mistralai/mixtral-8x7b-chat,1.0,0.0001452,0.0,4.84e-05,0.0,7.23e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
mmlu-logical-fallacies.val.34,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-high-school-geography.val.11,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,1.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-prehistory.val.72,mistralai/mixtral-8x7b-chat,0.0,8.22e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-biology.val.29,mistralai/mixtral-8x7b-chat,1.0,6.9e-05,1.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.128,WizardLM/WizardLM-13B-V1.2,0.75,0.0001455,0.25,0.0001042,0.75,0.0001455,0.25,0.000288,0.25,0.000336008,0.75,0.0063199999999999
mmlu-international-law.val.16,mistralai/mixtral-8x7b-chat,1.0,6.9e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
arc-challenge.test.1022,WizardLM/WizardLM-13B-V1.2,1.0,3.4200000000000005e-05,1.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-college-physics.val.80,mistralai/mixtral-8x7b-chat,0.0,7.5e-05,0.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00126
mmlu-formal-logic.val.65,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
mmlu-high-school-computer-science.val.48,mistralai/mistral-7b-chat,0.0,3.320000000000001e-05,0.0,3.320000000000001e-05,0.0,4.98e-05,1.0,9.96e-05,0.0,0.000128816,1.0,0.00167
mmlu-professional-law.val.1309,WizardLM/WizardLM-13B-V1.2,0.0,7.29e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,1.0,0.00244
mmlu-high-school-psychology.val.398,mistralai/mistral-7b-chat,0.0,3.3400000000000005e-05,0.0,3.3400000000000005e-05,1.0,5.01e-05,0.0,0.0001002,0.0,0.000129592,1.0,0.00168
hellaswag.val.4048,mistralai/mixtral-8x7b-chat,0.0,0.0001602,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
hellaswag.val.611,mistralai/mistral-7b-chat,1.0,2.92e-05,1.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,1.0,0.000113296,1.0,0.0015
mmlu-professional-law.val.841,WizardLM/WizardLM-13B-V1.2,0.0,0.0001053,0.0,7.02e-05,0.0,0.0001053,0.0,0.0002106,0.0,0.000272376,0.0,0.00352
hellaswag.val.3173,WizardLM/WizardLM-13B-V1.2,1.0,3.63e-05,1.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,1.0,9.3896e-05,1.0,0.00125
winogrande.dev.975,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,0.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
grade-school-math.dev.2180,WizardLM/WizardLM-13B-V1.2,0.25,0.0001610999999999,0.25,0.0001148,0.25,0.0001610999999999,0.25,0.0002868,0.25,0.000355408,0.5,0.00876
mmlu-sociology.val.129,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
hellaswag.val.6934,mistralai/mistral-7b-chat,0.0,5.76e-05,0.0,5.76e-05,0.0,8.609999999999999e-05,1.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
grade-school-math.dev.5776,WizardLM/WizardLM-13B-V1.2,0.75,0.0001668,0.75,8.319999999999999e-05,0.75,0.0001668,0.75,0.0002951999999999,0.25,0.000332128,0.75,0.01038
grade-school-math.dev.6945,WizardLM/WizardLM-13B-V1.2,0.75,0.0001638,0.25,6.04e-05,0.75,0.0001638,0.75,0.0002712,0.75,0.00029488,0.75,0.0056
hellaswag.val.3904,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,0.0,0.00261
mmlu-professional-law.val.1052,WizardLM/WizardLM-13B-V1.2,0.0,0.0001056,0.0,7.039999999999999e-05,0.0,0.0001056,0.0,0.0002112,0.0,0.000273152,0.0,0.00353
hellaswag.val.2064,mistralai/mixtral-8x7b-chat,1.0,0.0001158,1.0,3.86e-05,1.0,5.76e-05,1.0,0.0001158,1.0,0.000149768,1.0,0.00194
mbpp.dev.226,mistralai/mistral-7b-chat,0.0,4.46e-05,0.0,4.46e-05,0.0,8.850000000000001e-05,0.0,0.0002094,0.0,0.000295656,0.0,0.00967
arc-challenge.test.513,mistralai/mixtral-8x7b-chat,1.0,3.84e-05,0.0,1.28e-05,0.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00068
mmlu-high-school-statistics.val.134,mistralai/mistral-7b-chat,0.0,3.74e-05,0.0,3.74e-05,0.0,5.61e-05,1.0,0.0001122,0.0,0.000145112,1.0,0.00188
hellaswag.val.2991,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.52e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
mmlu-professional-psychology.val.157,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
grade-school-math.dev.4862,meta/code-llama-instruct-34b-chat,0.75,0.00031428,0.25,9.04e-05,0.5,0.0001461,0.75,0.0002226,0.75,0.00031428,0.75,0.00736
mmlu-conceptual-physics.val.100,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,1.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.00073
hellaswag.val.8183,mistralai/mixtral-8x7b-chat,0.0,0.0001349999999999,0.0,4.5e-05,0.0,6.749999999999999e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00229
hellaswag.val.2770,WizardLM/WizardLM-13B-V1.2,0.0,3.06e-05,1.0,2.0600000000000003e-05,0.0,3.06e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00107
hellaswag.val.8319,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
hellaswag.val.9546,mistralai/mixtral-8x7b-chat,1.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.7e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
grade-school-math.dev.1644,WizardLM/WizardLM-13B-V1.2,0.5,0.0001536,0.75,7.3e-05,0.5,0.0001536,0.75,0.0002837999999999,0.25,0.000315056,0.5,0.00838
grade-school-math.dev.2888,WizardLM/WizardLM-13B-V1.2,0.25,0.0001881,0.75,0.000119,0.25,0.0001881,0.5,0.0002586,0.25,0.000397312,0.75,0.01151
hellaswag.val.798,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.349,mistralai/mistral-7b-chat,0.0,3.460000000000001e-05,0.0,3.460000000000001e-05,0.0,5.16e-05,0.0,0.0001038,0.0,0.0001342479999999,1.0,0.00174
mmlu-high-school-us-history.val.146,mistralai/mixtral-8x7b-chat,1.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.51e-05,1.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
mmlu-philosophy.val.43,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,1.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
hellaswag.val.4522,mistralai/mixtral-8x7b-chat,1.0,0.0001434,1.0,4.780000000000001e-05,1.0,7.17e-05,1.0,0.0001434,1.0,0.0001854639999999,1.0,0.00243
hellaswag.val.9760,mistralai/mixtral-8x7b-chat,0.0,0.000159,0.0,5.28e-05,0.0,7.919999999999999e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
hellaswag.val.6591,mistralai/mixtral-8x7b-chat,0.0,0.0001836,0.0,6.120000000000001e-05,0.0,9.18e-05,0.0,0.0001836,0.0,0.0002374559999999,1.0,0.00307
mmlu-high-school-statistics.val.156,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
hellaswag.val.7221,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00242
mmlu-college-medicine.val.62,mistralai/mixtral-8x7b-chat,1.0,3.9e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
hellaswag.val.2928,WizardLM/WizardLM-13B-V1.2,1.0,3.66e-05,1.0,2.44e-05,1.0,3.66e-05,1.0,7.32e-05,1.0,9.4672e-05,1.0,0.0012599999999999
grade-school-math.dev.1874,WizardLM/WizardLM-13B-V1.2,0.75,0.0001278,0.25,6.96e-05,0.75,0.0001278,0.5,0.0001986,0.25,0.000307296,0.75,0.00615
hellaswag.val.7130,WizardLM/WizardLM-13B-V1.2,0.0,9.18e-05,0.0,6.14e-05,0.0,9.18e-05,0.0,0.0001842,0.0,0.000238232,0.0,0.00308
mmlu-high-school-world-history.val.4,mistralai/mixtral-8x7b-chat,1.0,0.0001794,0.0,5.980000000000001e-05,1.0,8.97e-05,1.0,0.0001794,0.0,0.000232024,1.0,0.003
hellaswag.val.863,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.18e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-moral-scenarios.val.446,mistralai/mistral-7b-chat,0.0,3.180000000000001e-05,0.0,3.180000000000001e-05,1.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,1.0,0.0016
mbpp.dev.48,mistralai/mistral-7b-chat,0.0,4.800000000000001e-05,0.0,4.800000000000001e-05,1.0,8.28e-05,1.0,0.0001494,1.0,0.0001482159999999,1.0,0.0089299999999999
mmlu-professional-law.val.1473,WizardLM/WizardLM-13B-V1.2,0.0,7.319999999999999e-05,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,0.0,0.00245
grade-school-math.dev.2539,WizardLM/WizardLM-13B-V1.2,0.25,0.0001653,0.25,0.0001104,0.25,0.0001653,0.25,0.0003149999999999,0.25,0.0003492,0.5,0.00825
mmlu-high-school-chemistry.val.171,mistralai/mixtral-8x7b-chat,0.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
hellaswag.val.3036,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.7470,mistralai/mixtral-8x7b-chat,0.0,0.0001392,1.0,4.64e-05,1.0,6.96e-05,0.0,0.0001392,1.0,0.000180032,1.0,0.00236
hellaswag.val.2431,WizardLM/WizardLM-13B-V1.2,0.0,3.06e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,0.0,0.00103
mmlu-professional-law.val.112,WizardLM/WizardLM-13B-V1.2,1.0,0.0001016999999999,0.0,6.780000000000001e-05,1.0,0.0001016999999999,1.0,0.0002033999999999,0.0,0.000263064,1.0,0.0034
grade-school-math.dev.2928,meta/code-llama-instruct-34b-chat,0.5,0.000266944,0.25,8.980000000000001e-05,0.75,0.0001335,0.5,0.0002226,0.5,0.000266944,0.5,0.00769
arc-challenge.test.245,mistralai/mistral-7b-chat,1.0,1.36e-05,1.0,1.36e-05,0.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00072
mmlu-high-school-mathematics.val.100,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-human-sexuality.val.34,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.744,mistralai/mistral-7b-chat,1.0,2.44e-05,1.0,2.44e-05,1.0,3.63e-05,1.0,7.32e-05,1.0,9.4672e-05,1.0,0.0012599999999999
grade-school-math.dev.598,WizardLM/WizardLM-13B-V1.2,0.25,0.0001746,0.25,8.300000000000001e-05,0.25,0.0001746,0.75,0.000312,0.25,0.000354632,0.25,0.00904
grade-school-math.dev.6772,WizardLM/WizardLM-13B-V1.2,0.25,0.0001791,0.25,9.58e-05,0.25,0.0001791,0.75,0.0004685999999999,0.75,0.000374808,0.5,0.01196
hellaswag.val.6547,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.9e-05,0.0,8.819999999999999e-05,0.0,0.000177,0.0,0.0002289199999999,0.0,0.00299
mmlu-college-physics.val.94,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
mmlu-professional-medicine.val.222,mistralai/mixtral-8x7b-chat,1.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
grade-school-math.dev.6764,WizardLM/WizardLM-13B-V1.2,0.25,0.0001515,0.25,8.02e-05,0.25,0.0001515,0.25,0.0002406,0.25,0.000296432,0.75,0.00932
grade-school-math.dev.230,WizardLM/WizardLM-13B-V1.2,0.25,0.0001728,0.25,9.320000000000002e-05,0.25,0.0001728,0.25,0.0003006,0.25,0.000405072,0.75,0.00845
mmlu-professional-law.val.643,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
arc-challenge.test.384,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,1.0,7.682400000000001e-05,1.0,0.001
mmlu-clinical-knowledge.val.134,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-psychology.val.201,mistralai/mistral-7b-chat,1.0,1.5e-05,1.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-college-computer-science.val.98,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,0.0,0.00233
hellaswag.val.3768,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-moral-scenarios.val.813,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-moral-scenarios.val.708,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,1.0,0.00151
hellaswag.val.7707,mistralai/mixtral-8x7b-chat,1.0,0.0001722,1.0,5.7400000000000006e-05,1.0,8.61e-05,1.0,0.0001722,1.0,0.000222712,1.0,0.00291
abstract2title.test.151,mistralai/mixtral-8x7b-chat,1.0,0.0001193999999999,1.0,3.64e-05,1.0,5.789999999999999e-05,1.0,0.0001193999999999,1.0,0.000145888,1.0,0.00258
mmlu-professional-law.val.153,WizardLM/WizardLM-13B-V1.2,0.0,0.0001068,0.0,7.12e-05,0.0,0.0001068,0.0,0.0002136,0.0,0.000276256,1.0,0.0036
hellaswag.val.7585,WizardLM/WizardLM-13B-V1.2,0.0,8.79e-05,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
hellaswag.val.3668,mistralai/mixtral-8x7b-chat,0.0,0.0001674,0.0,5.580000000000001e-05,0.0,8.34e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.00283
grade-school-math.dev.2300,WizardLM/WizardLM-13B-V1.2,0.25,0.0001827,0.5,0.0001036,0.25,0.0001827,0.75,0.000411,0.25,0.00040352,0.75,0.01078
mmlu-college-medicine.val.105,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.0011899999999999
mmlu-high-school-computer-science.val.58,mistralai/mistral-7b-chat,0.0,5.8800000000000006e-05,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
grade-school-math.dev.4589,WizardLM/WizardLM-13B-V1.2,1.0,0.0001371,0.25,0.0001,1.0,0.0001371,0.75,0.000273,0.25,0.000373256,0.75,0.00797
mmlu-professional-psychology.val.9,mistralai/mixtral-8x7b-chat,0.0,7.44e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
arc-challenge.test.735,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,0.0,1.95e-05,0.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
grade-school-math.dev.6532,WizardLM/WizardLM-13B-V1.2,0.75,0.0001539,0.5,8.42e-05,0.75,0.0001539,0.75,0.0002196,0.25,0.000260736,0.75,0.00656
grade-school-math.dev.1986,WizardLM/WizardLM-13B-V1.2,0.5,0.000135,0.25,6.7e-05,0.5,0.000135,0.5,0.0002634,0.75,0.000352304,0.75,0.00761
grade-school-math.dev.3783,mistralai/mistral-7b-chat,0.25,9.5e-05,0.25,9.5e-05,0.75,0.0001532999999999,0.25,0.0002352,0.25,0.000340664,0.75,0.00774
hellaswag.val.7425,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.003
mmlu-moral-disputes.val.22,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,0.0,0.00123
grade-school-math.dev.375,mistralai/mistral-7b-chat,0.75,8.520000000000001e-05,0.75,8.520000000000001e-05,0.75,0.0001442999999999,0.75,0.0002652,0.25,0.000315832,0.75,0.00653
hellaswag.val.9449,mistralai/mistral-7b-chat,0.0,5.860000000000001e-05,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
mmlu-professional-law.val.631,WizardLM/WizardLM-13B-V1.2,0.0,7.38e-05,1.0,4.920000000000001e-05,0.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
mmlu-econometrics.val.95,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-astronomy.val.81,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
grade-school-math.dev.7214,WizardLM/WizardLM-13B-V1.2,0.25,0.0001568999999999,0.25,8.72e-05,0.25,0.0001568999999999,0.5,0.0002544,0.5,0.000344544,0.5,0.01021
arc-challenge.test.1007,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,1.0,5.432e-05,1.0,0.00071
hellaswag.val.3158,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-high-school-statistics.val.55,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
arc-challenge.test.115,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
grade-school-math.dev.4312,mistralai/mistral-7b-chat,0.25,8.14e-05,0.25,8.14e-05,0.25,0.0001587,0.25,0.0002267999999999,0.25,0.000325144,0.75,0.0082
hellaswag.val.7968,mistralai/mistral-7b-chat,0.0,4.600000000000001e-05,0.0,4.600000000000001e-05,0.0,6.9e-05,0.0,0.000138,0.0,0.0001784799999999,1.0,0.00234
grade-school-math.dev.4697,meta/code-llama-instruct-34b-chat,0.25,0.00037248,0.25,0.000107,0.5,0.0001487999999999,0.25,0.0002214,0.25,0.00037248,0.5,0.00784
mmlu-marketing.val.83,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.7027,WizardLM/WizardLM-13B-V1.2,0.75,0.0001791,0.25,8.14e-05,0.75,0.0001791,0.75,0.0002712,0.75,0.000357736,0.75,0.00912
hellaswag.val.9162,mistralai/mixtral-8x7b-chat,1.0,0.0001362,1.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,1.0,0.0001761519999999,1.0,0.00231
mmlu-professional-law.val.53,WizardLM/WizardLM-13B-V1.2,0.0,8.669999999999999e-05,0.0,5.780000000000001e-05,0.0,8.669999999999999e-05,0.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
mmlu-professional-psychology.val.559,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
mmlu-elementary-mathematics.val.13,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-moral-scenarios.val.857,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,1.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,0.0,0.0014299999999999
mmlu-human-aging.val.209,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-professional-law.val.54,mistralai/mistral-7b-chat,1.0,5.480000000000001e-05,1.0,5.480000000000001e-05,1.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
mmlu-professional-law.val.590,mistralai/mistral-7b-chat,0.0,6.88e-05,0.0,6.88e-05,0.0,0.0001032,0.0,0.0002064,0.0,0.0002669439999999,0.0,0.00345
hellaswag.val.5432,mistralai/mistral-7b-chat,1.0,4.720000000000001e-05,1.0,4.720000000000001e-05,1.0,7.08e-05,1.0,0.0001416,1.0,0.000183136,1.0,0.0024
arc-challenge.test.651,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.7133,WizardLM/WizardLM-13B-V1.2,0.25,0.0001725,0.75,9.76e-05,0.25,0.0001725,0.25,0.0003024,0.25,0.000389552,0.75,0.01031
hellaswag.val.6021,mistralai/mistral-7b-chat,0.0,4.66e-05,0.0,4.66e-05,0.0,6.989999999999999e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00235
mmlu-management.val.59,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,0.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-college-chemistry.val.61,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
hellaswag.val.1318,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.2897,WizardLM/WizardLM-13B-V1.2,0.0,5.4e-05,0.0,3.600000000000001e-05,0.0,5.4e-05,1.0,0.000108,0.0,0.00013968,1.0,0.00181
abstract2title.test.248,mistralai/mixtral-8x7b-chat,1.0,0.0002088,1.0,6.86e-05,1.0,0.0001305,1.0,0.0002088,1.0,0.000266168,1.0,0.00403
hellaswag.val.6845,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
grade-school-math.dev.3354,WizardLM/WizardLM-13B-V1.2,0.5,0.0001569,0.25,8.840000000000001e-05,0.5,0.0001569,0.75,0.000258,0.75,0.0003942079999999,0.5,0.00966
hellaswag.val.1839,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00109
hellaswag.val.6819,WizardLM/WizardLM-13B-V1.2,0.0,6.54e-05,0.0,4.36e-05,0.0,6.54e-05,1.0,0.0001308,0.0,0.000169168,1.0,0.00219
mmlu-professional-law.val.1297,WizardLM/WizardLM-13B-V1.2,1.0,9.24e-05,0.0,6.159999999999999e-05,1.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,0.0,0.00309
mmlu-moral-scenarios.val.139,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-high-school-biology.val.279,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.6188,mistralai/mistral-7b-chat,1.0,5.4600000000000006e-05,1.0,5.4600000000000006e-05,1.0,8.159999999999999e-05,1.0,0.0001638,1.0,0.0002118479999999,1.0,0.00277
mmlu-professional-law.val.412,mistralai/mistral-7b-chat,1.0,5.660000000000001e-05,1.0,5.660000000000001e-05,0.0,8.49e-05,1.0,0.0001698,0.0,0.000219608,1.0,0.00284
hellaswag.val.9388,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,0.0,0.00259
hellaswag.val.9887,WizardLM/WizardLM-13B-V1.2,0.0,6.81e-05,0.0,4.5400000000000006e-05,0.0,6.81e-05,0.0,0.0001356,0.0,0.0001761519999999,1.0,0.00228
winogrande.dev.1074,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,0.0,0.00058
hellaswag.val.2199,mistralai/mistral-7b-chat,1.0,2.78e-05,1.0,2.78e-05,1.0,4.14e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
winogrande.dev.148,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,0.0,0.0005
mmlu-human-sexuality.val.62,mistralai/mixtral-8x7b-chat,0.0,6e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00104
hellaswag.val.429,WizardLM/WizardLM-13B-V1.2,0.0,3.51e-05,1.0,2.34e-05,0.0,3.51e-05,1.0,7.02e-05,1.0,9.0792e-05,0.0,0.00118
mmlu-high-school-mathematics.val.173,mistralai/mixtral-8x7b-chat,0.0,8.58e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-college-medicine.val.146,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,1.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,0.0,0.00083
hellaswag.val.5033,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.9e-05,0.0,8.819999999999999e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
grade-school-math.dev.2150,mistralai/mistral-7b-chat,0.25,9.78e-05,0.25,9.78e-05,0.75,0.0001659,0.75,0.0002808,0.75,0.000381016,0.25,0.01159
hellaswag.val.2098,mistralai/mistral-7b-chat,1.0,2.36e-05,1.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,1.0,9.1568e-05,1.0,0.00122
grade-school-math.dev.1677,mistralai/mistral-7b-chat,0.25,8.64e-05,0.25,8.64e-05,0.75,0.0001824,0.75,0.000282,0.25,0.000346872,0.75,0.01001
mmlu-virology.val.104,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.9711,mistralai/mixtral-8x7b-chat,1.0,0.0001422,0.0,4.74e-05,0.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00241
bias_detection.dev.60,mistralai/mistral-7b-chat,0.0,5.9e-05,0.0,5.9e-05,1.0,9.24e-05,0.0,0.000183,0.0,0.000242112,1.0,0.0085399999999999
mmlu-nutrition.val.63,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-sociology.val.36,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,1.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-high-school-chemistry.val.8,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.5705,WizardLM/WizardLM-13B-V1.2,0.25,0.0001698,0.25,9.72e-05,0.25,0.0001698,0.25,0.0002904,0.75,0.000445424,0.75,0.00888
grade-school-math.dev.1907,mistralai/mixtral-8x7b-chat,0.75,0.0002333999999999,0.75,8.54e-05,0.75,0.0001446,0.75,0.0002333999999999,0.75,0.000338336,0.75,0.00664
mbpp.dev.292,mistralai/mistral-7b-chat,0.0,6.14e-05,0.0,6.14e-05,0.0,6.9e-05,1.0,0.0001488,1.0,0.00020564,1.0,0.00887
mmlu-miscellaneous.val.384,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
winogrande.dev.608,mistralai/mixtral-8x7b-chat,1.0,3.12e-05,0.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
mmlu-professional-law.val.230,WizardLM/WizardLM-13B-V1.2,0.0,8.099999999999999e-05,1.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,0.0,0.00271
hellaswag.val.1747,WizardLM/WizardLM-13B-V1.2,0.0,3.3e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00114
hellaswag.val.2271,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-high-school-us-history.val.198,mistralai/mixtral-8x7b-chat,1.0,0.0001482,1.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,0.0,0.000191672,1.0,0.00251
consensus_summary.dev.216,mistralai/mixtral-8x7b-chat,0.75,0.0001661999999999,1.0,5.0400000000000005e-05,0.75,7.62e-05,0.75,0.0001661999999999,0.75,0.000243664,1.0,0.00267
mmlu-nutrition.val.76,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
mmlu-professional-law.val.1212,WizardLM/WizardLM-13B-V1.2,1.0,0.0001259999999999,0.0,8.400000000000001e-05,1.0,0.0001259999999999,0.0,0.0002519999999999,0.0,0.00032592,1.0,0.0042099999999999
grade-school-math.dev.2621,mistralai/mistral-7b-chat,0.25,6.500000000000001e-05,0.25,6.500000000000001e-05,0.75,0.000147,0.75,0.0002868,0.25,0.000325144,0.75,0.00757
hellaswag.val.8497,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
winogrande.dev.670,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,1.0,1.62e-05,1.0,3.24e-05,0.0,4.1128e-05,1.0,0.00058
mmlu-professional-law.val.1529,WizardLM/WizardLM-13B-V1.2,0.0,8.76e-05,0.0,5.84e-05,0.0,8.76e-05,1.0,0.0001752,0.0,0.000226592,1.0,0.00293
hellaswag.val.8592,mistralai/mixtral-8x7b-chat,0.0,0.0001463999999999,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
mmlu-professional-law.val.372,WizardLM/WizardLM-13B-V1.2,0.0,6.149999999999999e-05,0.0,4.100000000000001e-05,0.0,6.149999999999999e-05,1.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-professional-law.val.827,WizardLM/WizardLM-13B-V1.2,0.0,0.0001409999999999,1.0,9.4e-05,0.0,0.0001409999999999,0.0,0.0002819999999999,0.0,0.00036472,0.0,0.00471
grade-school-math.dev.1093,mistralai/mistral-7b-chat,0.25,0.0001064,0.25,0.0001064,0.25,0.0001902,0.75,0.0003702,0.25,0.000351528,0.5,0.01071
hellaswag.val.8767,mistralai/mistral-7b-chat,1.0,4.6800000000000006e-05,1.0,4.6800000000000006e-05,1.0,6.989999999999999e-05,1.0,0.0001404,1.0,0.000181584,1.0,0.00235
mmlu-professional-law.val.564,WizardLM/WizardLM-13B-V1.2,0.0,9.03e-05,0.0,6.0200000000000006e-05,0.0,9.03e-05,0.0,0.0001806,0.0,0.000233576,0.0,0.00302
grade-school-math.dev.5220,WizardLM/WizardLM-13B-V1.2,0.5,0.0002384999999999,0.25,0.0001082,0.5,0.0002384999999999,0.5,0.0003444,0.25,0.00050828,0.5,0.0123699999999999
grade-school-math.dev.3253,mistralai/mixtral-8x7b-chat,0.75,0.000243,0.75,8.44e-05,0.75,0.0001605,0.75,0.000243,0.5,0.00028712,0.5,0.00757
hellaswag.val.1872,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.5909,mistralai/mixtral-8x7b-chat,0.0,0.0001758,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
hellaswag.val.3832,WizardLM/WizardLM-13B-V1.2,0.0,6.989999999999999e-05,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
mmlu-high-school-government-and-politics.val.24,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-nutrition.val.156,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
arc-challenge.test.619,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mmlu-elementary-mathematics.val.222,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00113
hellaswag.val.4922,mistralai/mistral-7b-chat,1.0,5.480000000000001e-05,1.0,5.480000000000001e-05,1.0,8.189999999999998e-05,1.0,0.0001643999999999,1.0,0.000212624,1.0,0.00278
grade-school-math.dev.514,mistralai/mistral-7b-chat,0.25,5.74e-05,0.25,5.74e-05,0.5,0.0001347,0.75,0.0002196,0.75,0.000273152,0.5,0.00573
grade-school-math.dev.2915,WizardLM/WizardLM-13B-V1.2,0.25,0.0001253999999999,0.25,0.0005924,0.25,0.0001253999999999,0.25,0.0002327999999999,0.25,0.000273928,0.75,0.00909
mmlu-professional-law.val.969,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,0.0,7.83e-05,1.0,0.0001566,0.0,0.000202536,0.0,0.00265
mmlu-electrical-engineering.val.4,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
mmlu-philosophy.val.122,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00118
winogrande.dev.257,mistralai/mistral-7b-chat,0.0,1.22e-05,0.0,1.22e-05,0.0,1.8e-05,0.0,3.66e-05,0.0,4.7336e-05,1.0,0.00065
hellaswag.val.3352,mistralai/mixtral-8x7b-chat,0.0,0.0001523999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001523999999999,0.0,0.00019788,1.0,0.00259
hellaswag.val.6339,mistralai/mixtral-8x7b-chat,1.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.98e-05,1.0,0.0001596,0.0,0.0002064159999999,0.0,0.0027
grade-school-math.dev.5585,mistralai/mistral-7b-chat,0.5,9.34e-05,0.5,9.34e-05,0.5,0.0001413,0.5,0.0002262,0.75,0.000346096,0.75,0.00871
grade-school-math.dev.1252,mistralai/mixtral-8x7b-chat,0.75,0.0002615999999999,0.75,9.26e-05,0.0,0.0001640999999999,0.75,0.0002615999999999,0.25,0.000262288,0.75,0.00845
winogrande.dev.341,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,1.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,1.0,0.00055
mmlu-high-school-psychology.val.279,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.6779,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.51e-05,0.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
hellaswag.val.1496,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-accounting.val.208,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-high-school-us-history.val.8,WizardLM/WizardLM-13B-V1.2,0.0,9.33e-05,0.0,6.22e-05,0.0,9.33e-05,1.0,0.0001866,0.0,0.000241336,1.0,0.00312
mmlu-professional-law.val.260,WizardLM/WizardLM-13B-V1.2,0.0,8.91e-05,0.0,5.94e-05,0.0,8.91e-05,1.0,0.0001782,0.0,0.000230472,1.0,0.00298
mmlu-moral-scenarios.val.564,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,0.0,0.00147
hellaswag.val.4095,WizardLM/WizardLM-13B-V1.2,1.0,7.02e-05,1.0,4.6800000000000006e-05,1.0,7.02e-05,1.0,0.0001404,1.0,0.000181584,1.0,0.00238
hellaswag.val.6105,mistralai/mistral-7b-chat,0.0,6e-05,0.0,6e-05,0.0,8.999999999999999e-05,0.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
grade-school-math.dev.4005,mistralai/mistral-7b-chat,0.75,9.18e-05,0.75,9.18e-05,0.75,0.0001305,0.75,0.000198,0.75,0.000270824,0.75,0.00624
mmlu-high-school-chemistry.val.196,mistralai/mixtral-8x7b-chat,0.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-law.val.738,WizardLM/WizardLM-13B-V1.2,0.0,0.000108,0.0,7.2e-05,0.0,0.000108,0.0,0.000216,0.0,0.00027936,1.0,0.00361
grade-school-math.dev.3131,WizardLM/WizardLM-13B-V1.2,0.5,0.000135,0.5,7.76e-05,0.5,0.000135,0.5,0.0002196,0.5,0.000257632,0.75,0.00606
grade-school-math.dev.4484,mistralai/mistral-7b-chat,0.5,7.94e-05,0.5,7.94e-05,0.75,0.0001376999999999,0.25,0.0001968,0.75,0.000352304,0.5,0.00639
mbpp.dev.391,mistralai/mistral-7b-chat,1.0,6.2e-05,1.0,6.2e-05,0.0,8.579999999999998e-05,1.0,0.0002508,0.0,0.000126488,1.0,0.01134
hellaswag.val.815,mistralai/mixtral-8x7b-chat,1.0,8.94e-05,1.0,2.9800000000000003e-05,0.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-prehistory.val.36,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
hellaswag.val.4382,WizardLM/WizardLM-13B-V1.2,0.0,8.46e-05,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00284
mmlu-security-studies.val.105,mistralai/mistral-7b-chat,1.0,4.860000000000001e-05,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,1.0,0.00244
arc-challenge.val.35,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,1.0,1.62e-05,1.0,3.24e-05,1.0,4.1904e-05,1.0,0.0005499999999999
mmlu-moral-scenarios.val.339,mistralai/mixtral-8x7b-chat,0.0,8.04e-05,0.0,2.68e-05,1.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00138
grade-school-math.dev.6705,WizardLM/WizardLM-13B-V1.2,0.25,0.0001623,0.25,9.680000000000002e-05,0.25,0.0001623,0.25,0.0002628,0.25,0.00031428,0.5,0.01074
mmlu-security-studies.val.129,mistralai/mistral-7b-chat,0.0,3.5600000000000005e-05,0.0,3.5600000000000005e-05,1.0,5.34e-05,1.0,0.0001068,0.0,0.0001381279999999,1.0,0.00179
hellaswag.val.7015,mistralai/mistral-7b-chat,0.0,4.860000000000001e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,1.0,0.00244
mmlu-high-school-chemistry.val.6,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-moral-scenarios.val.648,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,0.0,0.00145
mmlu-prehistory.val.93,mistralai/mistral-7b-chat,1.0,1.96e-05,1.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-professional-law.val.621,WizardLM/WizardLM-13B-V1.2,1.0,0.0001119,0.0,7.46e-05,1.0,0.0001119,1.0,0.0002238,0.0,0.000289448,1.0,0.00374
grade-school-math.dev.194,mistralai/mistral-7b-chat,0.75,8.16e-05,0.75,8.16e-05,0.5,0.0001626,0.25,0.0002184,0.5,0.000313504,0.75,0.00729
mmlu-professional-law.val.1472,WizardLM/WizardLM-13B-V1.2,0.0,0.0001245,0.0,8.3e-05,0.0,0.0001245,0.0,0.000249,0.0,0.00032204,0.0,0.00416
hellaswag.val.446,WizardLM/WizardLM-13B-V1.2,1.0,3.09e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.7083,mistralai/mistral-7b-chat,0.25,8.840000000000001e-05,0.25,8.840000000000001e-05,0.75,0.0001742999999999,0.5,0.0002586,0.75,0.000308072,0.5,0.00711
mmlu-high-school-world-history.val.133,WizardLM/WizardLM-13B-V1.2,1.0,6.42e-05,1.0,4.280000000000001e-05,1.0,6.42e-05,1.0,0.0001284,0.0,0.000166064,1.0,0.00215
hellaswag.val.7857,mistralai/mixtral-8x7b-chat,0.0,0.0001452,1.0,4.84e-05,1.0,7.23e-05,0.0,0.0001452,1.0,0.000187792,1.0,0.00246
grade-school-math.dev.3454,mistralai/mistral-7b-chat,0.25,0.0001088,0.25,0.0001088,0.25,0.0001922999999999,0.25,0.0003558,0.25,0.000458616,0.75,0.01121
grade-school-math.dev.1567,WizardLM/WizardLM-13B-V1.2,0.25,0.0001539,0.25,0.0001012,0.25,0.0001539,0.25,0.000381,0.25,0.00041904,0.75,0.01411
consensus_summary.dev.121,mistralai/mixtral-8x7b-chat,0.75,0.0002201999999999,0.75,5.62e-05,0.75,0.000105,0.75,0.0002201999999999,0.75,0.000238232,0.75,0.00456
hellaswag.val.4847,WizardLM/WizardLM-13B-V1.2,0.0,6.09e-05,0.0,4.06e-05,0.0,6.09e-05,0.0,0.0001217999999999,0.0,0.000157528,1.0,0.00204
mmlu-professional-law.val.31,WizardLM/WizardLM-13B-V1.2,1.0,8.58e-05,0.0,5.720000000000001e-05,1.0,8.58e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.00287
hellaswag.val.4103,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,1.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
hellaswag.val.5231,mistralai/mixtral-8x7b-chat,0.0,0.0001433999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001433999999999,0.0,0.00018624,1.0,0.00244
hellaswag.val.2287,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,1.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,1.0,8.380800000000001e-05,1.0,0.00112
mmlu-professional-law.val.279,WizardLM/WizardLM-13B-V1.2,0.0,0.0001032,0.0,6.88e-05,0.0,0.0001032,0.0,0.0002064,0.0,0.0002669439999999,1.0,0.00345
grade-school-math.dev.134,WizardLM/WizardLM-13B-V1.2,0.25,0.0001631999999999,0.25,8.7e-05,0.25,0.0001631999999999,0.5,0.0002844,0.25,0.000297208,0.75,0.00819
hellaswag.val.27,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
hellaswag.val.8397,mistralai/mixtral-8x7b-chat,1.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00249
hellaswag.val.387,WizardLM/WizardLM-13B-V1.2,0.0,3.9e-05,0.0,2.6e-05,0.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
hellaswag.val.1940,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00131
grade-school-math.dev.1739,WizardLM/WizardLM-13B-V1.2,0.5,0.0001368,0.5,7.94e-05,0.5,0.0001368,0.75,0.0002322,0.25,0.000350752,0.5,0.00732
grade-school-math.dev.3286,WizardLM/WizardLM-13B-V1.2,0.5,0.0001497,0.25,0.0001052,0.5,0.0001497,0.5,0.0002622,0.25,0.00035696,0.5,0.00746
mmlu-prehistory.val.82,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-moral-scenarios.val.855,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-professional-medicine.val.1,mistralai/mixtral-8x7b-chat,1.0,0.0001182,1.0,3.94e-05,0.0,5.91e-05,1.0,0.0001182,0.0,0.0001528719999999,1.0,0.00201
mmlu-professional-law.val.1280,mistralai/mistral-7b-chat,0.0,8.3e-05,0.0,8.3e-05,0.0,0.0001245,1.0,0.000249,0.0,0.00032204,1.0,0.00416
winogrande.dev.571,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,0.0,0.0005
hellaswag.val.5595,mistralai/mixtral-8x7b-chat,1.0,0.0001518,0.0,5.06e-05,0.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.1666,mistralai/mistral-7b-chat,0.75,7.280000000000001e-05,0.75,7.280000000000001e-05,0.75,0.0001272,0.75,0.0002442,0.25,0.0002925519999999,0.75,0.00652
mmlu-miscellaneous.val.437,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.2889,meta/code-llama-instruct-34b-chat,0.25,0.0003298,0.75,0.0001018,0.75,0.0001587,0.75,0.0002616,0.25,0.0003298,0.75,0.01053
hellaswag.val.8476,mistralai/mixtral-8x7b-chat,1.0,0.0001314,0.0,4.380000000000001e-05,0.0,6.57e-05,1.0,0.0001314,0.0,0.0001699439999999,1.0,0.0022
mmlu-high-school-mathematics.val.266,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,0.0,6.3e-05,0.0,8.2256e-05,1.0,0.00107
hellaswag.val.8991,WizardLM/WizardLM-13B-V1.2,1.0,6.81e-05,0.0,4.5400000000000006e-05,1.0,6.81e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00231
hellaswag.val.5147,mistralai/mixtral-8x7b-chat,0.0,0.0001686,0.0,5.62e-05,0.0,8.4e-05,0.0,0.0001686,0.0,0.000218056,0.0,0.00285
hellaswag.val.6442,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
hellaswag.val.8771,mistralai/mixtral-8x7b-chat,0.0,0.0001866,0.0,6.22e-05,0.0,9.33e-05,0.0,0.0001866,0.0,0.000241336,1.0,0.00315
grade-school-math.dev.1767,mistralai/mixtral-8x7b-chat,0.5,0.0002766,0.25,6.04e-05,0.5,0.0001727999999999,0.5,0.0002766,0.25,0.000253752,0.75,0.0091
hellaswag.val.1770,WizardLM/WizardLM-13B-V1.2,0.0,3.51e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
mmlu-professional-law.val.127,WizardLM/WizardLM-13B-V1.2,1.0,0.0001347,1.0,8.98e-05,1.0,0.0001347,1.0,0.0002694,0.0,0.000348424,0.0,0.0045
mmlu-human-sexuality.val.33,mistralai/mistral-7b-chat,1.0,1.34e-05,1.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-college-chemistry.val.64,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.2674,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.93e-05,0.0,7.92e-05,0.0,0.000102432,1.0,0.00133
hellaswag.val.626,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.7143,mistralai/mixtral-8x7b-chat,0.25,0.0002279999999999,0.25,7.460000000000001e-05,0.5,0.0001401,0.25,0.0002279999999999,0.75,0.000281688,0.5,0.006
hellaswag.val.6078,mistralai/mistral-7b-chat,1.0,5.7400000000000006e-05,1.0,5.7400000000000006e-05,1.0,8.61e-05,1.0,0.0001722,1.0,0.000222712,1.0,0.00291
abstract2title.test.247,mistralai/mixtral-8x7b-chat,1.0,0.0001338,1.0,2.82e-05,1.0,4.83e-05,1.0,0.0001338,1.0,0.00012028,1.0,0.0021
grade-school-math.dev.596,meta/code-llama-instruct-34b-chat,0.25,0.000342216,0.25,8.58e-05,0.75,0.0001428,0.75,0.000324,0.25,0.000342216,0.5,0.01094
mmlu-moral-scenarios.val.357,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
grade-school-math.dev.6748,mistralai/mixtral-8x7b-chat,0.25,0.000243,0.5,0.0001082,0.25,0.0001955999999999,0.25,0.000243,0.25,0.000366272,0.5,0.00928
arc-challenge.val.286,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.1710,WizardLM/WizardLM-13B-V1.2,0.25,0.0001442999999999,0.25,8.240000000000001e-05,0.25,0.0001442999999999,0.75,0.0002244,0.25,0.00031428,0.75,0.00763
hellaswag.val.9161,mistralai/mixtral-8x7b-chat,0.0,0.0001518,0.0,5.06e-05,0.0,7.56e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-sociology.val.38,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-high-school-geography.val.196,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.6694,mistralai/mistral-7b-chat,0.0,4.56e-05,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,1.0,0.00232
mmlu-elementary-mathematics.val.70,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00108
grade-school-math.dev.3317,WizardLM/WizardLM-13B-V1.2,0.75,0.0001461,0.5,8.960000000000001e-05,0.75,0.0001461,0.25,0.0002688,0.5,0.000370152,0.5,0.00663
mmlu-us-foreign-policy.val.6,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
arc-challenge.test.1013,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
grade-school-math.dev.5444,mistralai/mistral-7b-chat,0.75,8.82e-05,0.75,8.82e-05,0.5,0.0001595999999999,0.5,0.0002604,0.25,0.000300312,0.5,0.00805
hellaswag.val.3344,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
mmlu-moral-scenarios.val.389,mistralai/mixtral-8x7b-chat,1.0,8.52e-05,0.0,2.84e-05,1.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00146
hellaswag.val.5661,mistralai/mixtral-8x7b-chat,1.0,0.0001482,1.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,1.0,0.000191672,1.0,0.00248
hellaswag.val.7401,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,1.0,7.8e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-philosophy.val.292,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.6180,mistralai/mistral-7b-chat,0.0,5.300000000000001e-05,0.0,5.300000000000001e-05,0.0,7.919999999999999e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00266
hellaswag.val.2074,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,1.0,2.97e-05,1.0,6e-05,1.0,7.76e-05,1.0,0.00104
hellaswag.val.3840,mistralai/mixtral-8x7b-chat,0.0,0.0001686,0.0,5.62e-05,0.0,8.4e-05,0.0,0.0001686,0.0,0.000218056,1.0,0.00285
mmlu-marketing.val.104,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-world-religions.val.161,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
winogrande.dev.35,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,1.0,1.62e-05,1.0,3.24e-05,1.0,4.1904e-05,1.0,0.0005499999999999
hellaswag.val.7410,mistralai/mixtral-8x7b-chat,1.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.19e-05,1.0,0.0001638,0.0,0.0002118479999999,1.0,0.00274
hellaswag.val.6065,mistralai/mixtral-8x7b-chat,1.0,0.0001308,0.0,4.36e-05,0.0,6.54e-05,1.0,0.0001308,0.0,0.000169168,1.0,0.00219
arc-challenge.val.229,WizardLM/WizardLM-13B-V1.2,0.0,2.67e-05,1.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,0.0,0.0009
hellaswag.val.4698,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.189999999999998e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
grade-school-math.dev.3275,mistralai/mixtral-8x7b-chat,0.5,0.0002172,0.25,9.02e-05,0.75,0.0001314,0.5,0.0002172,0.75,0.000260736,0.75,0.0051699999999999
grade-school-math.dev.5183,mistralai/mixtral-8x7b-chat,0.75,0.0002724,0.25,7.7e-05,0.75,0.0001722,0.75,0.0002724,0.75,0.000342216,0.75,0.01057
grade-school-math.dev.2321,mistralai/mistral-7b-chat,0.25,5.84e-05,0.25,5.84e-05,0.25,0.0001338,0.25,0.0002094,0.25,0.000311176,0.75,0.00679
mmlu-marketing.val.66,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
hellaswag.val.8059,mistralai/mixtral-8x7b-chat,0.0,0.0001278,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00217
grade-school-math.dev.3251,mistralai/mistral-7b-chat,0.5,8.400000000000001e-05,0.5,8.400000000000001e-05,0.5,0.0001623,0.75,0.0002634,0.75,0.000367048,0.75,0.00916
grade-school-math.dev.136,mistralai/mixtral-8x7b-chat,0.25,0.0003407999999999,0.25,0.0001006,0.25,0.0001539,0.25,0.0003407999999999,0.75,0.000486552,0.5,0.01189
arc-challenge.test.837,mistralai/mistral-7b-chat,1.0,2.28e-05,1.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,1.0,8.846400000000001e-05,1.0,0.00115
mmlu-college-chemistry.val.58,mistralai/mixtral-8x7b-chat,0.0,6.96e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.0012
hellaswag.val.3292,mistralai/mixtral-8x7b-chat,1.0,0.0001302,1.0,4.340000000000001e-05,1.0,6.51e-05,1.0,0.0001302,1.0,0.0001683919999999,1.0,0.00221
grade-school-math.dev.2909,mistralai/mistral-7b-chat,0.25,9.36e-05,0.25,9.36e-05,0.75,0.0001296,0.25,0.0002357999999999,0.75,0.000300312,0.5,0.00549
grade-school-math.dev.775,mistralai/mistral-7b-chat,0.25,8.22e-05,0.25,8.22e-05,0.75,0.0001338,0.25,0.0002063999999999,0.75,0.000484224,0.5,0.01059
hellaswag.val.4042,mistralai/mixtral-8x7b-chat,0.0,0.0001806,0.0,6.0200000000000006e-05,0.0,9.03e-05,0.0,0.0001806,0.0,0.000233576,1.0,0.00302
accounting_audit.dev.5,mistralai/mistral-7b-chat,0.0,4.12e-05,0.0,4.12e-05,0.0,4.2600000000000005e-05,1.0,0.0001296,0.0,0.0001101919999999,0.0,0.0014
mmlu-professional-law.val.612,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,0.0,0.00295
hellaswag.val.5277,mistralai/mixtral-8x7b-chat,1.0,0.000159,0.0,5.300000000000001e-05,0.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00266
hellaswag.val.1241,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00137
winogrande.dev.518,mistralai/mistral-7b-chat,0.0,1.06e-05,0.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,0.0,4.1128e-05,1.0,0.00054
grade-school-math.dev.1114,mistralai/mistral-7b-chat,0.25,0.0001074,0.25,0.0001074,0.75,0.0001220999999999,0.25,0.0002693999999999,0.5,0.000297208,0.75,0.00843
hellaswag.val.3023,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,0.0,5.28e-05,1.0,6.828800000000001e-05,0.0,0.00089
mmlu-elementary-mathematics.val.156,mistralai/mistral-7b-chat,1.0,2.8e-05,1.0,2.8e-05,1.0,4.2e-05,0.0,8.34e-05,0.0,0.00010864,1.0,0.00141
mmlu-professional-law.val.148,WizardLM/WizardLM-13B-V1.2,0.0,7.35e-05,1.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,0.0,0.00246
arc-challenge.test.989,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,1.0,6.673599999999999e-05,1.0,0.0009
hellaswag.val.5067,WizardLM/WizardLM-13B-V1.2,0.0,7.83e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,0.0,0.00265
mmlu-professional-law.val.1441,WizardLM/WizardLM-13B-V1.2,0.0,5.85e-05,1.0,3.9000000000000006e-05,0.0,5.85e-05,0.0,0.000117,0.0,0.0001513199999999,1.0,0.00196
hellaswag.val.5331,mistralai/mistral-7b-chat,0.0,5.800000000000001e-05,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
grade-school-math.dev.3536,WizardLM/WizardLM-13B-V1.2,0.5,0.0001491,0.25,8.26e-05,0.5,0.0001491,0.75,0.000261,0.25,0.000315832,0.5,0.00755
bias_detection.dev.137,mistralai/mistral-7b-chat,0.0,5.860000000000001e-05,0.0,5.860000000000001e-05,1.0,0.0001197,1.0,0.0003239999999999,1.0,0.000249096,0.0,0.01018
hellaswag.val.7947,mistralai/mixtral-8x7b-chat,1.0,0.0001446,1.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,1.0,0.0001446,1.0,0.000187016,1.0,0.00242
hellaswag.val.4466,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
hellaswag.val.2959,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
arc-challenge.test.598,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-college-medicine.val.23,mistralai/mixtral-8x7b-chat,1.0,7.02e-05,0.0,2.34e-05,0.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,0.0,0.00121
grade-school-math.dev.5701,WizardLM/WizardLM-13B-V1.2,0.25,0.0001178999999999,0.75,7.68e-05,0.25,0.0001178999999999,0.25,0.0002099999999999,0.75,0.000293328,0.5,0.00616
hellaswag.val.5124,mistralai/mistral-7b-chat,0.0,4.980000000000001e-05,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
mmlu-professional-law.val.1184,WizardLM/WizardLM-13B-V1.2,1.0,7.41e-05,0.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,0.0,0.000191672,1.0,0.00248
mmlu-world-religions.val.98,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
hellaswag.val.2956,mistralai/mistral-7b-chat,1.0,2.68e-05,1.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00138
mmlu-college-biology.val.40,mistralai/mixtral-8x7b-chat,1.0,0.0001428,0.0,4.7600000000000005e-05,0.0,7.14e-05,1.0,0.0001428,0.0,0.000184688,1.0,0.00239
mtbench-reference.dev.8,WizardLM/WizardLM-13B-V1.2,0.1,0.0002376,0.2,0.000204,0.1,0.0002376,0.2,0.0007164,0.1,0.000510608,0.2,0.02572
grade-school-math.dev.4363,WizardLM/WizardLM-13B-V1.2,0.75,0.0001791,0.25,0.0001176,0.75,0.0001791,0.5,0.0003006,0.25,0.000363944,0.75,0.00982
mmlu-professional-psychology.val.353,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mmlu-professional-psychology.val.210,mistralai/mixtral-8x7b-chat,0.0,8.340000000000001e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-high-school-psychology.val.154,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.3300,mistralai/mistral-7b-chat,0.0,4.7e-05,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00239
mmlu-human-aging.val.104,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-moral-scenarios.val.636,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,1.0,0.0013599999999999
grade-school-math.dev.6514,mistralai/mistral-7b-chat,0.75,8.300000000000001e-05,0.75,8.300000000000001e-05,0.5,0.0001365,0.5,0.0002357999999999,0.5,0.000304192,0.75,0.00622
grade-school-math.dev.6829,WizardLM/WizardLM-13B-V1.2,0.25,0.0001746,0.25,6.46e-05,0.25,0.0001746,0.25,0.000213,0.25,0.000270824,0.75,0.00598
mmlu-professional-law.val.1228,mistralai/mistral-7b-chat,0.0,5.160000000000001e-05,0.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,0.0,0.000200208,1.0,0.00259
grade-school-math.dev.1245,mistralai/mistral-7b-chat,0.5,7.999999999999999e-05,0.5,7.999999999999999e-05,0.25,0.0001886999999999,0.25,0.0002909999999999,0.75,0.000326696,0.5,0.00927
grade-school-math.dev.6741,WizardLM/WizardLM-13B-V1.2,0.5,0.0001394999999999,0.5,9.78e-05,0.5,0.0001394999999999,0.5,0.0002808,0.25,0.000304192,0.5,0.00804
mmlu-college-physics.val.87,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,1.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00108
hellaswag.val.9440,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00281
mmlu-high-school-statistics.val.71,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-anatomy.val.14,mistralai/mixtral-8x7b-chat,0.0,7.92e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,0.0,0.00133
mmlu-security-studies.val.179,mistralai/mixtral-8x7b-chat,0.0,0.0001074,0.0,3.58e-05,0.0,5.37e-05,0.0,0.0001074,0.0,0.000138904,1.0,0.0018
grade-school-math.dev.615,WizardLM/WizardLM-13B-V1.2,0.5,0.0001428,0.25,9.8e-05,0.5,0.0001428,0.25,0.0002573999999999,0.25,0.000394208,0.75,0.0072499999999999
mmlu-professional-accounting.val.66,mistralai/mistral-7b-chat,0.0,3.160000000000001e-05,0.0,3.160000000000001e-05,0.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00162
hellaswag.val.9164,WizardLM/WizardLM-13B-V1.2,1.0,7.98e-05,0.0,5.3200000000000006e-05,1.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.0027
mmlu-professional-law.val.1486,mistralai/mistral-7b-chat,0.0,6.819999999999999e-05,0.0,6.819999999999999e-05,0.0,0.0001023,1.0,0.0002046,0.0,0.000264616,1.0,0.00342
mbpp.dev.122,mistralai/mistral-7b-chat,0.0,7.400000000000001e-05,0.0,7.400000000000001e-05,1.0,0.0001010999999999,1.0,0.0001974,0.0,0.000132696,1.0,0.0143299999999999
hellaswag.val.9009,mistralai/mixtral-8x7b-chat,1.0,0.0001476,0.0,4.920000000000001e-05,1.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.3751,mistralai/mistral-7b-chat,0.5,7.92e-05,0.5,7.92e-05,0.25,0.0001269,0.5,0.0002369999999999,0.25,0.000304192,0.5,0.00665
mmlu-high-school-government-and-politics.val.43,mistralai/mistral-7b-chat,0.0,3.2000000000000005e-05,0.0,3.2000000000000005e-05,1.0,4.8e-05,1.0,9.6e-05,0.0,0.00012416,1.0,0.00161
mbpp.dev.175,mistralai/mistral-7b-chat,0.0,6.48e-05,0.0,6.48e-05,0.0,0.0001365,0.0,0.0002538,1.0,0.000241336,1.0,0.0137899999999999
mmlu-professional-law.val.1146,mistralai/mistral-7b-chat,0.0,3.94e-05,0.0,3.94e-05,0.0,5.91e-05,0.0,0.0001182,0.0,0.0001528719999999,1.0,0.00198
hellaswag.val.5339,mistralai/mixtral-8x7b-chat,1.0,0.0001386,1.0,4.6200000000000005e-05,1.0,6.93e-05,1.0,0.0001386,1.0,0.000179256,1.0,0.00235
grade-school-math.dev.1470,WizardLM/WizardLM-13B-V1.2,0.25,0.0001550999999999,0.25,8.620000000000001e-05,0.25,0.0001550999999999,0.25,0.0002285999999999,0.75,0.000299536,0.75,0.00853
mmlu-professional-law.val.1517,WizardLM/WizardLM-13B-V1.2,1.0,8.07e-05,0.0,5.380000000000001e-05,1.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-nutrition.val.244,mistralai/mixtral-8x7b-chat,1.0,6.06e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.4686,mistralai/mixtral-8x7b-chat,0.25,0.0002238,0.25,5.82e-05,0.75,0.0001220999999999,0.25,0.0002238,0.75,0.000252976,0.5,0.00648
hellaswag.val.6600,WizardLM/WizardLM-13B-V1.2,1.0,6.63e-05,1.0,4.420000000000001e-05,1.0,6.63e-05,0.0,0.0001326,1.0,0.000171496,1.0,0.00225
hellaswag.val.9036,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
hellaswag.val.8126,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.479999999999999e-05,0.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
grade-school-math.dev.5326,WizardLM/WizardLM-13B-V1.2,0.75,0.0001338,0.25,8.22e-05,0.75,0.0001338,0.75,0.0002472,0.75,0.000272376,0.75,0.0069
hellaswag.val.4635,mistralai/mixtral-8x7b-chat,1.0,0.000129,0.0,4.3e-05,0.0,6.45e-05,1.0,0.000129,0.0,0.00016684,1.0,0.00219
mmlu-miscellaneous.val.183,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
grade-school-math.dev.4167,WizardLM/WizardLM-13B-V1.2,0.5,0.0001643999999999,0.25,0.0001006,0.5,0.0001643999999999,0.75,0.0002676,0.25,0.000392656,0.75,0.01274
mmlu-sociology.val.113,mistralai/mixtral-8x7b-chat,0.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-professional-law.val.1084,WizardLM/WizardLM-13B-V1.2,0.0,5.85e-05,1.0,3.9000000000000006e-05,0.0,5.85e-05,0.0,0.000117,0.0,0.0001513199999999,0.0,0.00199
mmlu-logical-fallacies.val.129,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
grade-school-math.dev.1491,mistralai/mistral-7b-chat,0.75,8.560000000000001e-05,0.75,8.560000000000001e-05,0.75,0.0001308,0.75,0.0002112,0.75,0.000242112,0.75,0.0066999999999999
mmlu-high-school-chemistry.val.137,mistralai/mixtral-8x7b-chat,0.0,6.659999999999999e-05,1.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-us-foreign-policy.val.54,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-astronomy.val.70,mistralai/mixtral-8x7b-chat,1.0,6.06e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.2542,WizardLM/WizardLM-13B-V1.2,0.75,0.0001107,0.25,9.660000000000002e-05,0.75,0.0001107,0.75,0.0002256,0.75,0.000309624,0.75,0.00908
arc-challenge.test.840,mistralai/mistral-7b-chat,1.0,1.44e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,1.0,5.5872e-05,1.0,0.00076
grade-school-math.dev.6105,mistralai/mistral-7b-chat,0.5,7.68e-05,0.5,7.68e-05,0.5,0.0001449,0.5,0.0002262,0.5,0.00030652,0.5,0.00701
mmlu-elementary-mathematics.val.356,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-professional-accounting.val.119,WizardLM/WizardLM-13B-V1.2,0.0,3.9e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
mmlu-professional-law.val.618,mistralai/mistral-7b-chat,0.0,7.08e-05,0.0,7.08e-05,1.0,0.0001061999999999,0.0,0.0002123999999999,0.0,0.0002747039999999,0.0,0.00358
hellaswag.val.6605,mistralai/mixtral-8x7b-chat,1.0,0.0001392,1.0,4.64e-05,1.0,6.929999999999999e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00236
arc-challenge.test.331,mistralai/mixtral-8x7b-chat,0.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
mmlu-international-law.val.19,mistralai/mistral-7b-chat,0.0,3.8e-05,0.0,3.8e-05,0.0,5.7e-05,0.0,0.0001139999999999,0.0,0.0001474399999999,0.0,0.00191
mmlu-high-school-world-history.val.9,WizardLM/WizardLM-13B-V1.2,1.0,0.0001652999999999,0.0,0.0001102,1.0,0.0001652999999999,1.0,0.0003305999999999,0.0,0.000427576,1.0,0.00552
mmlu-moral-scenarios.val.230,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
hellaswag.val.9876,mistralai/mixtral-8x7b-chat,1.0,0.0001572,1.0,5.24e-05,1.0,7.86e-05,1.0,0.0001572,1.0,0.000203312,1.0,0.00266
mmlu-marketing.val.151,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
hellaswag.val.4557,mistralai/mixtral-8x7b-chat,0.0,0.0001332,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00226
hellaswag.val.9193,mistralai/mistral-7b-chat,1.0,5.160000000000001e-05,1.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00259
mmlu-logical-fallacies.val.13,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-microeconomics.val.140,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-professional-law.val.1494,WizardLM/WizardLM-13B-V1.2,0.0,6.869999999999999e-05,1.0,4.580000000000001e-05,0.0,6.869999999999999e-05,0.0,0.0001373999999999,0.0,0.000177704,1.0,0.0023
mmlu-management.val.43,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-professional-law.val.520,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-high-school-world-history.val.35,WizardLM/WizardLM-13B-V1.2,1.0,0.0001553999999999,0.0,0.0001036,1.0,0.0001553999999999,1.0,0.0003107999999999,0.0,0.000401968,1.0,0.0051899999999999
mmlu-high-school-physics.val.100,mistralai/mixtral-8x7b-chat,0.0,0.0001055999999999,1.0,3.520000000000001e-05,0.0,5.28e-05,0.0,0.0001055999999999,0.0,0.000136576,1.0,0.00177
mmlu-professional-medicine.val.44,mistralai/mixtral-8x7b-chat,0.0,0.0001014,0.0,3.38e-05,0.0,5.07e-05,0.0,0.0001014,0.0,0.000131144,1.0,0.0017
grade-school-math.dev.1717,mistralai/mistral-7b-chat,0.25,9.46e-05,0.25,9.46e-05,0.25,0.0001619999999999,0.25,0.0002526,0.25,0.000344544,0.5,0.00893
mmlu-professional-law.val.202,WizardLM/WizardLM-13B-V1.2,0.0,0.0001311,0.0,8.74e-05,0.0,0.0001311,0.0,0.0002622,0.0,0.000339112,0.0,0.00441
hellaswag.val.6571,mistralai/mistral-7b-chat,0.0,5.24e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-high-school-psychology.val.51,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
grade-school-math.dev.1525,mistralai/mistral-7b-chat,0.25,8.6e-05,0.25,8.6e-05,0.25,8.91e-05,0.75,0.0002736,0.25,0.00041516,0.75,0.00992
mmlu-moral-disputes.val.123,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.4382,mistralai/mistral-7b-chat,0.25,9.16e-05,0.25,9.16e-05,0.25,0.0001623,1.0,0.0001955999999999,0.25,0.000423696,0.75,0.00984
grade-school-math.dev.2252,WizardLM/WizardLM-13B-V1.2,0.75,0.000132,0.75,8.04e-05,0.75,0.000132,0.75,0.0002028,0.25,0.000292552,0.75,0.00595
hellaswag.val.493,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.76e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mbpp.dev.379,mistralai/mistral-7b-chat,0.0,5.660000000000001e-05,0.0,5.660000000000001e-05,1.0,8.369999999999999e-05,1.0,0.0001824,1.0,0.0001652879999999,0.0,0.00997
mmlu-professional-law.val.1393,WizardLM/WizardLM-13B-V1.2,1.0,9.69e-05,0.0,6.46e-05,1.0,9.69e-05,1.0,0.0001938,0.0,0.000250648,1.0,0.00324
winogrande.dev.594,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,0.0,1.59e-05,1.0,3.18e-05,0.0,4.0352e-05,0.0,0.00057
winogrande.dev.232,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,0.0,3.06e-05,1.0,3.9576e-05,1.0,0.00055
hellaswag.val.9381,mistralai/mixtral-8x7b-chat,1.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,1.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
mmlu-miscellaneous.val.657,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-jurisprudence.val.84,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-high-school-us-history.val.170,WizardLM/WizardLM-13B-V1.2,0.0,9.99e-05,0.0,6.659999999999999e-05,0.0,9.99e-05,1.0,0.0001998,0.0,0.0002584079999999,1.0,0.00334
hellaswag.val.7943,mistralai/mistral-7b-chat,0.0,4.460000000000001e-05,0.0,4.460000000000001e-05,0.0,6.69e-05,0.0,0.0001338,0.0,0.000173048,1.0,0.00227
hellaswag.val.4306,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-virology.val.92,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-high-school-world-history.val.43,WizardLM/WizardLM-13B-V1.2,0.0,8.730000000000001e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
grade-school-math.dev.5363,WizardLM/WizardLM-13B-V1.2,0.75,0.0001248,0.75,9.82e-05,0.75,0.0001248,0.75,0.0002916,0.25,0.000321264,0.75,0.00961
hellaswag.val.5042,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-professional-law.val.254,mistralai/mistral-7b-chat,1.0,5.34e-05,1.0,5.34e-05,1.0,8.01e-05,1.0,0.0001602,0.0,0.000207192,1.0,0.00268
grade-school-math.dev.1947,mistralai/mixtral-8x7b-chat,0.75,0.0002106,0.75,6.440000000000001e-05,0.75,0.0001374,0.75,0.0002106,0.75,0.000249872,0.75,0.00609
hellaswag.val.4010,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
hellaswag.val.2351,WizardLM/WizardLM-13B-V1.2,1.0,2.43e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-professional-law.val.857,WizardLM/WizardLM-13B-V1.2,0.0,0.0001004999999999,0.0,6.7e-05,0.0,0.0001004999999999,0.0,0.0002003999999999,0.0,0.00025996,1.0,0.00336
grade-school-math.dev.319,mistralai/mixtral-8x7b-chat,0.25,0.0002297999999999,0.25,7.54e-05,0.25,0.0001607999999999,0.25,0.0002297999999999,0.25,0.000287896,0.5,0.00769
hellaswag.val.4512,mistralai/mixtral-8x7b-chat,0.0,0.0001782,0.0,5.94e-05,0.0,8.91e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
hellaswag.val.6091,mistralai/mixtral-8x7b-chat,0.0,0.0001602,0.0,5.34e-05,0.0,7.979999999999999e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00271
mmlu-professional-medicine.val.213,WizardLM/WizardLM-13B-V1.2,0.0,0.0001041,1.0,6.939999999999999e-05,0.0,0.0001041,1.0,0.0002082,0.0,0.000269272,1.0,0.00351
mmlu-moral-disputes.val.337,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,0.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
grade-school-math.dev.665,mistralai/mistral-7b-chat,0.25,7.68e-05,0.25,7.68e-05,0.5,0.0001611,0.25,0.0002304,0.5,0.000287896,0.25,0.008
mmlu-high-school-biology.val.198,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-human-aging.val.48,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-college-medicine.val.14,mistralai/mixtral-8x7b-chat,1.0,7.98e-05,1.0,2.6600000000000003e-05,0.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,0.0,0.00134
hellaswag.val.3100,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.6810,mistralai/mistral-7b-chat,0.75,6.76e-05,0.75,6.76e-05,0.75,0.000135,0.75,0.0002514,0.75,0.000245992,0.75,0.00519
grade-school-math.dev.1805,mistralai/mixtral-8x7b-chat,0.75,0.0002376,0.25,0.0001016,0.5,0.0001512,0.75,0.0002376,0.25,0.000315832,0.5,0.0077
mmlu-philosophy.val.278,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-computer-security.val.94,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00142
hellaswag.val.8776,WizardLM/WizardLM-13B-V1.2,0.0,7.17e-05,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
grade-school-math.dev.1166,WizardLM/WizardLM-13B-V1.2,0.5,0.000159,0.25,8.800000000000001e-05,0.5,0.000159,0.25,0.0004752,0.75,0.0003298,0.75,0.00867
mmlu-elementary-mathematics.val.339,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,0.0,4.08e-05,0.0,5.354400000000001e-05,0.0,0.0007
mmlu-elementary-mathematics.val.22,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
grade-school-math.dev.3726,mistralai/mistral-7b-chat,0.75,7.780000000000001e-05,0.75,7.780000000000001e-05,0.75,0.0001643999999999,0.75,0.000183,0.75,0.000309624,0.75,0.00666
grade-school-math.dev.4489,WizardLM/WizardLM-13B-V1.2,0.25,0.0001335,0.25,5.88e-05,0.25,0.0001335,0.25,0.0002148,0.75,0.000265392,0.75,0.00691
grade-school-math.dev.4825,mistralai/mistral-7b-chat,0.75,8.16e-05,0.75,8.16e-05,0.75,0.0001557,0.25,0.0002592,0.25,0.000343768,0.75,0.00685
grade-school-math.dev.1332,meta/code-llama-instruct-34b-chat,0.75,0.000251424,0.25,7.42e-05,0.75,0.000144,0.25,0.000216,0.75,0.000251424,0.75,0.00743
grade-school-math.dev.1367,WizardLM/WizardLM-13B-V1.2,0.25,0.0002157,0.25,0.0001362,0.25,0.0002157,0.75,0.000318,0.25,0.000544752,0.75,0.0109
mmlu-moral-scenarios.val.676,WizardLM/WizardLM-13B-V1.2,1.0,4.26e-05,0.0,2.84e-05,1.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,0.0,0.00143
winogrande.dev.179,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.0005
grade-school-math.dev.768,mistralai/mistral-7b-chat,0.25,6.460000000000001e-05,0.25,6.460000000000001e-05,0.5,0.0001683,0.25,0.0002136,0.75,0.000308072,0.75,0.01026
mmlu-high-school-microeconomics.val.198,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.8025,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.769999999999999e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00261
grade-school-math.dev.2248,WizardLM/WizardLM-13B-V1.2,0.5,0.0001668,0.25,7.400000000000001e-05,0.5,0.0001668,0.5,0.0002196,0.25,0.000338336,0.75,0.00856
grade-school-math.dev.6523,mistralai/mistral-7b-chat,0.75,7.98e-05,0.75,7.98e-05,0.75,0.0001286999999999,0.75,0.0002129999999999,0.75,0.000269272,0.75,0.00624
mmlu-high-school-biology.val.153,mistralai/mixtral-8x7b-chat,1.0,7.68e-05,0.0,2.56e-05,0.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
grade-school-math.dev.555,mistralai/mixtral-8x7b-chat,0.75,0.0002466,1.0,0.000106,0.25,0.0001557,0.75,0.0002466,0.25,0.000426024,0.75,0.00815
mmlu-logical-fallacies.val.32,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
grade-school-math.dev.6292,meta/code-llama-instruct-34b-chat,0.25,0.00031816,0.25,9.02e-05,0.25,0.0001643999999999,0.25,0.0002934,0.25,0.00031816,0.75,0.00877
arc-challenge.val.220,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,1.0,7.0616e-05,1.0,0.00095
mmlu-human-sexuality.val.52,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-high-school-chemistry.val.193,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
grade-school-math.dev.2426,meta/code-llama-instruct-34b-chat,0.5,0.000322816,0.25,0.0003988,0.75,0.0001623,0.25,0.0001962,0.5,0.000322816,0.5,0.00942
mmlu-logical-fallacies.val.79,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-moral-scenarios.val.784,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
winogrande.dev.176,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,1.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00048
winogrande.dev.479,mistralai/mixtral-8x7b-chat,1.0,2.76e-05,0.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.5696e-05,1.0,0.00047
mmlu-electrical-engineering.val.20,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.3331,WizardLM/WizardLM-13B-V1.2,0.5,0.0002079,0.25,0.0001234,0.5,0.0002079,0.25,0.0003852,0.25,0.000484224,0.75,0.01219
hellaswag.val.7189,WizardLM/WizardLM-13B-V1.2,0.0,7.409999999999999e-05,0.0,4.9600000000000006e-05,0.0,7.409999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
hellaswag.val.984,mistralai/mistral-7b-chat,0.0,3.4200000000000005e-05,0.0,3.4200000000000005e-05,0.0,5.1e-05,0.0,0.0001026,0.0,0.000132696,1.0,0.00175
mmlu-professional-law.val.1265,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
winogrande.dev.745,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,0.0,1.59e-05,1.0,3.24e-05,1.0,4.1904e-05,0.0,0.0005499999999999
hellaswag.val.9877,mistralai/mixtral-8x7b-chat,1.0,0.0001649999999999,1.0,5.5e-05,1.0,8.249999999999999e-05,1.0,0.0001649999999999,1.0,0.0002134,1.0,0.00276
hellaswag.val.739,WizardLM/WizardLM-13B-V1.2,0.0,3.12e-05,1.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
mmlu-moral-scenarios.val.787,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,0.0,0.00141
grade-school-math.dev.5298,WizardLM/WizardLM-13B-V1.2,0.5,0.0001896,0.25,6.88e-05,0.5,0.0001896,0.75,0.0002712,0.25,0.000316608,0.5,0.00735
hellaswag.val.3355,mistralai/mixtral-8x7b-chat,1.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00264
hellaswag.val.350,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
arc-challenge.test.783,mistralai/mixtral-8x7b-chat,0.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
hellaswag.val.8211,mistralai/mixtral-8x7b-chat,1.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.369999999999999e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00281
grade-school-math.dev.3666,WizardLM/WizardLM-13B-V1.2,0.75,0.0001434,0.25,0.0001002,0.75,0.0001434,0.75,0.0002406,0.75,0.00038412,0.75,0.00643
hellaswag.val.9029,mistralai/mistral-7b-chat,1.0,5.6000000000000006e-05,1.0,5.6000000000000006e-05,1.0,8.4e-05,1.0,0.000168,1.0,0.00021728,1.0,0.00284
mmlu-professional-law.val.891,mistralai/mistral-7b-chat,1.0,6.58e-05,1.0,6.58e-05,0.0,9.87e-05,1.0,0.0001974,0.0,0.000255304,1.0,0.00333
grade-school-math.dev.5236,WizardLM/WizardLM-13B-V1.2,0.75,0.0001266,0.75,7.46e-05,0.75,0.0001266,0.25,0.0002087999999999,0.75,0.000285568,0.75,0.00547
grade-school-math.dev.5958,mistralai/mistral-7b-chat,0.75,8.840000000000001e-05,0.75,8.840000000000001e-05,0.75,0.000159,0.5,0.000279,0.5,0.0003662719999999,0.75,0.0078099999999999
mmlu-high-school-physics.val.38,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,1.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.7047,mistralai/mixtral-8x7b-chat,1.0,0.0001758,1.0,5.860000000000001e-05,1.0,8.79e-05,1.0,0.0001758,1.0,0.0002273679999999,1.0,0.00297
mmlu-high-school-geography.val.151,mistralai/mixtral-8x7b-chat,1.0,3.96e-05,1.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
mmlu-professional-law.val.1316,WizardLM/WizardLM-13B-V1.2,0.0,6.149999999999999e-05,0.0,4.100000000000001e-05,0.0,6.149999999999999e-05,1.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-professional-psychology.val.545,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.335,WizardLM/WizardLM-13B-V1.2,0.0,0.0001250999999999,0.0,8.34e-05,0.0,0.0001250999999999,0.0,0.0002501999999999,0.0,0.000323592,1.0,0.00418
grade-school-math.dev.4334,meta/code-llama-instruct-34b-chat,0.25,0.000377136,0.25,0.000106,0.25,0.0001851,0.75,0.0003078,0.25,0.000377136,0.75,0.01192
hellaswag.val.6070,mistralai/mistral-7b-chat,0.0,5.800000000000001e-05,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
grade-school-math.dev.3123,WizardLM/WizardLM-13B-V1.2,0.5,0.0001508999999999,0.25,8.560000000000001e-05,0.5,0.0001508999999999,0.5,0.0001931999999999,0.75,0.000303416,0.5,0.0065
grade-school-math.dev.6090,WizardLM/WizardLM-13B-V1.2,0.75,0.0001197,0.25,8.24e-05,0.75,0.0001197,0.75,0.0001884,0.75,0.00023668,0.75,0.00418
mmlu-moral-disputes.val.156,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
grade-school-math.dev.1065,mistralai/mistral-7b-chat,0.75,8.7e-05,0.75,8.7e-05,0.75,0.0001536,0.75,0.0002454,0.75,0.000335232,0.75,0.0085
grade-school-math.dev.4677,WizardLM/WizardLM-13B-V1.2,0.75,0.0001341,0.75,8.56e-05,0.75,0.0001341,0.75,0.0002208,0.75,0.00031428,0.5,0.0065
grade-school-math.dev.2178,WizardLM/WizardLM-13B-V1.2,0.75,0.0001796999999999,0.75,0.0001002,0.75,0.0001796999999999,0.75,0.000294,0.25,0.000282464,0.75,0.00929
mmlu-professional-law.val.556,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.4926,mistralai/mistral-7b-chat,0.75,8.6e-05,0.75,8.6e-05,0.5,0.0001418999999999,0.25,0.0002501999999999,0.5,0.00030652,0.75,0.00717
grade-school-math.dev.6255,mistralai/mistral-7b-chat,0.75,7.66e-05,0.75,7.66e-05,0.75,0.0001278,0.75,0.0002214,0.25,0.000297984,0.5,0.00662
mmlu-marketing.val.146,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
grade-school-math.dev.7382,WizardLM/WizardLM-13B-V1.2,0.25,0.0001385999999999,0.25,8.36e-05,0.25,0.0001385999999999,0.25,0.0002459999999999,0.25,0.000315832,0.75,0.00957
mmlu-moral-scenarios.val.273,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00148
mmlu-professional-law.val.640,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-high-school-macroeconomics.val.329,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
winogrande.dev.543,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,0.0,0.00054
hellaswag.val.9853,mistralai/mistral-7b-chat,0.0,4.660000000000001e-05,0.0,4.660000000000001e-05,0.0,6.959999999999998e-05,0.0,0.0001397999999999,0.0,0.000180808,1.0,0.00237
hellaswag.val.4229,mistralai/mixtral-8x7b-chat,1.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.28e-05,1.0,0.0001662,0.0,0.000214952,1.0,0.00278
hellaswag.val.2424,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,0.0,3.5999999999999994e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
mmlu-professional-law.val.866,WizardLM/WizardLM-13B-V1.2,1.0,6.84e-05,0.0,4.56e-05,1.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00229
winogrande.dev.1151,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
grade-school-math.dev.1597,mistralai/mistral-7b-chat,0.25,6.180000000000001e-05,0.25,6.180000000000001e-05,0.25,0.0001629,0.75,0.0002153999999999,0.75,0.000269272,0.75,0.00675
mmlu-marketing.val.218,WizardLM/WizardLM-13B-V1.2,1.0,2.73e-05,1.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
hellaswag.val.4491,mistralai/mixtral-8x7b-chat,1.0,0.0001674,0.0,5.580000000000001e-05,0.0,8.34e-05,1.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
hellaswag.val.3120,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.45e-05,0.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-high-school-us-history.val.7,WizardLM/WizardLM-13B-V1.2,1.0,9.27e-05,1.0,6.18e-05,1.0,9.27e-05,1.0,0.0001853999999999,0.0,0.000239784,1.0,0.0031
mmlu-public-relations.val.57,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
mmlu-high-school-government-and-politics.val.137,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-law.val.1206,mistralai/mistral-7b-chat,0.0,5.080000000000001e-05,0.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,0.0,0.00255
hellaswag.val.2507,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
hellaswag.val.4348,mistralai/mistral-7b-chat,1.0,4.8e-05,1.0,4.8e-05,1.0,7.169999999999998e-05,1.0,0.0001439999999999,1.0,0.00018624,1.0,0.00244
mmlu-high-school-mathematics.val.137,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-professional-law.val.5,WizardLM/WizardLM-13B-V1.2,0.0,3.72e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
grade-school-math.dev.2739,mistralai/mistral-7b-chat,0.25,7.120000000000001e-05,0.25,7.120000000000001e-05,0.5,0.0001512,0.75,0.0003888,0.75,0.000290224,0.5,0.00824
grade-school-math.dev.3755,mistralai/mistral-7b-chat,0.25,0.0001468,0.25,0.0001468,0.25,0.0002304,0.25,0.0003672,0.25,0.000773672,0.75,0.01206
hellaswag.val.47,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-human-aging.val.66,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,1.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-moral-scenarios.val.353,WizardLM/WizardLM-13B-V1.2,0.0,3.9e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00131
hellaswag.val.3959,mistralai/mistral-7b-chat,0.0,5.24e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
grade-school-math.dev.5848,mistralai/mistral-7b-chat,0.75,8.16e-05,0.75,8.16e-05,0.75,0.0001503,0.75,0.0002592,0.75,0.000285568,0.5,0.0088799999999999
mmlu-formal-logic.val.92,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.72e-05,0.0,8.768799999999999e-05,0.0,0.00114
hellaswag.val.7806,mistralai/mixtral-8x7b-chat,1.0,0.0001626,1.0,5.420000000000001e-05,1.0,8.099999999999999e-05,1.0,0.0001626,1.0,0.0002102959999999,1.0,0.00275
mmlu-professional-law.val.1225,mistralai/mistral-7b-chat,0.0,3.1e-05,0.0,3.1e-05,0.0,4.65e-05,1.0,9.3e-05,0.0,0.00012028,0.0,0.0015899999999999
mmlu-human-sexuality.val.127,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-college-biology.val.132,mistralai/mixtral-8x7b-chat,1.0,0.0001002,1.0,3.3400000000000005e-05,1.0,5.01e-05,1.0,0.0001002,0.0,0.000129592,1.0,0.00168
hellaswag.val.7545,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00279
hellaswag.val.2393,WizardLM/WizardLM-13B-V1.2,0.0,3.69e-05,0.0,2.4800000000000003e-05,0.0,3.69e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
winogrande.dev.448,mistralai/mistral-7b-chat,1.0,1.14e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00061
grade-school-math.dev.6840,mistralai/mistral-7b-chat,0.25,8.48e-05,0.25,8.48e-05,0.25,0.0001314,0.75,0.0002634,0.25,0.000304968,0.75,0.00775
grade-school-math.dev.265,WizardLM/WizardLM-13B-V1.2,0.25,0.0001506,0.75,0.0001008,0.25,0.0001506,0.75,0.0002238,0.75,0.000336784,0.75,0.00934
mmlu-high-school-macroeconomics.val.157,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
hellaswag.val.5141,mistralai/mixtral-8x7b-chat,0.0,0.0001397999999999,1.0,4.660000000000001e-05,1.0,6.989999999999999e-05,0.0,0.0001397999999999,1.0,0.000180808,1.0,0.00237
mmlu-high-school-computer-science.val.94,mistralai/mistral-7b-chat,0.0,3.1e-05,0.0,3.1e-05,0.0,4.65e-05,0.0,9.3e-05,0.0,0.00012028,1.0,0.00156
hellaswag.val.6291,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.169999999999998e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
grade-school-math.dev.967,WizardLM/WizardLM-13B-V1.2,0.75,0.0001436999999999,0.25,8.72e-05,0.75,0.0001436999999999,0.75,0.0002435999999999,0.25,0.000242888,0.75,0.00563
consensus_summary.dev.62,mistralai/mixtral-8x7b-chat,0.75,0.0002004,0.25,5.400000000000001e-05,0.0,0.0003128999999999,0.75,0.0002004,0.75,0.000317384,0.75,0.00409
hellaswag.val.7144,mistralai/mistral-7b-chat,0.0,5.5400000000000005e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
grade-school-math.dev.4252,mistralai/mistral-7b-chat,0.25,7.560000000000001e-05,0.25,7.560000000000001e-05,0.75,0.0001286999999999,0.75,0.0002142,0.25,0.000259184,0.75,0.00559
hellaswag.val.6568,mistralai/mistral-7b-chat,1.0,4.920000000000001e-05,1.0,4.920000000000001e-05,1.0,7.35e-05,1.0,0.0001476,1.0,0.0001908959999999,1.0,0.0025
hellaswag.val.5678,mistralai/mixtral-8x7b-chat,1.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.049999999999999e-05,1.0,0.0001416,0.0,0.000183136,1.0,0.00237
hellaswag.val.9123,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-professional-law.val.667,WizardLM/WizardLM-13B-V1.2,1.0,8.94e-05,0.0,5.9600000000000005e-05,1.0,8.94e-05,1.0,0.0001788,0.0,0.0002312479999999,1.0,0.00299
mmlu-nutrition.val.288,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
abstract2title.test.170,mistralai/mixtral-8x7b-chat,1.0,0.0001806,1.0,5.7400000000000006e-05,1.0,8.850000000000001e-05,1.0,0.0001806,1.0,0.00021728,1.0,0.00364
hellaswag.val.3606,mistralai/mistral-7b-chat,1.0,5.5400000000000005e-05,1.0,5.5400000000000005e-05,1.0,8.31e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00278
arc-challenge.test.41,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,0.0,2.07e-05,0.0,4.14e-05,1.0,5.354400000000001e-05,1.0,0.0007
mmlu-management.val.96,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-miscellaneous.val.307,mistralai/mistral-7b-chat,1.0,1.34e-05,1.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-professional-law.val.1120,WizardLM/WizardLM-13B-V1.2,1.0,7.89e-05,0.0,5.260000000000001e-05,1.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00264
grade-school-math.dev.2856,WizardLM/WizardLM-13B-V1.2,0.25,0.0001992,0.25,9.48e-05,0.25,0.0001992,0.75,0.0003294,0.75,0.000356184,0.75,0.01062
hellaswag.val.2091,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,1.0,7.139200000000001e-05,1.0,0.00096
hellaswag.val.2612,mistralai/mixtral-8x7b-chat,1.0,7.2e-05,0.0,2.4e-05,0.0,3.57e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00124
mmlu-security-studies.val.32,WizardLM/WizardLM-13B-V1.2,0.0,8.099999999999999e-05,1.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,0.0,0.00271
hellaswag.val.3402,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
hellaswag.val.2503,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
arc-challenge.test.569,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,1.0,5.1216000000000006e-05,1.0,0.00067
grade-school-math.dev.5621,mistralai/mistral-7b-chat,0.25,7.38e-05,0.25,7.38e-05,0.25,0.0001965,0.25,0.0002556,0.25,0.00029876,0.25,0.00913
hellaswag.val.3654,mistralai/mistral-7b-chat,1.0,5.7e-05,1.0,5.7e-05,1.0,8.519999999999998e-05,1.0,0.0001709999999999,1.0,0.00022116,1.0,0.00289
hellaswag.val.1602,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.2605,WizardLM/WizardLM-13B-V1.2,0.25,0.0001779,0.25,0.000103,0.25,0.0001779,0.25,0.0002628,0.25,0.0003685999999999,0.5,0.00983
hellaswag.val.3354,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,0.0,0.00264
mmlu-high-school-government-and-politics.val.128,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-econometrics.val.41,mistralai/mixtral-8x7b-chat,0.0,0.0001134,0.0,3.78e-05,0.0,5.67e-05,0.0,0.0001134,0.0,0.000145888,0.0,0.0019
mmlu-conceptual-physics.val.179,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
mmlu-clinical-knowledge.val.173,mistralai/mixtral-8x7b-chat,1.0,9.06e-05,0.0,3.02e-05,0.0,4.53e-05,1.0,9.06e-05,0.0,0.000117176,1.0,0.00152
arc-challenge.test.116,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-world-religions.val.11,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.9869,WizardLM/WizardLM-13B-V1.2,0.0,7.56e-05,0.0,5.06e-05,0.0,7.56e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-high-school-statistics.val.138,mistralai/mistral-7b-chat,1.0,3.2800000000000004e-05,1.0,3.2800000000000004e-05,0.0,4.92e-05,0.0,9.84e-05,0.0,0.0001272639999999,1.0,0.00165
hellaswag.val.1208,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
arc-challenge.test.1135,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.8016,mistralai/mixtral-8x7b-chat,0.0,0.0001842,0.0,6.14e-05,0.0,9.21e-05,0.0,0.0001842,0.0,0.000238232,1.0,0.00308
arc-challenge.test.876,WizardLM/WizardLM-13B-V1.2,1.0,2.9100000000000003e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,1.0,7.5272e-05,1.0,0.00101
winogrande.dev.786,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
consensus_summary.dev.109,mistralai/mistral-7b-chat,0.25,7.280000000000001e-05,0.25,7.280000000000001e-05,0.25,9.96e-05,0.25,0.0001944,0.0,0.000251424,0.25,0.00459
mmlu-professional-law.val.581,WizardLM/WizardLM-13B-V1.2,0.0,9.66e-05,0.0,6.44e-05,0.0,9.66e-05,0.0,0.0001932,0.0,0.000249872,0.0,0.00323
hellaswag.val.214,WizardLM/WizardLM-13B-V1.2,0.0,4.53e-05,0.0,3.04e-05,0.0,4.53e-05,0.0,9.12e-05,0.0,0.000117952,0.0,0.00156
abstract2title.test.140,mistralai/mixtral-8x7b-chat,1.0,0.0001709999999999,1.0,5.58e-05,1.0,8.609999999999999e-05,1.0,0.0001709999999999,1.0,0.000214952,1.0,0.00337
mmlu-professional-law.val.1518,WizardLM/WizardLM-13B-V1.2,1.0,9.96e-05,0.0,6.64e-05,1.0,9.96e-05,1.0,0.0001992,0.0,0.000257632,1.0,0.00333
hellaswag.val.4185,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.309999999999999e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
hellaswag.val.8100,mistralai/mistral-7b-chat,0.0,4.2e-05,0.0,4.2e-05,0.0,6.3e-05,0.0,0.000126,0.0,0.00016296,1.0,0.00211
mmlu-computer-security.val.58,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-abstract-algebra.val.70,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
hellaswag.val.5171,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.289999999999998e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00248
mmlu-professional-psychology.val.362,WizardLM/WizardLM-13B-V1.2,0.0,4.38e-05,1.0,2.92e-05,0.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
mmlu-philosophy.val.209,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
mmlu-jurisprudence.val.35,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
hellaswag.val.8769,WizardLM/WizardLM-13B-V1.2,0.0,7.589999999999999e-05,0.0,5.080000000000001e-05,0.0,7.589999999999999e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
arc-challenge.test.237,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00082
abstract2title.test.119,mistralai/mixtral-8x7b-chat,1.0,0.0002094,1.0,6.560000000000001e-05,1.0,0.0001008,1.0,0.0002094,1.0,0.000260736,1.0,0.00377
mmlu-professional-law.val.133,mistralai/mistral-7b-chat,0.0,3.44e-05,0.0,3.44e-05,1.0,5.16e-05,0.0,0.0001032,0.0,0.000133472,1.0,0.00173
mmlu-professional-law.val.43,WizardLM/WizardLM-13B-V1.2,0.0,4.59e-05,0.0,3.0600000000000005e-05,0.0,4.59e-05,1.0,9.18e-05,0.0,0.000118728,1.0,0.00154
mmlu-elementary-mathematics.val.127,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-high-school-macroeconomics.val.184,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-high-school-geography.val.81,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-miscellaneous.val.214,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-college-physics.val.75,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-law.val.660,WizardLM/WizardLM-13B-V1.2,0.0,0.0001238999999999,0.0,8.26e-05,0.0,0.0001238999999999,0.0,0.0002477999999999,0.0,0.000320488,0.0,0.00414
hellaswag.val.5348,WizardLM/WizardLM-13B-V1.2,1.0,8.249999999999999e-05,0.0,5.5e-05,1.0,8.249999999999999e-05,1.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
winogrande.dev.55,mistralai/mixtral-8x7b-chat,1.0,3.12e-05,1.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,1.0,4.0352e-05,1.0,0.00056
grade-school-math.dev.2020,mistralai/mistral-7b-chat,0.75,8.5e-05,0.75,8.5e-05,0.25,0.0001281,0.5,0.0002573999999999,0.25,0.000222712,0.5,0.00764
grade-school-math.dev.6641,mistralai/mistral-7b-chat,0.75,0.0001006,0.75,0.0001006,0.25,0.0001452,0.25,0.00033,0.25,0.000400416,0.75,0.01247
mmlu-moral-disputes.val.134,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.7845,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.0026
mbpp.dev.284,mistralai/mistral-7b-chat,0.0,5.1e-05,0.0,5.1e-05,0.0,7.05e-05,1.0,0.0001848,1.0,0.000138128,1.0,0.00886
mmlu-professional-law.val.989,WizardLM/WizardLM-13B-V1.2,1.0,5.61e-05,0.0,3.74e-05,1.0,5.61e-05,1.0,0.0001122,0.0,0.000145112,0.0,0.00188
grade-school-math.dev.6634,meta/code-llama-instruct-34b-chat,0.25,0.00029876,0.25,7.280000000000001e-05,0.25,0.0001584,0.75,0.0002592,0.25,0.00029876,0.75,0.0075899999999999
hellaswag.val.1303,WizardLM/WizardLM-13B-V1.2,1.0,3.63e-05,1.0,2.44e-05,1.0,3.63e-05,1.0,7.32e-05,1.0,9.4672e-05,0.0,0.00123
mmlu-professional-law.val.448,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
grade-school-math.dev.188,mistralai/mistral-7b-chat,0.5,6.38e-05,0.5,6.38e-05,0.75,0.0001233,0.75,0.0002021999999999,0.75,0.0003049679999999,0.5,0.00472
mmlu-moral-scenarios.val.776,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
grade-school-math.dev.96,mistralai/mistral-7b-chat,0.25,7.72e-05,0.25,7.72e-05,0.75,0.0001578,0.75,0.0003017999999999,0.5,0.000328248,0.75,0.00748
arc-challenge.test.386,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
grade-school-math.dev.1468,WizardLM/WizardLM-13B-V1.2,0.25,0.0001326,0.25,9.680000000000002e-05,0.25,0.0001326,0.25,0.0002352,0.75,0.000361616,0.75,0.00825
mmlu-professional-law.val.1081,WizardLM/WizardLM-13B-V1.2,1.0,7.98e-05,0.0,5.3200000000000006e-05,1.0,7.98e-05,1.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
mmlu-professional-law.val.1239,WizardLM/WizardLM-13B-V1.2,0.0,0.0001343999999999,0.0,8.96e-05,0.0,0.0001343999999999,1.0,0.0002687999999999,0.0,0.000347648,1.0,0.00449
winogrande.dev.375,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,1.0,3.5696e-05,1.0,0.0005
hellaswag.val.9611,mistralai/mixtral-8x7b-chat,0.0,0.0001362,0.0,4.5400000000000006e-05,0.0,6.81e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00228
mmlu-professional-law.val.1491,WizardLM/WizardLM-13B-V1.2,0.0,9.45e-05,0.0,6.3e-05,0.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
grade-school-math.dev.1797,mistralai/mistral-7b-chat,0.75,5.42e-05,0.75,5.42e-05,0.5,0.0001326,0.75,0.0002033999999999,0.5,0.000250648,0.75,0.00588
mmlu-high-school-macroeconomics.val.22,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
grade-school-math.dev.5330,WizardLM/WizardLM-13B-V1.2,0.5,0.0001685999999999,0.25,0.0001162,0.5,0.0001685999999999,1.0,0.0001919999999999,0.5,0.000435336,0.5,0.00881
mmlu-human-sexuality.val.81,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.2202,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
grade-school-math.dev.7228,WizardLM/WizardLM-13B-V1.2,0.25,0.0001701,0.25,8.680000000000001e-05,0.25,0.0001701,0.75,0.0002472,0.25,0.0003662719999999,0.75,0.01341
hellaswag.val.1480,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
grade-school-math.dev.4734,mistralai/mistral-7b-chat,0.25,8.26e-05,0.25,8.26e-05,0.75,0.0001701,0.25,0.0002826,0.25,0.00035696,0.75,0.00838
grade-school-math.dev.2467,WizardLM/WizardLM-13B-V1.2,0.75,0.0001479,0.75,7.48e-05,0.75,0.0001479,0.25,0.0002106,0.25,0.000250648,0.5,0.00616
hellaswag.val.4217,mistralai/mixtral-8x7b-chat,1.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,1.0,0.0001548,0.0,0.000200208,1.0,0.00259
mmlu-professional-medicine.val.183,WizardLM/WizardLM-13B-V1.2,1.0,6.45e-05,1.0,4.3e-05,1.0,6.45e-05,1.0,0.000129,0.0,0.00016684,0.0,0.00219
hellaswag.val.9940,mistralai/mixtral-8x7b-chat,1.0,0.0001319999999999,1.0,4.4000000000000006e-05,1.0,6.599999999999999e-05,1.0,0.0001319999999999,1.0,0.00017072,1.0,0.00224
mmlu-high-school-biology.val.285,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
hellaswag.val.6157,mistralai/mistral-7b-chat,0.0,5.4000000000000005e-05,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,0.0,0.00274
mmlu-professional-law.val.1268,WizardLM/WizardLM-13B-V1.2,0.0,0.0001217999999999,0.0,8.120000000000001e-05,0.0,0.0001217999999999,1.0,0.0002435999999999,0.0,0.000315056,1.0,0.00407
mbpp.dev.109,mistralai/mistral-7b-chat,0.0,6.04e-05,0.0,6.04e-05,0.0,8.609999999999999e-05,0.0,0.0002382,0.0,0.0002716,0.0,0.01072
mmlu-high-school-geography.val.94,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
hellaswag.val.712,WizardLM/WizardLM-13B-V1.2,1.0,2.97e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-human-sexuality.val.60,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
mbpp.dev.195,mistralai/mistral-7b-chat,1.0,2.74e-05,1.0,2.74e-05,1.0,4.35e-05,1.0,0.0001104,1.0,8.3808e-05,1.0,0.00724
mmlu-professional-law.val.1489,WizardLM/WizardLM-13B-V1.2,1.0,7.29e-05,0.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,0.0,0.00244
grade-school-math.dev.7400,mistralai/mistral-7b-chat,0.25,8.34e-05,0.25,8.34e-05,0.0,0.0001709999999999,0.25,0.0002622,0.25,0.000347648,0.5,0.00884
hellaswag.val.9319,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-high-school-us-history.val.11,mistralai/mixtral-8x7b-chat,1.0,0.0001733999999999,1.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
hellaswag.val.7996,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
hellaswag.val.3351,WizardLM/WizardLM-13B-V1.2,1.0,5.94e-05,1.0,3.980000000000001e-05,1.0,5.94e-05,1.0,0.0001193999999999,1.0,0.000154424,1.0,0.00203
hellaswag.val.8902,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,0.0,0.00276
winogrande.dev.1065,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,1.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.00058
hellaswag.val.12,WizardLM/WizardLM-13B-V1.2,1.0,3.51e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
mmlu-high-school-physics.val.137,mistralai/mixtral-8x7b-chat,1.0,9.12e-05,0.0,3.04e-05,0.0,4.56e-05,1.0,9.12e-05,0.0,0.000117952,1.0,0.00153
mmlu-professional-law.val.744,WizardLM/WizardLM-13B-V1.2,0.0,6.84e-05,1.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,0.0,0.00229
mmlu-college-biology.val.14,mistralai/mixtral-8x7b-chat,0.0,0.0001253999999999,0.0,4.1800000000000006e-05,0.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
mmlu-moral-disputes.val.225,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.2797,WizardLM/WizardLM-13B-V1.2,0.5,0.0001782,0.25,0.0001014,0.5,0.0001782,0.25,0.0003966,0.25,0.000331352,0.75,0.01242
mmlu-electrical-engineering.val.10,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.5282,WizardLM/WizardLM-13B-V1.2,0.75,0.0001319999999999,0.25,0.0001076,0.75,0.0001319999999999,0.25,0.0002454,0.25,0.000303416,0.75,0.00895
arc-challenge.test.213,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-college-biology.val.105,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-professional-law.val.1060,WizardLM/WizardLM-13B-V1.2,0.0,0.0001161,1.0,7.74e-05,0.0,0.0001161,1.0,0.0002322,0.0,0.0003003119999999,1.0,0.00388
mmlu-management.val.61,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.2015,WizardLM/WizardLM-13B-V1.2,0.25,0.0001809,0.5,0.0001028,0.25,0.0001809,0.5,0.0003,0.25,0.000357736,0.5,0.01057
grade-school-math.dev.3194,meta/code-llama-instruct-34b-chat,0.75,0.00033756,0.75,9.72e-05,0.75,0.0001529999999999,0.75,0.0002658,0.75,0.00033756,0.75,0.00961
mmlu-college-mathematics.val.94,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,0.0,1.95e-05,0.0,3.9e-05,0.0,5.044e-05,0.0,0.00066
mmlu-moral-disputes.val.96,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
abstract2title.test.68,mistralai/mixtral-8x7b-chat,1.0,0.0001296,1.0,4.24e-05,1.0,0.0001049999999999,1.0,0.0001296,1.0,0.000165288,1.0,0.0029
grade-school-math.dev.2021,WizardLM/WizardLM-13B-V1.2,0.5,0.0001293,0.25,7.16e-05,0.5,0.0001293,0.5,0.0002082,0.75,0.000326696,0.75,0.00561
arc-challenge.test.1011,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,0.0,0.00093
hellaswag.val.4690,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.049999999999999e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-professional-law.val.650,WizardLM/WizardLM-13B-V1.2,0.0,9.42e-05,0.0,6.280000000000001e-05,0.0,9.42e-05,0.0,0.0001884,0.0,0.000243664,1.0,0.00315
grade-school-math.dev.5013,mistralai/mistral-7b-chat,0.25,8.32e-05,0.25,8.32e-05,0.5,0.0001248,0.5,0.0002189999999999,0.75,0.000245216,0.75,0.00919
hellaswag.val.8599,mistralai/mistral-7b-chat,0.0,6.14e-05,0.0,6.14e-05,1.0,9.21e-05,0.0,0.0001842,0.0,0.000238232,1.0,0.00311
mmlu-business-ethics.val.58,mistralai/mistral-7b-chat,1.0,3.48e-05,1.0,3.48e-05,1.0,5.22e-05,0.0,0.0001044,0.0,0.000135024,1.0,0.00178
grade-school-math.dev.5246,mistralai/mistral-7b-chat,0.25,0.000108,0.25,0.000108,0.25,0.0001623,0.25,0.0003582,0.25,0.000315832,0.75,0.01167
hellaswag.val.8765,mistralai/mixtral-8x7b-chat,0.0,0.0001866,0.0,6.22e-05,0.0,9.33e-05,0.0,0.0001866,0.0,0.000241336,1.0,0.00315
mmlu-high-school-world-history.val.11,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,0.0,5.800000000000001e-05,1.0,8.699999999999999e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
mmlu-virology.val.100,mistralai/mixtral-8x7b-chat,0.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-professional-psychology.val.109,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,0.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
arc-challenge.test.110,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
grade-school-math.dev.3919,WizardLM/WizardLM-13B-V1.2,0.75,0.0001458,0.5,6.980000000000002e-05,0.75,0.0001458,0.5,0.0002028,0.25,0.0002374559999999,0.75,0.00648
mmlu-professional-law.val.357,WizardLM/WizardLM-13B-V1.2,0.0,9.33e-05,1.0,6.22e-05,0.0,9.33e-05,1.0,0.0001866,0.0,0.000241336,1.0,0.00312
abstract2title.test.74,mistralai/mixtral-8x7b-chat,1.0,0.0002681999999999,1.0,8.680000000000001e-05,1.0,0.0001796999999999,1.0,0.0002681999999999,1.0,0.000342216,1.0,0.00498
grade-school-math.dev.4710,WizardLM/WizardLM-13B-V1.2,0.25,0.0001709999999999,0.25,6.9e-05,0.25,0.0001709999999999,0.5,0.000255,0.75,0.000328248,0.75,0.00763
grade-school-math.dev.7251,mistralai/mistral-7b-chat,0.75,7.14e-05,0.75,7.14e-05,0.25,0.0001685999999999,0.25,0.0001769999999999,0.5,0.000340664,0.75,0.00694
hellaswag.val.4163,WizardLM/WizardLM-13B-V1.2,0.0,9.06e-05,0.0,6.04e-05,0.0,9.06e-05,0.0,0.0001812,0.0,0.000234352,1.0,0.00306
hellaswag.val.4805,mistralai/mixtral-8x7b-chat,1.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,1.0,0.000156,0.0,0.00020176,1.0,0.00264
mmlu-professional-law.val.1110,WizardLM/WizardLM-13B-V1.2,0.0,9.42e-05,0.0,6.280000000000001e-05,0.0,9.42e-05,0.0,0.0001884,0.0,0.000243664,0.0,0.00315
mmlu-global-facts.val.6,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,0.0,0.00085
hellaswag.val.9705,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
mmlu-jurisprudence.val.92,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
grade-school-math.dev.4490,mistralai/mistral-7b-chat,0.25,8.8e-05,0.25,8.8e-05,0.25,0.0001434,0.25,0.0002412,0.25,0.000332128,0.75,0.00879
mmlu-professional-law.val.997,mistralai/mixtral-8x7b-chat,0.0,0.0002046,0.0,6.819999999999999e-05,0.0,0.0001023,0.0,0.0002046,0.0,0.000264616,1.0,0.00342
hellaswag.val.2307,mistralai/mixtral-8x7b-chat,0.0,5.64e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.995,WizardLM/WizardLM-13B-V1.2,0.25,0.0001863,0.25,8.6e-05,0.25,0.0001863,0.25,0.0003228,0.25,0.00059364,0.75,0.0120399999999999
mmlu-high-school-macroeconomics.val.218,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-machine-learning.val.50,mistralai/mixtral-8x7b-chat,0.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
arc-challenge.val.20,mistralai/mistral-7b-chat,1.0,1.14e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00061
mmlu-electrical-engineering.val.63,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,0.0,0.00071
mmlu-high-school-government-and-politics.val.45,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,1.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
hellaswag.val.8897,mistralai/mixtral-8x7b-chat,0.0,0.0001278,0.0,4.2600000000000005e-05,0.0,6.359999999999999e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00217
bias_detection.dev.127,mistralai/mistral-7b-chat,0.0,5.08e-05,0.0,5.08e-05,0.0,8.1e-05,0.0,0.0001668,0.0,0.00024056,0.0,0.0097399999999999
mbpp.dev.384,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,1.0,8.13e-05,1.0,0.0001686,1.0,0.00018624,1.0,0.00913
hellaswag.val.178,WizardLM/WizardLM-13B-V1.2,1.0,3.84e-05,0.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
hellaswag.val.6083,mistralai/mixtral-8x7b-chat,0.0,0.0001319999999999,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,0.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
grade-school-math.dev.6361,meta/code-llama-instruct-34b-chat,0.75,0.000311176,0.25,7.94e-05,0.5,0.0001454999999999,0.5,0.0002639999999999,0.75,0.000311176,0.75,0.00694
mmlu-world-religions.val.163,mistralai/mixtral-8x7b-chat,0.0,5.22e-05,0.0,1.74e-05,1.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
mmlu-professional-law.val.204,mistralai/mistral-7b-chat,0.0,7.48e-05,0.0,7.48e-05,0.0,0.0001121999999999,1.0,0.0002243999999999,0.0,0.000290224,1.0,0.00375
mmlu-professional-psychology.val.468,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.7561,WizardLM/WizardLM-13B-V1.2,1.0,8.879999999999999e-05,1.0,5.94e-05,1.0,8.879999999999999e-05,1.0,0.0001782,1.0,0.000230472,1.0,0.00301
winogrande.dev.734,mistralai/mixtral-8x7b-chat,1.0,2.82e-05,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00051
mmlu-high-school-european-history.val.105,mistralai/mixtral-8x7b-chat,1.0,0.0003917999999999,0.0,0.0001306,1.0,0.0001958999999999,1.0,0.0003917999999999,0.0,0.000506728,1.0,0.00654
grade-school-math.dev.1994,mistralai/mistral-7b-chat,0.75,7.5e-05,0.75,7.5e-05,0.5,0.0001308,0.75,0.0002814,0.0,0.000266168,0.75,0.00792
hellaswag.val.5420,WizardLM/WizardLM-13B-V1.2,0.0,8.43e-05,0.0,5.62e-05,0.0,8.43e-05,1.0,0.0001686,0.0,0.000218056,1.0,0.00282
grade-school-math.dev.2068,WizardLM/WizardLM-13B-V1.2,0.5,0.0001602,0.25,8.66e-05,0.5,0.0001602,0.25,0.0002615999999999,0.25,0.000354632,0.75,0.0088799999999999
hellaswag.val.2830,WizardLM/WizardLM-13B-V1.2,0.0,3.78e-05,1.0,2.54e-05,0.0,3.78e-05,1.0,7.62e-05,1.0,9.8552e-05,1.0,0.00128
mmlu-high-school-psychology.val.266,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
mmlu-high-school-psychology.val.127,WizardLM/WizardLM-13B-V1.2,1.0,2.55e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
mmlu-professional-law.val.244,WizardLM/WizardLM-13B-V1.2,0.0,0.0001101,0.0,7.34e-05,0.0,0.0001101,1.0,0.0002202,0.0,0.000284792,0.0,0.00368
mmlu-high-school-biology.val.22,mistralai/mixtral-8x7b-chat,0.0,7.5e-05,0.0,2.5e-05,1.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-sociology.val.134,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.7100,mistralai/mixtral-8x7b-chat,0.0,0.0001722,0.0,5.7400000000000006e-05,0.0,8.58e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00288
arc-challenge.test.273,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.6926,mistralai/mistral-7b-chat,1.0,4.94e-05,1.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,1.0,0.000191672,1.0,0.00251
hellaswag.val.8201,WizardLM/WizardLM-13B-V1.2,0.0,8.13e-05,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,0.0,0.00275
hellaswag.val.9751,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.2809,WizardLM/WizardLM-13B-V1.2,0.25,0.0002045999999999,0.25,0.0001206,0.25,0.0002045999999999,1.0,0.0002322,0.25,0.000428352,0.5,0.01463
winogrande.dev.109,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,1.0,3e-05,0.0,3.802400000000001e-05,1.0,0.00051
mmlu-world-religions.val.113,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
winogrande.dev.806,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,1.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
grade-school-math.dev.6189,WizardLM/WizardLM-13B-V1.2,0.25,0.0001307999999999,0.25,8.36e-05,0.25,0.0001307999999999,0.25,0.000234,0.25,0.000284792,0.75,0.00643
hellaswag.val.4022,mistralai/mistral-7b-chat,1.0,5.24e-05,1.0,5.24e-05,1.0,7.829999999999999e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-high-school-psychology.val.144,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.4033,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mbpp.dev.293,mistralai/mistral-7b-chat,1.0,2.6600000000000003e-05,1.0,2.6600000000000003e-05,1.0,4.17e-05,1.0,0.0001121999999999,1.0,7.6824e-05,1.0,0.00356
mmlu-college-chemistry.val.97,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,0.0,0.00094
arc-challenge.test.1101,mistralai/mistral-7b-chat,1.0,1.42e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,1.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.2180,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
arc-challenge.test.276,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
arc-challenge.val.150,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,1.0,6.9064e-05,1.0,0.0009
hellaswag.val.556,WizardLM/WizardLM-13B-V1.2,0.0,4.02e-05,1.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,1.0,0.000103984,0.0,0.00135
mmlu-high-school-world-history.val.142,mistralai/mixtral-8x7b-chat,1.0,0.000216,1.0,7.2e-05,0.0,0.000108,1.0,0.000216,0.0,0.00027936,1.0,0.00364
hellaswag.val.9075,mistralai/mixtral-8x7b-chat,1.0,0.0001572,1.0,5.22e-05,1.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00263
grade-school-math.dev.1304,WizardLM/WizardLM-13B-V1.2,0.5,0.0001775999999999,0.25,0.0001002,0.5,0.0001775999999999,0.5,0.0003353999999999,0.5,0.000404296,0.5,0.0091399999999999
grade-school-math.dev.635,mistralai/mistral-7b-chat,0.75,7.1e-05,0.75,7.1e-05,0.5,0.0001389,0.25,0.0002279999999999,0.5,0.000274704,0.75,0.00472
mmlu-jurisprudence.val.105,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,0.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-high-school-chemistry.val.142,mistralai/mistral-7b-chat,0.0,3.1400000000000004e-05,0.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
winogrande.dev.129,mistralai/mistral-7b-chat,0.0,1.06e-05,0.0,1.06e-05,1.0,1.59e-05,0.0,3.18e-05,0.0,4.1128e-05,0.0,0.00057
mmlu-professional-law.val.6,WizardLM/WizardLM-13B-V1.2,0.0,0.0001029,0.0,6.86e-05,0.0,0.0001029,0.0,0.0002058,0.0,0.0002661679999999,1.0,0.00344
mmlu-human-aging.val.179,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-high-school-mathematics.val.236,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
grade-school-math.dev.6147,mistralai/mistral-7b-chat,0.25,8.400000000000001e-05,0.25,8.400000000000001e-05,0.25,0.000111,0.75,0.0001836,0.5,0.000260736,0.75,0.00669
grade-school-math.dev.4900,meta/code-llama-instruct-34b-chat,0.25,0.000274704,0.25,0.0004616,0.75,0.0001229999999999,0.25,0.0002615999999999,0.25,0.000274704,0.75,0.0083699999999999
hellaswag.val.6489,WizardLM/WizardLM-13B-V1.2,0.0,6.780000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,0.0,0.0023
grade-school-math.dev.700,WizardLM/WizardLM-13B-V1.2,0.25,0.0001397999999999,0.25,8.02e-05,0.25,0.0001397999999999,0.25,0.0002345999999999,0.25,0.000258408,0.75,0.00873
hellaswag.val.7731,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
hellaswag.val.4132,mistralai/mixtral-8x7b-chat,0.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,0.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
mmlu-high-school-physics.val.143,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,1.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,1.0,8.6136e-05,1.0,0.00112
mmlu-moral-scenarios.val.878,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
grade-school-math.dev.6782,mistralai/mistral-7b-chat,0.25,7.54e-05,0.25,7.54e-05,0.25,0.0001515,0.75,0.0002142,0.25,0.000285568,0.75,0.00702
grade-school-math.dev.3918,WizardLM/WizardLM-13B-V1.2,0.25,0.0001923,0.25,0.0001206,0.25,0.0001923,0.25,0.0003131999999999,0.25,0.000365496,0.5,0.00853
grade-school-math.dev.5324,mistralai/mistral-7b-chat,0.5,8.78e-05,0.5,8.78e-05,0.75,0.0001586999999999,0.75,0.0002375999999999,0.25,0.000286344,0.5,0.00787
mmlu-high-school-biology.val.121,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
bias_detection.dev.193,mistralai/mixtral-8x7b-chat,0.0,0.0001782,0.0,5.160000000000001e-05,0.0,9.45e-05,0.0,0.0001782,0.0,0.000264616,0.0,0.00552
grade-school-math.dev.4496,WizardLM/WizardLM-13B-V1.2,0.75,0.0001553999999999,0.25,9.22e-05,0.75,0.0001553999999999,0.25,0.0003438,0.75,0.000398864,0.75,0.00943
mmlu-security-studies.val.98,mistralai/mixtral-8x7b-chat,1.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,1.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
grade-school-math.dev.1762,meta/code-llama-instruct-34b-chat,0.25,0.000374032,0.25,0.0001016,0.25,0.0001548,0.25,0.0002298,0.25,0.000374032,0.75,0.01011
mmlu-sociology.val.78,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-professional-medicine.val.134,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00259
hellaswag.val.1357,mistralai/mistral-7b-chat,1.0,2.8e-05,1.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,1.0,0.00010864,1.0,0.00141
mmlu-miscellaneous.val.538,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-law.val.1145,WizardLM/WizardLM-13B-V1.2,0.0,9.24e-05,1.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00312
mmlu-elementary-mathematics.val.310,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
grade-school-math.dev.4408,WizardLM/WizardLM-13B-V1.2,0.75,0.0002049,0.25,0.0001484,0.75,0.0002049,0.25,0.0003984,0.75,0.000384896,0.75,0.01086
abstract2title.test.48,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,1.0,5.5e-05,1.0,8.549999999999999e-05,1.0,0.0001739999999999,1.0,0.000215728,1.0,0.00323
mmlu-high-school-psychology.val.157,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-high-school-world-history.val.63,WizardLM/WizardLM-13B-V1.2,1.0,0.0001418999999999,1.0,9.46e-05,1.0,0.0001418999999999,1.0,0.0002837999999999,0.0,0.000367048,1.0,0.0047399999999999
mmlu-professional-law.val.853,WizardLM/WizardLM-13B-V1.2,1.0,7.38e-05,0.0,4.920000000000001e-05,1.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.5538,mistralai/mixtral-8x7b-chat,0.25,0.0002466,0.25,0.0001086,0.25,0.0001683,0.25,0.0002466,0.25,0.0003484239999999,0.75,0.00791
grade-school-math.dev.657,WizardLM/WizardLM-13B-V1.2,0.25,0.0001553999999999,0.25,0.000108,0.25,0.0001553999999999,0.25,0.0002934,0.25,0.00038412,0.75,0.01137
mmlu-professional-law.val.1400,WizardLM/WizardLM-13B-V1.2,1.0,8.79e-05,0.0,5.860000000000001e-05,1.0,8.79e-05,1.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
mmlu-professional-law.val.637,WizardLM/WizardLM-13B-V1.2,1.0,9.06e-05,0.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
mmlu-high-school-us-history.val.73,WizardLM/WizardLM-13B-V1.2,1.0,0.0001176,0.0,7.84e-05,1.0,0.0001176,1.0,0.0002352,0.0,0.0003041919999999,1.0,0.0039299999999999
mmlu-human-sexuality.val.79,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-moral-scenarios.val.27,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
mmlu-medical-genetics.val.97,mistralai/mixtral-8x7b-chat,0.0,6.06e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.759999999999999e-05,1.0,0.00105
hellaswag.val.8250,mistralai/mixtral-8x7b-chat,1.0,0.0001818,1.0,6.06e-05,1.0,9.09e-05,1.0,0.0001818,1.0,0.0002351279999999,1.0,0.00307
hellaswag.val.194,mistralai/mixtral-8x7b-chat,0.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
grade-school-math.dev.3283,WizardLM/WizardLM-13B-V1.2,0.25,0.0002259,0.25,0.0001244,0.25,0.0002259,0.25,0.0003623999999999,0.25,0.00039964,0.75,0.01267
grade-school-math.dev.3864,mistralai/mistral-7b-chat,0.5,7.28e-05,0.5,7.28e-05,0.75,0.0001326,0.75,0.0002292,0.75,0.000296432,0.75,0.0057199999999999
consensus_summary.dev.312,mistralai/mixtral-8x7b-chat,0.75,0.0001955999999999,0.75,5.64e-05,0.75,0.0001317,0.75,0.0001955999999999,0.75,0.000253752,0.75,0.00541
mmlu-college-mathematics.val.50,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,0.0,0.00089
mbpp.dev.156,mistralai/mistral-7b-chat,1.0,3.540000000000001e-05,1.0,3.540000000000001e-05,1.0,6.54e-05,1.0,0.0001212,1.0,9.6224e-05,1.0,0.00751
grade-school-math.dev.3376,WizardLM/WizardLM-13B-V1.2,0.5,0.0001910999999999,0.25,0.0001026,0.5,0.0001910999999999,0.5,0.0002502,0.5,0.000390328,0.5,0.00971
mbpp.dev.63,mistralai/mistral-7b-chat,0.0,3.64e-05,0.0,3.64e-05,0.0,6.27e-05,0.0,0.0002214,0.0,0.000175376,0.0,0.01573
mmlu-high-school-government-and-politics.val.88,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
grade-school-math.dev.4060,mistralai/mistral-7b-chat,0.75,0.0001102,0.75,0.0001102,0.75,0.0001581,0.75,0.0002484,0.5,0.00029876,0.75,0.0092
grade-school-math.dev.1842,WizardLM/WizardLM-13B-V1.2,0.25,0.0001865999999999,0.25,9.74e-05,0.25,0.0001865999999999,0.75,0.0003053999999999,0.25,0.000425248,0.75,0.0113499999999999
mmlu-security-studies.val.146,WizardLM/WizardLM-13B-V1.2,0.0,9.6e-05,0.0,6.4e-05,0.0,9.6e-05,1.0,0.0001919999999999,0.0,0.00024832,1.0,0.00321
hellaswag.val.8887,mistralai/mixtral-8x7b-chat,1.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.22,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
hellaswag.val.7282,mistralai/mixtral-8x7b-chat,1.0,0.0001614,1.0,5.380000000000001e-05,1.0,8.07e-05,1.0,0.0001614,1.0,0.000208744,1.0,0.00273
hellaswag.val.4337,mistralai/mixtral-8x7b-chat,0.0,0.00015,1.0,5e-05,1.0,7.5e-05,0.0,0.00015,1.0,0.000194,0.0,0.00254
hellaswag.val.1400,mistralai/mixtral-8x7b-chat,0.0,9.42e-05,0.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
arc-challenge.val.153,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
bias_detection.dev.133,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,0.0,0.0001064999999999,0.0,0.000204,0.0,0.000241336,0.0,0.01066
grade-school-math.dev.2246,WizardLM/WizardLM-13B-V1.2,0.75,0.0001986,0.25,0.0001048,0.75,0.0001986,0.75,0.0002748,0.25,0.000354632,0.75,0.00952
grade-school-math.dev.655,WizardLM/WizardLM-13B-V1.2,0.75,0.0001386,0.75,7.58e-05,0.75,0.0001386,0.75,0.0002586,0.75,0.000294104,0.75,0.00658
hellaswag.val.6251,WizardLM/WizardLM-13B-V1.2,0.0,6.719999999999998e-05,0.0,4.5e-05,0.0,6.719999999999998e-05,1.0,0.0001349999999999,0.0,0.0001746,1.0,0.00226
mmlu-miscellaneous.val.647,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
mmlu-professional-psychology.val.597,mistralai/mistral-7b-chat,0.0,3.6200000000000006e-05,0.0,3.6200000000000006e-05,0.0,5.43e-05,0.0,0.0001086,0.0,0.0001404559999999,1.0,0.00182
mmlu-security-studies.val.28,WizardLM/WizardLM-13B-V1.2,1.0,7.62e-05,1.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
grade-school-math.dev.3781,mistralai/mixtral-8x7b-chat,0.75,0.000258,0.75,7.86e-05,0.75,0.0001178999999999,0.75,0.000258,0.75,0.000282464,0.5,0.00688
grade-school-math.dev.7069,WizardLM/WizardLM-13B-V1.2,0.25,0.0001227,0.25,0.000101,0.25,0.0001227,0.75,0.0003048,0.25,0.000331352,0.75,0.01032
mmlu-professional-accounting.val.183,mistralai/mistral-7b-chat,1.0,2.7600000000000003e-05,1.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00142
grade-school-math.dev.3124,mistralai/mixtral-8x7b-chat,0.25,0.0002724,0.25,8.48e-05,0.25,0.000174,0.25,0.0002724,0.25,0.0003685999999999,0.5,0.0115699999999999
grade-school-math.dev.3034,meta/code-llama-instruct-34b-chat,0.75,0.0003383359999999,0.25,7.48e-05,0.75,0.0001398,0.75,0.0002178,0.75,0.0003383359999999,0.75,0.00697
hellaswag.val.1614,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
grade-school-math.dev.321,WizardLM/WizardLM-13B-V1.2,0.25,0.000165,0.25,0.0001088,0.25,0.000165,0.25,0.0002436,0.25,0.000297208,0.25,0.00682
grade-school-math.dev.4741,mistralai/mixtral-8x7b-chat,0.75,0.0002099999999999,0.75,6.440000000000001e-05,0.75,0.0001314,0.75,0.0002099999999999,0.75,0.000254528,0.75,0.00544
grade-school-math.dev.2558,mistralai/mixtral-8x7b-chat,0.75,0.0002844,0.25,7.04e-05,0.75,0.0001340999999999,0.75,0.0002844,0.25,0.000324368,0.75,0.00748
mmlu-professional-law.val.1446,WizardLM/WizardLM-13B-V1.2,0.0,7.38e-05,1.0,4.920000000000001e-05,0.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,0.0,0.00247
mmlu-professional-accounting.val.154,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.00133
hellaswag.val.9717,mistralai/mistral-7b-chat,1.0,5.6000000000000006e-05,1.0,5.6000000000000006e-05,1.0,8.4e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00284
grade-school-math.dev.5307,mistralai/mistral-7b-chat,0.75,5.7e-05,0.75,5.7e-05,0.75,0.0001197,0.75,0.0002016,0.25,0.000214176,0.75,0.00481
hellaswag.val.6634,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
grade-school-math.dev.2849,WizardLM/WizardLM-13B-V1.2,0.75,0.0001629,0.75,6.52e-05,0.75,0.0001629,0.75,0.0002076,0.75,0.000315832,0.75,0.00799
mmlu-nutrition.val.225,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00109
mmlu-high-school-psychology.val.48,mistralai/mistral-7b-chat,1.0,2.46e-05,1.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-high-school-statistics.val.113,mistralai/mistral-7b-chat,0.0,4.020000000000001e-05,0.0,4.020000000000001e-05,1.0,6.03e-05,1.0,0.0001205999999999,0.0,0.000155976,1.0,0.00202
mmlu-high-school-geography.val.70,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
hellaswag.val.3016,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.9642,mistralai/mixtral-8x7b-chat,1.0,0.0001542,0.0,5.14e-05,1.0,7.71e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
grade-school-math.dev.1869,WizardLM/WizardLM-13B-V1.2,0.0,0.0001803,0.25,9.68e-05,0.0,0.0001803,0.75,0.0002718,0.25,0.000339112,0.75,0.00833
hellaswag.val.26,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
grade-school-math.dev.5729,mistralai/mixtral-8x7b-chat,0.75,0.0002646,0.25,0.0001026,0.25,0.0001688999999999,0.75,0.0002646,0.25,0.0003492,0.75,0.00866
hellaswag.val.9046,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
hellaswag.val.3060,mistralai/mistral-7b-chat,1.0,2.68e-05,1.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,0.0,0.00135
grade-school-math.dev.5964,WizardLM/WizardLM-13B-V1.2,0.25,0.0002322,0.25,0.0001202,0.25,0.0002322,0.25,0.0003545999999999,0.25,0.0003942079999999,0.75,0.01613
hellaswag.val.2630,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-professional-medicine.val.104,WizardLM/WizardLM-13B-V1.2,0.0,4.38e-05,0.0,2.92e-05,0.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.0015
grade-school-math.dev.5160,mistralai/mistral-7b-chat,0.75,9.06e-05,0.75,9.06e-05,0.5,0.0001598999999999,0.25,0.0002195999999999,0.25,0.000471032,0.75,0.0101
grade-school-math.dev.2511,WizardLM/WizardLM-13B-V1.2,0.5,0.0001746,0.25,9.18e-05,0.5,0.0001746,0.25,0.0002975999999999,0.25,0.000338336,0.5,0.00966
grade-school-math.dev.4364,WizardLM/WizardLM-13B-V1.2,0.25,0.0001236,0.75,6.1000000000000005e-05,0.25,0.0001236,0.75,0.0002562,0.75,0.000353856,0.75,0.00602
grade-school-math.dev.2318,WizardLM/WizardLM-13B-V1.2,0.75,0.0002007,0.75,0.0001146,0.75,0.0002007,0.75,0.0002916,0.5,0.00042292,0.75,0.0089199999999999
hellaswag.val.282,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-nutrition.val.101,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-miscellaneous.val.446,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.9051,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.51e-05,0.0,0.0001302,0.0,0.0001683919999999,0.0,0.00221
mmlu-human-sexuality.val.24,mistralai/mistral-7b-chat,1.0,2.6e-05,1.0,2.6e-05,0.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00134
mmlu-abstract-algebra.val.6,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
mmlu-professional-psychology.val.234,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
arc-challenge.test.189,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-moral-disputes.val.226,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
hellaswag.val.1307,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.220,mistralai/mixtral-8x7b-chat,0.0,9.3e-05,0.0,3.1e-05,0.0,4.65e-05,0.0,9.3e-05,0.0,0.00012028,1.0,0.00156
mmlu-formal-logic.val.29,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
hellaswag.val.6001,mistralai/mixtral-8x7b-chat,1.0,0.0001632,0.0,5.44e-05,0.0,8.13e-05,1.0,0.0001632,0.0,0.000211072,1.0,0.00273
hellaswag.val.8213,mistralai/mixtral-8x7b-chat,1.0,0.0001788,1.0,5.9600000000000005e-05,0.0,8.94e-05,1.0,0.0001788,1.0,0.0002312479999999,1.0,0.00299
mmlu-high-school-european-history.val.25,mistralai/mixtral-8x7b-chat,1.0,0.000225,0.0,7.500000000000001e-05,0.0,0.0001125,1.0,0.000225,0.0,0.000291,1.0,0.00376
mmlu-miscellaneous.val.468,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.1782,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
grade-school-math.dev.5676,mistralai/mistral-7b-chat,0.5,8.94e-05,0.5,8.94e-05,0.25,0.0001955999999999,0.5,0.0003281999999999,0.5,0.000381792,0.75,0.01117
hellaswag.val.9362,mistralai/mixtral-8x7b-chat,0.0,0.0001482,0.0,4.94e-05,0.0,7.41e-05,0.0,0.0001482,0.0,0.000191672,1.0,0.00251
grade-school-math.dev.6352,mistralai/mistral-7b-chat,0.25,9.82e-05,0.25,9.82e-05,0.75,0.000195,0.75,0.0002946,0.75,0.000357736,0.75,0.00966
mmlu-high-school-european-history.val.161,mistralai/mixtral-8x7b-chat,1.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,1.0,0.0001668,0.0,0.000215728,1.0,0.00279
mmlu-high-school-biology.val.65,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-moral-scenarios.val.741,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
mmlu-professional-psychology.val.30,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,0.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.0010999999999999
mmlu-high-school-computer-science.val.38,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-psychology.val.307,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-professional-law.val.471,WizardLM/WizardLM-13B-V1.2,1.0,7.17e-05,0.0,4.780000000000001e-05,1.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
mmlu-professional-law.val.151,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
grade-school-math.dev.5131,WizardLM/WizardLM-13B-V1.2,0.75,0.0001239,0.75,6.9e-05,0.75,0.0001239,0.75,0.0002214,0.5,0.000266944,0.75,0.00629
grade-school-math.dev.489,mistralai/mistral-7b-chat,0.75,8.76e-05,0.75,8.76e-05,0.75,0.0001508999999999,0.75,0.0002951999999999,0.75,0.000299536,0.75,0.00961
mmlu-high-school-european-history.val.11,WizardLM/WizardLM-13B-V1.2,0.0,9.63e-05,0.0,6.42e-05,0.0,9.63e-05,0.0,0.0001926,0.0,0.000249096,1.0,0.00322
mmlu-moral-disputes.val.216,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00129
mmlu-professional-psychology.val.355,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,0.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.0010999999999999
mmlu-high-school-biology.val.306,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-international-law.val.25,mistralai/mixtral-8x7b-chat,1.0,8.159999999999999e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-college-mathematics.val.54,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
mmlu-college-computer-science.val.50,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-professional-accounting.val.170,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00124
mmlu-public-relations.val.45,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00116
hellaswag.val.7347,mistralai/mixtral-8x7b-chat,0.0,0.0001698,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00287
mmlu-moral-disputes.val.332,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00113
hellaswag.val.1588,WizardLM/WizardLM-13B-V1.2,1.0,5.1e-05,1.0,3.4200000000000005e-05,1.0,5.1e-05,1.0,0.0001026,1.0,0.000132696,1.0,0.00172
grade-school-math.dev.5874,mistralai/mistral-7b-chat,0.75,8.520000000000001e-05,0.75,8.520000000000001e-05,0.75,0.0001458,0.75,0.0002658,0.75,0.000303416,0.75,0.0068899999999999
hellaswag.val.4791,mistralai/mixtral-8x7b-chat,1.0,0.0001494,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,1.0,0.0001932239999999,1.0,0.00253
mbpp.dev.201,mistralai/mistral-7b-chat,0.0,3.74e-05,0.0,3.74e-05,0.0,6.39e-05,1.0,0.0001295999999999,1.0,0.000114848,1.0,0.00567
consensus_summary.dev.241,mistralai/mistral-7b-chat,0.0,3.46e-05,0.0,3.46e-05,0.0,4.59e-05,0.75,0.0001086,0.75,0.00024832,1.0,0.00184
mmlu-international-law.val.107,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.5101,mistralai/mistral-7b-chat,0.25,9.38e-05,0.25,9.38e-05,0.25,0.0001640999999999,0.25,0.0002297999999999,0.75,0.000293328,0.75,0.00707
winogrande.dev.460,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,1.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,0.0,0.00054
hellaswag.val.3810,mistralai/mixtral-8x7b-chat,1.0,0.00015,0.0,5e-05,0.0,7.5e-05,1.0,0.00015,0.0,0.000194,1.0,0.00254
grade-school-math.dev.5637,mistralai/mistral-7b-chat,0.25,8.92e-05,0.25,8.92e-05,0.75,0.0001305,0.25,0.0002208,0.75,0.00026772,0.75,0.00541
winogrande.dev.853,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.44e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.0005
mmlu-professional-law.val.416,WizardLM/WizardLM-13B-V1.2,1.0,7.29e-05,0.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,1.0,0.00244
hellaswag.val.2847,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.27e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
hellaswag.val.4039,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00265
hellaswag.val.4216,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
grade-school-math.dev.5304,WizardLM/WizardLM-13B-V1.2,0.25,0.0001506,0.25,6.560000000000001e-05,0.25,0.0001506,0.25,0.0002148,0.25,0.000400416,0.75,0.00895
grade-school-math.dev.1477,mistralai/mistral-7b-chat,0.25,8.740000000000001e-05,0.25,8.740000000000001e-05,0.25,0.0001464,1.0,0.0002028,0.75,0.00034532,0.75,0.01091
arc-challenge.test.31,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,1.0,6.673599999999999e-05,1.0,0.0009
mmlu-abstract-algebra.val.98,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
hellaswag.val.8977,WizardLM/WizardLM-13B-V1.2,0.0,7.589999999999999e-05,0.0,5.080000000000001e-05,0.0,7.589999999999999e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
mmlu-anatomy.val.49,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
hellaswag.val.6075,mistralai/mixtral-8x7b-chat,1.0,0.0001799999999999,0.0,6e-05,0.0,8.999999999999999e-05,1.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
mmlu-high-school-psychology.val.455,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-human-aging.val.45,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
consensus_summary.dev.282,mistralai/mistral-7b-chat,0.75,6.48e-05,0.75,6.48e-05,0.75,0.0001215,0.75,0.0001812,0.75,0.000285568,0.75,0.00524
grade-school-math.dev.2591,mistralai/mistral-7b-chat,0.75,8.840000000000001e-05,0.75,8.840000000000001e-05,0.75,0.000159,0.75,0.0002321999999999,0.25,0.000336784,0.5,0.00752
mmlu-conceptual-physics.val.43,mistralai/mixtral-8x7b-chat,0.0,5.58e-05,1.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-high-school-macroeconomics.val.135,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
grade-school-math.dev.6477,WizardLM/WizardLM-13B-V1.2,0.25,0.000144,0.25,0.0001058,0.25,0.000144,0.75,0.000312,0.25,0.000383344,0.5,0.0082
grade-school-math.dev.7011,mistralai/mistral-7b-chat,0.75,8.860000000000001e-05,0.75,8.860000000000001e-05,0.75,0.0001413,0.75,0.000213,0.75,0.000292552,0.75,0.00668
hellaswag.val.6222,mistralai/mistral-7b-chat,0.0,5.420000000000001e-05,0.0,5.420000000000001e-05,0.0,8.099999999999999e-05,0.0,0.0001626,0.0,0.0002102959999999,0.0,0.00275
mmlu-security-studies.val.243,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
mmlu-prehistory.val.279,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.3676,WizardLM/WizardLM-13B-V1.2,0.25,0.000147,0.25,0.0001088,0.25,0.000147,0.75,0.0002496,0.75,0.000335232,0.5,0.00795
hellaswag.val.5773,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00259
grade-school-math.dev.4973,mistralai/mistral-7b-chat,0.25,7.52e-05,0.25,7.52e-05,0.75,0.0001616999999999,0.25,0.0002808,0.25,0.000371704,0.25,0.00825
hellaswag.val.5989,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mbpp.dev.154,mistralai/mistral-7b-chat,1.0,4.5e-05,1.0,4.5e-05,1.0,8.67e-05,0.0,0.0001542,1.0,0.0001358,1.0,0.01177
grade-school-math.dev.636,WizardLM/WizardLM-13B-V1.2,0.5,0.0002000999999999,0.25,9.86e-05,0.5,0.0002000999999999,0.25,0.0002879999999999,0.25,0.000445424,0.5,0.00927
mmlu-high-school-us-history.val.196,mistralai/mixtral-8x7b-chat,0.0,0.0001782,1.0,5.94e-05,1.0,8.91e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
hellaswag.val.5239,WizardLM/WizardLM-13B-V1.2,0.0,8.519999999999998e-05,0.0,5.7e-05,0.0,8.519999999999998e-05,0.0,0.0001709999999999,0.0,0.00022116,1.0,0.00286
mtbench.dev.10,mistralai/mistral-7b-chat,0.5,0.0001186,0.5,0.0001186,0.8,0.0001922999999999,0.5,0.0003713999999999,0.5,0.000560272,0.7,0.02101
mmlu-professional-law.val.131,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,1.0,5e-05,0.0,7.5e-05,1.0,0.00015,0.0,0.000194,1.0,0.00254
mmlu-human-aging.val.119,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-public-relations.val.53,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,0.0,0.00067
consensus_summary.dev.78,mistralai/mixtral-8x7b-chat,0.75,0.0001914,0.25,4.72e-05,0.25,6.54e-05,0.75,0.0001914,0.75,0.000251424,0.25,0.00222
mmlu-professional-law.val.479,WizardLM/WizardLM-13B-V1.2,0.0,0.0001217999999999,0.0,8.120000000000001e-05,0.0,0.0001217999999999,1.0,0.0002435999999999,0.0,0.000315056,1.0,0.00407
grade-school-math.dev.4258,mistralai/mixtral-8x7b-chat,0.75,0.0002694,0.75,9.06e-05,0.25,0.000156,0.75,0.0002694,0.25,0.0003104,0.75,0.00901
grade-school-math.dev.3369,mistralai/mistral-7b-chat,0.25,0.000107,0.25,0.000107,0.75,0.0001923,0.75,0.0003132,0.5,0.000383344,0.75,0.01185
mmlu-security-studies.val.119,mistralai/mixtral-8x7b-chat,1.0,8.64e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
arc-challenge.test.745,mistralai/mixtral-8x7b-chat,0.0,6.659999999999999e-05,1.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,1.0,8.6136e-05,1.0,0.00115
mbpp.dev.220,mistralai/mistral-7b-chat,0.0,8.240000000000001e-05,0.0,8.240000000000001e-05,0.0,7.65e-05,0.0,0.0002256,0.0,0.000188568,1.0,0.00957
mmlu-nutrition.val.6,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
mmlu-moral-scenarios.val.366,mistralai/mistral-7b-chat,0.0,3.02e-05,0.0,3.02e-05,0.0,4.53e-05,0.0,9.06e-05,0.0,0.000117176,0.0,0.00155
mmlu-formal-logic.val.62,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
grade-school-math.dev.6357,WizardLM/WizardLM-13B-V1.2,0.25,0.000141,0.75,9.44e-05,0.25,0.000141,0.5,0.000291,0.5,0.000387224,0.75,0.0102
hellaswag.val.622,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
consensus_summary.dev.303,mistralai/mixtral-8x7b-chat,0.75,0.0002171999999999,0.75,5.9e-05,0.0,7.319999999999999e-05,0.75,0.0002171999999999,0.75,0.000249872,0.75,0.00503
winogrande.dev.165,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00052
mmlu-high-school-psychology.val.446,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
hellaswag.val.6894,mistralai/mixtral-8x7b-chat,1.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,1.0,0.0001662,0.0,0.000214952,1.0,0.00281
grade-school-math.dev.3574,mistralai/mistral-7b-chat,0.25,0.0006224,0.25,0.0006224,0.25,0.0001935,0.25,0.0003684,0.25,0.000459392,0.75,0.01231
arc-challenge.test.577,mistralai/mixtral-8x7b-chat,1.0,9.96e-05,1.0,3.320000000000001e-05,1.0,4.98e-05,1.0,9.96e-05,1.0,0.000128816,1.0,0.0017
grade-school-math.dev.5079,WizardLM/WizardLM-13B-V1.2,0.5,0.0001614,0.25,6.18e-05,0.5,0.0001614,0.25,0.0002316,0.5,0.00035308,0.75,0.00682
mmlu-management.val.8,mistralai/mixtral-8x7b-chat,0.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-high-school-world-history.val.105,mistralai/mixtral-8x7b-chat,1.0,0.000258,1.0,8.6e-05,1.0,0.000129,1.0,0.000258,0.0,0.00033368,1.0,0.00431
arc-challenge.test.608,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00079
mmlu-professional-law.val.15,WizardLM/WizardLM-13B-V1.2,0.0,5.91e-05,0.0,3.94e-05,0.0,5.91e-05,1.0,0.0001182,0.0,0.0001528719999999,1.0,0.00198
mmlu-moral-scenarios.val.328,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
hellaswag.val.2950,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,0.0,1.96e-05,0.0,2.91e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.3012,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.69e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
winogrande.dev.475,mistralai/mistral-7b-chat,0.0,1.02e-05,0.0,1.02e-05,0.0,1.5e-05,0.0,3.06e-05,0.0,3.9576e-05,1.0,0.00052
mmlu-miscellaneous.val.471,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
winogrande.dev.361,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
mmlu-computer-security.val.98,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-elementary-mathematics.val.351,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
arc-challenge.test.1039,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.613,WizardLM/WizardLM-13B-V1.2,0.5,0.0001571999999999,0.75,7.92e-05,0.5,0.0001571999999999,0.75,0.0002316,0.75,0.000297984,0.5,0.00812
grade-school-math.dev.2580,mistralai/mixtral-8x7b-chat,0.25,0.0002394,0.25,6.8e-05,0.75,0.0001254,0.25,0.0002394,0.25,0.0002925519999999,0.75,0.00796
grade-school-math.dev.2818,mistralai/mistral-7b-chat,0.5,7.500000000000001e-05,0.5,7.500000000000001e-05,0.5,0.0001368,0.5,0.0002238,0.25,0.000315056,0.5,0.00755
abstract2title.test.229,mistralai/mixtral-8x7b-chat,1.0,0.0001565999999999,1.0,5.08e-05,1.0,7.89e-05,1.0,0.0001565999999999,1.0,0.000195552,1.0,0.00306
consensus_summary.dev.54,mistralai/mistral-7b-chat,0.75,6.48e-05,0.75,6.48e-05,0.75,9.48e-05,0.75,0.0001434,0.75,0.000255304,0.75,0.0033
grade-school-math.dev.6948,mistralai/mistral-7b-chat,0.25,8.88e-05,0.25,8.88e-05,0.75,0.000126,0.75,0.0002388,0.75,0.00031428,0.75,0.00579
mmlu-philosophy.val.161,WizardLM/WizardLM-13B-V1.2,0.0,4.71e-05,1.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,0.0,0.0016099999999999
winogrande.dev.190,mistralai/mixtral-8x7b-chat,1.0,3.3e-05,1.0,1.1e-05,1.0,1.65e-05,1.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00059
hellaswag.val.6955,WizardLM/WizardLM-13B-V1.2,0.0,8.549999999999999e-05,0.0,5.720000000000001e-05,0.0,8.549999999999999e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.0029
hellaswag.val.1475,WizardLM/WizardLM-13B-V1.2,1.0,3.69e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.7937,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
hellaswag.val.8044,mistralai/mistral-7b-chat,0.0,4.580000000000001e-05,0.0,4.580000000000001e-05,0.0,6.869999999999999e-05,1.0,0.0001373999999999,0.0,0.000177704,1.0,0.00233
hellaswag.val.7950,WizardLM/WizardLM-13B-V1.2,1.0,7.680000000000001e-05,0.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,0.0,0.000198656,1.0,0.0026
hellaswag.val.1192,WizardLM/WizardLM-13B-V1.2,0.0,3.27e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-philosophy.val.73,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
hellaswag.val.9256,WizardLM/WizardLM-13B-V1.2,0.0,8.01e-05,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
mmlu-logical-fallacies.val.104,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,0.0,0.00087
grade-school-math.dev.7344,WizardLM/WizardLM-13B-V1.2,0.25,0.0001338,0.25,9.24e-05,0.25,0.0001338,0.25,0.0002454,0.25,0.000381792,0.75,0.01138
arc-challenge.test.560,mistralai/mixtral-8x7b-chat,1.0,4.08e-05,1.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00072
mmlu-professional-law.val.688,WizardLM/WizardLM-13B-V1.2,1.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
hellaswag.val.1746,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,0.0,0.0011899999999999
hellaswag.val.4233,mistralai/mistral-7b-chat,0.0,4.480000000000001e-05,0.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
mmlu-high-school-psychology.val.222,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,1.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
consensus_summary.dev.332,mistralai/mixtral-8x7b-chat,0.0,0.0001296,0.0,4.3e-05,0.75,8.79e-05,0.0,0.0001296,1.0,0.000212624,0.25,0.00201
hellaswag.val.1775,WizardLM/WizardLM-13B-V1.2,1.0,4.44e-05,0.0,2.96e-05,1.0,4.44e-05,1.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
hellaswag.val.2026,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-miscellaneous.val.595,mistralai/mistral-7b-chat,0.0,3.960000000000001e-05,0.0,3.960000000000001e-05,0.0,5.94e-05,1.0,0.0001188,0.0,0.000153648,1.0,0.00199
hellaswag.val.3787,mistralai/mixtral-8x7b-chat,1.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
mmlu-high-school-geography.val.113,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-high-school-microeconomics.val.75,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-machine-learning.val.53,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.6807,mistralai/mistral-7b-chat,0.75,0.000116,0.75,0.000116,0.5,0.000162,0.75,0.0002916,0.5,0.000320488,0.75,0.00732
mmlu-logical-fallacies.val.42,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.9049,mistralai/mixtral-8x7b-chat,1.0,0.0001529999999999,0.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
winogrande.dev.1239,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,0.0,0.0005
mmlu-moral-scenarios.val.594,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00143
mmlu-professional-psychology.val.479,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
mmlu-anatomy.val.57,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.6396,WizardLM/WizardLM-13B-V1.2,0.5,0.0001413,0.5,8.18e-05,0.5,0.0001413,0.25,0.0002544,0.75,0.000339112,0.75,0.00673
hellaswag.val.3175,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
arc-challenge.test.854,WizardLM/WizardLM-13B-V1.2,0.0,3.96e-05,0.0,2.62e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
arc-challenge.test.693,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.1715,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.591,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-professional-law.val.404,WizardLM/WizardLM-13B-V1.2,0.0,6.599999999999999e-05,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,1.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
grade-school-math.dev.6899,WizardLM/WizardLM-13B-V1.2,0.25,0.0001173,0.25,0.000107,0.25,0.0001173,0.25,0.000309,0.25,0.000394984,0.75,0.00686
mmlu-professional-law.val.528,WizardLM/WizardLM-13B-V1.2,0.0,9.45e-05,0.0,6.3e-05,0.0,9.45e-05,0.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
hellaswag.val.8591,mistralai/mixtral-8x7b-chat,0.0,0.0001524,1.0,5.080000000000001e-05,1.0,7.62e-05,0.0,0.0001524,1.0,0.0001971039999999,1.0,0.00258
bias_detection.dev.191,meta/code-llama-instruct-34b-chat,0.0,0.000241336,0.0,5.06e-05,0.0,9.45e-05,1.0,0.0001727999999999,0.0,0.000241336,1.0,0.00827
mmlu-professional-law.val.714,WizardLM/WizardLM-13B-V1.2,1.0,9.03e-05,0.0,6.0200000000000006e-05,1.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
mmlu-professional-law.val.1038,WizardLM/WizardLM-13B-V1.2,0.0,7.26e-05,0.0,4.84e-05,0.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
mmlu-elementary-mathematics.val.216,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-moral-scenarios.val.131,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,0.0,0.00149
mmlu-moral-scenarios.val.296,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-professional-psychology.val.580,mistralai/mistral-7b-chat,1.0,1.62e-05,1.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
mmlu-human-aging.val.183,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-college-mathematics.val.60,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.5e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.936,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.72e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-professional-law.val.726,WizardLM/WizardLM-13B-V1.2,0.0,9.03e-05,0.0,6.0200000000000006e-05,0.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
mmlu-high-school-mathematics.val.140,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.54e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-law.val.265,mistralai/mixtral-8x7b-chat,0.0,0.0001344,0.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
hellaswag.val.5245,mistralai/mixtral-8x7b-chat,1.0,0.0001782,0.0,5.94e-05,0.0,8.91e-05,1.0,0.0001782,0.0,0.000230472,1.0,0.00298
winogrande.dev.950,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,0.0,0.00049
hellaswag.val.2569,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,1.0,2.7600000000000003e-05,1.0,4.11e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00142
hellaswag.val.7120,mistralai/mixtral-8x7b-chat,0.0,0.0001296,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,1.0,0.0022
mmlu-professional-law.val.844,WizardLM/WizardLM-13B-V1.2,0.0,8.999999999999999e-05,0.0,6e-05,0.0,8.999999999999999e-05,1.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
mbpp.dev.332,mistralai/mixtral-8x7b-chat,0.0,0.000174,0.0,5.82e-05,0.0,9e-05,0.0,0.000174,0.0,0.00024056,0.0,0.00831
mmlu-professional-medicine.val.138,WizardLM/WizardLM-13B-V1.2,0.0,6.84e-05,0.0,4.56e-05,0.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00232
grade-school-math.dev.1335,mistralai/mistral-7b-chat,0.75,6.080000000000001e-05,0.75,6.080000000000001e-05,0.75,0.0001205999999999,0.75,0.000174,0.75,0.000234352,0.5,0.00416
mmlu-virology.val.161,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
grade-school-math.dev.7419,meta/code-llama-instruct-34b-chat,0.75,0.000336784,0.25,9.64e-05,0.75,0.0001529999999999,0.75,0.0002441999999999,0.75,0.000336784,0.75,0.00607
mmlu-high-school-government-and-politics.val.2,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.3940,mistralai/mixtral-8x7b-chat,0.0,0.00012,1.0,4e-05,1.0,6e-05,0.0,0.00012,1.0,0.0001551999999999,1.0,0.00204
mmlu-professional-law.val.695,WizardLM/WizardLM-13B-V1.2,1.0,0.0001023,0.0,6.819999999999999e-05,1.0,0.0001023,0.0,0.0002046,0.0,0.000264616,0.0,0.00342
mmlu-abstract-algebra.val.46,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-public-relations.val.86,WizardLM/WizardLM-13B-V1.2,1.0,3.96e-05,0.0,2.64e-05,1.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,0.0,0.00133
mmlu-professional-psychology.val.494,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
grade-school-math.dev.3189,mistralai/mistral-7b-chat,0.5,8.400000000000001e-05,0.5,8.400000000000001e-05,0.5,0.0001532999999999,0.5,0.0002568,0.25,0.000304968,0.5,0.0077699999999999
mmlu-professional-law.val.910,WizardLM/WizardLM-13B-V1.2,0.0,7.29e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,1.0,0.00244
hellaswag.val.9819,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.34e-05,1.0,0.0001668,0.0,0.000215728,1.0,0.00282
grade-school-math.dev.771,WizardLM/WizardLM-13B-V1.2,0.5,0.0001338,0.25,8.58e-05,0.5,0.0001338,0.25,0.0002694,0.75,0.000263064,0.5,0.00586
mmlu-jurisprudence.val.6,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
abstract2title.test.243,mistralai/mixtral-8x7b-chat,1.0,0.0001188,1.0,3.78e-05,1.0,5.97e-05,1.0,0.0001188,1.0,0.000145888,1.0,0.00247
grade-school-math.dev.4278,mistralai/mistral-7b-chat,0.25,7.879999999999999e-05,0.25,7.879999999999999e-05,0.25,0.0001206,0.75,0.000198,0.25,0.000228144,0.75,0.00558
winogrande.dev.82,mistralai/mistral-7b-chat,0.0,1.02e-05,0.0,1.02e-05,1.0,1.53e-05,0.0,3.06e-05,0.0,3.9576e-05,0.0,0.00055
mmlu-high-school-psychology.val.101,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-clinical-knowledge.val.146,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.7399,mistralai/mistral-7b-chat,0.25,8.94e-05,0.25,8.94e-05,0.5,0.0001743,0.25,0.0002676,0.25,0.000417488,0.5,0.00813
grade-school-math.dev.3745,WizardLM/WizardLM-13B-V1.2,0.75,0.0001404,0.75,8.82e-05,0.75,0.0001404,0.75,0.0002556,0.75,0.00034144,0.75,0.0078599999999999
arc-challenge.test.392,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,1.0,6.5184e-05,1.0,0.00088
winogrande.dev.1218,mistralai/mistral-7b-chat,1.0,1.22e-05,1.0,1.22e-05,0.0,1.8e-05,1.0,3.66e-05,1.0,4.7336e-05,1.0,0.00062
hellaswag.val.8460,mistralai/mixtral-8x7b-chat,1.0,0.0001836,1.0,6.120000000000001e-05,1.0,9.15e-05,1.0,0.0001836,1.0,0.0002374559999999,1.0,0.0031
hellaswag.val.2153,WizardLM/WizardLM-13B-V1.2,0.0,3.63e-05,0.0,2.44e-05,0.0,3.63e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
grade-school-math.dev.1920,mistralai/mistral-7b-chat,0.25,6.54e-05,0.25,6.54e-05,0.75,0.0001338,0.75,0.0002166,0.75,0.000305744,0.75,0.0061
mmlu-professional-law.val.1344,WizardLM/WizardLM-13B-V1.2,0.0,0.0001746,1.0,0.0001164,0.0,0.0001746,1.0,0.0003492,0.0,0.000451632,1.0,0.0058299999999999
grade-school-math.dev.4215,WizardLM/WizardLM-13B-V1.2,0.25,0.0001512,0.25,9.74e-05,0.25,0.0001512,0.5,0.000288,0.25,0.000328248,0.5,0.01086
mtbench.dev.3,meta/code-llama-instruct-34b-chat,0.9,0.000466376,0.4,0.0001424,0.9,0.0003209999999999,1.0,0.0006575999999999,0.9,0.000466376,1.0,0.03033
hellaswag.val.7119,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,1.0,7.979999999999999e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
hellaswag.val.3641,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00242
hellaswag.val.7527,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,0.0,7.89e-05,0.0,0.0001584,0.0,0.000204864,0.0,0.00268
mmlu-professional-law.val.1416,mistralai/mistral-7b-chat,0.0,6.1000000000000005e-05,0.0,6.1000000000000005e-05,1.0,9.15e-05,0.0,0.0001829999999999,0.0,0.00023668,0.0,0.00306
consensus_summary.dev.266,mistralai/mistral-7b-chat,0.75,4.8200000000000006e-05,0.75,4.8200000000000006e-05,0.75,0.0001446,0.75,0.0001541999999999,0.75,0.000223488,0.75,0.00438
grade-school-math.dev.7043,WizardLM/WizardLM-13B-V1.2,0.25,0.0002115,0.25,0.0001158,0.25,0.0002115,0.25,0.0003036,0.25,0.000431456,0.5,0.01231
hellaswag.val.5933,mistralai/mixtral-8x7b-chat,1.0,0.0001428,1.0,4.7600000000000005e-05,1.0,7.11e-05,1.0,0.0001428,1.0,0.000184688,1.0,0.00239
mmlu-professional-law.val.591,WizardLM/WizardLM-13B-V1.2,0.0,7.049999999999999e-05,1.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,0.0,0.00236
winogrande.dev.95,mistralai/mistral-7b-chat,0.0,8.999999999999999e-06,0.0,8.999999999999999e-06,0.0,1.35e-05,0.0,2.7e-05,0.0,3.4920000000000004e-05,1.0,0.00049
mmlu-professional-law.val.342,WizardLM/WizardLM-13B-V1.2,1.0,6.21e-05,0.0,4.14e-05,1.0,6.21e-05,1.0,0.0001242,0.0,0.000160632,1.0,0.00208
grade-school-math.dev.7126,WizardLM/WizardLM-13B-V1.2,0.5,0.0001677,0.75,7.7e-05,0.5,0.0001677,0.75,0.000255,0.25,0.000273152,0.5,0.01006
hellaswag.val.8461,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.28e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00281
grade-school-math.dev.2702,WizardLM/WizardLM-13B-V1.2,0.5,0.0001494,0.75,8.72e-05,0.5,0.0001494,0.75,0.0002172,0.25,0.000294104,0.75,0.00758
hellaswag.val.9719,WizardLM/WizardLM-13B-V1.2,1.0,7.680000000000001e-05,1.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,1.0,0.000198656,1.0,0.0026
hellaswag.val.8229,mistralai/mixtral-8x7b-chat,1.0,0.0001829999999999,0.0,6.1000000000000005e-05,0.0,9.119999999999998e-05,1.0,0.0001829999999999,0.0,0.00023668,1.0,0.00306
mmlu-prehistory.val.309,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.8819,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,0.0,0.00294
mmlu-miscellaneous.val.273,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-nutrition.val.303,WizardLM/WizardLM-13B-V1.2,0.0,3.84e-05,0.0,2.56e-05,0.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
mmlu-jurisprudence.val.81,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,1.0,3.15e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-college-physics.val.4,mistralai/mixtral-8x7b-chat,1.0,7.86e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.9559,mistralai/mistral-7b-chat,1.0,5.5400000000000005e-05,1.0,5.5400000000000005e-05,1.0,8.28e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00278
mmlu-anatomy.val.98,mistralai/mistral-7b-chat,1.0,1.82e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.2917,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
hellaswag.val.5959,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00246
hellaswag.val.4368,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,0.0,0.00266
hellaswag.val.3252,mistralai/mixtral-8x7b-chat,1.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.95e-05,1.0,0.0001596,0.0,0.0002064159999999,0.0,0.0027
mmlu-moral-scenarios.val.8,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00145
mmlu-high-school-biology.val.244,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-medicine.val.137,WizardLM/WizardLM-13B-V1.2,0.0,5.55e-05,1.0,3.7000000000000005e-05,0.0,5.55e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00189
hellaswag.val.2661,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.48e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
bias_detection.dev.283,mistralai/mistral-7b-chat,0.0,6.58e-05,0.0,6.58e-05,0.0,9.96e-05,0.0,0.0002753999999999,0.0,0.000239784,0.0,0.00954
mmlu-high-school-computer-science.val.80,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,1.0,2.76e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-elementary-mathematics.val.372,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.14e-05,0.0,5.432e-05,0.0,0.00071
grade-school-math.dev.37,WizardLM/WizardLM-13B-V1.2,0.75,0.000183,0.25,9.160000000000002e-05,0.75,0.000183,0.75,0.000294,0.25,0.000354632,0.75,0.01047
hellaswag.val.7849,mistralai/mixtral-8x7b-chat,0.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,0.0,0.0001397999999999,0.0,0.000180808,1.0,0.00237
mmlu-moral-scenarios.val.824,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
winogrande.dev.491,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00051
mmlu-public-relations.val.75,WizardLM/WizardLM-13B-V1.2,0.0,2.37e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-high-school-microeconomics.val.173,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-statistics.val.81,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
hellaswag.val.2534,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-high-school-microeconomics.val.59,mistralai/mistral-7b-chat,1.0,2.92e-05,1.0,2.92e-05,0.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.0015
hellaswag.val.6490,mistralai/mistral-7b-chat,0.0,5.300000000000001e-05,0.0,5.300000000000001e-05,0.0,7.919999999999999e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00266
mmlu-nutrition.val.233,mistralai/mistral-7b-chat,1.0,2.54e-05,1.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,0.0,0.00128
grade-school-math.dev.4715,WizardLM/WizardLM-13B-V1.2,0.5,0.0001889999999999,0.75,0.0001236,0.5,0.0001889999999999,0.5,0.0003006,0.5,0.000383344,0.5,0.00996
hellaswag.val.8580,mistralai/mistral-7b-chat,1.0,5.7e-05,1.0,5.7e-05,1.0,8.519999999999998e-05,1.0,0.0001709999999999,1.0,0.00022116,1.0,0.00289
hellaswag.val.9774,mistralai/mistral-7b-chat,0.0,4.56e-05,0.0,4.56e-05,0.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00229
grade-school-math.dev.4470,mistralai/mistral-7b-chat,0.75,6.780000000000001e-05,0.75,6.780000000000001e-05,0.75,0.0001311,0.75,0.0002004,0.75,0.0002328,0.75,0.00559
arc-challenge.test.1095,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,0.0,1.62e-05,1.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.9629,mistralai/mixtral-8x7b-chat,1.0,0.0001434,1.0,4.780000000000001e-05,1.0,7.17e-05,1.0,0.0001434,1.0,0.0001854639999999,1.0,0.00243
mmlu-high-school-microeconomics.val.3,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
hellaswag.val.9859,mistralai/mixtral-8x7b-chat,0.0,0.0001578,1.0,5.260000000000001e-05,1.0,7.89e-05,0.0,0.0001578,1.0,0.000204088,1.0,0.00267
hellaswag.val.9245,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.189999999999998e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
mmlu-miscellaneous.val.742,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
winogrande.dev.1135,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.492e-05,1.0,0.0005
mmlu-professional-accounting.val.257,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
mmlu-miscellaneous.val.496,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.3984,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00243
mmlu-high-school-geography.val.17,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.4318,WizardLM/WizardLM-13B-V1.2,0.25,0.0001953,0.25,0.000112,0.25,0.0001953,0.25,0.0003192,0.25,0.000265392,0.75,0.01304
mmlu-high-school-government-and-politics.val.38,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.10002,WizardLM/WizardLM-13B-V1.2,0.0,9.27e-05,0.0,6.18e-05,0.0,9.27e-05,0.0,0.0001853999999999,0.0,0.000239784,1.0,0.00313
mmlu-high-school-european-history.val.22,WizardLM/WizardLM-13B-V1.2,0.0,9.48e-05,1.0,6.32e-05,0.0,9.48e-05,0.0,0.0001896,0.0,0.000245216,0.0,0.00317
winogrande.dev.1039,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,1.0,4.1128e-05,0.0,0.00057
mmlu-high-school-mathematics.val.183,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,0.0,0.0009699999999999
mmlu-professional-psychology.val.144,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.95,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
grade-school-math.dev.5495,WizardLM/WizardLM-13B-V1.2,0.75,0.000156,0.75,6.860000000000001e-05,0.75,0.000156,0.75,0.0002226,0.75,0.0003492,0.75,0.00717
mmlu-college-medicine.val.25,WizardLM/WizardLM-13B-V1.2,0.0,4.59e-05,0.0,3.0600000000000005e-05,0.0,4.59e-05,0.0,9.18e-05,0.0,0.000118728,1.0,0.00154
grade-school-math.dev.1140,meta/code-llama-instruct-34b-chat,0.25,0.000273928,0.25,9.78e-05,0.25,0.0001674,0.25,0.000285,0.25,0.000273928,0.75,0.01221
grade-school-math.dev.3297,WizardLM/WizardLM-13B-V1.2,0.5,0.000147,0.25,0.0001022,0.5,0.000147,0.75,0.0003228,0.25,0.000330576,0.75,0.00853
mbpp.dev.276,mistralai/mistral-7b-chat,1.0,2.9000000000000004e-05,1.0,2.9000000000000004e-05,1.0,0.0001038,1.0,0.0001056,1.0,0.000131144,1.0,0.01562
mmlu-electrical-engineering.val.8,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,1.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,0.0,0.00075
grade-school-math.dev.2923,mistralai/mixtral-8x7b-chat,0.75,0.0002298,0.25,5.3e-05,0.5,0.0001329,0.75,0.0002298,0.75,0.000282464,0.75,0.00618
mmlu-high-school-biology.val.191,mistralai/mixtral-8x7b-chat,0.0,8.52e-05,1.0,2.84e-05,0.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00143
grade-school-math.dev.1713,WizardLM/WizardLM-13B-V1.2,0.5,0.000156,0.25,6.62e-05,0.5,0.000156,0.75,0.0002153999999999,0.5,0.0003383359999999,0.5,0.00995
mmlu-professional-law.val.800,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,0.0,0.00241
mmlu-moral-scenarios.val.647,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.0015199999999999
mmlu-machine-learning.val.27,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,0.0,0.00075
winogrande.dev.926,mistralai/mixtral-8x7b-chat,0.0,3.06e-05,0.0,1.02e-05,1.0,1.53e-05,0.0,3.06e-05,0.0,3.9576e-05,0.0,0.00055
hellaswag.val.4124,mistralai/mixtral-8x7b-chat,1.0,0.0001632,0.0,5.44e-05,0.0,8.16e-05,1.0,0.0001632,0.0,0.000211072,1.0,0.00273
mmlu-sociology.val.11,mistralai/mixtral-8x7b-chat,1.0,8.759999999999999e-05,0.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
mmlu-high-school-world-history.val.216,mistralai/mixtral-8x7b-chat,1.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
hellaswag.val.1092,WizardLM/WizardLM-13B-V1.2,0.0,3.84e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
grade-school-math.dev.7208,mistralai/mistral-7b-chat,0.5,7.6e-05,0.5,7.6e-05,0.5,0.0001521,0.75,0.000249,0.5,0.0003026399999999,0.75,0.0071699999999999
hellaswag.val.3465,mistralai/mixtral-8x7b-chat,1.0,0.0001812,1.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,1.0,0.000234352,1.0,0.00303
grade-school-math.dev.4220,mistralai/mistral-7b-chat,0.5,9.1e-05,0.5,9.1e-05,0.25,0.0001397999999999,0.75,0.0002934,0.75,0.00035308,0.75,0.00894
grade-school-math.dev.3501,mistralai/mistral-7b-chat,0.25,9.12e-05,0.25,9.12e-05,0.75,0.0001524,0.5,0.0002466,0.5,0.000301088,0.75,0.00878
mmlu-elementary-mathematics.val.360,mistralai/mistral-7b-chat,1.0,1.82e-05,1.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
grade-school-math.dev.1329,WizardLM/WizardLM-13B-V1.2,0.75,0.000198,0.25,8.58e-05,0.75,0.000198,0.75,0.0002844,0.75,0.000340664,0.75,0.01225
mmlu-high-school-european-history.val.13,WizardLM/WizardLM-13B-V1.2,0.0,0.000144,0.0,9.6e-05,0.0,0.000144,0.0,0.000288,0.0,0.00037248,0.0,0.00484
mmlu-moral-scenarios.val.476,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
hellaswag.val.7289,mistralai/mistral-7b-chat,0.0,4.520000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,1.0,0.00227
mmlu-college-biology.val.64,mistralai/mixtral-8x7b-chat,0.0,9.12e-05,0.0,3.04e-05,1.0,4.56e-05,0.0,9.12e-05,0.0,0.000117952,1.0,0.00153
grade-school-math.dev.2142,WizardLM/WizardLM-13B-V1.2,0.75,0.0001671,0.75,9.06e-05,0.75,0.0001671,0.75,0.000297,0.75,0.000374808,0.5,0.00879
grade-school-math.dev.5058,mistralai/mistral-7b-chat,0.75,9.2e-05,0.75,9.2e-05,0.5,0.0001610999999999,0.25,0.0002309999999999,0.25,0.000479568,0.5,0.00957
mmlu-anatomy.val.92,mistralai/mistral-7b-chat,1.0,2.4800000000000003e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
mmlu-professional-accounting.val.222,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,1.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-professional-law.val.266,mistralai/mixtral-8x7b-chat,1.0,0.0001842,1.0,6.14e-05,0.0,9.21e-05,1.0,0.0001842,0.0,0.000238232,1.0,0.00308
hellaswag.val.6711,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.0025
grade-school-math.dev.333,mistralai/mistral-7b-chat,0.25,6.16e-05,0.25,6.16e-05,0.75,0.0001482,0.25,0.000282,0.75,0.000318936,0.75,0.01089
hellaswag.val.5242,mistralai/mistral-7b-chat,1.0,4.340000000000001e-05,1.0,4.340000000000001e-05,1.0,6.51e-05,0.0,0.0001302,1.0,0.0001683919999999,1.0,0.00221
hellaswag.val.4295,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,1.0,7.8e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-computer-security.val.64,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.5461,mistralai/mixtral-8x7b-chat,0.0,0.0001565999999999,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001565999999999,0.0,0.000203312,0.0,0.00266
mmlu-marketing.val.216,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-high-school-biology.val.134,mistralai/mixtral-8x7b-chat,0.0,8.22e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-chemistry.val.54,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
hellaswag.val.268,WizardLM/WizardLM-13B-V1.2,0.0,3.3e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.3263,mistralai/mistral-7b-chat,0.25,0.000114,0.25,0.000114,0.25,0.0001779,0.25,0.0003768,0.25,0.000296432,0.25,0.01187
grade-school-math.dev.5808,meta/code-llama-instruct-34b-chat,0.25,0.000375584,0.25,8.560000000000001e-05,0.5,0.0001605,0.5,0.0002333999999999,0.25,0.000375584,0.75,0.00916
mmlu-college-mathematics.val.61,mistralai/mistral-7b-chat,0.0,3.1200000000000006e-05,0.0,3.1200000000000006e-05,0.0,4.68e-05,0.0,9.36e-05,0.0,0.000121056,1.0,0.00157
hellaswag.val.8716,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,0.0,0.00254
mmlu-high-school-chemistry.val.105,WizardLM/WizardLM-13B-V1.2,0.0,3.39e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00117
grade-school-math.dev.90,mistralai/mistral-7b-chat,0.25,8.72e-05,0.25,8.72e-05,0.75,0.0001529999999999,0.75,0.0002622,0.25,0.000455512,0.75,0.00862
hellaswag.val.7030,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-professional-law.val.745,WizardLM/WizardLM-13B-V1.2,0.0,0.000108,0.0,7.2e-05,0.0,0.000108,0.0,0.000216,0.0,0.00027936,1.0,0.00361
grade-school-math.dev.7150,meta/code-llama-instruct-34b-chat,0.5,0.000328248,0.25,8.18e-05,0.5,0.0001341,0.5,0.0002844,0.5,0.000328248,0.5,0.0085
mmlu-high-school-european-history.val.83,mistralai/mixtral-8x7b-chat,1.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
hellaswag.val.3571,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,1.0,0.00232
grade-school-math.dev.4097,meta/code-llama-instruct-34b-chat,0.25,0.00037636,0.25,0.0001012,0.75,0.0001536,0.25,0.0002562,0.25,0.00037636,0.75,0.00944
hellaswag.val.5635,mistralai/mixtral-8x7b-chat,1.0,0.0001284,1.0,4.280000000000001e-05,1.0,6.42e-05,1.0,0.0001284,1.0,0.000166064,1.0,0.00218
consensus_summary.dev.175,mistralai/mistral-7b-chat,0.5,4.78e-05,0.5,4.78e-05,1.0,6.51e-05,0.75,0.000201,0.75,0.0002133999999999,1.0,0.00221
mbpp.dev.49,mistralai/mistral-7b-chat,1.0,2.08e-05,1.0,2.08e-05,1.0,7.529999999999999e-05,1.0,0.0001109999999999,1.0,0.0001714959999999,1.0,0.0075899999999999
mmlu-professional-law.val.194,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,1.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,0.0,0.0027
mmlu-philosophy.val.61,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
hellaswag.val.1546,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,0.0,0.00101
mmlu-professional-psychology.val.406,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.3674,mistralai/mistral-7b-chat,0.75,8.840000000000001e-05,0.75,8.840000000000001e-05,0.5,0.0001422,0.75,0.000264,0.25,0.0002770319999999,0.75,0.00849
mmlu-professional-law.val.1006,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,0.0,0.0024
mbpp.dev.401,mistralai/mistral-7b-chat,0.0,5.76e-05,0.0,5.76e-05,0.0,9.78e-05,1.0,0.0001715999999999,0.0,0.0002304719999999,1.0,0.02001
hellaswag.val.2563,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.4432,mistralai/mistral-7b-chat,1.0,5.5400000000000005e-05,1.0,5.5400000000000005e-05,1.0,8.28e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00281
mmlu-marketing.val.72,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
grade-school-math.dev.2465,mistralai/mistral-7b-chat,0.25,9.24e-05,0.25,9.24e-05,0.5,0.0001872,0.25,0.0004032,0.25,0.000505176,0.75,0.0097299999999999
hellaswag.val.6664,WizardLM/WizardLM-13B-V1.2,1.0,7.83e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00262
mmlu-high-school-psychology.val.478,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.2411,mistralai/mistral-7b-chat,1.0,2.78e-05,1.0,2.78e-05,1.0,4.14e-05,1.0,8.280000000000001e-05,0.0,0.000107864,1.0,0.0014
hellaswag.val.4489,mistralai/mixtral-8x7b-chat,1.0,0.0001806,0.0,6.0200000000000006e-05,0.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
mmlu-miscellaneous.val.743,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-professional-law.val.1175,mistralai/mistral-7b-chat,1.0,6.159999999999999e-05,1.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,0.0,0.00309
arc-challenge.test.1063,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.757,WizardLM/WizardLM-13B-V1.2,0.5,0.0002111999999999,0.25,0.000123,0.5,0.0002111999999999,0.5,0.0003162,0.5,0.000374032,0.75,0.01004
grade-school-math.dev.4013,WizardLM/WizardLM-13B-V1.2,0.5,0.0001299,0.25,7.6e-05,0.5,0.0001299,0.75,0.0001986,0.75,0.000325144,0.75,0.0068899999999999
hellaswag.val.1213,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3e-05,0.0,6.06e-05,0.0,7.8376e-05,0.0,0.00102
hellaswag.val.6972,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.23e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00246
hellaswag.val.5602,WizardLM/WizardLM-13B-V1.2,0.0,8.4e-05,0.0,5.62e-05,0.0,8.4e-05,0.0,0.0001686,0.0,0.000218056,1.0,0.00282
grade-school-math.dev.6988,WizardLM/WizardLM-13B-V1.2,0.75,0.0001326,0.75,7.04e-05,0.75,0.0001326,0.25,0.0002106,0.5,0.000318936,0.75,0.00615
hellaswag.val.7905,WizardLM/WizardLM-13B-V1.2,1.0,8.34e-05,1.0,5.56e-05,1.0,8.34e-05,1.0,0.0001668,1.0,0.000215728,1.0,0.00282
mmlu-high-school-geography.val.98,mistralai/mistral-7b-chat,1.0,1.64e-05,1.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
grade-school-math.dev.2543,WizardLM/WizardLM-13B-V1.2,0.75,0.0001541999999999,0.25,8.5e-05,0.75,0.0001541999999999,0.75,0.0002477999999999,0.75,0.000294104,0.75,0.00782
mbpp.dev.369,mistralai/mixtral-8x7b-chat,1.0,0.0002604,1.0,8.74e-05,0.0,0.0001737,1.0,0.0002604,1.0,0.0002925519999999,1.0,0.01635
hellaswag.val.9326,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.189999999999998e-05,0.0,0.0001643999999999,0.0,0.000212624,0.0,0.00278
hellaswag.val.1451,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.6646,mistralai/mistral-7b-chat,0.75,5.4e-05,0.75,5.4e-05,0.75,0.0001331999999999,0.75,0.0002177999999999,0.75,0.000266944,0.5,0.0054199999999999
mmlu-high-school-biology.val.59,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.0012599999999999
hellaswag.val.7375,mistralai/mistral-7b-chat,1.0,4.7600000000000005e-05,1.0,4.7600000000000005e-05,1.0,7.14e-05,0.0,0.0001428,1.0,0.000184688,1.0,0.00242
hellaswag.val.5113,mistralai/mixtral-8x7b-chat,1.0,0.000159,0.0,5.300000000000001e-05,0.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00269
arc-challenge.test.427,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-mathematics.val.41,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-high-school-macroeconomics.val.339,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-virology.val.13,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
grade-school-math.dev.2212,WizardLM/WizardLM-13B-V1.2,0.25,0.0002105999999999,0.25,0.0001324,0.25,0.0002105999999999,0.25,0.0002694,0.25,0.000295656,0.5,0.01286
hellaswag.val.6169,mistralai/mistral-7b-chat,0.0,5.160000000000001e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
grade-school-math.dev.2740,WizardLM/WizardLM-13B-V1.2,0.25,0.0001685999999999,0.25,7.840000000000001e-05,0.25,0.0001685999999999,0.25,0.0002064,0.25,0.0003104,0.75,0.00929
hellaswag.val.3099,WizardLM/WizardLM-13B-V1.2,1.0,3.54e-05,0.0,2.36e-05,1.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,0.0,0.00119
winogrande.dev.825,mistralai/mistral-7b-chat,1.0,1.24e-05,1.0,1.24e-05,1.0,1.83e-05,1.0,3.72e-05,1.0,4.8112e-05,1.0,0.00066
grade-school-math.dev.6781,mistralai/mistral-7b-chat,0.5,7.860000000000001e-05,0.5,7.860000000000001e-05,0.5,0.0001323,0.25,0.0002165999999999,0.75,0.000308072,0.5,0.00588
mmlu-professional-accounting.val.146,WizardLM/WizardLM-13B-V1.2,1.0,5.73e-05,1.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00195
grade-school-math.dev.871,meta/code-llama-instruct-34b-chat,0.25,0.000268496,0.25,8.060000000000001e-05,0.75,0.0001671,0.25,0.0002622,0.25,0.000268496,0.5,0.0066
mmlu-professional-psychology.val.138,mistralai/mistral-7b-chat,1.0,1.64e-05,1.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
mmlu-moral-scenarios.val.2,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
hellaswag.val.462,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.2370,mistralai/mistral-7b-chat,0.75,7.52e-05,0.75,7.52e-05,0.5,0.000147,0.75,0.0002766,0.75,0.00027936,0.75,0.00775
hellaswag.val.1128,mistralai/mixtral-8x7b-chat,1.0,7.740000000000001e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,1.0,0.000100104,1.0,0.0013
mmlu-professional-law.val.1076,WizardLM/WizardLM-13B-V1.2,1.0,8.669999999999999e-05,0.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
grade-school-math.dev.5197,WizardLM/WizardLM-13B-V1.2,0.5,0.0001416,0.25,7.04e-05,0.5,0.0001416,0.5,0.0002573999999999,0.25,0.00054708,0.5,0.00734
mmlu-professional-psychology.val.39,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00134
mmlu-high-school-chemistry.val.73,WizardLM/WizardLM-13B-V1.2,0.0,3.15e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
mbpp.dev.22,mistralai/mistral-7b-chat,1.0,4.54e-05,1.0,4.54e-05,1.0,7.199999999999999e-05,1.0,0.0001266,1.0,0.000193224,1.0,0.0074
hellaswag.val.5139,WizardLM/WizardLM-13B-V1.2,1.0,7.649999999999999e-05,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00259
mmlu-marketing.val.171,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
winogrande.dev.1167,mistralai/mistral-7b-chat,1.0,1.12e-05,1.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,1.0,0.00057
grade-school-math.dev.604,WizardLM/WizardLM-13B-V1.2,0.25,0.0001977,0.25,8.840000000000001e-05,0.25,0.0001977,0.25,0.000288,0.25,0.000342216,0.75,0.01189
hellaswag.val.1409,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.03e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
hellaswag.val.814,mistralai/mixtral-8x7b-chat,0.0,6.96e-05,0.0,2.32e-05,0.0,3.45e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
hellaswag.val.3058,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-conceptual-physics.val.155,mistralai/mistral-7b-chat,1.0,2.42e-05,1.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
hellaswag.val.3784,mistralai/mixtral-8x7b-chat,1.0,0.0001127999999999,1.0,3.7600000000000006e-05,0.0,5.64e-05,1.0,0.0001127999999999,1.0,0.000145888,1.0,0.00192
mmlu-miscellaneous.val.205,mistralai/mistral-7b-chat,1.0,1.96e-05,1.0,1.96e-05,1.0,2.91e-05,1.0,5.88e-05,1.0,7.604800000000001e-05,1.0,0.00102
mmlu-professional-psychology.val.250,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.3936,mistralai/mixtral-8x7b-chat,0.0,0.0001296,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,1.0,0.00217
mmlu-astronomy.val.137,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.7190,mistralai/mixtral-8x7b-chat,1.0,0.0001458,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00247
grade-school-math.dev.77,mistralai/mistral-7b-chat,0.25,7.740000000000001e-05,0.25,7.740000000000001e-05,0.75,0.0001473,0.25,0.0002484,0.75,0.0003608399999999,0.75,0.00698
arc-challenge.test.1059,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-college-chemistry.val.50,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.5929,WizardLM/WizardLM-13B-V1.2,1.0,7.409999999999999e-05,1.0,4.9600000000000006e-05,1.0,7.409999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
mmlu-professional-law.val.1186,WizardLM/WizardLM-13B-V1.2,0.0,6.269999999999999e-05,0.0,4.1800000000000006e-05,0.0,6.269999999999999e-05,1.0,0.0001253999999999,0.0,0.000162184,1.0,0.00213
mmlu-miscellaneous.val.660,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
mmlu-professional-law.val.442,mistralai/mistral-7b-chat,0.0,6.68e-05,0.0,6.68e-05,0.0,0.0001002,1.0,0.0002004,0.0,0.000259184,0.0,0.00335
mmlu-professional-law.val.920,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,0.0,0.00095
mmlu-management.val.51,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-moral-scenarios.val.496,mistralai/mistral-7b-chat,0.0,3.08e-05,0.0,3.08e-05,0.0,4.6200000000000005e-05,0.0,9.24e-05,0.0,0.000119504,1.0,0.00158
mmlu-professional-law.val.938,WizardLM/WizardLM-13B-V1.2,0.0,7.71e-05,0.0,5.14e-05,0.0,7.71e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
mmlu-professional-law.val.1156,WizardLM/WizardLM-13B-V1.2,0.0,8.85e-05,0.0,5.9e-05,0.0,8.85e-05,0.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
mmlu-high-school-biology.val.209,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-miscellaneous.val.752,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,0.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
mmlu-jurisprudence.val.22,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.1817,mistralai/mistral-7b-chat,0.25,0.000113,0.25,0.000113,0.75,0.0002399999999999,1.0,0.0002076,0.25,0.0004648239999999,0.75,0.01365
mmlu-moral-scenarios.val.890,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,0.0,0.00148
mmlu-clinical-knowledge.val.85,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-miscellaneous.val.304,mistralai/mistral-7b-chat,0.0,1.34e-05,0.0,1.34e-05,0.0,2.01e-05,0.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-professional-accounting.val.30,mistralai/mixtral-8x7b-chat,1.0,9.54e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,1.0,0.00163
winogrande.dev.795,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
hellaswag.val.4815,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
hellaswag.val.7499,mistralai/mistral-7b-chat,0.0,4.44e-05,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00226
mmlu-global-facts.val.94,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
bias_detection.dev.4,mistralai/mistral-7b-chat,0.0,4.86e-05,0.0,4.86e-05,0.0,8.13e-05,0.0,0.000159,0.0,0.0002149519999999,1.0,0.00754
hellaswag.val.8890,mistralai/mistral-7b-chat,0.0,5.12e-05,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
grade-school-math.dev.3068,WizardLM/WizardLM-13B-V1.2,0.5,0.00015,0.75,9.42e-05,0.5,0.00015,0.75,0.0002885999999999,0.75,0.000413608,0.75,0.00838
hellaswag.val.958,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,0.0,0.00103
mmlu-high-school-psychology.val.298,mistralai/mistral-7b-chat,1.0,2.44e-05,1.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
hellaswag.val.8370,mistralai/mixtral-8x7b-chat,1.0,0.0001698,1.0,5.660000000000001e-05,1.0,8.49e-05,1.0,0.0001698,1.0,0.000219608,1.0,0.00284
arc-challenge.test.858,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,0.0,3.24e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
hellaswag.val.6393,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,0.0,6.2e-05,0.0,9.3e-05,0.0,0.000186,0.0,0.00024056,0.0,0.00314
mbpp.dev.416,mistralai/mistral-7b-chat,0.0,5.6e-05,0.0,5.6e-05,0.0,7.230000000000001e-05,0.0,0.0001848,1.0,0.000132696,1.0,0.01243
mmlu-human-aging.val.100,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
hellaswag.val.4317,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
hellaswag.val.2220,mistralai/mistral-7b-chat,1.0,1.96e-05,1.0,1.96e-05,0.0,2.91e-05,1.0,5.88e-05,1.0,7.604800000000001e-05,0.0,0.00099
mmlu-miscellaneous.val.749,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
hellaswag.val.9399,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00268
arc-challenge.test.926,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
arc-challenge.test.231,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
accounting_audit.dev.11,mistralai/mistral-7b-chat,0.0,5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,0.0,0.00234
mmlu-marketing.val.11,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
hellaswag.val.8283,mistralai/mixtral-8x7b-chat,1.0,0.0001674,1.0,5.580000000000001e-05,1.0,8.34e-05,1.0,0.0001674,1.0,0.0002165039999999,1.0,0.0028
hellaswag.val.2173,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,0.0,0.001
mmlu-high-school-world-history.val.119,mistralai/mixtral-8x7b-chat,1.0,0.0002388,1.0,7.96e-05,1.0,0.0001194,1.0,0.0002388,0.0,0.0003088479999999,1.0,0.00399
winogrande.dev.1155,mistralai/mistral-7b-chat,1.0,1.1e-05,1.0,1.1e-05,1.0,1.62e-05,1.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00059
mmlu-college-biology.val.51,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.7413,WizardLM/WizardLM-13B-V1.2,0.25,0.0001407,0.75,9.7e-05,0.25,0.0001407,0.5,0.0002885999999999,0.25,0.000270824,0.75,0.00844
mmlu-moral-disputes.val.284,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-high-school-mathematics.val.146,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
mmlu-professional-law.val.1017,WizardLM/WizardLM-13B-V1.2,0.0,8.34e-05,1.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
grade-school-math.dev.4624,WizardLM/WizardLM-13B-V1.2,0.25,0.0001761,0.25,0.0001034,0.25,0.0001761,0.25,0.0003413999999999,0.25,0.000371704,0.5,0.00893
hellaswag.val.3309,WizardLM/WizardLM-13B-V1.2,0.0,8.549999999999999e-05,0.0,5.720000000000001e-05,0.0,8.549999999999999e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.0029
hellaswag.val.3839,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
arc-challenge.test.765,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,1.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,1.0,5.5096e-05,0.0,0.0007199999999999
grade-school-math.dev.6370,WizardLM/WizardLM-13B-V1.2,0.5,0.0001308,0.25,9.38e-05,0.5,0.0001308,0.25,0.000225,0.25,0.000315056,0.75,0.00743
hellaswag.val.3385,mistralai/mistral-7b-chat,0.0,5.580000000000001e-05,0.0,5.580000000000001e-05,0.0,8.34e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.00283
bias_detection.dev.183,mistralai/mistral-7b-chat,0.0,6.68e-05,0.0,6.68e-05,0.0,0.000105,0.0,0.000183,0.0,0.000259184,0.0,0.00981
mmlu-moral-scenarios.val.410,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-high-school-macroeconomics.val.327,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,1.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
grade-school-math.dev.3029,WizardLM/WizardLM-13B-V1.2,0.25,0.0001587,0.25,9.52e-05,0.25,0.0001587,0.25,0.0002712,0.25,0.0003585119999999,0.75,0.00883
grade-school-math.dev.6572,WizardLM/WizardLM-13B-V1.2,0.75,0.000156,0.5,7.82e-05,0.75,0.000156,0.25,0.0002286,0.75,0.000316608,0.75,0.00752
mmlu-high-school-world-history.val.46,WizardLM/WizardLM-13B-V1.2,1.0,0.0001409999999999,0.0,9.4e-05,1.0,0.0001409999999999,1.0,0.0002819999999999,0.0,0.00036472,1.0,0.00471
mmlu-conceptual-physics.val.30,mistralai/mixtral-8x7b-chat,0.0,4.26e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.00075
hellaswag.val.8124,WizardLM/WizardLM-13B-V1.2,1.0,7.5e-05,0.0,5e-05,1.0,7.5e-05,0.0,0.0001493999999999,0.0,0.000194,1.0,0.00254
mmlu-high-school-mathematics.val.198,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.48e-05,0.0,8.4584e-05,0.0,0.0011
hellaswag.val.3347,mistralai/mistral-7b-chat,0.0,5.800000000000001e-05,0.0,5.800000000000001e-05,0.0,8.669999999999998e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
hellaswag.val.517,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
grade-school-math.dev.674,WizardLM/WizardLM-13B-V1.2,0.75,0.0001932,0.25,9.8e-05,0.75,0.0001932,0.5,0.0003414,0.25,0.000342216,0.5,0.01396
abstract2title.test.245,mistralai/mixtral-8x7b-chat,1.0,0.000168,1.0,5.5400000000000005e-05,1.0,8.4e-05,1.0,0.000168,1.0,0.000211848,1.0,0.00345
grade-school-math.dev.5772,WizardLM/WizardLM-13B-V1.2,0.25,0.0001430999999999,0.25,8.840000000000001e-05,0.25,0.0001430999999999,0.25,0.0002483999999999,0.25,0.00029876,0.75,0.00852
hellaswag.val.3659,mistralai/mixtral-8x7b-chat,1.0,0.0001716,1.0,5.720000000000001e-05,1.0,8.549999999999999e-05,1.0,0.0001716,1.0,0.000221936,1.0,0.0029
mmlu-professional-law.val.79,mistralai/mistral-7b-chat,0.0,4.380000000000001e-05,0.0,4.380000000000001e-05,0.0,6.57e-05,1.0,0.0001314,0.0,0.0001699439999999,1.0,0.00223
hellaswag.val.640,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.3186,WizardLM/WizardLM-13B-V1.2,0.75,0.0001541999999999,0.25,0.000104,0.75,0.0001541999999999,0.75,0.0003792,0.25,0.000326696,0.5,0.00897
mmlu-moral-scenarios.val.82,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,0.0,0.00142
grade-school-math.dev.4259,WizardLM/WizardLM-13B-V1.2,0.25,0.0001542,0.75,8.439999999999999e-05,0.25,0.0001542,0.75,0.0002418,0.25,0.000311176,0.75,0.00922
hellaswag.val.2775,mistralai/mistral-7b-chat,1.0,2.2e-05,1.0,2.2e-05,0.0,3.27e-05,1.0,6.6e-05,1.0,8.536000000000001e-05,1.0,0.00114
hellaswag.val.3181,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-professional-law.val.809,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,0.0,0.00258
hellaswag.val.4282,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-security-studies.val.79,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
mmlu-security-studies.val.140,mistralai/mixtral-8x7b-chat,0.0,8.94e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-professional-law.val.30,WizardLM/WizardLM-13B-V1.2,1.0,4.98e-05,1.0,3.320000000000001e-05,1.0,4.98e-05,0.0,9.96e-05,1.0,0.000128816,0.0,0.00167
mmlu-professional-law.val.553,WizardLM/WizardLM-13B-V1.2,0.0,9.18e-05,1.0,6.120000000000001e-05,0.0,9.18e-05,1.0,0.000183,0.0,0.0002374559999999,1.0,0.00307
mmlu-jurisprudence.val.66,WizardLM/WizardLM-13B-V1.2,1.0,3.93e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.0013499999999999
mmlu-miscellaneous.val.296,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
hellaswag.val.6705,mistralai/mixtral-8x7b-chat,1.0,0.0001524,1.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,1.0,0.0001971039999999,1.0,0.00258
mmlu-high-school-us-history.val.171,mistralai/mixtral-8x7b-chat,0.0,0.000159,1.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
mmlu-moral-scenarios.val.632,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,0.0,0.00145
mmlu-professional-law.val.580,mistralai/mistral-7b-chat,1.0,4.1200000000000005e-05,1.0,4.1200000000000005e-05,0.0,6.18e-05,1.0,0.0001236,0.0,0.000159856,0.0,0.0021
mmlu-moral-scenarios.val.199,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-global-facts.val.46,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00097
arc-challenge.test.1171,mistralai/mistral-7b-chat,0.0,1.28e-05,0.0,1.28e-05,0.0,1.92e-05,0.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
mmlu-professional-accounting.val.75,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
hellaswag.val.8067,mistralai/mixtral-8x7b-chat,0.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.19e-05,0.0,0.0001638,0.0,0.0002118479999999,1.0,0.00274
grade-school-math.dev.2526,WizardLM/WizardLM-13B-V1.2,0.75,0.0001430999999999,0.75,8.16e-05,0.75,0.0001430999999999,0.25,0.0002724,0.25,0.0003686,0.5,0.00637
grade-school-math.dev.7308,mistralai/mixtral-8x7b-chat,0.75,0.0002034,0.75,6.18e-05,0.75,0.0001329,0.75,0.0002034,0.75,0.000254528,0.75,0.0066
mmlu-high-school-world-history.val.229,WizardLM/WizardLM-13B-V1.2,1.0,0.0001253999999999,1.0,8.36e-05,1.0,0.0001253999999999,1.0,0.0002507999999999,0.0,0.000323592,1.0,0.0041899999999999
mmlu-world-religions.val.154,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-miscellaneous.val.688,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
hellaswag.val.9806,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.039999999999999e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.0027
grade-school-math.dev.2302,mistralai/mistral-7b-chat,0.25,8.02e-05,0.25,8.02e-05,0.5,0.0001623,1.0,0.0001788,0.75,0.0003406639999999,0.75,0.00706
mmlu-college-computer-science.val.80,mistralai/mistral-7b-chat,1.0,2.4800000000000003e-05,1.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,0.0,0.00125
mmlu-professional-psychology.val.135,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
winogrande.dev.1102,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.00053
hellaswag.val.3851,WizardLM/WizardLM-13B-V1.2,0.0,8.309999999999999e-05,0.0,5.56e-05,0.0,8.309999999999999e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
mmlu-public-relations.val.41,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
bias_detection.dev.236,mistralai/mistral-7b-chat,0.0,6.64e-05,0.0,6.64e-05,0.0,0.0001266,0.0,0.0001782,0.0,0.000276256,0.0,0.0118999999999999
mbpp.dev.222,mistralai/mistral-7b-chat,0.0,3.84e-05,0.0,3.84e-05,0.0,5.8800000000000006e-05,0.0,0.0001764,0.0,0.00012804,1.0,0.0102999999999999
mmlu-professional-law.val.1023,WizardLM/WizardLM-13B-V1.2,0.0,0.0001493999999999,0.0,9.96e-05,0.0,0.0001493999999999,0.0,0.0002982,0.0,0.000386448,0.0,0.00499
hellaswag.val.1870,mistralai/mistral-7b-chat,0.0,3.04e-05,0.0,3.04e-05,0.0,4.56e-05,1.0,9.12e-05,0.0,0.000117952,1.0,0.00153
arc-challenge.test.214,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,1.0,6.984e-05,1.0,0.00094
mmlu-human-aging.val.33,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.1129,mistralai/mistral-7b-chat,0.5,8.18e-05,0.5,8.18e-05,0.5,0.0001527,0.75,0.0002201999999999,0.5,0.000370928,0.75,0.00695
grade-school-math.dev.4571,mistralai/mistral-7b-chat,0.25,8.840000000000001e-05,0.25,8.840000000000001e-05,0.75,0.0001581,0.75,0.0002747999999999,0.25,0.000293328,0.5,0.00932
mmlu-professional-law.val.996,mistralai/mistral-7b-chat,1.0,5.520000000000001e-05,1.0,5.520000000000001e-05,0.0,8.280000000000001e-05,1.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
mmlu-public-relations.val.93,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
grade-school-math.dev.3112,meta/code-llama-instruct-34b-chat,0.25,0.000412056,0.5,0.0001234,0.5,0.0001605,0.75,0.0002406,0.25,0.000412056,0.5,0.00922
hellaswag.val.8983,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
grade-school-math.dev.4179,WizardLM/WizardLM-13B-V1.2,0.25,0.0001818,0.75,0.0001008,0.25,0.0001818,0.25,0.0002916,0.25,0.000332904,0.75,0.01257
hellaswag.val.3165,mistralai/mixtral-8x7b-chat,1.0,7.98e-05,1.0,2.6600000000000003e-05,0.0,3.96e-05,1.0,7.98e-05,1.0,0.000103208,0.0,0.00137
grade-school-math.dev.6777,mistralai/mistral-7b-chat,0.75,0.0001018,0.75,0.0001018,0.5,0.0001272,0.5,0.0002969999999999,0.5,0.00037248,0.75,0.00976
grade-school-math.dev.2175,mistralai/mixtral-8x7b-chat,0.25,0.0002753999999999,0.25,9.7e-05,0.5,0.0001899,0.25,0.0002753999999999,0.25,0.00030652,0.5,0.00991
hellaswag.val.9834,mistralai/mistral-7b-chat,0.0,4.280000000000001e-05,0.0,4.280000000000001e-05,0.0,6.42e-05,0.0,0.0001284,0.0,0.000166064,0.0,0.00218
mmlu-college-chemistry.val.7,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,1.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-miscellaneous.val.143,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-computer-security.val.62,mistralai/mixtral-8x7b-chat,0.0,0.0001164,0.0,3.880000000000001e-05,1.0,5.82e-05,0.0,0.0001164,0.0,0.000150544,0.0,0.00195
hellaswag.val.3996,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00268
mmlu-professional-law.val.1045,mistralai/mixtral-8x7b-chat,0.0,0.0001758,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
grade-school-math.dev.7360,mistralai/mistral-7b-chat,0.25,0.0001166,0.25,0.0001166,0.25,0.0001869,0.25,0.0003258,0.25,0.000322816,0.75,0.00909
mmlu-high-school-physics.val.54,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
hellaswag.val.9423,mistralai/mistral-7b-chat,0.0,4.860000000000001e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,1.0,0.00244
hellaswag.val.3052,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,0.0,2.79e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-professional-law.val.22,WizardLM/WizardLM-13B-V1.2,1.0,8.58e-05,0.0,5.720000000000001e-05,1.0,8.58e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.00287
hellaswag.val.6681,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.309999999999999e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
mmlu-moral-scenarios.val.719,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,0.0,0.00139
grade-school-math.dev.2835,mistralai/mistral-7b-chat,0.25,9.7e-05,0.25,9.7e-05,0.25,0.0001338,0.75,0.0003048,0.25,0.000347648,0.75,0.0102399999999999
hellaswag.val.6724,mistralai/mixtral-8x7b-chat,0.0,0.0001458,1.0,4.860000000000001e-05,1.0,7.29e-05,0.0,0.0001458,1.0,0.000188568,1.0,0.00247
hellaswag.val.5949,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-moral-scenarios.val.411,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-professional-law.val.708,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.0001553999999999,0.0,0.00020176,1.0,0.00261
grade-school-math.dev.4643,WizardLM/WizardLM-13B-V1.2,0.75,9.99e-05,0.75,6.08e-05,0.75,9.99e-05,0.75,0.0002316,0.75,0.000258408,0.75,0.00549
hellaswag.val.199,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-logical-fallacies.val.27,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.1757,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.69e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
winogrande.dev.1125,mistralai/mixtral-8x7b-chat,0.0,3.12e-05,0.0,1.04e-05,1.0,1.56e-05,0.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
mmlu-professional-law.val.962,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5e-05,0.0,7.5e-05,1.0,0.00015,0.0,0.000194,1.0,0.00251
grade-school-math.dev.6269,mistralai/mixtral-8x7b-chat,0.75,0.0003396,0.25,0.0001262,0.75,0.0001401,0.75,0.0003396,0.75,0.000311176,0.75,0.00779
mmlu-elementary-mathematics.val.135,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-professional-law.val.868,WizardLM/WizardLM-13B-V1.2,0.0,7.049999999999999e-05,0.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
grade-school-math.dev.3740,meta/code-llama-instruct-34b-chat,0.25,0.000346096,0.25,8.5e-05,0.75,0.0001395,0.25,0.0002202,0.25,0.000346096,0.75,0.00775
mmlu-professional-psychology.val.83,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
grade-school-math.dev.6364,mistralai/mistral-7b-chat,0.25,0.0001254,0.25,0.0001254,0.25,0.0002028,0.75,0.0003306,0.25,0.0004399919999999,0.75,0.01012
mmlu-professional-law.val.1401,WizardLM/WizardLM-13B-V1.2,0.0,0.0001004999999999,1.0,6.7e-05,0.0,0.0001004999999999,0.0,0.0002009999999999,0.0,0.00025996,0.0,0.00336
grade-school-math.dev.6028,WizardLM/WizardLM-13B-V1.2,0.75,0.0001695,0.25,6.319999999999999e-05,0.75,0.0001695,0.75,0.0002688,0.75,0.000308848,0.75,0.00835
hellaswag.val.8403,mistralai/mixtral-8x7b-chat,1.0,0.0001817999999999,1.0,6.080000000000001e-05,1.0,9.12e-05,1.0,0.0001817999999999,1.0,0.000235904,1.0,0.00308
mmlu-high-school-psychology.val.353,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-high-school-statistics.val.137,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
grade-school-math.dev.1916,mistralai/mistral-7b-chat,0.5,9.38e-05,0.5,9.38e-05,0.75,0.0001746,0.75,0.0002772,0.5,0.000367048,0.75,0.00714
mmlu-philosophy.val.133,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-professional-law.val.17,mistralai/mistral-7b-chat,0.0,6.500000000000001e-05,0.0,6.500000000000001e-05,1.0,9.75e-05,0.0,0.000195,0.0,0.0002522,0.0,0.00329
mmlu-prehistory.val.233,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,0.0,4.14e-05,0.0,5.354400000000001e-05,0.0,0.0007
mmlu-professional-law.val.527,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,1.0,7.71e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-professional-accounting.val.129,WizardLM/WizardLM-13B-V1.2,1.0,3.63e-05,0.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
hellaswag.val.6276,WizardLM/WizardLM-13B-V1.2,1.0,8.37e-05,1.0,5.580000000000001e-05,1.0,8.37e-05,1.0,0.0001674,1.0,0.0002165039999999,1.0,0.00283
mmlu-professional-psychology.val.208,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.6878,WizardLM/WizardLM-13B-V1.2,0.0,8.64e-05,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,0.0,0.00292
hellaswag.val.316,mistralai/mixtral-8x7b-chat,1.0,0.0001188,1.0,3.960000000000001e-05,0.0,5.94e-05,1.0,0.0001188,0.0,0.000153648,1.0,0.00199
mmlu-machine-learning.val.103,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
abstract2title.test.183,mistralai/mixtral-8x7b-chat,1.0,0.0001872,1.0,6e-05,1.0,9.45e-05,1.0,0.0001872,1.0,0.000239008,1.0,0.00362
grade-school-math.dev.4007,WizardLM/WizardLM-13B-V1.2,0.25,0.0001764,0.25,0.0001008,0.25,0.0001764,0.25,0.00027,0.25,0.000418264,0.5,0.01022
mmlu-high-school-us-history.val.105,WizardLM/WizardLM-13B-V1.2,0.0,0.0001485,0.0,9.9e-05,0.0,0.0001485,1.0,0.000297,0.0,0.0003841199999999,1.0,0.00496
hellaswag.val.2957,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
arc-challenge.test.565,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.4343,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00281
hellaswag.val.3517,mistralai/mixtral-8x7b-chat,1.0,0.0001487999999999,1.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
mmlu-college-physics.val.50,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,1.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00102
mmlu-professional-law.val.139,WizardLM/WizardLM-13B-V1.2,1.0,0.0001358999999999,1.0,9.06e-05,1.0,0.0001358999999999,1.0,0.0002717999999999,0.0,0.000351528,1.0,0.00454
mmlu-high-school-government-and-politics.val.113,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-professional-law.val.854,mistralai/mistral-7b-chat,0.0,5.220000000000001e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,0.0,0.00262
grade-school-math.dev.1007,mistralai/mistral-7b-chat,0.25,7.860000000000001e-05,0.25,7.860000000000001e-05,0.75,0.0001608,0.75,0.000234,0.25,0.00032592,0.5,0.0092
bias_detection.dev.244,mistralai/mistral-7b-chat,0.0,5.64e-05,0.0,5.64e-05,0.0,9.359999999999998e-05,1.0,0.0001769999999999,0.0,0.000204088,1.0,0.00562
mmlu-logical-fallacies.val.142,mistralai/mixtral-8x7b-chat,0.0,6.06e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-professional-law.val.1207,WizardLM/WizardLM-13B-V1.2,0.0,5.13e-05,0.0,3.4200000000000005e-05,0.0,5.13e-05,0.0,0.0001026,0.0,0.000132696,0.0,0.00172
grade-school-math.dev.2377,WizardLM/WizardLM-13B-V1.2,0.75,0.0001479,0.5,9.56e-05,0.75,0.0001479,0.75,0.0002274,0.5,0.000274704,0.5,0.0057599999999999
mmlu-college-chemistry.val.54,mistralai/mixtral-8x7b-chat,0.0,6.48e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,0.0,0.00109
hellaswag.val.3908,mistralai/mixtral-8x7b-chat,0.0,0.0001386,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00232
mmlu-astronomy.val.132,mistralai/mixtral-8x7b-chat,1.0,8.7e-05,1.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
mmlu-human-sexuality.val.82,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-college-computer-science.val.97,mistralai/mistral-7b-chat,1.0,2.72e-05,1.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-virology.val.163,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.1804,mistralai/mistral-7b-chat,0.25,5.22e-05,0.25,5.22e-05,0.5,0.0001425,0.25,0.0002142,0.75,0.000239008,0.75,0.00503
arc-challenge.val.77,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,1.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,1.0,7.682400000000001e-05,1.0,0.001
mmlu-prehistory.val.108,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,0.0,0.00073
arc-challenge.test.701,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
mmlu-professional-law.val.659,WizardLM/WizardLM-13B-V1.2,1.0,8.46e-05,0.0,5.64e-05,1.0,8.46e-05,1.0,0.0001692,0.0,0.000218832,1.0,0.00283
hellaswag.val.5856,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
mmlu-college-medicine.val.163,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.3612,mistralai/mixtral-8x7b-chat,0.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,0.0,0.0027
mmlu-professional-accounting.val.239,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
winogrande.dev.308,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
grade-school-math.dev.3023,WizardLM/WizardLM-13B-V1.2,0.25,0.0001473,0.25,0.000108,0.25,0.0001473,0.25,0.000234,0.25,0.00028712,0.75,0.0069999999999999
winogrande.dev.758,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,0.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.492e-05,0.0,0.0005
mmlu-professional-law.val.906,mistralai/mistral-7b-chat,1.0,4.100000000000001e-05,1.0,4.100000000000001e-05,0.0,6.149999999999999e-05,0.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-moral-disputes.val.109,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-high-school-statistics.val.179,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.6993,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
mmlu-elementary-mathematics.val.366,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-philosophy.val.306,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-global-facts.val.50,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-professional-law.val.382,WizardLM/WizardLM-13B-V1.2,0.0,0.0001041,0.0,6.939999999999999e-05,0.0,0.0001041,0.0,0.0002082,0.0,0.000269272,0.0,0.00351
mmlu-high-school-macroeconomics.val.51,mistralai/mistral-7b-chat,0.0,3.3400000000000005e-05,0.0,3.3400000000000005e-05,0.0,5.01e-05,0.0,0.0001002,0.0,0.000129592,1.0,0.00168
mmlu-professional-law.val.28,WizardLM/WizardLM-13B-V1.2,0.0,0.0001083,0.0,7.219999999999999e-05,0.0,0.0001083,0.0,0.0002166,0.0,0.000280136,1.0,0.00362
hellaswag.val.1198,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
mmlu-professional-law.val.1533,WizardLM/WizardLM-13B-V1.2,0.0,0.0001035,0.0,6.900000000000001e-05,0.0,0.0001035,1.0,0.000207,0.0,0.00026772,1.0,0.00346
hellaswag.val.7557,WizardLM/WizardLM-13B-V1.2,0.0,8.069999999999998e-05,0.0,5.4000000000000005e-05,0.0,8.069999999999998e-05,0.0,0.0001613999999999,0.0,0.00020952,1.0,0.00274
mmlu-marketing.val.140,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.4133,mistralai/mistral-7b-chat,0.5,9.14e-05,0.5,9.14e-05,0.75,0.0001733999999999,0.5,0.0002783999999999,0.25,0.000468704,0.5,0.01062
hellaswag.val.5528,mistralai/mistral-7b-chat,0.0,4.920000000000001e-05,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
mmlu-professional-law.val.1188,WizardLM/WizardLM-13B-V1.2,1.0,7.59e-05,0.0,5.06e-05,1.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-high-school-us-history.val.50,WizardLM/WizardLM-13B-V1.2,1.0,9.09e-05,0.0,6.06e-05,1.0,9.09e-05,1.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
hellaswag.val.7278,WizardLM/WizardLM-13B-V1.2,1.0,6.33e-05,1.0,4.220000000000001e-05,1.0,6.33e-05,1.0,0.0001266,1.0,0.000163736,1.0,0.00215
mmlu-high-school-biology.val.298,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-professional-psychology.val.584,WizardLM/WizardLM-13B-V1.2,0.0,6.989999999999999e-05,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,0.0,0.0001397999999999,0.0,0.000180808,0.0,0.00234
mmlu-professional-law.val.869,WizardLM/WizardLM-13B-V1.2,1.0,6.84e-05,0.0,4.56e-05,1.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00229
mmlu-high-school-biology.val.289,mistralai/mixtral-8x7b-chat,1.0,8.7e-05,1.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
arc-challenge.test.1116,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,1.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
mmlu-college-medicine.val.18,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
hellaswag.val.6548,mistralai/mixtral-8x7b-chat,0.0,0.0001848,0.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00309
grade-school-math.dev.5500,WizardLM/WizardLM-13B-V1.2,0.25,0.000174,0.5,0.0001056,0.25,0.000174,0.5,0.0002742,0.25,0.00031428,0.5,0.0092299999999999
mmlu-professional-accounting.val.134,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,0.0,0.00138
hellaswag.val.2635,WizardLM/WizardLM-13B-V1.2,0.0,3.75e-05,0.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
grade-school-math.dev.5193,mistralai/mistral-7b-chat,0.25,9.9e-05,0.25,9.9e-05,0.75,0.0001983,0.75,0.0003006,0.5,0.000467152,0.75,0.00928
hellaswag.val.6421,mistralai/mixtral-8x7b-chat,1.0,0.0001368,1.0,4.56e-05,1.0,6.84e-05,1.0,0.0001368,1.0,0.000176928,1.0,0.00232
grade-school-math.dev.2764,mistralai/mistral-7b-chat,0.75,0.0001018,0.75,0.0001018,0.5,0.0001758,0.75,0.0002592,0.25,0.000339112,0.5,0.00898
grade-school-math.dev.1279,WizardLM/WizardLM-13B-V1.2,0.25,0.0001752,0.25,0.0001338,0.25,0.0001752,0.75,0.0003204,0.75,0.000452408,0.75,0.01079
grade-school-math.dev.4361,mistralai/mixtral-8x7b-chat,0.25,0.0002844,0.25,8.800000000000001e-05,0.25,0.0001335,0.25,0.0002844,0.25,0.000315832,0.75,0.0074
mmlu-college-mathematics.val.7,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
hellaswag.val.786,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.3013,mistralai/mistral-7b-chat,0.5,5.940000000000001e-05,0.5,5.940000000000001e-05,0.5,0.0001275,0.75,0.0002201999999999,0.75,0.00031816,0.5,0.00604
hellaswag.val.2051,WizardLM/WizardLM-13B-V1.2,1.0,5.73e-05,0.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00195
mmlu-conceptual-physics.val.146,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-world-religions.val.170,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.2591,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.27e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-college-physics.val.97,WizardLM/WizardLM-13B-V1.2,0.0,3.69e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
mmlu-business-ethics.val.38,mistralai/mistral-7b-chat,1.0,2.88e-05,1.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-professional-law.val.687,WizardLM/WizardLM-13B-V1.2,1.0,6.45e-05,0.0,4.3e-05,1.0,6.45e-05,0.0,0.000129,0.0,0.00016684,0.0,0.00216
grade-school-math.dev.4055,WizardLM/WizardLM-13B-V1.2,0.75,0.0001563,0.75,8.48e-05,0.75,0.0001563,0.25,0.0002435999999999,0.25,0.00027548,0.75,0.00767
mmlu-college-medicine.val.61,mistralai/mixtral-8x7b-chat,1.0,6.96e-05,1.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
winogrande.dev.235,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,0.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
hellaswag.val.4634,mistralai/mixtral-8x7b-chat,0.0,0.0001776,0.0,5.920000000000001e-05,0.0,8.85e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.00297
arc-challenge.val.67,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
grade-school-math.dev.416,WizardLM/WizardLM-13B-V1.2,0.75,0.00015,0.75,9.48e-05,0.75,0.00015,0.25,0.0002375999999999,0.75,0.000305744,0.75,0.0075699999999999
mmlu-miscellaneous.val.131,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
hellaswag.val.8021,WizardLM/WizardLM-13B-V1.2,0.0,8.73e-05,0.0,5.84e-05,0.0,8.73e-05,0.0,0.0001752,0.0,0.000226592,0.0,0.00293
grade-school-math.dev.4538,mistralai/mistral-7b-chat,0.25,8.6e-05,0.25,8.6e-05,0.25,0.0001794,0.75,0.0002406,0.25,0.00026772,0.75,0.00754
arc-challenge.test.654,mistralai/mixtral-8x7b-chat,1.0,3.84e-05,0.0,1.28e-05,0.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
mmlu-econometrics.val.66,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.2604,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
bias_detection.dev.31,mistralai/mistral-7b-chat,0.0,6.04e-05,0.0,6.04e-05,0.0,8.850000000000001e-05,0.0,0.0001734,0.0,0.000226592,0.0,0.00763
hellaswag.val.1859,WizardLM/WizardLM-13B-V1.2,0.0,3.66e-05,0.0,2.46e-05,0.0,3.66e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
grade-school-math.dev.2415,mistralai/mistral-7b-chat,0.0,9.62e-05,0.0,9.62e-05,0.5,0.000147,0.25,0.0002904,0.25,0.000286344,0.75,0.00937
hellaswag.val.8011,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.56e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.1463,WizardLM/WizardLM-13B-V1.2,0.75,0.000165,0.25,8.960000000000001e-05,0.75,0.000165,0.25,0.0002832,0.25,0.000352304,0.75,0.01004
mmlu-global-facts.val.48,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.00095
mtbench-math.dev.2,mistralai/mistral-7b-chat,0.9,7.240000000000001e-05,0.9,7.240000000000001e-05,1.0,0.0001865999999999,1.0,0.0001878,0.8,0.000520696,1.0,0.02303
winogrande.dev.850,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,0.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,0.0,0.00051
grade-school-math.dev.7062,WizardLM/WizardLM-13B-V1.2,0.75,0.0001581,0.25,9.18e-05,0.75,0.0001581,0.5,0.0003053999999999,0.25,0.000354632,0.5,0.00825
mmlu-jurisprudence.val.82,mistralai/mixtral-8x7b-chat,0.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
arc-challenge.test.460,mistralai/mistral-7b-chat,1.0,2.3800000000000003e-05,1.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,1.0,9.2344e-05,1.0,0.00123
mmlu-high-school-macroeconomics.val.290,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-professional-law.val.565,WizardLM/WizardLM-13B-V1.2,0.0,9.66e-05,0.0,6.44e-05,0.0,9.66e-05,1.0,0.0001932,0.0,0.000249872,1.0,0.00323
mmlu-professional-law.val.1442,WizardLM/WizardLM-13B-V1.2,0.0,0.000117,1.0,7.8e-05,0.0,0.000117,1.0,0.000234,0.0,0.00030264,1.0,0.00391
mmlu-sociology.val.86,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-miscellaneous.val.672,WizardLM/WizardLM-13B-V1.2,1.0,2.73e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
grade-school-math.dev.4320,mistralai/mixtral-8x7b-chat,0.5,0.0003149999999999,0.25,0.0001124,0.25,0.0001512,0.5,0.0003149999999999,0.75,0.000398864,0.5,0.01249
bias_detection.dev.274,mistralai/mixtral-8x7b-chat,0.0,0.0001889999999999,0.0,6.6e-05,0.0,0.0001104,0.0,0.0001889999999999,0.0,0.000260736,0.0,0.00655
grade-school-math.dev.6387,mistralai/mixtral-8x7b-chat,0.75,0.0002507999999999,0.75,9.320000000000002e-05,0.75,0.0001455,0.75,0.0002507999999999,0.75,0.0002824639999999,0.75,0.00887
mmlu-us-foreign-policy.val.7,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,0.0,0.00091
mmlu-college-mathematics.val.58,mistralai/mixtral-8x7b-chat,0.0,7.379999999999999e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
mmlu-high-school-microeconomics.val.100,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.00073
hellaswag.val.3387,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-miscellaneous.val.233,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-high-school-psychology.val.329,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.4906,mistralai/mixtral-8x7b-chat,0.25,0.0002418,0.25,8.56e-05,0.75,0.0001487999999999,0.25,0.0002418,0.75,0.000291,0.75,0.00639
hellaswag.val.5462,mistralai/mixtral-8x7b-chat,0.0,0.0001164,0.0,3.880000000000001e-05,1.0,5.79e-05,0.0,0.0001164,0.0,0.000150544,1.0,0.00198
hellaswag.val.6587,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
grade-school-math.dev.2374,mistralai/mistral-7b-chat,0.25,8.620000000000001e-05,0.25,8.620000000000001e-05,0.5,0.0001782,0.25,0.0003005999999999,0.25,0.000363944,0.5,0.01201
arc-challenge.test.455,mistralai/mistral-7b-chat,0.0,1.34e-05,0.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.00071
arc-challenge.test.604,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-miscellaneous.val.146,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
mmlu-astronomy.val.86,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-professional-psychology.val.561,mistralai/mistral-7b-chat,1.0,2.32e-05,1.0,2.32e-05,1.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
mmlu-moral-scenarios.val.334,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.0013499999999999
mmlu-high-school-statistics.val.68,mistralai/mistral-7b-chat,1.0,3.64e-05,1.0,3.64e-05,0.0,5.46e-05,1.0,0.0001092,0.0,0.000141232,1.0,0.0018599999999999
mmlu-high-school-psychology.val.13,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
winogrande.dev.770,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
mmlu-professional-law.val.1059,WizardLM/WizardLM-13B-V1.2,0.0,0.0001098,1.0,7.319999999999999e-05,0.0,0.0001098,0.0,0.0002196,0.0,0.000284016,0.0,0.00367
mmlu-high-school-macroeconomics.val.187,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-prehistory.val.122,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
arc-challenge.val.69,mistralai/mistral-7b-chat,1.0,1.92e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,1.0,7.4496e-05,1.0,0.0009699999999999
mmlu-astronomy.val.11,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-high-school-psychology.val.308,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.3728,mistralai/mistral-7b-chat,0.0,5.44e-05,0.0,5.44e-05,0.0,8.13e-05,1.0,0.0001632,0.0,0.000211072,1.0,0.00273
hellaswag.val.4402,mistralai/mixtral-8x7b-chat,0.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00274
hellaswag.val.5056,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
arc-challenge.test.314,mistralai/mistral-7b-chat,1.0,2.94e-05,1.0,2.94e-05,1.0,4.41e-05,1.0,8.82e-05,1.0,0.000114072,1.0,0.00148
hellaswag.val.4646,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
grade-school-math.dev.3942,WizardLM/WizardLM-13B-V1.2,0.75,0.0001626,0.25,8.620000000000001e-05,0.75,0.0001626,0.25,0.000324,0.75,0.000394208,0.5,0.00931
arc-challenge.test.365,mistralai/mistral-7b-chat,1.0,1.48e-05,1.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,1.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.3784,mistralai/mixtral-8x7b-chat,0.75,0.0003281999999999,0.25,9.84e-05,0.5,0.000159,0.75,0.0003281999999999,0.25,0.000317384,0.75,0.01133
mmlu-high-school-microeconomics.val.138,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
hellaswag.val.4262,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,1.0,0.00018624,1.0,0.00244
abstract2title.test.133,mistralai/mixtral-8x7b-chat,1.0,6.66e-05,1.0,1.96e-05,1.0,3.15e-05,1.0,6.66e-05,1.0,8.3032e-05,1.0,0.00167
mmlu-professional-law.val.468,WizardLM/WizardLM-13B-V1.2,1.0,7.26e-05,0.0,4.84e-05,1.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00243
hellaswag.val.6209,mistralai/mistral-7b-chat,0.0,5.3200000000000006e-05,0.0,5.3200000000000006e-05,1.0,7.98e-05,1.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
mmlu-professional-psychology.val.391,mistralai/mistral-7b-chat,1.0,2.88e-05,1.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,0.0,0.00145
winogrande.dev.1014,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.41e-05,0.0,2.8799999999999995e-05,1.0,3.7248e-05,1.0,0.00052
grade-school-math.dev.1243,mistralai/mistral-7b-chat,0.25,6.82e-05,0.25,6.82e-05,0.75,0.0001242,0.75,0.000231,0.75,0.000319712,0.75,0.00592
mbpp.dev.244,mistralai/mistral-7b-chat,0.0,6.220000000000001e-05,0.0,6.220000000000001e-05,0.0,8.790000000000001e-05,0.0,0.0001236,1.0,0.000215728,0.0,0.00753
mmlu-professional-accounting.val.213,mistralai/mistral-7b-chat,0.0,4e-05,0.0,4e-05,0.0,6e-05,0.0,0.00012,0.0,0.0001551999999999,0.0,0.00201
mmlu-anatomy.val.64,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.6500,WizardLM/WizardLM-13B-V1.2,0.5,0.0001250999999999,0.25,0.0001028,0.5,0.0001250999999999,0.5,0.0002243999999999,0.75,0.000266944,0.5,0.00639
grade-school-math.dev.2235,mistralai/mistral-7b-chat,0.5,8.960000000000001e-05,0.5,8.960000000000001e-05,0.75,0.000165,0.5,0.000273,0.25,0.000346872,0.5,0.0090899999999999
mmlu-moral-scenarios.val.205,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-professional-law.val.518,mistralai/mistral-7b-chat,1.0,4.7600000000000005e-05,1.0,4.7600000000000005e-05,0.0,7.14e-05,0.0,0.0001428,0.0,0.000184688,0.0,0.00242
mmlu-high-school-psychology.val.26,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
arc-challenge.val.147,mistralai/mixtral-8x7b-chat,0.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mbpp.dev.298,mistralai/mistral-7b-chat,0.0,5.86e-05,0.0,5.86e-05,0.0,8.340000000000001e-05,0.0,0.0001656,1.0,0.00017072,0.0,0.01249
grade-school-math.dev.5044,meta/code-llama-instruct-34b-chat,0.75,0.00029876,0.75,8.560000000000001e-05,0.75,0.0001467,0.75,0.0002399999999999,0.75,0.00029876,0.5,0.00711
grade-school-math.dev.2789,WizardLM/WizardLM-13B-V1.2,0.75,0.0001505999999999,0.75,9.92e-05,0.75,0.0001505999999999,0.75,0.0002795999999999,0.25,0.000344544,0.75,0.00849
mmlu-professional-law.val.689,mistralai/mixtral-8x7b-chat,0.0,0.0002214,0.0,7.38e-05,1.0,0.0001107,0.0,0.0002214,0.0,0.000286344,0.0,0.0037
hellaswag.val.6255,mistralai/mixtral-8x7b-chat,0.0,0.0001362,0.0,4.5400000000000006e-05,0.0,6.78e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00228
hellaswag.val.3462,mistralai/mistral-7b-chat,0.0,4.480000000000001e-05,0.0,4.480000000000001e-05,0.0,6.689999999999999e-05,0.0,0.0001344,0.0,0.0001738239999999,0.0,0.00228
grade-school-math.dev.6456,meta/code-llama-instruct-34b-chat,0.5,0.000301864,1.0,6.220000000000001e-05,0.5,0.0001524,0.75,0.0002646,0.5,0.000301864,0.75,0.00611
mmlu-anatomy.val.97,mistralai/mixtral-8x7b-chat,0.0,7.98e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,0.0,0.00134
grade-school-math.dev.5764,WizardLM/WizardLM-13B-V1.2,0.75,0.0001281,0.75,7.82e-05,0.75,0.0001281,0.75,0.0002058,0.25,0.00027936,0.75,0.0057199999999999
mmlu-moral-scenarios.val.702,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,0.0,0.00146
mmlu-professional-law.val.1090,WizardLM/WizardLM-13B-V1.2,0.0,3.48e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
hellaswag.val.5802,mistralai/mixtral-8x7b-chat,0.0,0.0001799999999999,0.0,6e-05,0.0,8.969999999999998e-05,0.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
arc-challenge.test.48,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
hellaswag.val.7004,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00242
mmlu-professional-law.val.1130,WizardLM/WizardLM-13B-V1.2,1.0,4.86e-05,1.0,3.24e-05,1.0,4.86e-05,1.0,9.72e-05,0.0,0.000125712,1.0,0.00166
hellaswag.val.2837,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
winogrande.dev.1227,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00051
hellaswag.val.2667,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,1.0,6.51e-05,0.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
mmlu-professional-law.val.982,WizardLM/WizardLM-13B-V1.2,0.0,0.0001059,0.0,7.06e-05,0.0,0.0001059,0.0,0.0002118,0.0,0.000273928,0.0,0.00354
hellaswag.val.4725,mistralai/mixtral-8x7b-chat,1.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,1.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-anatomy.val.96,mistralai/mixtral-8x7b-chat,0.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
hellaswag.val.8192,WizardLM/WizardLM-13B-V1.2,0.0,6.749999999999999e-05,0.0,4.5e-05,0.0,6.749999999999999e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00229
hellaswag.val.847,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
hellaswag.val.9882,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00236
mmlu-formal-logic.val.27,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-moral-scenarios.val.829,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,1.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00146
mmlu-professional-law.val.1124,WizardLM/WizardLM-13B-V1.2,0.0,4.89e-05,0.0,3.2600000000000006e-05,0.0,4.89e-05,0.0,9.78e-05,0.0,0.0001264879999999,0.0,0.00167
hellaswag.val.4288,mistralai/mixtral-8x7b-chat,0.0,0.000156,1.0,5.2e-05,1.0,7.8e-05,0.0,0.000156,1.0,0.00020176,1.0,0.00264
mmlu-sociology.val.81,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
arc-challenge.test.994,mistralai/mixtral-8x7b-chat,1.0,4.02e-05,0.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-philosophy.val.90,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-professional-law.val.802,mistralai/mistral-7b-chat,1.0,6.24e-05,1.0,6.24e-05,0.0,9.36e-05,1.0,0.0001872,0.0,0.000242112,0.0,0.00313
hellaswag.val.2132,WizardLM/WizardLM-13B-V1.2,1.0,3.78e-05,0.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
hellaswag.val.7635,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,1.0,0.00018624,1.0,0.00241
hellaswag.val.9725,mistralai/mixtral-8x7b-chat,0.0,0.0001692,0.0,5.64e-05,0.0,8.46e-05,0.0,0.0001692,0.0,0.000218832,1.0,0.00283
hellaswag.val.9302,mistralai/mixtral-8x7b-chat,0.0,0.0001758,0.0,5.860000000000001e-05,0.0,8.759999999999999e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00297
hellaswag.val.1047,mistralai/mistral-7b-chat,1.0,2.74e-05,1.0,2.74e-05,1.0,4.08e-05,1.0,8.22e-05,1.0,0.000106312,1.0,0.00141
hellaswag.val.5426,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
winogrande.dev.687,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.53e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00056
hellaswag.val.3364,WizardLM/WizardLM-13B-V1.2,0.0,6.72e-05,0.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
grade-school-math.dev.1814,meta/code-llama-instruct-34b-chat,0.25,0.000251424,0.5,8.900000000000001e-05,0.75,0.000129,0.75,0.0002351999999999,0.25,0.000251424,0.5,0.0074699999999999
arc-challenge.val.159,mistralai/mistral-7b-chat,0.0,1.22e-05,0.0,1.22e-05,0.0,1.83e-05,1.0,3.66e-05,0.0,4.7336e-05,1.0,0.00065
grade-school-math.dev.5012,mistralai/mixtral-8x7b-chat,0.25,0.00024,0.25,6.780000000000001e-05,0.25,0.0001587,0.25,0.00024,0.25,0.000249096,0.75,0.00588
winogrande.dev.1109,mistralai/mixtral-8x7b-chat,1.0,3.18e-05,1.0,1.06e-05,0.0,1.56e-05,1.0,3.18e-05,1.0,4.1128e-05,0.0,0.00054
mmlu-professional-law.val.1293,WizardLM/WizardLM-13B-V1.2,0.0,4.53e-05,0.0,3.02e-05,0.0,4.53e-05,0.0,9.06e-05,0.0,0.000117176,0.0,0.00155
winogrande.dev.861,mistralai/mistral-7b-chat,1.0,1.1e-05,1.0,1.1e-05,0.0,1.65e-05,1.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00056
mmlu-professional-accounting.val.209,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00114
mmlu-high-school-physics.val.6,mistralai/mixtral-8x7b-chat,0.0,0.000177,0.0,5.9e-05,0.0,8.85e-05,0.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
hellaswag.val.536,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,1.0,7.2168e-05,1.0,0.00097
grade-school-math.dev.1969,WizardLM/WizardLM-13B-V1.2,0.25,0.0001311,0.25,0.0001038,0.25,0.0001311,0.75,0.0002238,0.25,0.000308072,0.5,0.00641
grade-school-math.dev.6186,WizardLM/WizardLM-13B-V1.2,0.25,0.0001643999999999,0.25,5.9600000000000005e-05,0.25,0.0001643999999999,0.25,0.0002615999999999,0.25,0.0003166079999999,0.75,0.01075
mmlu-high-school-biology.val.236,mistralai/mixtral-8x7b-chat,0.0,6.36e-05,0.0,2.12e-05,1.0,3.18e-05,0.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
hellaswag.val.5883,mistralai/mistral-7b-chat,0.0,6.1000000000000005e-05,0.0,6.1000000000000005e-05,0.0,9.15e-05,0.0,0.0001829999999999,0.0,0.00023668,1.0,0.00309
grade-school-math.dev.5039,WizardLM/WizardLM-13B-V1.2,0.75,0.0001578,0.25,9.72e-05,0.75,0.0001578,0.25,0.0002988,0.75,0.000315832,0.75,0.0074399999999999
grade-school-math.dev.6636,WizardLM/WizardLM-13B-V1.2,0.5,0.0001617,0.25,0.000116,0.5,0.0001617,0.75,0.0003197999999999,0.25,0.000381792,0.5,0.00767
hellaswag.val.9655,mistralai/mixtral-8x7b-chat,1.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,0.0,0.00249
mmlu-high-school-us-history.val.42,mistralai/mixtral-8x7b-chat,0.0,0.0001824,0.0,6.080000000000001e-05,0.0,9.12e-05,0.0,0.0001824,0.0,0.000235904,1.0,0.00305
mmlu-high-school-microeconomics.val.216,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
mmlu-high-school-psychology.val.539,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-professional-law.val.88,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,1.0,5.080000000000001e-05,0.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,0.0,0.00255
winogrande.dev.486,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00052
mmlu-high-school-biology.val.73,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.6906,WizardLM/WizardLM-13B-V1.2,1.0,8.04e-05,1.0,5.360000000000001e-05,1.0,8.04e-05,1.0,0.0001608,1.0,0.0002079679999999,1.0,0.00272
arc-challenge.test.655,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,1.0,5.8976e-05,1.0,0.00077
mmlu-high-school-microeconomics.val.170,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mtbench-reference.dev.3,mistralai/mistral-7b-chat,0.1,9.54e-05,0.1,9.54e-05,0.1,0.0002663999999999,0.1,0.0005543999999999,0.2,0.000676672,1.0,0.0305
mmlu-professional-law.val.187,WizardLM/WizardLM-13B-V1.2,0.0,5.97e-05,0.0,3.980000000000001e-05,0.0,5.97e-05,1.0,0.0001193999999999,0.0,0.000154424,1.0,0.002
hellaswag.val.7176,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-prehistory.val.140,mistralai/mixtral-8x7b-chat,1.0,7.08e-05,1.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
mmlu-professional-law.val.94,mistralai/mistral-7b-chat,1.0,3.3400000000000005e-05,1.0,3.3400000000000005e-05,0.0,5.01e-05,0.0,0.0001002,0.0,0.000129592,1.0,0.00168
mmlu-high-school-mathematics.val.74,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,0.0,0.00121
arc-challenge.test.913,mistralai/mistral-7b-chat,1.0,2.18e-05,1.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,1.0,8.4584e-05,1.0,0.00113
grade-school-math.dev.5306,meta/code-llama-instruct-34b-chat,0.75,0.000363168,0.25,8.72e-05,0.75,0.000138,0.75,0.000207,0.75,0.000363168,0.75,0.00917
hellaswag.val.8816,WizardLM/WizardLM-13B-V1.2,1.0,8.31e-05,1.0,5.5400000000000005e-05,1.0,8.31e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00278
hellaswag.val.3001,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,0.0,3.12e-05,1.0,6.3e-05,1.0,8.148e-05,1.0,0.00106
consensus_summary.dev.156,meta/code-llama-instruct-34b-chat,0.75,0.0001746,0.75,3.9800000000000005e-05,0.0,5.58e-05,0.75,0.0001211999999999,0.75,0.0001746,0.5,0.0019
mmlu-international-law.val.33,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-high-school-physics.val.26,mistralai/mixtral-8x7b-chat,0.0,7.86e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.0013499999999999
mmlu-jurisprudence.val.40,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00117
grade-school-math.dev.5452,WizardLM/WizardLM-13B-V1.2,0.5,0.0001722,0.25,0.0001054,0.5,0.0001722,0.25,0.0002766,0.25,0.00043068,0.5,0.01177
hellaswag.val.1331,mistralai/mistral-7b-chat,1.0,2.9e-05,1.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,0.0,0.00146
hellaswag.val.9582,WizardLM/WizardLM-13B-V1.2,1.0,8.04e-05,0.0,5.360000000000001e-05,1.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
mmlu-professional-law.val.1301,WizardLM/WizardLM-13B-V1.2,1.0,0.0001094999999999,0.0,7.3e-05,1.0,0.0001094999999999,1.0,0.0002189999999999,0.0,0.00028324,0.0,0.00366
mmlu-high-school-world-history.val.179,WizardLM/WizardLM-13B-V1.2,0.0,0.0001133999999999,0.0,7.56e-05,0.0,0.0001133999999999,1.0,0.0002267999999999,0.0,0.000293328,1.0,0.00379
grade-school-math.dev.248,WizardLM/WizardLM-13B-V1.2,0.25,0.0001506,0.25,6.6e-05,0.25,0.0001506,0.75,0.000318,0.25,0.000263064,0.75,0.00807
mmlu-philosophy.val.127,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-management.val.35,mistralai/mistral-7b-chat,0.0,1.34e-05,0.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-philosophy.val.244,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
mmlu-moral-scenarios.val.472,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-moral-disputes.val.282,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mmlu-professional-law.val.1261,WizardLM/WizardLM-13B-V1.2,1.0,8.13e-05,0.0,5.420000000000001e-05,1.0,8.13e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
arc-challenge.test.407,mistralai/mixtral-8x7b-chat,1.0,4.02e-05,1.0,1.34e-05,0.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
grade-school-math.dev.3127,WizardLM/WizardLM-13B-V1.2,0.75,0.0001683,0.75,6.88e-05,0.75,0.0001683,0.75,0.0001986,0.75,0.00027936,0.75,0.00999
arc-challenge.test.320,mistralai/mistral-7b-chat,1.0,1.3e-05,1.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,1.0,5.044e-05,1.0,0.00066
mmlu-moral-scenarios.val.62,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00141
hellaswag.val.2992,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,2.97e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-management.val.57,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00102
mmlu-professional-psychology.val.607,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
mmlu-professional-medicine.val.67,WizardLM/WizardLM-13B-V1.2,1.0,5.82e-05,0.0,3.880000000000001e-05,1.0,5.82e-05,1.0,0.0001164,0.0,0.000150544,1.0,0.00195
mmlu-elementary-mathematics.val.49,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.6869,mistralai/mistral-7b-chat,0.0,3.960000000000001e-05,0.0,3.960000000000001e-05,0.0,5.94e-05,0.0,0.0001188,0.0,0.000153648,1.0,0.00202
mmlu-jurisprudence.val.52,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-moral-disputes.val.90,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.411,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.5780,WizardLM/WizardLM-13B-V1.2,0.75,0.0001203,0.75,8.36e-05,0.75,0.0001203,0.75,0.0002268,0.75,0.000270824,0.5,0.00573
hellaswag.val.2488,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
hellaswag.val.6621,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.5e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00255
hellaswag.val.8367,WizardLM/WizardLM-13B-V1.2,0.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
mmlu-high-school-statistics.val.129,mistralai/mixtral-8x7b-chat,0.0,8.58e-05,1.0,2.88e-05,0.0,4.32e-05,0.0,8.58e-05,0.0,0.000111744,0.0,0.00148
arc-challenge.test.248,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00114
hellaswag.val.2598,WizardLM/WizardLM-13B-V1.2,0.0,4.23e-05,0.0,2.84e-05,0.0,4.23e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00143
grade-school-math.dev.453,mistralai/mixtral-8x7b-chat,0.75,0.0002454,0.75,8.680000000000001e-05,0.5,0.0001404,0.75,0.0002454,0.75,0.000338336,0.75,0.00748
hellaswag.val.9086,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
mtbench-reference.dev.2,mistralai/mistral-7b-chat,0.2,5.46e-05,0.2,5.46e-05,0.3,0.0001587,0.3,0.0003282,0.1,0.000576568,0.9,0.02193
arc-challenge.val.66,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,1.0,6.4408e-05,1.0,0.00087
arc-challenge.val.36,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,1.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.523,mistralai/mistral-7b-chat,1.0,3.02e-05,1.0,3.02e-05,1.0,4.5e-05,1.0,9.06e-05,0.0,0.000117176,1.0,0.00155
mmlu-professional-law.val.994,WizardLM/WizardLM-13B-V1.2,0.0,6.57e-05,0.0,4.380000000000001e-05,0.0,6.57e-05,1.0,0.0001314,0.0,0.0001699439999999,1.0,0.0022
grade-school-math.dev.4750,mistralai/mixtral-8x7b-chat,0.75,0.000225,0.25,0.000142,0.75,0.0001971,0.75,0.000225,0.75,0.000334456,0.75,0.0113499999999999
hellaswag.val.5687,WizardLM/WizardLM-13B-V1.2,0.0,6.929999999999999e-05,0.0,4.64e-05,0.0,6.929999999999999e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00233
mmlu-high-school-european-history.val.129,mistralai/mixtral-8x7b-chat,0.0,0.0001992,0.0,6.64e-05,1.0,9.96e-05,0.0,0.0001992,0.0,0.000257632,1.0,0.00336
hellaswag.val.2343,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-high-school-chemistry.val.93,mistralai/mixtral-8x7b-chat,0.0,6.96e-05,1.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
winogrande.dev.233,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.00053
winogrande.dev.652,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,1.0,0.00055
hellaswag.val.8473,mistralai/mistral-7b-chat,0.0,5.4000000000000005e-05,0.0,5.4000000000000005e-05,0.0,8.069999999999998e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
mmlu-professional-law.val.198,mistralai/mistral-7b-chat,0.0,6.04e-05,0.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
grade-school-math.dev.3382,WizardLM/WizardLM-13B-V1.2,0.5,0.0001454999999999,0.25,8.04e-05,0.5,0.0001454999999999,0.75,0.0003107999999999,0.5,0.000327472,0.5,0.00842
hellaswag.val.7376,mistralai/mixtral-8x7b-chat,1.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.19e-05,1.0,0.0001638,0.0,0.0002118479999999,1.0,0.00277
mmlu-professional-law.val.1058,WizardLM/WizardLM-13B-V1.2,0.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
hellaswag.val.2730,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00144
consensus_summary.dev.134,mistralai/mistral-7b-chat,0.75,7.42e-05,0.75,7.42e-05,0.75,0.0001152,0.75,0.0002136,0.75,0.000243664,0.75,0.00475
hellaswag.val.6293,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
grade-school-math.dev.6003,WizardLM/WizardLM-13B-V1.2,0.25,0.0001854,0.25,0.0001138,0.25,0.0001854,0.25,0.0003095999999999,0.25,0.000423696,0.5,0.01244
mmlu-clinical-knowledge.val.8,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
grade-school-math.dev.791,meta/code-llama-instruct-34b-chat,0.5,0.00032204,0.75,9.96e-05,0.75,0.000159,0.75,0.0002532,0.5,0.00032204,0.75,0.00687
arc-challenge.test.711,mistralai/mixtral-8x7b-chat,1.0,4.02e-05,1.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
arc-challenge.test.909,mistralai/mixtral-8x7b-chat,1.0,3.4200000000000005e-05,0.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00061
mmlu-moral-scenarios.val.843,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
hellaswag.val.6381,mistralai/mixtral-8x7b-chat,0.0,0.0001548,1.0,5.160000000000001e-05,1.0,7.709999999999999e-05,0.0,0.0001548,1.0,0.000200208,1.0,0.00262
hellaswag.val.9473,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00243
grade-school-math.dev.2894,WizardLM/WizardLM-13B-V1.2,0.5,0.0001449,0.75,6.68e-05,0.5,0.0001449,0.5,0.0002628,0.75,0.00026384,0.5,0.00678
hellaswag.val.4600,WizardLM/WizardLM-13B-V1.2,0.0,6.03e-05,0.0,4.020000000000001e-05,0.0,6.03e-05,0.0,0.0001205999999999,0.0,0.000155976,1.0,0.00202
mmlu-elementary-mathematics.val.218,WizardLM/WizardLM-13B-V1.2,0.0,2.22e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-high-school-mathematics.val.119,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
grade-school-math.dev.216,mistralai/mistral-7b-chat,0.75,0.0001104,0.75,0.0001104,0.75,0.0001983,0.25,0.00033,0.75,0.000389552,0.75,0.01012
grade-school-math.dev.659,WizardLM/WizardLM-13B-V1.2,0.5,0.0001857,0.25,9.68e-05,0.5,0.0001857,0.75,0.0002898,0.25,0.000392656,0.75,0.01544
mmlu-high-school-government-and-politics.val.176,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.8979,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
mmlu-elementary-mathematics.val.122,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-miscellaneous.val.308,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.46e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.4439,mistralai/mistral-7b-chat,0.75,7.88e-05,0.75,7.88e-05,0.75,0.0001623,0.75,0.0002718,0.75,0.0002716,0.75,0.00844
hellaswag.val.7805,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
hellaswag.val.3231,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.11e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-professional-law.val.1040,WizardLM/WizardLM-13B-V1.2,0.0,0.0001269,0.0,8.46e-05,0.0,0.0001269,0.0,0.0002538,0.0,0.000328248,0.0,0.00424
hellaswag.val.4450,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-moral-disputes.val.153,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-high-school-psychology.val.220,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,1.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-clinical-knowledge.val.229,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-professional-medicine.val.4,mistralai/mistral-7b-chat,1.0,5.020000000000001e-05,1.0,5.020000000000001e-05,1.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00252
hellaswag.val.5167,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
hellaswag.val.7579,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
mmlu-professional-law.val.107,WizardLM/WizardLM-13B-V1.2,0.0,4.89e-05,0.0,3.2600000000000006e-05,0.0,4.89e-05,1.0,9.78e-05,0.0,0.0001264879999999,1.0,0.00164
hellaswag.val.5659,mistralai/mixtral-8x7b-chat,1.0,0.0001758,0.0,5.860000000000001e-05,0.0,8.759999999999999e-05,1.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
hellaswag.val.2138,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
mmlu-high-school-chemistry.val.36,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-high-school-geography.val.183,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.7199,mistralai/mistral-7b-chat,0.25,0.0001016,0.25,0.0001016,0.25,0.0001526999999999,0.75,0.0002628,0.25,0.000290224,0.5,0.00581
mmlu-formal-logic.val.82,mistralai/mistral-7b-chat,0.0,3.2000000000000005e-05,0.0,3.2000000000000005e-05,0.0,4.8e-05,0.0,9.6e-05,0.0,0.00012416,1.0,0.00161
mmlu-professional-law.val.793,WizardLM/WizardLM-13B-V1.2,0.0,9.87e-05,0.0,6.58e-05,0.0,9.87e-05,0.0,0.0001974,0.0,0.000255304,0.0,0.0033
hellaswag.val.1006,WizardLM/WizardLM-13B-V1.2,1.0,4.08e-05,1.0,2.74e-05,1.0,4.08e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00141
mmlu-machine-learning.val.66,mistralai/mistral-7b-chat,0.0,3.8400000000000005e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00196
hellaswag.val.3311,WizardLM/WizardLM-13B-V1.2,1.0,7.17e-05,1.0,4.780000000000001e-05,1.0,7.17e-05,1.0,0.0001434,1.0,0.0001854639999999,1.0,0.00243
mmlu-world-religions.val.13,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.4401,mistralai/mixtral-8x7b-chat,0.0,0.000159,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
hellaswag.val.1115,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
hellaswag.val.5807,mistralai/mistral-7b-chat,1.0,4.44e-05,1.0,4.44e-05,1.0,6.66e-05,1.0,0.0001332,1.0,0.0001722719999999,1.0,0.00226
mbpp.dev.144,mistralai/mistral-7b-chat,0.0,3.2200000000000003e-05,0.0,3.2200000000000003e-05,1.0,0.0001245,0.0,0.0001446,1.0,0.000122608,1.0,0.00875
arc-challenge.test.342,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.3135,mistralai/mistral-7b-chat,0.75,8.5e-05,0.75,8.5e-05,0.75,0.0001632,0.75,0.0002724,0.25,0.000379464,0.5,0.00878
mmlu-miscellaneous.val.102,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
arc-challenge.test.394,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,1.0,8.148e-05,1.0,0.00109
mmlu-professional-law.val.1159,WizardLM/WizardLM-13B-V1.2,1.0,5.46e-05,0.0,3.64e-05,1.0,5.46e-05,0.0,0.0001092,0.0,0.000141232,0.0,0.00183
mmlu-high-school-world-history.val.173,WizardLM/WizardLM-13B-V1.2,0.0,0.0001661999999999,0.0,0.0001108,0.0,0.0001661999999999,1.0,0.0003323999999999,0.0,0.000429904,1.0,0.0055499999999999
hellaswag.val.6828,WizardLM/WizardLM-13B-V1.2,0.0,8.61e-05,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00291
grade-school-math.dev.91,WizardLM/WizardLM-13B-V1.2,0.75,0.0001584,0.25,8.68e-05,0.75,0.0001584,0.75,0.0002466,0.25,0.000339888,0.75,0.00697
mmlu-professional-law.val.496,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,0.0,7.92e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00265
mmlu-miscellaneous.val.37,mistralai/mistral-7b-chat,0.0,1.26e-05,0.0,1.26e-05,1.0,1.89e-05,1.0,3.78e-05,0.0,4.8888e-05,1.0,0.0006399999999999
mmlu-philosophy.val.66,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
winogrande.dev.869,mistralai/mistral-7b-chat,1.0,1.12e-05,1.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,0.0,0.00057
hellaswag.val.2763,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.12e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-machine-learning.val.43,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-high-school-psychology.val.506,mistralai/mixtral-8x7b-chat,1.0,7.32e-05,0.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
grade-school-math.dev.4573,meta/code-llama-instruct-34b-chat,0.25,0.000357736,0.75,9.8e-05,0.25,0.0002322,0.25,0.0002441999999999,0.25,0.000357736,0.75,0.0108499999999999
mmlu-high-school-world-history.val.171,mistralai/mixtral-8x7b-chat,1.0,0.0001986,0.0,6.62e-05,0.0,9.93e-05,1.0,0.0001986,0.0,0.0002568559999999,1.0,0.00332
hellaswag.val.5074,mistralai/mistral-7b-chat,0.0,4.5400000000000006e-05,0.0,4.5400000000000006e-05,0.0,6.81e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00228
grade-school-math.dev.6472,mistralai/mixtral-8x7b-chat,0.75,0.0002514,0.25,7.02e-05,0.25,0.0001994999999999,0.75,0.0002514,0.5,0.000432232,0.75,0.00898
mmlu-professional-law.val.192,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,0.0,8.76e-05,1.0,0.0001752,0.0,0.000226592,1.0,0.00293
mmlu-professional-law.val.1325,WizardLM/WizardLM-13B-V1.2,0.0,9.6e-05,0.0,6.4e-05,0.0,9.6e-05,0.0,0.0001919999999999,0.0,0.00024832,1.0,0.00321
hellaswag.val.8704,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
mmlu-clinical-knowledge.val.138,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
grade-school-math.dev.2742,mistralai/mistral-7b-chat,0.75,8e-05,0.75,8e-05,0.5,0.0001404,0.75,0.0002802,0.5,0.000287896,0.75,0.00736
mmlu-professional-medicine.val.245,WizardLM/WizardLM-13B-V1.2,0.0,0.0001074,0.0,7.16e-05,0.0,0.0001074,1.0,0.0002148,0.0,0.000277808,1.0,0.00359
hellaswag.val.6039,WizardLM/WizardLM-13B-V1.2,0.0,7.8e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
hellaswag.val.4021,mistralai/mistral-7b-chat,0.0,4.340000000000001e-05,0.0,4.340000000000001e-05,0.0,6.479999999999999e-05,0.0,0.0001302,0.0,0.0001683919999999,0.0,0.00218
hellaswag.val.4845,WizardLM/WizardLM-13B-V1.2,0.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00259
grade-school-math.dev.773,mistralai/mistral-7b-chat,0.25,7.54e-05,0.25,7.54e-05,0.75,0.0001662,0.75,0.0002892,0.75,0.00034532,0.5,0.00845
mtbench-reference.dev.16,mistralai/mistral-7b-chat,0.1,0.0001774,0.1,0.0001774,0.2,0.0003680999999999,0.9,0.0006431999999999,0.4,0.000744184,0.8,0.0341599999999999
grade-school-math.dev.3174,meta/code-llama-instruct-34b-chat,0.25,0.000369376,0.25,9.880000000000002e-05,0.25,0.0002475,0.25,0.0002742,0.25,0.000369376,0.75,0.01368
grade-school-math.dev.4025,mistralai/mistral-7b-chat,0.75,8.66e-05,0.75,8.66e-05,0.75,0.0001395,0.75,0.0002142,0.25,0.000375584,0.5,0.0068299999999999
mmlu-professional-law.val.1180,mistralai/mistral-7b-chat,1.0,5.3200000000000006e-05,1.0,5.3200000000000006e-05,1.0,7.98e-05,1.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
hellaswag.val.3392,mistralai/mistral-7b-chat,0.0,5.6000000000000006e-05,0.0,5.6000000000000006e-05,0.0,8.369999999999999e-05,0.0,0.000168,0.0,0.00021728,0.0,0.00284
abstract2title.test.252,mistralai/mixtral-8x7b-chat,1.0,0.0002718,1.0,7.28e-05,1.0,0.0001074,1.0,0.0002718,1.0,0.000286344,1.0,0.00424
mmlu-high-school-european-history.val.63,WizardLM/WizardLM-13B-V1.2,0.0,0.0001049999999999,0.0,7.000000000000001e-05,0.0,0.0001049999999999,0.0,0.0002099999999999,0.0,0.0002716,1.0,0.00351
grade-school-math.dev.4433,WizardLM/WizardLM-13B-V1.2,0.25,0.0001848,0.25,8.900000000000001e-05,0.25,0.0001848,0.75,0.0002766,0.5,0.000311176,0.75,0.01097
mmlu-high-school-biology.val.171,mistralai/mistral-7b-chat,1.0,2.8600000000000004e-05,1.0,2.8600000000000004e-05,0.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
grade-school-math.dev.6647,WizardLM/WizardLM-13B-V1.2,0.75,0.0001323,0.25,7.04e-05,0.75,0.0001323,0.25,0.0002016,0.25,0.000299536,0.75,0.0081199999999999
grade-school-math.dev.6052,mistralai/mistral-7b-chat,0.25,9.100000000000002e-05,0.25,9.100000000000002e-05,0.5,0.0001347,0.75,0.0002562,0.5,0.000355408,0.75,0.00652
mmlu-conceptual-physics.val.11,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-elementary-mathematics.val.62,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
grade-school-math.dev.1663,mistralai/mistral-7b-chat,0.5,6.24e-05,0.5,6.24e-05,0.75,0.0001203,0.5,0.0002045999999999,0.25,0.000350752,0.75,0.00514
grade-school-math.dev.3542,WizardLM/WizardLM-13B-V1.2,0.25,0.0001815,0.25,9.64e-05,0.25,0.0001815,0.25,0.0003815999999999,0.75,0.000369376,0.75,0.0108799999999999
arc-challenge.test.1143,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
hellaswag.val.6854,mistralai/mixtral-8x7b-chat,1.0,0.0001428,1.0,4.7600000000000005e-05,1.0,7.14e-05,1.0,0.0001428,1.0,0.000184688,1.0,0.00239
mmlu-security-studies.val.133,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-psychology.val.251,mistralai/mixtral-8x7b-chat,1.0,8.22e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-professional-law.val.826,WizardLM/WizardLM-13B-V1.2,0.0,5.76e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00196
winogrande.dev.116,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,1.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
arc-challenge.val.204,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
grade-school-math.dev.2729,WizardLM/WizardLM-13B-V1.2,0.75,0.0001584,0.75,8.04e-05,0.75,0.0001584,0.25,0.00027,0.25,0.000301864,0.75,0.0069999999999999
mmlu-professional-law.val.1403,WizardLM/WizardLM-13B-V1.2,1.0,0.0001092,0.0,7.280000000000001e-05,1.0,0.0001092,1.0,0.0002184,0.0,0.000282464,1.0,0.00365
abstract2title.test.75,mistralai/mixtral-8x7b-chat,1.0,0.000114,1.0,3.600000000000001e-05,1.0,5.79e-05,1.0,0.000114,1.0,0.000141232,1.0,0.00244
hellaswag.val.10019,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.589999999999999e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
mmlu-high-school-biology.val.133,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-law.val.1358,WizardLM/WizardLM-13B-V1.2,0.0,0.0001220999999999,1.0,8.14e-05,0.0,0.0001220999999999,0.0,0.0002441999999999,0.0,0.000315832,0.0,0.0040799999999999
mmlu-high-school-european-history.val.52,WizardLM/WizardLM-13B-V1.2,0.0,0.0001059,0.0,7.06e-05,0.0,0.0001059,1.0,0.0002118,0.0,0.000273928,1.0,0.00354
mmlu-formal-logic.val.30,mistralai/mistral-7b-chat,0.0,3.54e-05,0.0,3.54e-05,1.0,5.31e-05,1.0,0.0001062,0.0,0.000137352,0.0,0.00178
grade-school-math.dev.7448,mistralai/mistral-7b-chat,0.75,7.66e-05,0.75,7.66e-05,0.75,0.0001302,0.75,0.000201,0.75,0.000280912,0.75,0.00596
mmlu-jurisprudence.val.54,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,0.0,0.0013
mmlu-human-aging.val.163,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
winogrande.dev.1110,mistralai/mixtral-8x7b-chat,0.0,3.18e-05,1.0,1.06e-05,1.0,1.59e-05,0.0,3.18e-05,0.0,4.1128e-05,0.0,0.00054
hellaswag.val.9528,mistralai/mistral-7b-chat,1.0,4.9600000000000006e-05,1.0,4.9600000000000006e-05,1.0,7.409999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
mmlu-professional-law.val.306,WizardLM/WizardLM-13B-V1.2,0.0,6.42e-05,1.0,4.280000000000001e-05,0.0,6.42e-05,0.0,0.0001284,0.0,0.000166064,0.0,0.00215
mmlu-moral-scenarios.val.461,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-moral-scenarios.val.888,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
mbpp.dev.279,mistralai/mistral-7b-chat,0.0,6.48e-05,0.0,6.48e-05,0.0,7.74e-05,0.0,0.0002556,0.0,0.00019788,0.0,0.01338
mmlu-high-school-statistics.val.47,mistralai/mixtral-8x7b-chat,0.0,9.54e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,0.0,9.54e-05,0.0,0.000123384,1.0,0.00163
mmlu-high-school-chemistry.val.113,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-econometrics.val.62,mistralai/mixtral-8x7b-chat,1.0,0.0001092,0.0,3.62e-05,0.0,5.46e-05,1.0,0.0001092,0.0,0.000140456,1.0,0.00183
grade-school-math.dev.4354,WizardLM/WizardLM-13B-V1.2,0.75,0.0002078999999999,0.25,7.54e-05,0.75,0.0002078999999999,0.75,0.000276,0.75,0.00038412,0.5,0.00939
grade-school-math.dev.1888,WizardLM/WizardLM-13B-V1.2,0.75,0.0001397999999999,0.75,8.180000000000001e-05,0.75,0.0001397999999999,0.25,0.0002352,0.5,0.000389552,0.75,0.0062299999999999
mmlu-machine-learning.val.84,mistralai/mixtral-8x7b-chat,0.0,7.44e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.7348,mistralai/mistral-7b-chat,0.0,4.480000000000001e-05,0.0,4.480000000000001e-05,0.0,6.72e-05,1.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
mmlu-professional-law.val.804,WizardLM/WizardLM-13B-V1.2,0.0,8.64e-05,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
grade-school-math.dev.389,WizardLM/WizardLM-13B-V1.2,0.5,0.0001605,0.5,9.86e-05,0.5,0.0001605,1.0,0.0002189999999999,0.5,0.000363168,0.5,0.0084
mmlu-high-school-government-and-politics.val.86,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
hellaswag.val.7027,WizardLM/WizardLM-13B-V1.2,0.0,8.28e-05,0.0,5.5400000000000005e-05,0.0,8.28e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-high-school-macroeconomics.val.124,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-law.val.12,mistralai/mistral-7b-chat,0.0,7.1e-05,0.0,7.1e-05,1.0,0.0001064999999999,0.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
grade-school-math.dev.5962,WizardLM/WizardLM-13B-V1.2,0.75,0.000132,0.25,7.64e-05,0.75,0.000132,0.75,0.0002274,0.25,0.000268496,0.75,0.00679
mmlu-professional-law.val.296,mistralai/mistral-7b-chat,0.0,3.7000000000000005e-05,0.0,3.7000000000000005e-05,1.0,5.55e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00186
mmlu-professional-psychology.val.599,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
hellaswag.val.6055,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,0.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00241
mmlu-high-school-statistics.val.56,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
bias_detection.dev.96,mistralai/mistral-7b-chat,0.0,5.940000000000001e-05,0.0,5.940000000000001e-05,0.0,9.57e-05,0.0,0.0001871999999999,0.0,0.000249872,0.0,0.008
mmlu-professional-law.val.1528,WizardLM/WizardLM-13B-V1.2,1.0,0.0001074,1.0,7.16e-05,1.0,0.0001074,1.0,0.0002148,0.0,0.000277808,1.0,0.00359
winogrande.dev.78,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,1.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,0.0,0.00054
hellaswag.val.2550,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.54e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
hellaswag.val.9660,mistralai/mixtral-8x7b-chat,1.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00259
mmlu-high-school-statistics.val.50,mistralai/mistral-7b-chat,1.0,3.24e-05,1.0,3.24e-05,0.0,4.86e-05,1.0,9.72e-05,0.0,0.000125712,1.0,0.00166
hellaswag.val.293,WizardLM/WizardLM-13B-V1.2,0.0,3.63e-05,1.0,2.42e-05,0.0,3.63e-05,0.0,7.259999999999999e-05,1.0,9.3896e-05,0.0,0.00122
mmlu-professional-law.val.666,mistralai/mistral-7b-chat,1.0,3.4000000000000007e-05,1.0,3.4000000000000007e-05,0.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00174
hellaswag.val.2461,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
mmlu-miscellaneous.val.644,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,1.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-prehistory.val.179,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,1.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
hellaswag.val.5923,mistralai/mistral-7b-chat,1.0,4.1800000000000006e-05,1.0,4.1800000000000006e-05,1.0,6.269999999999999e-05,0.0,0.0001253999999999,1.0,0.000162184,1.0,0.00213
mmlu-moral-scenarios.val.668,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00142
mmlu-professional-law.val.1229,WizardLM/WizardLM-13B-V1.2,0.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
hellaswag.val.2560,WizardLM/WizardLM-13B-V1.2,0.0,2.9100000000000003e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
abstract2title.test.146,mistralai/mixtral-8x7b-chat,1.0,0.000168,1.0,5.4600000000000006e-05,1.0,8.369999999999999e-05,1.0,0.000168,1.0,0.0002095199999999,1.0,0.00341
grade-school-math.dev.1498,WizardLM/WizardLM-13B-V1.2,0.25,0.0001929,0.25,9.18e-05,0.25,0.0001929,0.5,0.0002772,0.25,0.000384896,0.5,0.00887
hellaswag.val.7107,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,1.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00246
mmlu-prehistory.val.290,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.4324,WizardLM/WizardLM-13B-V1.2,0.75,0.0001467,0.25,6.9e-05,0.75,0.0001467,0.25,0.0002789999999999,0.75,0.000339888,0.75,0.01065
mmlu-jurisprudence.val.72,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-elementary-mathematics.val.35,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-high-school-microeconomics.val.183,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.3092,mistralai/mistral-7b-chat,1.0,2.52e-05,1.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,0.0,0.00127
winogrande.dev.524,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
hellaswag.val.6379,mistralai/mixtral-8x7b-chat,0.0,0.0001326,0.0,4.420000000000001e-05,0.0,6.599999999999999e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00225
grade-school-math.dev.1514,WizardLM/WizardLM-13B-V1.2,0.75,0.0001286999999999,0.75,6.6e-05,0.75,0.0001286999999999,0.75,0.0001878,0.5,0.00024832,0.75,0.00557
hellaswag.val.7715,mistralai/mistral-7b-chat,1.0,5.260000000000001e-05,1.0,5.260000000000001e-05,1.0,7.89e-05,0.0,0.0001578,1.0,0.000204088,1.0,0.00267
mmlu-clinical-knowledge.val.209,mistralai/mixtral-8x7b-chat,1.0,8.340000000000001e-05,0.0,2.78e-05,1.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
hellaswag.val.5460,WizardLM/WizardLM-13B-V1.2,0.0,8.069999999999998e-05,0.0,5.4000000000000005e-05,0.0,8.069999999999998e-05,1.0,0.0001619999999999,0.0,0.00020952,0.0,0.00274
winogrande.dev.321,mistralai/mistral-7b-chat,0.0,1.12e-05,0.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,0.0,4.3456000000000005e-05,1.0,0.00057
mmlu-virology.val.146,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.995,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.2914,mistralai/mixtral-8x7b-chat,1.0,8.64e-05,0.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-professional-law.val.378,WizardLM/WizardLM-13B-V1.2,0.0,7.649999999999999e-05,1.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,0.0,0.00256
mmlu-miscellaneous.val.252,mistralai/mixtral-8x7b-chat,1.0,9.18e-05,1.0,3.0600000000000005e-05,1.0,4.59e-05,1.0,9.18e-05,0.0,0.000118728,1.0,0.00154
mmlu-professional-psychology.val.201,WizardLM/WizardLM-13B-V1.2,1.0,3.6e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
arc-challenge.test.106,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,1.0,8.380800000000001e-05,1.0,0.00112
mmlu-professional-law.val.1004,WizardLM/WizardLM-13B-V1.2,1.0,0.0001631999999999,1.0,0.0001088,1.0,0.0001631999999999,0.0,0.0003263999999999,0.0,0.0004221439999999,1.0,0.00545
hellaswag.val.5617,WizardLM/WizardLM-13B-V1.2,0.0,8.04e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
hellaswag.val.7542,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.709999999999999e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
bias_detection.dev.90,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,0.0,8.91e-05,1.0,0.0001608,0.0,0.000224264,1.0,0.00768
winogrande.dev.400,mistralai/mixtral-8x7b-chat,0.0,2.8799999999999995e-05,0.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00052
mmlu-professional-psychology.val.390,mistralai/mixtral-8x7b-chat,1.0,8.04e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-high-school-government-and-politics.val.82,mistralai/mistral-7b-chat,1.0,2.7e-05,1.0,2.7e-05,1.0,4.02e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-professional-law.val.44,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
hellaswag.val.1978,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-college-chemistry.val.38,mistralai/mixtral-8x7b-chat,0.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-high-school-mathematics.val.4,mistralai/mixtral-8x7b-chat,0.0,0.0001188,0.0,3.960000000000001e-05,0.0,5.94e-05,0.0,0.0001188,0.0,0.000153648,1.0,0.00199
grade-school-math.dev.1935,WizardLM/WizardLM-13B-V1.2,0.25,0.0002034,0.25,9.82e-05,0.25,0.0002034,0.75,0.0002826,0.25,0.00041128,0.75,0.0108
hellaswag.val.3988,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,0.0,8.76e-05,0.0,0.0001752,0.0,0.000226592,1.0,0.00296
mmlu-professional-law.val.1215,mistralai/mistral-7b-chat,0.0,7.319999999999999e-05,0.0,7.319999999999999e-05,0.0,0.0001098,0.0,0.0002196,0.0,0.000284016,1.0,0.00367
mmlu-high-school-microeconomics.val.229,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-miscellaneous.val.779,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.801,WizardLM/WizardLM-13B-V1.2,0.0,5.01e-05,1.0,3.3400000000000005e-05,0.0,5.01e-05,1.0,0.0001002,0.0,0.000129592,1.0,0.00171
mmlu-high-school-physics.val.43,mistralai/mixtral-8x7b-chat,0.0,7.62e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,0.0,0.00128
mtbench-reference.dev.15,mistralai/mistral-7b-chat,0.2,9.84e-05,0.2,9.84e-05,0.9,0.0003324,0.8,0.000498,0.7,0.00065184,1.0,0.03607
mmlu-high-school-us-history.val.133,mistralai/mixtral-8x7b-chat,1.0,0.0002148,0.0,7.16e-05,0.0,0.0001074,1.0,0.0002148,0.0,0.000277808,1.0,0.00362
grade-school-math.dev.6230,mistralai/mistral-7b-chat,0.25,0.0001062,0.25,0.0001062,0.25,0.0001629,0.75,0.000264,0.75,0.000313504,0.75,0.0066099999999999
hellaswag.val.300,WizardLM/WizardLM-13B-V1.2,1.0,3.33e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
winogrande.dev.536,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00056
mmlu-professional-law.val.261,mistralai/mistral-7b-chat,0.0,3.460000000000001e-05,0.0,3.460000000000001e-05,0.0,5.19e-05,0.0,0.0001038,0.0,0.0001342479999999,1.0,0.00174
mmlu-elementary-mathematics.val.292,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-philosophy.val.189,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
hellaswag.val.4251,mistralai/mixtral-8x7b-chat,0.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.95e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.0027
grade-school-math.dev.3446,WizardLM/WizardLM-13B-V1.2,0.5,0.0001989,0.5,0.000103,0.5,0.0001989,0.5,0.0003185999999999,0.25,0.000284016,0.5,0.00941
hellaswag.val.9215,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.319999999999999e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-high-school-macroeconomics.val.358,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
grade-school-math.dev.4962,WizardLM/WizardLM-13B-V1.2,0.25,0.0001716,0.25,9.34e-05,0.25,0.0001716,0.25,0.0003485999999999,0.25,0.000406624,0.5,0.0087999999999999
hellaswag.val.7948,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00243
mmlu-world-religions.val.55,mistralai/mixtral-8x7b-chat,0.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,0.0,0.00078
grade-school-math.dev.6457,mistralai/mistral-7b-chat,0.25,0.0001,0.25,0.0001,0.25,0.0002055,0.25,0.0003461999999999,0.25,0.000330576,0.75,0.00993
grade-school-math.dev.4037,WizardLM/WizardLM-13B-V1.2,0.75,0.0001311,0.25,6.64e-05,0.75,0.0001311,0.75,0.0002219999999999,0.75,0.000241336,0.75,0.0053799999999999
grade-school-math.dev.1629,meta/code-llama-instruct-34b-chat,0.5,0.000301864,0.5,8.840000000000001e-05,0.5,0.0001383,0.5,0.0002598,0.5,0.000301864,0.75,0.00679
hellaswag.val.460,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,0.0,0.00089
mmlu-professional-law.val.1443,WizardLM/WizardLM-13B-V1.2,0.0,0.0001397999999999,0.0,9.32e-05,0.0,0.0001397999999999,0.0,0.0002795999999999,0.0,0.000361616,1.0,0.00467
hellaswag.val.9074,mistralai/mixtral-8x7b-chat,1.0,0.0001482,1.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,1.0,0.000191672,1.0,0.00251
hellaswag.val.4225,mistralai/mistral-7b-chat,0.0,5.3200000000000006e-05,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
hellaswag.val.9894,WizardLM/WizardLM-13B-V1.2,1.0,7.439999999999999e-05,1.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,0.0,0.00249
grade-school-math.dev.1942,WizardLM/WizardLM-13B-V1.2,0.75,0.0001311,0.75,8.66e-05,0.75,0.0001311,0.75,0.0002328,0.75,0.000331352,0.75,0.00642
winogrande.dev.647,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00051
grade-school-math.dev.5574,WizardLM/WizardLM-13B-V1.2,0.25,0.0001574999999999,0.25,8.16e-05,0.25,0.0001574999999999,0.75,0.0002753999999999,0.25,0.00032204,0.75,0.00935
grade-school-math.dev.2833,mistralai/mistral-7b-chat,0.25,0.000113,0.25,0.000113,0.75,0.0001796999999999,0.75,0.0003294,0.5,0.000398864,0.5,0.0087199999999999
hellaswag.val.1987,WizardLM/WizardLM-13B-V1.2,1.0,4.35e-05,0.0,2.9e-05,1.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,0.0,0.00146
mmlu-medical-genetics.val.64,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,1.0,1.58e-05,1.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-professional-law.val.388,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
hellaswag.val.7049,mistralai/mixtral-8x7b-chat,1.0,0.0001542,0.0,5.14e-05,0.0,7.68e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
mmlu-conceptual-physics.val.105,mistralai/mixtral-8x7b-chat,0.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-moral-scenarios.val.146,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
hellaswag.val.8988,WizardLM/WizardLM-13B-V1.2,0.0,8.879999999999999e-05,0.0,5.94e-05,0.0,8.879999999999999e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
consensus_summary.dev.220,mistralai/mistral-7b-chat,0.0,4.1e-05,0.0,4.1e-05,0.0,5.67e-05,0.75,0.0001566,0.0,0.000262288,0.0,0.0019299999999999
hellaswag.val.8567,mistralai/mistral-7b-chat,1.0,6.38e-05,1.0,6.38e-05,1.0,9.57e-05,1.0,0.0001914,1.0,0.000247544,1.0,0.00323
mmlu-professional-law.val.1083,WizardLM/WizardLM-13B-V1.2,0.0,0.0001247999999999,0.0,8.32e-05,0.0,0.0001247999999999,0.0,0.0002495999999999,0.0,0.000322816,1.0,0.0041699999999999
mmlu-management.val.55,mistralai/mixtral-8x7b-chat,0.0,4.98e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
hellaswag.val.10025,mistralai/mixtral-8x7b-chat,0.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.00273
mmlu-professional-law.val.652,WizardLM/WizardLM-13B-V1.2,0.0,5.88e-05,0.0,3.92e-05,0.0,5.88e-05,1.0,0.0001176,0.0,0.000152096,1.0,0.00197
mmlu-moral-scenarios.val.845,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00138
mmlu-miscellaneous.val.577,WizardLM/WizardLM-13B-V1.2,1.0,2.79e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.6072,mistralai/mistral-7b-chat,0.75,7.66e-05,0.75,7.66e-05,0.75,0.0001608,0.75,0.0002502,0.75,0.000311176,0.75,0.00778
grade-school-math.dev.2293,WizardLM/WizardLM-13B-V1.2,0.25,0.0001224,0.75,7.12e-05,0.25,0.0001224,0.75,0.0002184,0.75,0.000320488,0.75,0.00669
hellaswag.val.4583,mistralai/mixtral-8x7b-chat,1.0,0.0001788,0.0,5.9600000000000005e-05,0.0,8.94e-05,1.0,0.0001788,0.0,0.0002312479999999,1.0,0.00302
mmlu-professional-law.val.665,WizardLM/WizardLM-13B-V1.2,0.0,7.680000000000001e-05,1.0,5.12e-05,0.0,7.680000000000001e-05,1.0,0.0001536,0.0,0.000198656,1.0,0.0026
hellaswag.val.4109,mistralai/mistral-7b-chat,1.0,4.920000000000001e-05,1.0,4.920000000000001e-05,1.0,7.35e-05,0.0,0.0001476,1.0,0.0001908959999999,1.0,0.0025
grade-school-math.dev.4281,WizardLM/WizardLM-13B-V1.2,0.75,0.0001496999999999,0.75,8.620000000000001e-05,0.75,0.0001496999999999,0.75,0.0002718,0.75,0.00033756,0.75,0.00695
mmlu-moral-scenarios.val.712,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00139
hellaswag.val.3365,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-high-school-mathematics.val.69,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00101
mmlu-philosophy.val.108,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,0.0,0.00077
grade-school-math.dev.1284,mistralai/mistral-7b-chat,0.25,8.620000000000001e-05,0.25,8.620000000000001e-05,0.75,0.0001304999999999,0.75,0.0002525999999999,0.75,0.000338336,0.75,0.01026
hellaswag.val.7843,mistralai/mixtral-8x7b-chat,0.0,0.0001674,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.00283
hellaswag.val.8506,mistralai/mixtral-8x7b-chat,0.0,0.0001763999999999,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00298
hellaswag.val.7442,mistralai/mixtral-8x7b-chat,1.0,0.0001704,1.0,5.680000000000001e-05,1.0,8.52e-05,1.0,0.0001704,0.0,0.0002203839999999,1.0,0.00288
mmlu-professional-law.val.164,mistralai/mistral-7b-chat,0.0,5.780000000000001e-05,0.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
consensus_summary.dev.226,mistralai/mistral-7b-chat,0.5,6e-05,0.5,6e-05,0.75,0.0001100999999999,0.75,0.0001529999999999,0.75,0.0002095199999999,0.75,0.00341
hellaswag.val.1889,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.1034,WizardLM/WizardLM-13B-V1.2,1.0,3.66e-05,0.0,2.44e-05,1.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
mmlu-formal-logic.val.74,mistralai/mixtral-8x7b-chat,0.0,5.34e-05,1.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
hellaswag.val.1378,mistralai/mistral-7b-chat,0.0,3.4000000000000007e-05,0.0,3.4000000000000007e-05,1.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
mmlu-high-school-chemistry.val.98,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00113
mmlu-nutrition.val.209,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-professional-psychology.val.308,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,0.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-high-school-us-history.val.81,WizardLM/WizardLM-13B-V1.2,0.0,0.0001199999999999,0.0,8e-05,0.0,0.0001199999999999,1.0,0.0002399999999999,0.0,0.0003104,1.0,0.00401
mmlu-professional-law.val.373,WizardLM/WizardLM-13B-V1.2,0.0,8.58e-05,0.0,5.720000000000001e-05,0.0,8.58e-05,0.0,0.0001716,0.0,0.000221936,0.0,0.00287
mmlu-business-ethics.val.46,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,1.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
arc-challenge.test.531,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,1.0,7.4496e-05,1.0,0.001
hellaswag.val.8544,mistralai/mistral-7b-chat,1.0,5.920000000000001e-05,1.0,5.920000000000001e-05,1.0,8.85e-05,1.0,0.0001776,1.0,0.000229696,1.0,0.00297
mmlu-miscellaneous.val.105,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.2401,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
hellaswag.val.1541,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,1.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,1.0,8.2256e-05,0.0,0.00107
mmlu-professional-law.val.32,WizardLM/WizardLM-13B-V1.2,0.0,0.0001335,0.0,8.900000000000001e-05,0.0,0.0001335,0.0,0.000267,0.0,0.00034532,1.0,0.0044599999999999
mbpp.dev.35,mistralai/mixtral-8x7b-chat,0.0,0.0002352,0.0,4.96e-05,0.0,0.0001821,0.0,0.0002352,1.0,0.000110968,1.0,0.0066
mmlu-marketing.val.180,WizardLM/WizardLM-13B-V1.2,0.0,2.88e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
mmlu-high-school-geography.val.29,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mtbench.dev.11,mistralai/mixtral-8x7b-chat,0.9,0.0002832,0.5,4.22e-05,0.7,8.639999999999999e-05,0.9,0.0002832,0.5,0.000231248,0.5,0.00876
mmlu-security-studies.val.137,mistralai/mistral-7b-chat,1.0,2.32e-05,1.0,2.32e-05,1.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-professional-law.val.692,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-high-school-mathematics.val.138,mistralai/mixtral-8x7b-chat,0.0,7.44e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.5169,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.319999999999999e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,0.0,0.00248
hellaswag.val.8879,mistralai/mixtral-8x7b-chat,1.0,0.0001818,1.0,6.06e-05,1.0,9.09e-05,1.0,0.0001818,1.0,0.0002351279999999,1.0,0.00307
mmlu-human-aging.val.133,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-high-school-chemistry.val.120,mistralai/mixtral-8x7b-chat,0.0,3.96e-05,0.0,1.32e-05,0.0,1.98e-05,0.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
hellaswag.val.7459,WizardLM/WizardLM-13B-V1.2,0.0,6.45e-05,0.0,4.3e-05,0.0,6.45e-05,0.0,0.000129,0.0,0.00016684,1.0,0.00216
hellaswag.val.4486,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.589999999999999e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00258
hellaswag.val.4655,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,0.0,0.00253
mmlu-human-aging.val.29,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,0.0,0.00086
hellaswag.val.3888,WizardLM/WizardLM-13B-V1.2,1.0,9.15e-05,1.0,6.1000000000000005e-05,1.0,9.15e-05,0.0,0.0001829999999999,1.0,0.00023668,1.0,0.00309
hellaswag.val.2996,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,0.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-professional-law.val.1133,WizardLM/WizardLM-13B-V1.2,1.0,8.34e-05,0.0,5.56e-05,1.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
mmlu-moral-scenarios.val.559,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,0.0,0.00151
mmlu-professional-law.val.236,WizardLM/WizardLM-13B-V1.2,1.0,6.24e-05,0.0,4.160000000000001e-05,1.0,6.24e-05,0.0,0.0001248,0.0,0.0001614079999999,1.0,0.00209
mmlu-professional-law.val.1237,WizardLM/WizardLM-13B-V1.2,0.0,5.97e-05,0.0,3.980000000000001e-05,0.0,5.97e-05,0.0,0.0001193999999999,0.0,0.000154424,1.0,0.002
hellaswag.val.9300,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,0.0,0.00282
hellaswag.val.7399,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.9e-05,0.0,8.819999999999999e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
arc-challenge.val.251,mistralai/mixtral-8x7b-chat,0.0,3.24e-05,0.0,1.08e-05,0.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
hellaswag.val.5148,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mbpp.dev.305,mistralai/mistral-7b-chat,1.0,5.86e-05,1.0,5.86e-05,1.0,5.88e-05,1.0,0.0001074,1.0,0.000101656,1.0,0.00941
mmlu-professional-psychology.val.515,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.5347,mistralai/mixtral-8x7b-chat,1.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00256
hellaswag.val.6647,mistralai/mistral-7b-chat,0.0,4.520000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,0.0,0.00227
mmlu-human-aging.val.113,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
hellaswag.val.5057,mistralai/mixtral-8x7b-chat,0.0,0.0001842,0.0,6.14e-05,0.0,9.21e-05,0.0,0.0001842,0.0,0.000238232,1.0,0.00308
mmlu-college-medicine.val.41,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
accounting_audit.dev.6,WizardLM/WizardLM-13B-V1.2,0.0,4.41e-05,0.0,2.9400000000000003e-05,0.0,4.41e-05,0.0,8.819999999999999e-05,0.0,0.000114072,1.0,0.00142
mmlu-miscellaneous.val.82,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,0.0,1.92e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
grade-school-math.dev.432,WizardLM/WizardLM-13B-V1.2,0.25,0.0001385999999999,0.25,0.0001448,0.25,0.0001385999999999,0.75,0.0002477999999999,0.75,0.000392656,0.75,0.00823
hellaswag.val.5093,mistralai/mixtral-8x7b-chat,0.0,0.0001614,1.0,5.380000000000001e-05,1.0,8.07e-05,0.0,0.0001614,1.0,0.000208744,1.0,0.00273
mmlu-clinical-knowledge.val.44,mistralai/mixtral-8x7b-chat,1.0,6.06e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.51,WizardLM/WizardLM-13B-V1.2,0.5,0.0001626,0.25,6.120000000000001e-05,0.5,0.0001626,0.75,0.0002958,0.75,0.000346872,0.5,0.01017
arc-challenge.test.1019,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-public-relations.val.82,mistralai/mixtral-8x7b-chat,0.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
mmlu-moral-scenarios.val.774,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mbpp.dev.41,mistralai/mistral-7b-chat,0.0,5.12e-05,0.0,5.12e-05,1.0,8.7e-05,0.0,0.0001512,1.0,0.000140456,0.0,0.01203
mmlu-high-school-statistics.val.77,mistralai/mixtral-8x7b-chat,0.0,7.68e-05,1.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
hellaswag.val.9798,mistralai/mixtral-8x7b-chat,0.0,0.0001656,1.0,5.520000000000001e-05,1.0,8.280000000000001e-05,0.0,0.0001656,1.0,0.0002141759999999,1.0,0.00277
grade-school-math.dev.6842,meta/code-llama-instruct-34b-chat,0.75,0.0002747039999999,0.75,8.7e-05,0.5,0.0001374,0.75,0.0002676,0.75,0.0002747039999999,0.75,0.00835
grade-school-math.dev.3881,WizardLM/WizardLM-13B-V1.2,0.25,0.0002169,0.25,0.0001052,0.25,0.0002169,0.75,0.000312,0.25,0.0003298,0.75,0.01006
hellaswag.val.6770,WizardLM/WizardLM-13B-V1.2,0.0,8.730000000000001e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00295
grade-school-math.dev.1518,WizardLM/WizardLM-13B-V1.2,0.75,0.0001661999999999,0.25,8.54e-05,0.75,0.0001661999999999,0.5,0.0002484,0.75,0.00032592,0.75,0.01286
mmlu-elementary-mathematics.val.251,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.2e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.9995,WizardLM/WizardLM-13B-V1.2,0.0,7.379999999999999e-05,0.0,4.94e-05,0.0,7.379999999999999e-05,0.0,0.0001482,0.0,0.000191672,1.0,0.00248
grade-school-math.dev.3567,WizardLM/WizardLM-13B-V1.2,0.25,0.0001563,0.75,7.840000000000001e-05,0.25,0.0001563,0.25,0.0003323999999999,0.25,0.0003406639999999,0.5,0.00753
mmlu-high-school-statistics.val.54,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-nutrition.val.239,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-high-school-psychology.val.246,WizardLM/WizardLM-13B-V1.2,1.0,2.37e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,0.0,0.00083
grade-school-math.dev.5472,mistralai/mistral-7b-chat,0.5,0.000101,0.5,0.000101,0.75,0.0001704,0.5,0.0002418,0.5,0.000301864,0.5,0.00683
hellaswag.val.6300,WizardLM/WizardLM-13B-V1.2,1.0,6.9e-05,1.0,4.6200000000000005e-05,1.0,6.9e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00235
hellaswag.val.9810,mistralai/mixtral-8x7b-chat,0.0,0.0001373999999999,0.0,4.580000000000001e-05,0.0,6.869999999999999e-05,0.0,0.0001373999999999,0.0,0.000177704,1.0,0.0023
hellaswag.val.7215,mistralai/mixtral-8x7b-chat,0.0,0.0001674,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.00283
mmlu-professional-law.val.1431,mistralai/mistral-7b-chat,1.0,2.42e-05,1.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
mmlu-conceptual-physics.val.233,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00082
grade-school-math.dev.1039,mistralai/mistral-7b-chat,0.75,8.9e-05,0.75,8.9e-05,0.25,0.0001359,0.75,0.0002316,0.75,0.00036472,0.75,0.00809
mmlu-professional-law.val.812,WizardLM/WizardLM-13B-V1.2,0.0,9.03e-05,0.0,6.0200000000000006e-05,0.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
grade-school-math.dev.3876,WizardLM/WizardLM-13B-V1.2,0.75,0.0001512,0.75,7.04e-05,0.75,0.0001512,0.5,0.0003042,0.25,0.000352304,0.75,0.00869
grade-school-math.dev.256,WizardLM/WizardLM-13B-V1.2,0.25,0.0001515,0.25,8.1e-05,0.25,0.0001515,0.25,0.0003156,0.25,0.000293328,0.75,0.01143
mmlu-moral-scenarios.val.732,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.9529,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,0.0,0.00232
grade-school-math.dev.911,WizardLM/WizardLM-13B-V1.2,0.25,0.0001565999999999,0.25,0.0001116,0.25,0.0001565999999999,0.75,0.0003126,0.25,0.000358512,0.25,0.0075699999999999
grade-school-math.dev.3356,mistralai/mistral-7b-chat,0.25,8.48e-05,0.25,8.48e-05,0.75,0.0001631999999999,0.25,0.0002507999999999,0.25,0.000362392,0.5,0.00798
mmlu-professional-psychology.val.538,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.4263,mistralai/mistral-7b-chat,1.0,6.120000000000001e-05,1.0,6.120000000000001e-05,1.0,9.15e-05,1.0,0.0001836,1.0,0.0002374559999999,1.0,0.0031
mmlu-professional-accounting.val.140,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.3642,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.769999999999999e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
mmlu-high-school-psychology.val.22,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
arc-challenge.test.379,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-high-school-psychology.val.358,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.939,mistralai/mistral-7b-chat,1.0,2.2e-05,1.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,1.0,8.536000000000001e-05,0.0,0.00111
grade-school-math.dev.3721,WizardLM/WizardLM-13B-V1.2,0.25,0.0002091,0.25,9.12e-05,0.25,0.0002091,0.25,0.0002639999999999,0.25,0.000382568,0.75,0.00899
winogrande.dev.146,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
mmlu-public-relations.val.43,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-high-school-macroeconomics.val.279,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-miscellaneous.val.532,mistralai/mixtral-8x7b-chat,0.0,4.92e-05,0.0,1.64e-05,1.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-high-school-biology.val.156,mistralai/mixtral-8x7b-chat,1.0,0.0001008,1.0,3.3600000000000004e-05,0.0,5.04e-05,1.0,0.0001008,0.0,0.0001303679999999,1.0,0.00169
hellaswag.val.1509,WizardLM/WizardLM-13B-V1.2,0.0,4.05e-05,1.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
mmlu-high-school-us-history.val.76,mistralai/mixtral-8x7b-chat,1.0,0.0001932,0.0,6.44e-05,0.0,9.66e-05,1.0,0.0001932,0.0,0.000249872,1.0,0.00323
mmlu-elementary-mathematics.val.239,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
arc-challenge.test.164,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mmlu-high-school-chemistry.val.81,mistralai/mixtral-8x7b-chat,1.0,8.58e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
hellaswag.val.6174,mistralai/mistral-7b-chat,0.0,4.7600000000000005e-05,0.0,4.7600000000000005e-05,0.0,7.14e-05,0.0,0.0001428,0.0,0.000184688,0.0,0.00242
grade-school-math.dev.4642,meta/code-llama-instruct-34b-chat,0.25,0.000316608,0.5,7.88e-05,0.75,0.0001296,0.75,0.0001914,0.25,0.000316608,0.5,0.0059
abstract2title.test.171,mistralai/mixtral-8x7b-chat,1.0,0.0001962,1.0,6.0200000000000006e-05,1.0,9.51e-05,1.0,0.0001962,1.0,0.000235904,1.0,0.00353
mmlu-econometrics.val.38,mistralai/mixtral-8x7b-chat,1.0,7.2e-05,0.0,2.4e-05,0.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-clinical-knowledge.val.151,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-sociology.val.173,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
mmlu-high-school-macroeconomics.val.293,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.9610,mistralai/mistral-7b-chat,0.0,5.24e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
hellaswag.val.4579,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.479999999999999e-05,0.0,0.0001302,0.0,0.0001683919999999,0.0,0.00221
mmlu-professional-law.val.736,WizardLM/WizardLM-13B-V1.2,0.0,9.69e-05,1.0,6.46e-05,0.0,9.69e-05,1.0,0.0001938,0.0,0.000250648,0.0,0.00324
winogrande.dev.752,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.59e-05,1.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
mmlu-medical-genetics.val.61,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-high-school-mathematics.val.25,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-moral-scenarios.val.756,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
hellaswag.val.1341,mistralai/mixtral-8x7b-chat,1.0,0.0001127999999999,0.0,3.7600000000000006e-05,1.0,5.64e-05,1.0,0.0001127999999999,0.0,0.000145888,1.0,0.00189
hellaswag.val.855,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,0.0,0.0015
grade-school-math.dev.1086,mistralai/mixtral-8x7b-chat,0.75,0.0002298,0.5,7.56e-05,0.75,0.0001409999999999,0.75,0.0002298,0.75,0.000293328,0.75,0.0075899999999999
hellaswag.val.6294,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
mmlu-conceptual-physics.val.218,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
mbpp.dev.290,mistralai/mistral-7b-chat,0.0,5.080000000000001e-05,0.0,5.080000000000001e-05,0.0,0.0002813999999999,0.0,0.000369,0.0,0.000107088,1.0,0.01076
mmlu-jurisprudence.val.83,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
grade-school-math.dev.2814,WizardLM/WizardLM-13B-V1.2,0.5,0.0001737,0.75,8.22e-05,0.5,0.0001737,0.25,0.0003792,0.25,0.000389552,0.5,0.0094
mmlu-security-studies.val.142,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
mmlu-professional-law.val.1333,WizardLM/WizardLM-13B-V1.2,1.0,8.97e-05,1.0,5.980000000000001e-05,1.0,8.97e-05,1.0,0.0001794,0.0,0.000232024,1.0,0.003
hellaswag.val.3110,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
grade-school-math.dev.1701,WizardLM/WizardLM-13B-V1.2,0.5,0.0001677,0.25,8.86e-05,0.5,0.0001677,0.5,0.0002357999999999,0.5,0.000320488,0.5,0.00634
mmlu-high-school-macroeconomics.val.36,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,0.0,0.00116
grade-school-math.dev.6729,WizardLM/WizardLM-13B-V1.2,0.5,0.0001304999999999,0.75,9.34e-05,0.5,0.0001304999999999,0.75,0.0002615999999999,0.75,0.000331352,0.75,0.006
hellaswag.val.3854,mistralai/mixtral-8x7b-chat,1.0,0.0001758,1.0,5.860000000000001e-05,1.0,8.79e-05,1.0,0.0001758,1.0,0.0002273679999999,1.0,0.00297
arc-challenge.test.1140,mistralai/mistral-7b-chat,1.0,2.12e-05,1.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,1.0,8.2256e-05,1.0,0.00107
mmlu-professional-law.val.1039,WizardLM/WizardLM-13B-V1.2,1.0,7.769999999999999e-05,1.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,1.0,0.0001547999999999,0.0,0.000200984,1.0,0.0026
hellaswag.val.941,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,1.0,4.17e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
hellaswag.val.278,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.4580,WizardLM/WizardLM-13B-V1.2,0.25,0.0002205,0.25,0.0005468,0.25,0.0002205,0.25,0.0003348,0.25,0.000307296,0.75,0.01582
grade-school-math.dev.2376,mistralai/mistral-7b-chat,0.25,9.36e-05,0.25,9.36e-05,0.75,0.0001743,0.25,0.0002544,0.25,0.0003298,0.75,0.00736
grade-school-math.dev.981,mistralai/mixtral-8x7b-chat,0.75,0.0002796,0.5,0.0001018,0.75,0.0001857,0.75,0.0002796,0.75,0.000359288,0.75,0.00996
mmlu-professional-law.val.383,WizardLM/WizardLM-13B-V1.2,0.0,0.0001101,0.0,7.34e-05,0.0,0.0001101,1.0,0.0002202,0.0,0.000284792,0.0,0.00368
mmlu-moral-scenarios.val.674,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-international-law.val.27,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
hellaswag.val.1667,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-prehistory.val.153,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
arc-challenge.test.64,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00079
hellaswag.val.5829,mistralai/mixtral-8x7b-chat,0.0,0.000177,0.0,5.9e-05,0.0,8.85e-05,0.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
hellaswag.val.2798,WizardLM/WizardLM-13B-V1.2,1.0,3.78e-05,0.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
grade-school-math.dev.1185,mistralai/mistral-7b-chat,0.75,8.6e-05,0.75,8.6e-05,0.75,0.0001536,0.75,0.0002646,0.25,0.000258408,0.75,0.00697
mbpp.dev.361,mistralai/mistral-7b-chat,0.0,4.4800000000000005e-05,0.0,4.4800000000000005e-05,0.0,9.27e-05,1.0,0.000159,0.0,0.00024056,0.0,0.01534
mmlu-professional-law.val.1294,WizardLM/WizardLM-13B-V1.2,1.0,0.0001241999999999,0.0,8.280000000000001e-05,1.0,0.0001241999999999,0.0,0.0002483999999999,0.0,0.000321264,1.0,0.00415
mmlu-professional-law.val.359,WizardLM/WizardLM-13B-V1.2,0.0,0.000174,1.0,0.000116,0.0,0.000174,1.0,0.000348,0.0,0.00045008,1.0,0.00581
mmlu-anatomy.val.75,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
arc-challenge.val.192,mistralai/mixtral-8x7b-chat,1.0,3.9e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
mmlu-high-school-mathematics.val.133,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-high-school-microeconomics.val.137,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-professional-law.val.1236,WizardLM/WizardLM-13B-V1.2,1.0,0.0001302,0.0,8.68e-05,1.0,0.0001302,0.0,0.0002604,0.0,0.000336784,0.0,0.00438
mmlu-professional-law.val.1394,WizardLM/WizardLM-13B-V1.2,0.0,0.0001044,1.0,6.96e-05,0.0,0.0001044,0.0,0.0002088,0.0,0.0002700479999999,0.0,0.00349
mmlu-sociology.val.196,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,1.0,3.18e-05,0.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mbpp.dev.69,mistralai/mistral-7b-chat,1.0,3.98e-05,1.0,3.98e-05,0.0,7.17e-05,0.0,0.0001494,0.0,0.000180808,0.0,0.01142
hellaswag.val.9805,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
hellaswag.val.8395,mistralai/mixtral-8x7b-chat,1.0,0.0001716,1.0,5.720000000000001e-05,1.0,8.58e-05,1.0,0.0001716,1.0,0.000221936,1.0,0.00287
hellaswag.val.4179,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.4322,WizardLM/WizardLM-13B-V1.2,0.75,0.0001427999999999,0.75,9.98e-05,0.75,0.0001427999999999,0.75,0.0002663999999999,0.75,0.000381792,0.75,0.0089699999999999
grade-school-math.dev.5158,mistralai/mixtral-8x7b-chat,0.25,0.0002351999999999,0.25,9.04e-05,0.25,0.0001656,0.25,0.0002351999999999,0.25,0.000326696,0.75,0.0088899999999999
mmlu-moral-disputes.val.305,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
grade-school-math.dev.6826,mistralai/mixtral-8x7b-chat,0.25,0.0002772,0.75,9.22e-05,0.75,0.0001758,0.25,0.0002772,0.25,0.000439216,0.5,0.00911
mmlu-global-facts.val.7,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,0.0,0.0012
mmlu-high-school-chemistry.val.119,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
grade-school-math.dev.3955,WizardLM/WizardLM-13B-V1.2,0.5,0.0001707,0.25,9.18e-05,0.5,0.0001707,0.75,0.0001986,0.75,0.000339888,0.75,0.00723
grade-school-math.dev.2159,WizardLM/WizardLM-13B-V1.2,0.25,0.0001376999999999,0.25,5.92e-05,0.25,0.0001376999999999,0.25,0.0002261999999999,0.75,0.000237456,0.75,0.0058
grade-school-math.dev.6341,WizardLM/WizardLM-13B-V1.2,0.25,0.0001494,0.25,9.3e-05,0.25,0.0001494,0.25,0.0002885999999999,0.25,0.000387224,0.5,0.00845
bias_detection.dev.161,mistralai/mistral-7b-chat,0.0,5.5400000000000005e-05,0.0,5.5400000000000005e-05,1.0,9.749999999999998e-05,1.0,0.0001925999999999,0.0,0.0002374559999999,1.0,0.00875
grade-school-math.dev.6422,WizardLM/WizardLM-13B-V1.2,0.75,0.0001389,0.5,7.740000000000001e-05,0.75,0.0001389,0.25,0.0002244,0.75,0.0003298,0.5,0.00642
mmlu-college-mathematics.val.64,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
grade-school-math.dev.4237,mistralai/mistral-7b-chat,0.25,9.06e-05,0.25,9.06e-05,0.25,0.0001449,0.25,0.0002724,0.25,0.000319712,0.75,0.00864
hellaswag.val.5962,mistralai/mistral-7b-chat,0.0,5.720000000000001e-05,0.0,5.720000000000001e-05,0.0,8.58e-05,0.0,0.0001716,0.0,0.000221936,1.0,0.0029
hellaswag.val.1567,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
grade-school-math.dev.2638,meta/code-llama-instruct-34b-chat,0.25,0.0002134,0.25,9.54e-05,0.75,0.0001449,0.25,0.0002399999999999,0.25,0.0002134,0.75,0.0077
mmlu-philosophy.val.101,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
hellaswag.val.9350,mistralai/mixtral-8x7b-chat,1.0,0.0001578,1.0,5.260000000000001e-05,1.0,7.89e-05,1.0,0.0001578,1.0,0.000204088,1.0,0.00267
hellaswag.val.9243,mistralai/mistral-7b-chat,1.0,5.080000000000001e-05,1.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,1.0,0.0001971039999999,1.0,0.00255
mmlu-high-school-macroeconomics.val.239,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-law.val.557,mistralai/mistral-7b-chat,0.0,6.539999999999999e-05,0.0,6.539999999999999e-05,0.0,9.81e-05,0.0,0.0001962,0.0,0.000253752,1.0,0.00328
hellaswag.val.5641,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.2e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00242
grade-school-math.dev.24,WizardLM/WizardLM-13B-V1.2,0.25,0.0001487999999999,0.5,7.780000000000001e-05,0.25,0.0001487999999999,0.5,0.0002148,0.5,0.000285568,0.75,0.00616
mmlu-professional-law.val.349,mistralai/mistral-7b-chat,0.0,6.659999999999999e-05,0.0,6.659999999999999e-05,0.0,9.99e-05,0.0,0.0001998,0.0,0.0002584079999999,0.0,0.00334
mmlu-abstract-algebra.val.60,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
mmlu-high-school-macroeconomics.val.35,mistralai/mistral-7b-chat,1.0,1.54e-05,1.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-professional-law.val.158,WizardLM/WizardLM-13B-V1.2,0.0,0.0001064999999999,1.0,7.1e-05,0.0,0.0001064999999999,0.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
arc-challenge.test.965,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,1.0,6.984e-05,1.0,0.00094
mmlu-professional-law.val.1078,WizardLM/WizardLM-13B-V1.2,1.0,0.0001371,0.0,9.14e-05,1.0,0.0001371,1.0,0.0002742,0.0,0.0003546319999999,1.0,0.00458
hellaswag.val.8000,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-human-sexuality.val.84,mistralai/mistral-7b-chat,1.0,2.36e-05,1.0,2.36e-05,1.0,3.51e-05,0.0,7.08e-05,0.0,9.1568e-05,0.0,0.00119
mmlu-nutrition.val.208,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
mmlu-professional-medicine.val.266,mistralai/mixtral-8x7b-chat,1.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00236
mmlu-college-physics.val.93,mistralai/mixtral-8x7b-chat,0.0,7.92e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,0.0,0.0013599999999999
hellaswag.val.9020,mistralai/mixtral-8x7b-chat,1.0,0.0001806,0.0,6.0200000000000006e-05,0.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00305
grade-school-math.dev.7207,WizardLM/WizardLM-13B-V1.2,0.25,0.0001373999999999,0.25,6.840000000000001e-05,0.25,0.0001373999999999,0.25,0.000195,0.25,0.000245216,0.5,0.00645
mmlu-moral-disputes.val.67,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,0.0,0.0009
mmlu-moral-scenarios.val.426,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
grade-school-math.dev.1017,mistralai/mixtral-8x7b-chat,0.5,0.0002507999999999,0.25,7.18e-05,0.75,0.0001449,0.5,0.0002507999999999,0.5,0.0002716,0.5,0.00768
mmlu-high-school-european-history.val.5,mistralai/mixtral-8x7b-chat,1.0,0.000306,1.0,0.0001022,0.0,0.0001532999999999,1.0,0.000306,0.0,0.000396536,1.0,0.0051199999999999
hellaswag.val.2437,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.3900000000000004e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
grade-school-math.dev.147,mistralai/mixtral-8x7b-chat,0.75,0.0001992,0.25,5.7e-05,0.75,0.0001347,0.75,0.0001992,0.75,0.000277808,0.75,0.0051699999999999
hellaswag.val.8999,WizardLM/WizardLM-13B-V1.2,0.0,7.8e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,0.0,0.00264
mmlu-global-facts.val.64,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,0.0,0.0012
mmlu-high-school-european-history.val.163,mistralai/mixtral-8x7b-chat,1.0,0.0001536,0.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,0.0,0.000198656,1.0,0.00257
mmlu-high-school-chemistry.val.82,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,0.0,0.00229
mmlu-high-school-macroeconomics.val.110,mistralai/mistral-7b-chat,1.0,2.12e-05,1.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.0010999999999999
mmlu-nutrition.val.36,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.5757,mistralai/mixtral-8x7b-chat,1.0,0.0001422,1.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00241
hellaswag.val.960,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-miscellaneous.val.301,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mbpp.dev.218,mistralai/mixtral-8x7b-chat,0.0,0.0002238,0.0,5.160000000000001e-05,0.0,0.0001242,0.0,0.0002238,0.0,8.536000000000001e-05,0.0,0.01784
hellaswag.val.1525,mistralai/mixtral-8x7b-chat,0.0,6.3e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
mmlu-high-school-biology.val.161,mistralai/mixtral-8x7b-chat,1.0,9.42e-05,0.0,3.1400000000000004e-05,1.0,4.71e-05,1.0,9.42e-05,0.0,0.000121832,1.0,0.00158
hellaswag.val.8200,mistralai/mistral-7b-chat,0.0,4.64e-05,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00233
hellaswag.val.56,WizardLM/WizardLM-13B-V1.2,1.0,3.66e-05,0.0,2.44e-05,1.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.0012599999999999
grade-school-math.dev.2623,meta/code-llama-instruct-34b-chat,0.5,0.000370152,0.25,0.0001038,0.5,0.0002121,0.25,0.0002958,0.5,0.000370152,0.5,0.00815
hellaswag.val.6820,mistralai/mixtral-8x7b-chat,1.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,1.0,0.0001668,0.0,0.000215728,1.0,0.00282
consensus_summary.dev.353,mistralai/mixtral-8x7b-chat,0.75,0.0001752,0.75,6.740000000000001e-05,0.75,9.45e-05,0.75,0.0001752,0.0,0.000239008,0.0,0.00425
grade-school-math.dev.5982,WizardLM/WizardLM-13B-V1.2,0.75,0.0001119,0.25,5.72e-05,0.75,0.0001119,0.75,0.0002952,0.75,0.000266168,0.75,0.00685
hellaswag.val.1211,mistralai/mixtral-8x7b-chat,1.0,7.08e-05,1.0,2.36e-05,0.0,3.51e-05,1.0,7.08e-05,1.0,9.1568e-05,0.0,0.00119
mmlu-professional-law.val.1113,mistralai/mistral-7b-chat,1.0,4.160000000000001e-05,1.0,4.160000000000001e-05,0.0,6.24e-05,1.0,0.0001248,0.0,0.0001614079999999,1.0,0.00209
mmlu-conceptual-physics.val.198,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.77,WizardLM/WizardLM-13B-V1.2,0.0,3.06e-05,0.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00106
mmlu-college-computer-science.val.99,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
hellaswag.val.5978,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
hellaswag.val.906,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
arc-challenge.test.731,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,1.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,1.0,7.604800000000001e-05,1.0,0.00102
mmlu-college-medicine.val.83,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-computer-security.val.97,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-nutrition.val.119,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.1927,WizardLM/WizardLM-13B-V1.2,0.25,0.0002016,0.25,9.44e-05,0.25,0.0002016,0.25,0.0003624,0.25,0.00041128,0.5,0.01402
hellaswag.val.508,mistralai/mistral-7b-chat,1.0,3.320000000000001e-05,1.0,3.320000000000001e-05,1.0,4.98e-05,1.0,9.96e-05,0.0,0.000128816,1.0,0.0017
mmlu-high-school-statistics.val.183,WizardLM/WizardLM-13B-V1.2,1.0,6.96e-05,1.0,4.64e-05,1.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00233
grade-school-math.dev.6045,WizardLM/WizardLM-13B-V1.2,0.5,0.0001383,0.25,7.560000000000001e-05,0.5,0.0001383,0.5,0.0002322,0.25,0.000238232,0.75,0.00694
mmlu-high-school-psychology.val.330,mistralai/mistral-7b-chat,0.0,4.100000000000001e-05,0.0,4.100000000000001e-05,1.0,6.149999999999999e-05,1.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-high-school-us-history.val.180,mistralai/mixtral-8x7b-chat,1.0,0.0001248,0.0,4.160000000000001e-05,1.0,6.24e-05,1.0,0.0001248,0.0,0.0001614079999999,1.0,0.00209
mbpp.dev.88,mistralai/mistral-7b-chat,1.0,3.84e-05,1.0,3.84e-05,1.0,8.01e-05,1.0,0.0001836,1.0,0.000234352,1.0,0.00994
mmlu-moral-scenarios.val.326,mistralai/mistral-7b-chat,0.0,3.04e-05,0.0,3.04e-05,0.0,4.56e-05,0.0,9.12e-05,0.0,0.000117952,1.0,0.00156
mmlu-prehistory.val.220,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-psychology.val.175,mistralai/mixtral-8x7b-chat,0.0,5.8200000000000005e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
grade-school-math.dev.4845,WizardLM/WizardLM-13B-V1.2,0.25,0.0001851,0.25,0.0001121999999999,0.25,0.0001851,0.75,0.0002526,0.5,0.000338336,0.75,0.01105
mmlu-high-school-psychology.val.501,mistralai/mistral-7b-chat,1.0,1.64e-05,1.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
mmlu-abstract-algebra.val.77,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-high-school-physics.val.67,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
grade-school-math.dev.5394,mistralai/mixtral-8x7b-chat,0.75,0.0002351999999999,0.75,6.02e-05,0.75,0.0001251,0.75,0.0002351999999999,0.75,0.000258408,0.75,0.00618
mmlu-professional-law.val.657,WizardLM/WizardLM-13B-V1.2,0.0,0.0001032,0.0,6.88e-05,0.0,0.0001032,0.0,0.0002064,0.0,0.0002669439999999,1.0,0.00345
mmlu-professional-law.val.1414,WizardLM/WizardLM-13B-V1.2,1.0,0.0001119,0.0,7.46e-05,1.0,0.0001119,1.0,0.0002238,0.0,0.000289448,1.0,0.00374
mmlu-moral-scenarios.val.893,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,1.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-medical-genetics.val.60,mistralai/mixtral-8x7b-chat,1.0,6.3e-05,0.0,2.1e-05,0.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-us-foreign-policy.val.60,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
hellaswag.val.6612,mistralai/mixtral-8x7b-chat,1.0,0.0001698,0.0,5.660000000000001e-05,0.0,8.49e-05,1.0,0.0001698,0.0,0.000219608,1.0,0.00287
hellaswag.val.728,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-us-foreign-policy.val.64,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.7344,mistralai/mixtral-8x7b-chat,1.0,0.0001632,1.0,5.44e-05,1.0,8.16e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00276
arc-challenge.test.97,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.9586,mistralai/mixtral-8x7b-chat,0.0,0.0001272,0.0,4.24e-05,0.0,6.36e-05,0.0,0.0001272,0.0,0.0001645119999999,1.0,0.00213
hellaswag.val.5768,mistralai/mixtral-8x7b-chat,0.0,0.0001296,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,1.0,0.0022
mmlu-professional-law.val.87,mistralai/mistral-7b-chat,0.0,5.220000000000001e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,0.0,0.00262
mmlu-professional-law.val.1326,mistralai/mistral-7b-chat,0.0,5.520000000000001e-05,0.0,5.520000000000001e-05,1.0,8.280000000000001e-05,1.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
hellaswag.val.464,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,0.0,0.00086
mmlu-professional-law.val.1026,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,1.0,7.92e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00265
grade-school-math.dev.1890,WizardLM/WizardLM-13B-V1.2,0.75,0.0001947,0.25,0.0001022,0.75,0.0001947,0.5,0.0003059999999999,0.75,0.000409728,0.5,0.01154
mmlu-moral-scenarios.val.562,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,0.0,0.00149
hellaswag.val.202,WizardLM/WizardLM-13B-V1.2,0.0,4.29e-05,0.0,2.88e-05,0.0,4.29e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00148
grade-school-math.dev.6462,mistralai/mistral-7b-chat,0.5,7.000000000000001e-05,0.5,7.000000000000001e-05,0.75,0.0001326,0.75,0.0002214,0.25,0.000295656,0.75,0.00665
grade-school-math.dev.6960,WizardLM/WizardLM-13B-V1.2,0.75,0.0001730999999999,0.25,0.0001016,0.75,0.0001730999999999,0.75,0.0002742,0.25,0.000321264,0.25,0.0083
hellaswag.val.9726,mistralai/mixtral-8x7b-chat,0.0,0.000177,0.0,5.9e-05,0.0,8.85e-05,0.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
mmlu-professional-law.val.549,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,1.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-professional-law.val.1395,WizardLM/WizardLM-13B-V1.2,0.0,5.91e-05,1.0,3.94e-05,0.0,5.91e-05,0.0,0.0001182,0.0,0.0001528719999999,1.0,0.00201
mmlu-miscellaneous.val.435,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-public-relations.val.68,mistralai/mistral-7b-chat,1.0,1.82e-05,1.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
mmlu-moral-scenarios.val.828,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-astronomy.val.93,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
grade-school-math.dev.3070,mistralai/mistral-7b-chat,0.25,9.56e-05,0.25,9.56e-05,0.5,0.000159,0.25,0.000261,0.5,0.00034532,0.75,0.00814
mmlu-sociology.val.179,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-high-school-mathematics.val.180,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00121
hellaswag.val.2749,WizardLM/WizardLM-13B-V1.2,0.0,3.27e-05,1.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,1.0,8.4584e-05,1.0,0.0011
grade-school-math.dev.1910,mistralai/mistral-7b-chat,0.5,7.98e-05,0.5,7.98e-05,0.25,0.000198,0.25,0.0002885999999999,0.25,0.00039964,0.5,0.01127
winogrande.dev.972,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,1.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.00058
mmlu-miscellaneous.val.775,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
hellaswag.val.5452,mistralai/mixtral-8x7b-chat,1.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
mmlu-prehistory.val.69,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-prehistory.val.239,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-high-school-chemistry.val.59,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,1.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
grade-school-math.dev.2593,mistralai/mixtral-8x7b-chat,0.5,0.0002508,0.25,6.840000000000001e-05,0.75,0.0001293,0.5,0.0002508,1.0,0.000263064,0.75,0.0062299999999999
mmlu-high-school-statistics.val.80,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
hellaswag.val.9261,mistralai/mixtral-8x7b-chat,0.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
grade-school-math.dev.5686,mistralai/mistral-7b-chat,0.75,7.1e-05,0.75,7.1e-05,0.75,0.0001487999999999,0.75,0.0002651999999999,0.5,0.000293328,0.75,0.00618
mmlu-moral-disputes.val.140,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.7819,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
hellaswag.val.4167,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-moral-disputes.val.290,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-business-ethics.val.97,mistralai/mistral-7b-chat,1.0,3.1400000000000004e-05,1.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
grade-school-math.dev.3911,WizardLM/WizardLM-13B-V1.2,0.75,0.000156,0.75,9.84e-05,0.75,0.000156,0.75,0.0002885999999999,0.25,0.000328248,0.75,0.00869
grade-school-math.dev.6002,WizardLM/WizardLM-13B-V1.2,0.25,0.0001413,0.25,9.24e-05,0.25,0.0001413,0.5,0.0003048,0.25,0.0003429919999999,0.75,0.01066
mmlu-high-school-macroeconomics.val.140,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.00133
hellaswag.val.9952,mistralai/mistral-7b-chat,0.0,5.62e-05,0.0,5.62e-05,0.0,8.4e-05,0.0,0.0001686,0.0,0.000218056,0.0,0.00285
hellaswag.val.3472,mistralai/mistral-7b-chat,0.0,4.6200000000000005e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00232
hellaswag.val.3053,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-electrical-engineering.val.103,mistralai/mixtral-8x7b-chat,0.0,4.38e-05,0.0,1.46e-05,0.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,0.0,0.00077
hellaswag.val.8022,WizardLM/WizardLM-13B-V1.2,1.0,7.2e-05,1.0,4.8200000000000006e-05,1.0,7.2e-05,1.0,0.0001446,1.0,0.000187016,1.0,0.00242
mmlu-moral-scenarios.val.779,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,0.0,0.00138
winogrande.dev.842,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
hellaswag.val.4707,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,0.0,0.00275
hellaswag.val.6699,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00281
grade-school-math.dev.1843,WizardLM/WizardLM-13B-V1.2,0.75,0.0001541999999999,0.25,7.76e-05,0.75,0.0001541999999999,0.75,0.0002214,0.75,0.000280912,0.75,0.00588
mmlu-high-school-macroeconomics.val.46,mistralai/mixtral-8x7b-chat,0.0,4.92e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
hellaswag.val.4323,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
hellaswag.val.5658,mistralai/mixtral-8x7b-chat,1.0,0.0001362,1.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,1.0,0.0001761519999999,1.0,0.00231
hellaswag.val.5407,mistralai/mistral-7b-chat,0.0,6.22e-05,0.0,6.22e-05,0.0,9.3e-05,0.0,0.0001866,0.0,0.000241336,1.0,0.00312
mmlu-professional-law.val.1460,WizardLM/WizardLM-13B-V1.2,0.0,0.0001119,0.0,7.46e-05,0.0,0.0001119,1.0,0.0002238,0.0,0.000289448,1.0,0.00374
grade-school-math.dev.3548,WizardLM/WizardLM-13B-V1.2,0.75,0.0001902,0.25,0.00011,0.75,0.0001902,0.5,0.0002885999999999,0.25,0.000417488,0.75,0.00897
hellaswag.val.6632,mistralai/mixtral-8x7b-chat,1.0,0.0001674,1.0,5.580000000000001e-05,1.0,8.37e-05,1.0,0.0001674,1.0,0.0002165039999999,1.0,0.0028
bias_detection.dev.229,mistralai/mistral-7b-chat,0.0,6.32e-05,0.0,6.32e-05,0.0,9.9e-05,0.0,0.0001775999999999,0.0,0.000250648,0.0,0.00951
grade-school-math.dev.4972,mistralai/mistral-7b-chat,0.25,8.6e-05,0.25,8.6e-05,0.75,0.0001635,0.25,0.0002646,0.25,0.000245992,0.75,0.00757
mmlu-conceptual-physics.val.81,mistralai/mixtral-8x7b-chat,0.0,7.02e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00118
mmlu-miscellaneous.val.762,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
grade-school-math.dev.33,mistralai/mistral-7b-chat,0.75,8.180000000000001e-05,0.75,8.180000000000001e-05,1.0,0.0001437,0.25,0.000309,0.5,0.000339112,0.75,0.01037
winogrande.dev.48,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,0.0,1.56e-05,0.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
mmlu-moral-disputes.val.55,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.5538,mistralai/mixtral-8x7b-chat,0.0,0.0001686,0.0,5.62e-05,0.0,8.43e-05,0.0,0.0001686,0.0,0.000218056,1.0,0.00282
mmlu-nutrition.val.29,mistralai/mixtral-8x7b-chat,0.0,7.68e-05,1.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
grade-school-math.dev.3168,WizardLM/WizardLM-13B-V1.2,0.75,0.0001422,0.25,6.0200000000000006e-05,0.75,0.0001422,0.25,0.0002267999999999,0.25,0.0002909999999999,0.5,0.00681
grade-school-math.dev.707,mistralai/mistral-7b-chat,0.5,7.32e-05,0.5,7.32e-05,0.75,0.000117,0.75,0.0003186,0.25,0.000249872,0.5,0.0062699999999999
mmlu-medical-genetics.val.38,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-high-school-macroeconomics.val.369,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,0.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
hellaswag.val.8256,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
hellaswag.val.7502,WizardLM/WizardLM-13B-V1.2,0.0,9.33e-05,0.0,6.24e-05,0.0,9.33e-05,0.0,0.0001872,0.0,0.000242112,1.0,0.00313
hellaswag.val.6336,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00246
grade-school-math.dev.5006,WizardLM/WizardLM-13B-V1.2,0.75,0.0001281,0.25,7.82e-05,0.75,0.0001281,0.75,0.0001962,0.75,0.000290224,0.75,0.00586
hellaswag.val.8956,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,1.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
hellaswag.val.1374,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-management.val.74,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
arc-challenge.test.59,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00082
grade-school-math.dev.5339,WizardLM/WizardLM-13B-V1.2,0.75,0.0001974,0.25,0.0001152,0.75,0.0001974,0.75,0.0002753999999999,0.25,0.000460168,0.75,0.0117299999999999
hellaswag.val.4753,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,0.0,7.739999999999998e-05,0.0,0.0001553999999999,0.0,0.000200984,0.0,0.0026
mmlu-prehistory.val.0,mistralai/mixtral-8x7b-chat,0.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
mmlu-professional-law.val.888,mistralai/mistral-7b-chat,1.0,3.4200000000000005e-05,1.0,3.4200000000000005e-05,0.0,5.13e-05,1.0,0.0001026,0.0,0.000132696,0.0,0.00175
arc-challenge.test.25,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,1.0,6.5184e-05,1.0,0.00088
mmlu-professional-law.val.822,WizardLM/WizardLM-13B-V1.2,0.0,9.9e-05,0.0,6.6e-05,0.0,9.9e-05,1.0,0.000198,0.0,0.00025608,1.0,0.00331
grade-school-math.dev.6989,mistralai/mistral-7b-chat,0.75,8.32e-05,0.75,8.32e-05,0.5,0.0001467,0.75,0.0002417999999999,0.75,0.00025608,0.5,0.00553
mmlu-miscellaneous.val.61,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-professional-law.val.430,WizardLM/WizardLM-13B-V1.2,0.0,7.049999999999999e-05,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
mmlu-high-school-us-history.val.82,WizardLM/WizardLM-13B-V1.2,0.0,9.45e-05,0.0,6.3e-05,0.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
grade-school-math.dev.1903,WizardLM/WizardLM-13B-V1.2,0.5,0.0001581,0.25,8.400000000000001e-05,0.5,0.0001581,0.75,0.0002441999999999,0.25,0.000360064,0.5,0.00959
mmlu-computer-security.val.52,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
grade-school-math.dev.1633,mistralai/mistral-7b-chat,0.25,8.980000000000001e-05,0.25,8.980000000000001e-05,0.75,0.000156,0.75,0.0002567999999999,0.75,0.000282464,0.75,0.00832
hellaswag.val.5895,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.289999999999998e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00245
arc-challenge.test.271,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,1.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.6279,mistralai/mistral-7b-chat,0.75,9.36e-05,0.75,9.36e-05,0.75,0.0001758,0.75,0.0002652,0.5,0.000321264,0.5,0.00712
grade-school-math.dev.794,mistralai/mistral-7b-chat,0.25,9.86e-05,0.25,9.86e-05,0.75,0.0001731,0.5,0.000285,0.25,0.000412056,0.75,0.00855
arc-challenge.test.1169,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
hellaswag.val.5419,mistralai/mixtral-8x7b-chat,1.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,1.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
mmlu-moral-scenarios.val.244,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00138
grade-school-math.dev.3192,mistralai/mixtral-8x7b-chat,0.25,0.0002238,0.75,8.840000000000001e-05,0.75,0.0001395,0.25,0.0002238,0.75,0.000308848,0.75,0.00735
mmlu-professional-law.val.1197,WizardLM/WizardLM-13B-V1.2,0.0,8.43e-05,1.0,5.62e-05,0.0,8.43e-05,1.0,0.0001686,0.0,0.000218056,1.0,0.00282
mbpp.dev.329,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.649999999999999e-05,0.0,0.0002993999999999,1.0,0.0002095199999999,0.0,0.0091799999999999
arc-challenge.test.916,mistralai/mistral-7b-chat,1.0,2.34e-05,1.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,1.0,9.0792e-05,1.0,0.00121
bias_detection.dev.138,mistralai/mistral-7b-chat,0.0,5.900000000000001e-05,0.0,5.900000000000001e-05,1.0,9.749999999999998e-05,0.0,0.0002171999999999,0.0,0.0002522,0.0,0.00552
mmlu-clinical-knowledge.val.113,mistralai/mixtral-8x7b-chat,0.0,5.64e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
hellaswag.val.6754,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-miscellaneous.val.73,mistralai/mixtral-8x7b-chat,1.0,4.08e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-electrical-engineering.val.72,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-high-school-macroeconomics.val.241,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-high-school-biology.val.278,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-astronomy.val.19,mistralai/mixtral-8x7b-chat,1.0,7.68e-05,0.0,2.56e-05,0.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-high-school-geography.val.180,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
arc-challenge.test.289,mistralai/mistral-7b-chat,0.0,1.26e-05,0.0,1.26e-05,0.0,1.89e-05,1.0,3.78e-05,0.0,4.8888e-05,1.0,0.0006399999999999
hellaswag.val.2448,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
grade-school-math.dev.6617,WizardLM/WizardLM-13B-V1.2,0.75,0.0001529999999999,0.75,9.08e-05,0.75,0.0001529999999999,0.75,0.0002219999999999,0.75,0.00029876,0.75,0.00631
mmlu-high-school-macroeconomics.val.109,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-professional-law.val.981,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,0.0,0.000226592,1.0,0.00293
mmlu-professional-law.val.1469,WizardLM/WizardLM-13B-V1.2,0.0,6.3e-05,0.0,4.2e-05,0.0,6.3e-05,0.0,0.000126,0.0,0.00016296,0.0,0.00214
grade-school-math.dev.3150,WizardLM/WizardLM-13B-V1.2,0.75,0.0001557,0.25,8.82e-05,0.75,0.0001557,0.25,0.0002676,0.25,0.00028712,0.5,0.00651
hellaswag.val.1988,WizardLM/WizardLM-13B-V1.2,0.0,3.48e-05,1.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,1.0,9.0016e-05,1.0,0.00117
grade-school-math.dev.7080,WizardLM/WizardLM-13B-V1.2,0.25,0.000168,0.25,9.06e-05,0.25,0.000168,0.5,0.000237,0.75,0.00040352,0.75,0.0085399999999999
mmlu-clinical-knowledge.val.11,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-macroeconomics.val.54,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,1.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
grade-school-math.dev.5027,WizardLM/WizardLM-13B-V1.2,0.75,0.0001725,0.25,9.12e-05,0.75,0.0001725,0.75,0.0002826,0.75,0.000429904,0.75,0.00979
arc-challenge.test.1078,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.2657,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,0.0,0.00093
mmlu-professional-law.val.76,WizardLM/WizardLM-13B-V1.2,0.0,5.91e-05,1.0,3.94e-05,0.0,5.91e-05,0.0,0.0001182,0.0,0.0001528719999999,1.0,0.00198
mmlu-clinical-knowledge.val.28,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
mmlu-moral-scenarios.val.523,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.1292,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
hellaswag.val.5423,mistralai/mixtral-8x7b-chat,1.0,0.000159,1.0,5.300000000000001e-05,1.0,7.95e-05,1.0,0.000159,1.0,0.00020564,1.0,0.00269
hellaswag.val.196,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
grade-school-math.dev.3386,mistralai/mistral-7b-chat,0.25,0.0001022,0.25,0.0001022,0.25,0.0001521,0.25,0.0003474,0.25,0.000342216,0.75,0.0066599999999999
mmlu-moral-scenarios.val.586,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00146
hellaswag.val.3038,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,1.0,2.79e-05,1.0,5.64e-05,0.0,7.2944e-05,0.0,0.00098
mmlu-econometrics.val.45,WizardLM/WizardLM-13B-V1.2,0.0,4.29e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
mmlu-nutrition.val.187,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-professional-law.val.1222,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,0.0,0.00232
hellaswag.val.6701,mistralai/mixtral-8x7b-chat,0.0,0.0001656,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.0028
hellaswag.val.9462,WizardLM/WizardLM-13B-V1.2,1.0,8.94e-05,1.0,5.9600000000000005e-05,1.0,8.94e-05,1.0,0.0001788,1.0,0.0002312479999999,1.0,0.00299
mmlu-professional-law.val.506,WizardLM/WizardLM-13B-V1.2,0.0,0.0001014,1.0,6.76e-05,0.0,0.0001014,0.0,0.0002028,0.0,0.0002622879999999,0.0,0.00339
mmlu-us-foreign-policy.val.58,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.455,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-high-school-world-history.val.87,mistralai/mixtral-8x7b-chat,1.0,0.0002333999999999,0.0,7.780000000000001e-05,1.0,0.0001166999999999,1.0,0.0002333999999999,0.0,0.000301864,1.0,0.0039
grade-school-math.dev.4749,mistralai/mistral-7b-chat,0.25,8.7e-05,0.25,8.7e-05,0.25,0.0001172999999999,0.75,0.0002472,0.5,0.000315832,0.75,0.00762
arc-challenge.test.466,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-human-aging.val.142,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
grade-school-math.dev.2874,WizardLM/WizardLM-13B-V1.2,0.25,0.000141,0.25,8.88e-05,0.25,0.000141,0.75,0.0002766,0.25,0.000353856,0.75,0.00878
mmlu-miscellaneous.val.765,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
hellaswag.val.8228,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.7e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
mmlu-anatomy.val.69,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
grade-school-math.dev.4976,mistralai/mistral-7b-chat,0.25,9.26e-05,0.25,9.26e-05,0.25,0.000156,0.25,0.0002741999999999,0.25,0.000340664,0.75,0.00996
winogrande.dev.480,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.7248e-05,0.0,0.0005
mmlu-abstract-algebra.val.58,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00096
winogrande.dev.1010,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,1.0,1.5e-05,1.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00051
mmlu-logical-fallacies.val.51,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-high-school-mathematics.val.134,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00129
hellaswag.val.335,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-international-law.val.59,mistralai/mixtral-8x7b-chat,1.0,9e-05,0.0,3e-05,1.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
hellaswag.val.4867,mistralai/mixtral-8x7b-chat,0.0,0.0001463999999999,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
mmlu-high-school-macroeconomics.val.144,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-jurisprudence.val.49,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.678,WizardLM/WizardLM-13B-V1.2,0.75,0.0001725,0.75,8.82e-05,0.75,0.0001725,0.75,0.0002826,0.25,0.000369376,0.75,0.00855
mmlu-professional-accounting.val.244,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
consensus_summary.dev.110,mistralai/mistral-7b-chat,0.75,7.24e-05,0.75,7.24e-05,0.75,0.0001184999999999,0.75,0.0002873999999999,0.75,0.000350752,0.75,0.00688
grade-school-math.dev.315,meta/code-llama-instruct-34b-chat,0.25,0.000353856,0.25,0.0001002,0.25,0.0001397999999999,0.25,0.0002742,0.25,0.000353856,0.25,0.0116899999999999
hellaswag.val.3167,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
hellaswag.val.4667,mistralai/mixtral-8x7b-chat,0.0,0.0001332,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,1.0,0.00223
hellaswag.val.6784,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
abstract2title.test.156,mistralai/mixtral-8x7b-chat,1.0,0.0002304,1.0,7.560000000000001e-05,1.0,0.0001127999999999,1.0,0.0002304,1.0,0.0002902239999999,1.0,0.00431
arc-challenge.test.628,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,0.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-high-school-biology.val.271,mistralai/mistral-7b-chat,1.0,2.74e-05,1.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
grade-school-math.dev.2853,WizardLM/WizardLM-13B-V1.2,0.75,0.0001695,0.75,8.92e-05,0.75,0.0001695,0.25,0.000348,0.5,0.000394984,0.75,0.00804
hellaswag.val.5062,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,0.0,0.00254
grade-school-math.dev.4156,WizardLM/WizardLM-13B-V1.2,0.25,0.0001671,0.25,7.94e-05,0.25,0.0001671,0.25,0.0002525999999999,0.75,0.000377136,0.75,0.01072
grade-school-math.dev.4473,mistralai/mixtral-8x7b-chat,0.25,0.0002508,0.25,0.0001092,0.25,0.0001137,0.25,0.0002508,0.25,0.00031428,0.5,0.01042
winogrande.dev.1148,mistralai/mixtral-8x7b-chat,0.0,3e-05,1.0,1e-05,0.0,1.5e-05,0.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00051
mmlu-professional-law.val.1221,mistralai/mistral-7b-chat,1.0,4.780000000000001e-05,1.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
grade-school-math.dev.6247,mistralai/mistral-7b-chat,0.25,8.960000000000001e-05,0.25,8.960000000000001e-05,0.5,0.0001368,0.75,0.0002394,0.25,0.000264616,0.75,0.00663
grade-school-math.dev.7277,WizardLM/WizardLM-13B-V1.2,0.25,0.0001356,0.25,0.0001066,0.25,0.0001356,0.25,0.0003059999999999,0.25,0.000363168,0.75,0.01028
mmlu-moral-scenarios.val.468,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-marketing.val.179,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
grade-school-math.dev.2297,mistralai/mixtral-8x7b-chat,0.75,0.0002232,0.75,7.88e-05,0.75,0.0001284,0.75,0.0002232,0.25,0.000293328,0.75,0.00635
hellaswag.val.561,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
winogrande.dev.54,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,1.0,4.1128e-05,1.0,0.00057
hellaswag.val.4724,mistralai/mistral-7b-chat,0.0,6.06e-05,0.0,6.06e-05,1.0,9.09e-05,0.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
mmlu-professional-law.val.288,WizardLM/WizardLM-13B-V1.2,1.0,8.61e-05,0.0,5.7400000000000006e-05,1.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,0.0,0.00288
grade-school-math.dev.1688,WizardLM/WizardLM-13B-V1.2,0.5,0.0001376999999999,0.5,8.92e-05,0.5,0.0001376999999999,0.75,0.0002604,0.25,0.0002987599999999,0.5,0.00757
mmlu-professional-law.val.555,WizardLM/WizardLM-13B-V1.2,1.0,8.97e-05,0.0,5.980000000000001e-05,1.0,8.97e-05,0.0,0.0001787999999999,0.0,0.000232024,0.0,0.003
mmlu-college-computer-science.val.61,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-high-school-macroeconomics.val.222,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
grade-school-math.dev.6463,mistralai/mistral-7b-chat,0.25,5.4600000000000006e-05,0.25,5.4600000000000006e-05,0.75,0.0001224,0.25,0.0001889999999999,0.25,0.0002234879999999,0.25,0.00423
mmlu-clinical-knowledge.val.5,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
grade-school-math.dev.1247,mistralai/mistral-7b-chat,0.5,9.08e-05,0.5,9.08e-05,0.75,0.0001701,0.25,0.0002832,0.25,0.000470256,0.75,0.0090899999999999
mmlu-elementary-mathematics.val.329,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.4e-05,0.0,7.0616e-05,0.0,0.0009199999999999
mmlu-professional-law.val.635,WizardLM/WizardLM-13B-V1.2,0.0,8.79e-05,0.0,5.860000000000001e-05,0.0,8.79e-05,1.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
hellaswag.val.7588,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
grade-school-math.dev.2924,meta/code-llama-instruct-34b-chat,0.25,0.00030652,0.75,8.26e-05,0.75,0.0001452,0.75,0.0002352,0.25,0.00030652,0.75,0.00839
hellaswag.val.2223,WizardLM/WizardLM-13B-V1.2,0.0,3.09e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
mmlu-professional-law.val.318,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
hellaswag.val.4411,mistralai/mistral-7b-chat,0.0,4.580000000000001e-05,0.0,4.580000000000001e-05,0.0,6.869999999999999e-05,1.0,0.0001373999999999,0.0,0.000177704,1.0,0.00233
mmlu-professional-accounting.val.161,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00104
grade-school-math.dev.313,meta/code-llama-instruct-34b-chat,0.25,0.000235128,0.75,6.620000000000001e-05,0.5,0.0001389,0.5,0.0001812,0.25,0.000235128,0.75,0.00622
arc-challenge.test.119,mistralai/mixtral-8x7b-chat,1.0,6.12e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.1409,WizardLM/WizardLM-13B-V1.2,0.75,0.0001437,0.75,8.68e-05,0.75,0.0001437,0.75,0.0002274,0.75,0.000311176,0.75,0.00679
grade-school-math.dev.5988,mistralai/mistral-7b-chat,0.75,7.400000000000001e-05,0.75,7.400000000000001e-05,0.25,0.0001721999999999,0.75,0.0002123999999999,0.75,0.00024832,0.75,0.00713
mmlu-nutrition.val.189,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.4228,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.139999999999999e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
hellaswag.val.264,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-philosophy.val.138,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
arc-challenge.val.218,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,1.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-high-school-microeconomics.val.49,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-psychology.val.175,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
grade-school-math.dev.3420,mistralai/mistral-7b-chat,0.25,9.880000000000002e-05,0.25,9.880000000000002e-05,0.75,0.0001431,0.25,0.0002507999999999,0.25,0.00035696,0.75,0.00834
mmlu-professional-law.val.152,WizardLM/WizardLM-13B-V1.2,0.0,7.95e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00266
mmlu-professional-law.val.1454,WizardLM/WizardLM-13B-V1.2,0.0,5.73e-05,0.0,3.820000000000001e-05,0.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,0.0,0.00195
hellaswag.val.3481,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,0.0,0.00266
mmlu-jurisprudence.val.98,mistralai/mixtral-8x7b-chat,0.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-professional-law.val.999,WizardLM/WizardLM-13B-V1.2,0.0,0.0001347,0.0,8.98e-05,0.0,0.0001347,0.0,0.0002694,0.0,0.000348424,0.0,0.0045
mmlu-abstract-algebra.val.64,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.2022,WizardLM/WizardLM-13B-V1.2,0.75,0.000144,0.75,9e-05,0.75,0.000144,0.75,0.0002688,0.75,0.000311952,0.75,0.00592
hellaswag.val.1483,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.6166,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00235
mmlu-high-school-geography.val.146,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-high-school-geography.val.137,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.1811,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.3262,WizardLM/WizardLM-13B-V1.2,0.75,0.0001338,0.25,7.68e-05,0.75,0.0001338,0.5,0.0002189999999999,0.5,0.000259184,0.75,0.00603
hellaswag.val.8456,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
grade-school-math.dev.5409,mistralai/mistral-7b-chat,0.75,6.44e-05,0.75,6.44e-05,0.75,0.0001640999999999,0.25,0.0001962,0.75,0.00026772,0.5,0.0069099999999999
grade-school-math.dev.5659,WizardLM/WizardLM-13B-V1.2,0.5,0.0001494,0.75,9.52e-05,0.5,0.0001494,0.25,0.000276,0.75,0.000362392,0.5,0.0089699999999999
hellaswag.val.7011,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,1.0,5.800000000000001e-05,1.0,8.669999999999998e-05,1.0,0.0001739999999999,1.0,0.00022504,1.0,0.00294
hellaswag.val.7593,mistralai/mixtral-8x7b-chat,1.0,0.0001746,0.0,5.8200000000000005e-05,1.0,8.7e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
grade-school-math.dev.2984,mistralai/mistral-7b-chat,0.75,8.640000000000001e-05,0.75,8.640000000000001e-05,0.75,0.0001191,0.75,0.0002388,0.75,0.000266168,0.75,0.00684
hellaswag.val.4644,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,0.0,0.00236
mmlu-prehistory.val.244,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
grade-school-math.dev.5427,WizardLM/WizardLM-13B-V1.2,0.75,0.0001185,0.75,6.94e-05,0.75,0.0001185,0.75,0.0001944,0.75,0.000277808,0.75,0.00568
mmlu-professional-law.val.632,WizardLM/WizardLM-13B-V1.2,0.0,0.0001605,0.0,0.000107,0.0,0.0001605,0.0,0.000321,0.0,0.00041516,0.0,0.0053599999999999
hellaswag.val.9455,mistralai/mixtral-8x7b-chat,0.0,0.0001314,0.0,4.380000000000001e-05,0.0,6.57e-05,0.0,0.0001314,0.0,0.0001699439999999,1.0,0.0022
grade-school-math.dev.5810,meta/code-llama-instruct-34b-chat,0.25,0.000328248,0.25,8.6e-05,0.75,0.0001551,0.75,0.0002916,0.25,0.000328248,0.5,0.00872
grade-school-math.dev.3107,WizardLM/WizardLM-13B-V1.2,0.25,0.0001491,0.25,9.2e-05,0.25,0.0001491,0.25,0.0002532,0.75,0.000421368,0.5,0.0065699999999999
grade-school-math.dev.2546,WizardLM/WizardLM-13B-V1.2,0.25,0.0001368,0.25,0.0001076,0.25,0.0001368,0.0,0.000207,0.25,0.000389552,0.75,0.01034
hellaswag.val.9330,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
grade-school-math.dev.801,WizardLM/WizardLM-13B-V1.2,0.25,0.0001728,0.25,7.14e-05,0.25,0.0001728,0.75,0.0002345999999999,0.25,0.000313504,0.75,0.00878
winogrande.dev.740,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,1.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,0.0,0.00052
grade-school-math.dev.5826,mistralai/mistral-7b-chat,0.25,8.420000000000001e-05,0.25,8.420000000000001e-05,0.75,0.0001518,0.25,0.0002556,0.25,0.000255304,0.75,0.00784
grade-school-math.dev.4867,WizardLM/WizardLM-13B-V1.2,0.25,0.0001479,0.0,9.48e-05,0.25,0.0001479,0.75,0.0002502,0.75,0.000354632,0.75,0.00845
mmlu-high-school-macroeconomics.val.332,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-high-school-microeconomics.val.171,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
grade-school-math.dev.1398,WizardLM/WizardLM-13B-V1.2,0.75,0.0001335,0.75,7.94e-05,0.75,0.0001335,0.75,0.0002063999999999,0.25,0.000305744,0.75,0.00561
hellaswag.val.2903,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-econometrics.val.4,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.415,mistralai/mistral-7b-chat,0.5,9.94e-05,0.5,9.94e-05,0.75,0.0001458,0.75,0.0002712,0.25,0.000367824,0.75,0.00774
mmlu-high-school-biology.val.105,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.3102,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,0.0,3.03e-05,0.0,6.12e-05,1.0,7.9152e-05,0.0,0.00103
grade-school-math.dev.4183,WizardLM/WizardLM-13B-V1.2,0.75,0.0001725,0.75,0.0001004,0.75,0.0001725,0.0,0.0002232,0.75,0.000331352,0.75,0.0080299999999999
mmlu-professional-accounting.val.229,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-elementary-mathematics.val.4,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
hellaswag.val.6218,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00261
mmlu-professional-law.val.886,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
bias_detection.dev.245,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,0.0,0.0001125,0.0,0.000183,0.0,0.0002522,0.0,0.01279
mmlu-professional-accounting.val.171,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00132
hellaswag.val.5539,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
hellaswag.val.522,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
grade-school-math.dev.922,WizardLM/WizardLM-13B-V1.2,0.25,0.0001905,0.25,0.0001526,0.25,0.0001905,0.5,0.0002742,0.75,0.0004074,0.75,0.01172
mmlu-formal-logic.val.76,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.84e-05,0.0,8.924e-05,1.0,0.00116
mtbench.dev.37,mistralai/mistral-7b-chat,1.0,0.000166,1.0,0.000166,1.0,0.0002697,1.0,0.0005436,0.9,0.000708488,1.0,0.03378
mmlu-moral-scenarios.val.861,WizardLM/WizardLM-13B-V1.2,0.0,3.99e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00134
grade-school-math.dev.3728,WizardLM/WizardLM-13B-V1.2,0.5,0.0002049,0.25,9.82e-05,0.5,0.0002049,0.25,0.000288,0.25,0.000472584,0.75,0.00942
mmlu-high-school-psychology.val.276,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
mmlu-professional-law.val.93,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
consensus_summary.dev.4,mistralai/mixtral-8x7b-chat,0.75,0.0001824,0.75,6.58e-05,0.75,9.03e-05,0.75,0.0001824,0.75,0.000276256,1.0,0.0026999999999999
mmlu-professional-law.val.903,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
hellaswag.val.244,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-jurisprudence.val.80,mistralai/mixtral-8x7b-chat,0.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00089
mmlu-professional-law.val.1435,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,1.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
mmlu-astronomy.val.17,mistralai/mixtral-8x7b-chat,1.0,8.340000000000001e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
hellaswag.val.8565,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,0.0,0.0026
hellaswag.val.2960,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00099
hellaswag.val.7953,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,0.0,0.00291
hellaswag.val.1163,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-security-studies.val.63,mistralai/mistral-7b-chat,0.0,3.8400000000000005e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00193
mmlu-high-school-world-history.val.89,WizardLM/WizardLM-13B-V1.2,1.0,5.73e-05,1.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00192
mmlu-clinical-knowledge.val.216,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-law.val.1338,WizardLM/WizardLM-13B-V1.2,0.0,5.4e-05,0.0,3.600000000000001e-05,0.0,5.4e-05,1.0,0.000108,0.0,0.00013968,1.0,0.00181
hellaswag.val.7616,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,0.0,5.800000000000001e-05,0.0,8.669999999999998e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
grade-school-math.dev.2871,mistralai/mixtral-8x7b-chat,0.25,0.0003348,0.25,0.0001106,0.25,0.0001977,0.25,0.0003348,0.25,0.000369376,0.75,0.01155
mmlu-professional-law.val.71,WizardLM/WizardLM-13B-V1.2,0.0,0.0001841999999999,0.0,0.0001228,0.0,0.0001841999999999,0.0,0.0003683999999999,0.0,0.000476464,1.0,0.0061499999999999
grade-school-math.dev.4219,WizardLM/WizardLM-13B-V1.2,0.25,0.0001352999999999,0.25,7.7e-05,0.25,0.0001352999999999,0.75,0.0002946,0.75,0.000332128,0.75,0.01006
mmlu-high-school-psychology.val.184,mistralai/mixtral-8x7b-chat,0.0,8.46e-05,1.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00145
mmlu-high-school-physics.val.85,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.6620,WizardLM/WizardLM-13B-V1.2,0.75,0.0001796999999999,0.5,0.0001122,0.75,0.0001796999999999,0.75,0.0003342,0.75,0.00057812,0.75,0.01358
mmlu-professional-law.val.1496,WizardLM/WizardLM-13B-V1.2,0.0,7.89e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
mmlu-high-school-microeconomics.val.43,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
mmlu-professional-law.val.1510,WizardLM/WizardLM-13B-V1.2,1.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
hellaswag.val.1489,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
hellaswag.val.9202,mistralai/mixtral-8x7b-chat,0.0,0.0001824,0.0,6.080000000000001e-05,0.0,9.12e-05,0.0,0.0001824,0.0,0.000235904,1.0,0.00305
hellaswag.val.6444,WizardLM/WizardLM-13B-V1.2,0.0,6.78e-05,0.0,4.5400000000000006e-05,0.0,6.78e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00231
grade-school-math.dev.2075,WizardLM/WizardLM-13B-V1.2,0.25,0.0001664999999999,0.75,0.000102,0.25,0.0001664999999999,0.25,0.0002826,0.25,0.000374032,0.75,0.01529
hellaswag.val.9984,WizardLM/WizardLM-13B-V1.2,0.0,7.65e-05,0.0,5.12e-05,0.0,7.65e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.0026
grade-school-math.dev.3447,WizardLM/WizardLM-13B-V1.2,0.75,0.0001305,0.5,8.26e-05,0.75,0.0001305,0.5,0.0002532,0.5,0.00031428,0.5,0.00741
grade-school-math.dev.6902,mistralai/mistral-7b-chat,0.75,6.14e-05,0.75,6.14e-05,0.25,0.0001338,0.75,0.0001877999999999,0.5,0.000245216,0.5,0.00636
mmlu-international-law.val.111,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.8989,WizardLM/WizardLM-13B-V1.2,0.0,8.94e-05,0.0,5.9600000000000005e-05,0.0,8.94e-05,0.0,0.0001788,0.0,0.0002312479999999,1.0,0.00299
mmlu-professional-medicine.val.22,WizardLM/WizardLM-13B-V1.2,0.0,5.16e-05,0.0,3.44e-05,0.0,5.16e-05,0.0,0.0001032,0.0,0.000133472,0.0,0.0017599999999999
mmlu-professional-psychology.val.137,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,0.0,0.00081
mmlu-miscellaneous.val.7,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,0.0,0.00074
mmlu-professional-medicine.val.133,WizardLM/WizardLM-13B-V1.2,0.0,6e-05,0.0,4e-05,0.0,6e-05,1.0,0.00012,0.0,0.0001551999999999,1.0,0.00204
hellaswag.val.9382,mistralai/mixtral-8x7b-chat,1.0,0.0001362,1.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,1.0,0.0001761519999999,1.0,0.00231
grade-school-math.dev.7156,WizardLM/WizardLM-13B-V1.2,0.75,0.0001326,0.75,8.42e-05,0.75,0.0001326,0.75,0.0002442,0.75,0.000318936,0.75,0.0075
mmlu-professional-law.val.724,mistralai/mistral-7b-chat,0.0,4.3200000000000007e-05,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,1.0,0.00217
hellaswag.val.7741,mistralai/mistral-7b-chat,1.0,5.720000000000001e-05,1.0,5.720000000000001e-05,1.0,8.58e-05,1.0,0.0001716,1.0,0.000221936,1.0,0.0029
hellaswag.val.8310,WizardLM/WizardLM-13B-V1.2,0.0,7.95e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
mmlu-prehistory.val.209,mistralai/mixtral-8x7b-chat,1.0,7.08e-05,0.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
hellaswag.val.7677,mistralai/mixtral-8x7b-chat,1.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
mmlu-miscellaneous.val.260,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,1.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-college-computer-science.val.38,mistralai/mistral-7b-chat,1.0,2.32e-05,1.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
mmlu-college-chemistry.val.94,mistralai/mixtral-8x7b-chat,0.0,7.56e-05,0.0,2.52e-05,1.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
abstract2title.test.129,mistralai/mixtral-8x7b-chat,1.0,0.0001841999999999,1.0,5.940000000000001e-05,1.0,9.15e-05,1.0,0.0001841999999999,1.0,0.000232024,1.0,0.00347
grade-school-math.dev.2052,WizardLM/WizardLM-13B-V1.2,0.25,0.0001827,0.75,0.0001206,0.25,0.0001827,0.25,0.000279,0.25,0.0003104,0.5,0.00825
mmlu-high-school-macroeconomics.val.310,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
hellaswag.val.6160,mistralai/mistral-7b-chat,1.0,5.1000000000000006e-05,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00259
mmlu-security-studies.val.59,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,0.0,0.00145
grade-school-math.dev.4709,mistralai/mistral-7b-chat,0.25,8.280000000000001e-05,0.25,8.280000000000001e-05,0.75,0.0001305,0.75,0.0002387999999999,0.75,0.000291,0.5,0.00734
abstract2title.test.134,mistralai/mixtral-8x7b-chat,1.0,0.0001631999999999,1.0,5.160000000000001e-05,1.0,7.739999999999998e-05,1.0,0.0001631999999999,1.0,0.000207192,1.0,0.00333
mmlu-logical-fallacies.val.137,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
arc-challenge.test.923,mistralai/mixtral-8x7b-chat,1.0,6.12e-05,1.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,1.0,7.9152e-05,1.0,0.00106
mmlu-professional-law.val.408,WizardLM/WizardLM-13B-V1.2,1.0,7.230000000000001e-05,0.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,1.0,0.0001446,0.0,0.000187016,1.0,0.00242
grade-school-math.dev.5681,mistralai/mixtral-8x7b-chat,0.75,0.0002616,0.75,7.66e-05,0.75,0.0001442999999999,0.75,0.0002616,0.75,0.000258408,0.75,0.00738
mmlu-nutrition.val.39,mistralai/mixtral-8x7b-chat,1.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.173,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,1.0,6.984e-05,1.0,0.00094
hellaswag.val.7444,mistralai/mistral-7b-chat,1.0,5.420000000000001e-05,1.0,5.420000000000001e-05,1.0,8.13e-05,1.0,0.0001626,1.0,0.0002102959999999,1.0,0.00275
mmlu-international-law.val.43,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-statistics.val.209,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.1326,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
hellaswag.val.3228,WizardLM/WizardLM-13B-V1.2,1.0,3.03e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
consensus_summary.dev.140,mistralai/mistral-7b-chat,0.5,4.5e-05,0.5,4.5e-05,1.0,6.21e-05,0.75,0.000135,0.25,0.000252976,0.5,0.00211
mmlu-professional-law.val.586,WizardLM/WizardLM-13B-V1.2,0.0,8.64e-05,0.0,5.76e-05,0.0,8.64e-05,1.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-moral-scenarios.val.538,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-us-history.val.183,mistralai/mixtral-8x7b-chat,0.0,0.0002712,0.0,9.04e-05,0.0,0.0001356,0.0,0.0002712,0.0,0.0003507519999999,1.0,0.0045299999999999
mmlu-high-school-psychology.val.381,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-professional-medicine.val.54,WizardLM/WizardLM-13B-V1.2,0.0,6.69e-05,0.0,4.460000000000001e-05,0.0,6.69e-05,1.0,0.0001338,0.0,0.000173048,1.0,0.00224
mmlu-professional-law.val.170,WizardLM/WizardLM-13B-V1.2,1.0,6.780000000000001e-05,0.0,4.520000000000001e-05,1.0,6.780000000000001e-05,1.0,0.0001356,0.0,0.000175376,1.0,0.00227
grade-school-math.dev.1619,mistralai/mistral-7b-chat,0.25,6.64e-05,0.25,6.64e-05,0.5,0.0001611,0.75,0.0001986,0.25,0.000280912,0.75,0.0051699999999999
hellaswag.val.2191,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
arc-challenge.test.986,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
winogrande.dev.1104,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.00053
mmlu-sociology.val.171,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-professional-medicine.val.73,mistralai/mixtral-8x7b-chat,0.0,8.879999999999999e-05,1.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.0015199999999999
hellaswag.val.4504,mistralai/mixtral-8x7b-chat,1.0,0.0001458,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00244
arc-challenge.test.409,mistralai/mixtral-8x7b-chat,0.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-virology.val.98,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
hellaswag.val.7874,mistralai/mixtral-8x7b-chat,1.0,0.0001709999999999,1.0,5.7e-05,1.0,8.519999999999998e-05,1.0,0.0001709999999999,1.0,0.00022116,1.0,0.00289
hellaswag.val.2593,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.0010999999999999
mmlu-econometrics.val.51,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
grade-school-math.dev.7466,WizardLM/WizardLM-13B-V1.2,0.75,0.0001935,0.25,9.2e-05,0.75,0.0001935,0.75,0.0002885999999999,0.25,0.00043068,0.75,0.00777
mmlu-high-school-macroeconomics.val.153,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-us-foreign-policy.val.38,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.7893,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
grade-school-math.dev.2495,mistralai/mistral-7b-chat,0.75,6.960000000000001e-05,0.75,6.960000000000001e-05,0.75,0.0001551,0.75,0.0002399999999999,0.25,0.000274704,0.75,0.0091399999999999
winogrande.dev.372,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
grade-school-math.dev.5211,mistralai/mixtral-8x7b-chat,0.25,0.0002261999999999,0.25,0.0001014,0.25,0.0001664999999999,0.25,0.0002261999999999,0.25,0.000296432,0.75,0.00996
hellaswag.val.6989,mistralai/mixtral-8x7b-chat,1.0,0.0001349999999999,0.0,4.5e-05,0.0,6.749999999999999e-05,1.0,0.0001349999999999,0.0,0.0001746,1.0,0.00229
mmlu-marketing.val.129,WizardLM/WizardLM-13B-V1.2,0.0,4.11e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-nutrition.val.70,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
hellaswag.val.9194,mistralai/mistral-7b-chat,1.0,4.84e-05,1.0,4.84e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00244
mmlu-conceptual-physics.val.75,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-econometrics.val.83,mistralai/mixtral-8x7b-chat,0.0,5.52e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.52e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-psychology.val.35,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.5896,mistralai/mixtral-8x7b-chat,0.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
mmlu-professional-law.val.456,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,1.0,0.0001776,0.0,0.000229696,1.0,0.00297
hellaswag.val.7714,WizardLM/WizardLM-13B-V1.2,0.0,7.95e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00266
mbpp.dev.110,mistralai/mistral-7b-chat,1.0,5.14e-05,1.0,5.14e-05,1.0,4.3499999999999993e-05,1.0,0.000129,1.0,9.7e-05,1.0,0.0054199999999999
winogrande.dev.96,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,0.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00051
mmlu-high-school-geography.val.31,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.2781,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,1.0,6.673599999999999e-05,0.0,0.00087
hellaswag.val.4290,mistralai/mixtral-8x7b-chat,1.0,0.0001626,1.0,5.420000000000001e-05,1.0,8.13e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
mmlu-professional-psychology.val.414,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
arc-challenge.test.3,mistralai/mistral-7b-chat,1.0,2.28e-05,1.0,2.28e-05,1.0,3.45e-05,1.0,6.9e-05,1.0,8.924e-05,1.0,0.00116
hellaswag.val.510,mistralai/mixtral-8x7b-chat,1.0,9e-05,0.0,3e-05,1.0,4.47e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-professional-law.val.403,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,0.0,0.00101
grade-school-math.dev.6513,mistralai/mistral-7b-chat,0.75,6.500000000000001e-05,0.75,6.500000000000001e-05,0.5,0.0001206,0.25,0.0002226,0.25,0.000278584,0.75,0.0053
mmlu-high-school-psychology.val.393,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.6661,mistralai/mistral-7b-chat,0.25,0.0001065999999999,0.25,0.0001065999999999,0.5,0.0001725,0.25,0.0003786,0.5,0.000409728,0.5,0.01127
mmlu-high-school-macroeconomics.val.50,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.4923,WizardLM/WizardLM-13B-V1.2,0.75,0.0001668,0.25,0.000115,0.75,0.0001668,0.25,0.0003426,0.25,0.000391104,0.25,0.01126
arc-challenge.test.853,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,1.0,7.372e-05,1.0,0.00096
grade-school-math.dev.4094,meta/code-llama-instruct-34b-chat,0.75,0.00030652,0.25,8.4e-05,0.25,0.0001503,0.25,0.0002634,0.75,0.00030652,0.75,0.00706
grade-school-math.dev.1317,WizardLM/WizardLM-13B-V1.2,0.75,0.0001607999999999,0.25,0.0001118,0.75,0.0001607999999999,0.75,0.0003131999999999,0.25,0.000458616,0.75,0.01023
mmlu-astronomy.val.143,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
hellaswag.val.4040,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00265
mmlu-professional-law.val.302,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,0.0,0.0026
mmlu-professional-law.val.214,WizardLM/WizardLM-13B-V1.2,1.0,0.0001149,1.0,7.66e-05,1.0,0.0001149,1.0,0.0002292,0.0,0.000297208,1.0,0.00384
arc-challenge.test.37,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.8416,mistralai/mistral-7b-chat,1.0,4.44e-05,1.0,4.44e-05,1.0,6.63e-05,1.0,0.0001332,1.0,0.0001722719999999,1.0,0.00223
hellaswag.val.8401,mistralai/mixtral-8x7b-chat,1.0,0.0001548,1.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00259
mmlu-philosophy.val.279,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.1323,mistralai/mixtral-8x7b-chat,0.75,0.0002567999999999,0.25,7.86e-05,0.75,0.0001496999999999,0.75,0.0002567999999999,0.25,0.000338336,0.75,0.00783
hellaswag.val.5315,mistralai/mixtral-8x7b-chat,0.0,0.0001722,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00288
hellaswag.val.9349,WizardLM/WizardLM-13B-V1.2,0.0,8.01e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00271
mmlu-professional-law.val.790,WizardLM/WizardLM-13B-V1.2,1.0,9.96e-05,0.0,6.64e-05,1.0,9.96e-05,1.0,0.0001992,0.0,0.000257632,1.0,0.00333
arc-challenge.test.343,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,1.0,6.208e-05,1.0,0.00081
arc-challenge.test.316,mistralai/mixtral-8x7b-chat,0.0,8.82e-05,0.0,2.94e-05,1.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
mmlu-elementary-mathematics.val.101,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.74e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-psychology.val.184,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
mmlu-anatomy.val.3,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.215,meta/code-llama-instruct-34b-chat,0.25,0.00025608,0.75,8.38e-05,0.75,0.0001545,0.5,0.0002238,0.25,0.00025608,0.75,0.00681
grade-school-math.dev.2815,WizardLM/WizardLM-13B-V1.2,0.75,0.0001398,1.0,5.940000000000001e-05,0.75,0.0001398,0.75,0.0002376,0.25,0.0002281439999999,0.75,0.00596
mmlu-professional-law.val.855,WizardLM/WizardLM-13B-V1.2,0.0,8.4e-05,0.0,5.6000000000000006e-05,0.0,8.4e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00281
hellaswag.val.118,mistralai/mixtral-8x7b-chat,1.0,7.98e-05,0.0,2.6600000000000003e-05,1.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
hellaswag.val.2887,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,1.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-high-school-statistics.val.133,mistralai/mixtral-8x7b-chat,1.0,7.62e-05,0.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
grade-school-math.dev.1733,mistralai/mistral-7b-chat,0.25,0.0001164,0.25,0.0001164,0.5,0.0002321999999999,0.5,0.0003492,0.25,0.00041128,0.5,0.01081
mmlu-machine-learning.val.63,mistralai/mixtral-8x7b-chat,0.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
mmlu-international-law.val.53,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.1830,WizardLM/WizardLM-13B-V1.2,0.75,0.0001785,0.25,8.6e-05,0.75,0.0001785,0.5,0.0002736,0.75,0.0003329039999999,0.25,0.00943
hellaswag.val.1577,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.1510,WizardLM/WizardLM-13B-V1.2,0.0,3.63e-05,0.0,2.42e-05,0.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
mmlu-professional-medicine.val.173,WizardLM/WizardLM-13B-V1.2,1.0,6.45e-05,0.0,4.3e-05,1.0,6.45e-05,0.0,0.000129,0.0,0.00016684,1.0,0.00216
hellaswag.val.9568,mistralai/mistral-7b-chat,0.0,6.06e-05,0.0,6.06e-05,0.0,9.06e-05,0.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
hellaswag.val.3909,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00288
mmlu-jurisprudence.val.71,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.2794,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
grade-school-math.dev.3733,mistralai/mistral-7b-chat,0.75,0.0001214,0.75,0.0001214,0.5,0.0001938,0.25,0.000312,0.75,0.000385672,0.75,0.01102
grade-school-math.dev.4579,mistralai/mixtral-8x7b-chat,0.75,0.0002628,0.75,7.3e-05,0.75,0.0001386,0.75,0.0002628,0.75,0.0003104,0.75,0.00792
mmlu-professional-psychology.val.471,mistralai/mixtral-8x7b-chat,0.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-security-studies.val.170,mistralai/mixtral-8x7b-chat,0.0,0.0001152,0.0,3.8400000000000005e-05,1.0,5.76e-05,0.0,0.0001152,0.0,0.0001489919999999,0.0,0.00193
grade-school-math.dev.2324,WizardLM/WizardLM-13B-V1.2,0.25,0.0001386,0.75,7.760000000000002e-05,0.25,0.0001386,0.5,0.0002525999999999,0.75,0.000308072,0.75,0.00784
hellaswag.val.7863,WizardLM/WizardLM-13B-V1.2,0.0,8.669999999999998e-05,0.0,5.800000000000001e-05,0.0,8.669999999999998e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00294
hellaswag.val.6807,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
hellaswag.val.3783,WizardLM/WizardLM-13B-V1.2,0.0,7.680000000000001e-05,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
grade-school-math.dev.2058,WizardLM/WizardLM-13B-V1.2,0.5,0.0001661999999999,0.25,7.92e-05,0.5,0.0001661999999999,0.75,0.0002177999999999,0.25,0.000307296,0.75,0.00869
hellaswag.val.1923,WizardLM/WizardLM-13B-V1.2,1.0,3.96e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-high-school-psychology.val.439,mistralai/mixtral-8x7b-chat,1.0,7.56e-05,1.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-high-school-government-and-politics.val.98,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.9923,mistralai/mixtral-8x7b-chat,0.0,0.0001782,0.0,5.94e-05,0.0,8.879999999999999e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00301
mmlu-professional-law.val.259,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,1.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.0028
mmlu-professional-law.val.1357,WizardLM/WizardLM-13B-V1.2,0.0,8.91e-05,0.0,5.94e-05,0.0,8.91e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
hellaswag.val.6666,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
hellaswag.val.7032,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,0.0,0.0024
mmlu-nutrition.val.64,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-clinical-knowledge.val.140,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
hellaswag.val.4467,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001607999999999,0.0,0.000208744,1.0,0.00273
mmlu-miscellaneous.val.141,mistralai/mixtral-8x7b-chat,0.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.5107,WizardLM/WizardLM-13B-V1.2,0.25,0.0001683,0.75,7.76e-05,0.25,0.0001683,0.75,0.0002514,0.5,0.000323592,0.75,0.0075
hellaswag.val.3330,mistralai/mistral-7b-chat,1.0,5.16e-05,1.0,5.16e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,1.0,0.000200984,1.0,0.00263
mmlu-moral-disputes.val.259,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-professional-law.val.823,WizardLM/WizardLM-13B-V1.2,1.0,0.0001125,0.0,7.500000000000001e-05,1.0,0.0001125,1.0,0.000225,0.0,0.000291,1.0,0.00376
grade-school-math.dev.737,mistralai/mistral-7b-chat,0.75,7.32e-05,0.75,7.32e-05,0.75,0.0001392,0.75,0.000273,0.75,0.000285568,0.75,0.00598
mmlu-nutrition.val.220,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.50,WizardLM/WizardLM-13B-V1.2,0.25,0.0001482,0.25,0.000582,0.25,0.0001482,0.25,0.0002598,0.25,0.000336008,0.75,0.00937
winogrande.dev.403,mistralai/mistral-7b-chat,0.0,1.28e-05,0.0,1.28e-05,1.0,1.92e-05,0.0,3.84e-05,0.0,4.9664e-05,1.0,0.00068
hellaswag.val.3200,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,0.0,0.00127
mmlu-human-sexuality.val.22,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
mmlu-anatomy.val.6,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
arc-challenge.test.1148,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,1.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,1.0,6.3632e-05,1.0,0.00086
hellaswag.val.3305,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
accounting_audit.dev.28,WizardLM/WizardLM-13B-V1.2,0.0,6.839999999999998e-05,0.0,8.340000000000001e-05,0.0,6.839999999999998e-05,1.0,0.0001487999999999,0.0,0.000191672,1.0,0.0023
mmlu-professional-law.val.209,WizardLM/WizardLM-13B-V1.2,1.0,6.93e-05,0.0,4.6200000000000005e-05,1.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00235
mmlu-professional-law.val.1097,WizardLM/WizardLM-13B-V1.2,0.0,5.37e-05,1.0,3.58e-05,0.0,5.37e-05,0.0,0.0001074,0.0,0.000138904,1.0,0.00183
hellaswag.val.4807,WizardLM/WizardLM-13B-V1.2,0.0,8.999999999999999e-05,0.0,6e-05,0.0,8.999999999999999e-05,0.0,0.0001799999999999,0.0,0.0002328,0.0,0.00304
hellaswag.val.6220,mistralai/mistral-7b-chat,0.0,5.920000000000001e-05,0.0,5.920000000000001e-05,0.0,8.85e-05,0.0,0.0001776,0.0,0.000229696,0.0,0.003
arc-challenge.test.382,mistralai/mixtral-8x7b-chat,1.0,7.379999999999999e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-professional-law.val.475,WizardLM/WizardLM-13B-V1.2,0.0,9.09e-05,1.0,6.06e-05,0.0,9.09e-05,1.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
grade-school-math.dev.6501,mistralai/mistral-7b-chat,0.25,7.34e-05,0.25,7.34e-05,0.5,0.0001434,0.5,0.000213,0.75,0.000284792,0.75,0.00809
winogrande.dev.1256,mistralai/mistral-7b-chat,1.0,1.1e-05,1.0,1.1e-05,1.0,1.65e-05,0.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00059
hellaswag.val.2375,WizardLM/WizardLM-13B-V1.2,1.0,5.16e-05,0.0,3.44e-05,1.0,5.16e-05,0.0,0.0001032,0.0,0.000133472,1.0,0.00173
consensus_summary.dev.251,mistralai/mixtral-8x7b-chat,0.75,0.0001356,0.75,6e-05,0.75,8.04e-05,0.75,0.0001356,0.75,0.000225816,0.75,0.00329
hellaswag.val.5947,mistralai/mistral-7b-chat,1.0,4.980000000000001e-05,1.0,4.980000000000001e-05,1.0,7.439999999999999e-05,1.0,0.0001494,1.0,0.0001932239999999,1.0,0.0025
hellaswag.val.5090,mistralai/mixtral-8x7b-chat,1.0,0.0001626,1.0,5.420000000000001e-05,1.0,8.099999999999999e-05,1.0,0.0001626,1.0,0.0002102959999999,1.0,0.00275
mmlu-professional-law.val.1451,WizardLM/WizardLM-13B-V1.2,0.0,9.75e-05,1.0,6.500000000000001e-05,0.0,9.75e-05,1.0,0.000195,0.0,0.0002522,1.0,0.00329
hellaswag.val.6211,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
arc-challenge.val.222,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,1.0,5.7424e-05,1.0,0.00078
hellaswag.val.4438,WizardLM/WizardLM-13B-V1.2,0.0,6.569999999999998e-05,0.0,4.4000000000000006e-05,0.0,6.569999999999998e-05,0.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
bias_detection.dev.218,mistralai/mistral-7b-chat,0.0,5.940000000000001e-05,0.0,5.940000000000001e-05,0.0,9.63e-05,1.0,0.0001992,0.0,0.000266944,1.0,0.00987
grade-school-math.dev.3916,meta/code-llama-instruct-34b-chat,0.25,0.000331352,0.25,8.68e-05,0.25,0.0001545,0.25,0.0002718,0.25,0.000331352,0.5,0.0098999999999999
hellaswag.val.8002,WizardLM/WizardLM-13B-V1.2,0.0,8.76e-05,0.0,5.84e-05,0.0,8.76e-05,0.0,0.0001752,0.0,0.000226592,1.0,0.00293
hellaswag.val.3859,mistralai/mixtral-8x7b-chat,1.0,0.0001422,1.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,1.0,0.000183912,1.0,0.00238
grade-school-math.dev.6249,mistralai/mistral-7b-chat,0.5,7.02e-05,0.5,7.02e-05,0.5,0.0001196999999999,0.25,0.0002435999999999,0.5,0.000243664,0.5,0.0056399999999999
hellaswag.val.9096,mistralai/mistral-7b-chat,1.0,4.600000000000001e-05,1.0,4.600000000000001e-05,1.0,6.9e-05,0.0,0.0001373999999999,1.0,0.0001784799999999,1.0,0.00234
mmlu-virology.val.51,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,0.0,0.00089
grade-school-math.dev.2659,mistralai/mixtral-8x7b-chat,0.75,0.0002483999999999,0.25,8.02e-05,0.75,0.0001413,0.75,0.0002483999999999,0.25,0.000316608,0.75,0.00749
arc-challenge.test.1153,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,1.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,1.0,7.5272e-05,1.0,0.00101
grade-school-math.dev.4841,meta/code-llama-instruct-34b-chat,0.75,0.000329024,0.5,9.72e-05,0.5,0.0001536,0.5,0.0002375999999999,0.75,0.000329024,0.5,0.00848
grade-school-math.dev.4633,WizardLM/WizardLM-13B-V1.2,0.25,0.0001775999999999,0.25,7.860000000000001e-05,0.25,0.0001775999999999,0.25,0.0003246,0.25,0.000350752,0.75,0.01228
winogrande.dev.877,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
mmlu-professional-accounting.val.133,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,0.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
grade-school-math.dev.4308,mistralai/mistral-7b-chat,0.25,8.72e-05,0.25,8.72e-05,0.5,0.0001161,0.5,0.0002058,0.75,0.000250648,0.75,0.00509
winogrande.dev.415,mistralai/mistral-7b-chat,1.0,1.26e-05,1.0,1.26e-05,1.0,1.89e-05,1.0,3.78e-05,1.0,4.8888e-05,1.0,0.00067
mmlu-world-religions.val.85,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.6410,mistralai/mixtral-8x7b-chat,0.0,0.0001829999999999,0.0,6.1000000000000005e-05,0.0,9.15e-05,0.0,0.0001829999999999,0.0,0.00023668,1.0,0.00309
mmlu-professional-psychology.val.352,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
hellaswag.val.3800,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.319999999999999e-05,0.0,0.000147,0.0,0.00019012,0.0,0.00249
mmlu-professional-law.val.691,WizardLM/WizardLM-13B-V1.2,1.0,0.0001059,0.0,7.06e-05,1.0,0.0001059,1.0,0.0002118,0.0,0.000273928,1.0,0.00354
hellaswag.val.2336,WizardLM/WizardLM-13B-V1.2,0.0,3.84e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00132
mmlu-professional-law.val.1254,WizardLM/WizardLM-13B-V1.2,0.0,5.25e-05,1.0,3.5000000000000004e-05,0.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00179
mmlu-professional-law.val.119,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,0.0,0.00154
winogrande.dev.249,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00051
hellaswag.val.9934,mistralai/mistral-7b-chat,0.0,4.24e-05,0.0,4.24e-05,0.0,6.36e-05,1.0,0.0001272,0.0,0.0001645119999999,1.0,0.00216
mmlu-elementary-mathematics.val.226,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
mbpp.dev.157,mistralai/mistral-7b-chat,0.0,3.78e-05,0.0,3.78e-05,0.0,8.64e-05,0.0,0.0002796,0.0,0.000111744,1.0,0.01254
grade-school-math.dev.6539,meta/code-llama-instruct-34b-chat,0.25,0.000427576,0.0,9.320000000000002e-05,0.75,0.0002000999999999,0.25,0.0003342,0.25,0.000427576,0.75,0.01219
winogrande.dev.706,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
mmlu-prehistory.val.41,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
hellaswag.val.3212,WizardLM/WizardLM-13B-V1.2,0.0,4.05e-05,0.0,2.7e-05,0.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
hellaswag.val.5259,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.409999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
hellaswag.val.8026,mistralai/mixtral-8x7b-chat,1.0,0.0001698,1.0,5.660000000000001e-05,1.0,8.49e-05,1.0,0.0001698,1.0,0.000219608,1.0,0.00284
grade-school-math.dev.29,mistralai/mistral-7b-chat,0.25,0.0001144,0.25,0.0001144,0.25,0.0001725,0.75,0.0003006,0.25,0.000352304,0.75,0.01124
hellaswag.val.1583,mistralai/mixtral-8x7b-chat,1.0,7.2e-05,0.0,2.4e-05,0.0,3.57e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
grade-school-math.dev.6920,mistralai/mistral-7b-chat,0.25,9.84e-05,0.25,9.84e-05,0.25,0.0002156999999999,0.25,0.0002664,0.25,0.000301088,0.75,0.00859
grade-school-math.dev.976,mistralai/mistral-7b-chat,0.25,8.400000000000001e-05,0.25,8.400000000000001e-05,0.25,0.0001749,0.5,0.000303,0.25,0.000329024,0.5,0.00766
hellaswag.val.2370,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.5684,mistralai/mixtral-8x7b-chat,0.0,0.0001332,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00226
mmlu-professional-law.val.109,WizardLM/WizardLM-13B-V1.2,1.0,0.0001004999999999,0.0,6.7e-05,1.0,0.0001004999999999,1.0,0.0002009999999999,0.0,0.00025996,1.0,0.00336
grade-school-math.dev.4238,WizardLM/WizardLM-13B-V1.2,0.25,0.0001671,0.25,9.78e-05,0.25,0.0001671,0.75,0.0002748,0.25,0.000326696,0.75,0.0089
grade-school-math.dev.1369,meta/code-llama-instruct-34b-chat,0.25,0.000334456,0.75,8.620000000000001e-05,0.25,0.0002414999999999,0.75,0.0003096,0.25,0.000334456,0.75,0.00875
mmlu-virology.val.129,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,1.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
arc-challenge.test.2,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,1.0,7.604800000000001e-05,1.0,0.00102
mmlu-virology.val.77,mistralai/mistral-7b-chat,1.0,1.48e-05,1.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,0.0,0.00078
winogrande.dev.751,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,0.0,3.9576e-05,1.0,0.00055
mmlu-moral-disputes.val.161,mistralai/mistral-7b-chat,1.0,2.22e-05,1.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00115
hellaswag.val.4409,WizardLM/WizardLM-13B-V1.2,0.0,9.6e-05,0.0,6.42e-05,0.0,9.6e-05,0.0,0.0001926,0.0,0.000249096,1.0,0.00322
mmlu-logical-fallacies.val.161,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
hellaswag.val.7341,WizardLM/WizardLM-13B-V1.2,0.0,7.47e-05,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
mmlu-prehistory.val.144,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
grade-school-math.dev.1655,WizardLM/WizardLM-13B-V1.2,0.5,0.0001730999999999,0.5,8.58e-05,0.5,0.0001730999999999,0.25,0.0002466,0.75,0.0003429919999999,0.75,0.0086
mmlu-high-school-chemistry.val.179,WizardLM/WizardLM-13B-V1.2,0.0,4.08e-05,1.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-sociology.val.59,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
bias_detection.dev.63,mistralai/mistral-7b-chat,0.0,5.780000000000001e-05,0.0,5.780000000000001e-05,0.0,9.12e-05,0.0,0.0001686,0.0,0.000224264,1.0,0.00875
mmlu-professional-law.val.1376,WizardLM/WizardLM-13B-V1.2,1.0,9.42e-05,0.0,6.280000000000001e-05,1.0,9.42e-05,0.0,0.0001884,0.0,0.000243664,1.0,0.00315
hellaswag.val.3134,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-moral-disputes.val.135,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
arc-challenge.test.281,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,0.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,1.0,0.00122
grade-school-math.dev.3284,mistralai/mistral-7b-chat,0.25,0.0001012,0.25,0.0001012,0.25,0.0001886999999999,0.25,0.0002862,0.75,0.000305744,0.75,0.0098
mmlu-moral-scenarios.val.23,mistralai/mistral-7b-chat,0.0,3.38e-05,0.0,3.38e-05,1.0,5.07e-05,1.0,0.0001014,0.0,0.000131144,1.0,0.0017
winogrande.dev.323,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,0.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00048
arc-challenge.test.846,mistralai/mistral-7b-chat,1.0,1.62e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,1.0,6.285600000000001e-05,1.0,0.00085
hellaswag.val.710,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
hellaswag.val.9167,mistralai/mixtral-8x7b-chat,0.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00274
mmlu-miscellaneous.val.478,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
hellaswag.val.5142,mistralai/mixtral-8x7b-chat,1.0,0.000156,1.0,5.2e-05,1.0,7.769999999999999e-05,1.0,0.000156,1.0,0.00020176,1.0,0.00264
mmlu-marketing.val.64,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-high-school-mathematics.val.48,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
hellaswag.val.3251,mistralai/mistral-7b-chat,1.0,4.480000000000001e-05,1.0,4.480000000000001e-05,1.0,6.72e-05,1.0,0.0001344,1.0,0.0001738239999999,1.0,0.00228
mmlu-us-foreign-policy.val.62,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-conceptual-physics.val.193,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-high-school-physics.val.10,mistralai/mistral-7b-chat,0.0,3.38e-05,0.0,3.38e-05,0.0,5.07e-05,0.0,0.0001014,0.0,0.000131144,0.0,0.0017
mbpp.dev.251,mistralai/mistral-7b-chat,0.0,3.54e-05,0.0,3.54e-05,0.0,6.3e-05,0.0,0.0002201999999999,1.0,0.000109416,1.0,0.00923
mmlu-high-school-chemistry.val.151,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mbpp.dev.184,mistralai/mistral-7b-chat,0.0,5.12e-05,0.0,5.12e-05,1.0,0.0001043999999999,0.0,0.0002321999999999,0.0,0.0002234879999999,1.0,0.01135
mmlu-high-school-psychology.val.252,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.1136,mistralai/mistral-7b-chat,0.75,0.000108,0.75,0.000108,0.75,0.0001592999999999,0.75,0.0002261999999999,0.75,0.00034532,0.75,0.00943
mmlu-human-aging.val.170,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.208e-05,1.0,0.00085
mmlu-elementary-mathematics.val.314,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.7725,mistralai/mistral-7b-chat,1.0,5e-05,1.0,5e-05,1.0,7.5e-05,1.0,0.00015,1.0,0.000194,1.0,0.00251
hellaswag.val.6607,mistralai/mixtral-8x7b-chat,0.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
grade-school-math.dev.5655,mistralai/mistral-7b-chat,1.0,6.48e-05,1.0,6.48e-05,0.25,0.0001610999999999,0.75,0.0002766,0.25,0.000326696,0.75,0.00844
grade-school-math.dev.2865,WizardLM/WizardLM-13B-V1.2,0.75,0.0001521,0.25,8.26e-05,0.75,0.0001521,0.75,0.0002232,0.75,0.0003049679999999,0.5,0.00589
mmlu-professional-law.val.1187,WizardLM/WizardLM-13B-V1.2,1.0,7.53e-05,0.0,5.020000000000001e-05,1.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00255
mmlu-clinical-knowledge.val.39,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,0.0,0.00105
mmlu-professional-law.val.486,WizardLM/WizardLM-13B-V1.2,0.0,7.199999999999999e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-miscellaneous.val.339,WizardLM/WizardLM-13B-V1.2,1.0,2.22e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.1229,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,1.0,2.55e-05,1.0,5.16e-05,1.0,6.673599999999999e-05,1.0,0.00087
mmlu-electrical-engineering.val.92,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
grade-school-math.dev.7243,WizardLM/WizardLM-13B-V1.2,0.75,0.0001434,0.25,8.840000000000001e-05,0.75,0.0001434,1.0,0.0002033999999999,0.75,0.000299536,0.75,0.0085
hellaswag.val.8843,mistralai/mixtral-8x7b-chat,1.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
winogrande.dev.284,mistralai/mistral-7b-chat,1.0,1.12e-05,1.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,1.0,0.00057
mmlu-elementary-mathematics.val.332,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-clinical-knowledge.val.142,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-miscellaneous.val.709,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-professional-medicine.val.198,mistralai/mixtral-8x7b-chat,1.0,0.0002412,0.0,8.04e-05,1.0,0.0001206,1.0,0.0002412,0.0,0.000311952,1.0,0.00403
mmlu-high-school-european-history.val.100,mistralai/mixtral-8x7b-chat,0.0,0.0002562,0.0,8.54e-05,0.0,0.0001281,0.0,0.0002562,0.0,0.000331352,1.0,0.00428
mmlu-prehistory.val.110,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
hellaswag.val.3267,mistralai/mixtral-8x7b-chat,1.0,0.0001716,1.0,5.720000000000001e-05,1.0,8.549999999999999e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.0029
grade-school-math.dev.4286,WizardLM/WizardLM-13B-V1.2,0.25,0.0001508999999999,0.25,8.860000000000001e-05,0.25,0.0001508999999999,0.25,0.0002532,0.75,0.000327472,0.75,0.00753
winogrande.dev.26,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00052
grade-school-math.dev.4284,mistralai/mistral-7b-chat,0.25,7.7e-05,0.25,7.7e-05,0.25,0.0001751999999999,0.25,0.0003258,0.25,0.000321264,0.5,0.01239
mmlu-professional-law.val.892,WizardLM/WizardLM-13B-V1.2,0.0,8.249999999999999e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-moral-scenarios.val.794,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
arc-challenge.val.76,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
hellaswag.val.553,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00109
grade-school-math.dev.4525,WizardLM/WizardLM-13B-V1.2,0.25,0.0001872,0.25,8.42e-05,0.25,0.0001872,0.25,0.000303,0.25,0.000387224,0.75,0.01169
mmlu-world-religions.val.58,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,0.0,0.00082
arc-challenge.test.75,mistralai/mixtral-8x7b-chat,1.0,7.02e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
mmlu-professional-law.val.235,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-professional-law.val.671,mistralai/mistral-7b-chat,0.0,5.520000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,0.0,0.00277
hellaswag.val.9294,WizardLM/WizardLM-13B-V1.2,1.0,8.4e-05,1.0,5.62e-05,1.0,8.4e-05,1.0,0.0001686,1.0,0.000218056,1.0,0.00285
mmlu-professional-law.val.1332,mistralai/mistral-7b-chat,0.0,8.68e-05,0.0,8.68e-05,1.0,0.0001302,1.0,0.0002604,0.0,0.000336784,1.0,0.00435
bias_detection.dev.146,mistralai/mistral-7b-chat,0.0,5.58e-05,0.0,5.58e-05,0.0,0.0001002,1.0,0.0001698,0.0,0.0002304719999999,1.0,0.01039
grade-school-math.dev.1913,WizardLM/WizardLM-13B-V1.2,0.75,0.0001908,0.75,0.000103,0.75,0.0001908,0.25,0.0002898,0.75,0.000273152,0.25,0.0138
mmlu-professional-psychology.val.185,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.9043,meta/code-llama-instruct-34b-chat,1.0,0.0002079679999999,1.0,5.360000000000001e-05,1.0,8.01e-05,1.0,0.0001608,1.0,0.0002079679999999,1.0,0.00269
grade-school-math.dev.2793,mistralai/mistral-7b-chat,0.25,5.5400000000000005e-05,0.25,5.5400000000000005e-05,0.75,0.0001275,0.75,0.0002327999999999,0.5,0.00029876,0.5,0.00602
grade-school-math.dev.4964,WizardLM/WizardLM-13B-V1.2,0.5,0.0001521,0.5,0.00011,0.5,0.0001521,0.5,0.0002694,0.25,0.00038024,0.5,0.00794
mmlu-high-school-psychology.val.451,WizardLM/WizardLM-13B-V1.2,1.0,2.49e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.617,WizardLM/WizardLM-13B-V1.2,0.5,0.0002013,0.25,0.000101,0.5,0.0002013,0.25,0.0003558,0.25,0.000467152,0.5,0.0113
mmlu-international-law.val.90,WizardLM/WizardLM-13B-V1.2,1.0,4.41e-05,1.0,2.94e-05,1.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
grade-school-math.dev.467,mistralai/mistral-7b-chat,0.25,6.340000000000001e-05,0.25,6.340000000000001e-05,0.75,0.0001344,0.25,0.0002598,0.5,0.00033756,0.5,0.00694
winogrande.dev.60,mistralai/mistral-7b-chat,0.0,9.2e-06,0.0,9.2e-06,1.0,1.3799999999999998e-05,0.0,2.76e-05,0.0,3.5696e-05,0.0,0.00047
hellaswag.val.2390,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.6014,mistralai/mistral-7b-chat,0.25,8.5e-05,0.25,8.5e-05,0.25,0.0001586999999999,0.75,0.0002345999999999,0.25,0.000358512,0.75,0.00781
hellaswag.val.8943,WizardLM/WizardLM-13B-V1.2,0.0,8.46e-05,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001692,0.0,0.000219608,1.0,0.00287
bias_detection.dev.154,mistralai/mixtral-8x7b-chat,0.0,0.0001782,0.0,5.68e-05,0.0,0.0001185,0.0,0.0001782,0.0,0.000273152,1.0,0.00611
mmlu-professional-law.val.222,mistralai/mistral-7b-chat,0.0,7.56e-05,0.0,7.56e-05,0.0,0.0001133999999999,0.0,0.0002267999999999,0.0,0.000293328,0.0,0.00379
hellaswag.val.9879,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
grade-school-math.dev.950,mistralai/mistral-7b-chat,0.75,9.6e-05,0.75,9.6e-05,0.75,0.0001818,0.25,0.000327,0.5,0.000339112,0.75,0.01134
hellaswag.val.3077,mistralai/mistral-7b-chat,1.0,2.12e-05,1.0,2.12e-05,1.0,3.15e-05,1.0,6.36e-05,1.0,8.2256e-05,1.0,0.00107
mmlu-college-biology.val.72,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-public-relations.val.55,mistralai/mistral-7b-chat,0.0,1.26e-05,0.0,1.26e-05,0.0,1.89e-05,0.0,3.78e-05,0.0,4.8888e-05,0.0,0.0006399999999999
hellaswag.val.7604,mistralai/mixtral-8x7b-chat,0.0,0.0001602,0.0,5.34e-05,0.0,7.979999999999999e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00271
mmlu-professional-medicine.val.170,mistralai/mixtral-8x7b-chat,1.0,0.000147,0.0,4.9000000000000005e-05,1.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00249
hellaswag.val.9828,mistralai/mistral-7b-chat,1.0,5.680000000000001e-05,1.0,5.680000000000001e-05,1.0,8.52e-05,1.0,0.0001704,1.0,0.0002203839999999,1.0,0.00285
mmlu-machine-learning.val.78,mistralai/mixtral-8x7b-chat,1.0,8.46e-05,0.0,2.82e-05,0.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
hellaswag.val.9251,mistralai/mixtral-8x7b-chat,0.0,0.0001463999999999,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
mmlu-moral-scenarios.val.760,mistralai/mixtral-8x7b-chat,0.0,8.759999999999999e-05,0.0,2.92e-05,1.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
hellaswag.val.6391,mistralai/mistral-7b-chat,1.0,4.580000000000001e-05,1.0,4.580000000000001e-05,1.0,6.869999999999999e-05,1.0,0.0001373999999999,1.0,0.000177704,1.0,0.0023
grade-school-math.dev.1414,WizardLM/WizardLM-13B-V1.2,0.25,0.0001539,0.25,9.880000000000002e-05,0.25,0.0001539,0.25,0.0002868,0.75,0.000335232,0.5,0.00749
mmlu-professional-law.val.256,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,1.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
mmlu-professional-psychology.val.432,mistralai/mixtral-8x7b-chat,1.0,0.000105,0.0,3.5000000000000004e-05,1.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00176
mmlu-professional-psychology.val.572,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-law.val.1164,mistralai/mixtral-8x7b-chat,1.0,0.0002052,1.0,6.84e-05,0.0,0.0001026,1.0,0.0002052,0.0,0.000265392,1.0,0.00343
mmlu-professional-law.val.1016,WizardLM/WizardLM-13B-V1.2,0.0,3.15e-05,0.0,2.1e-05,0.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
hellaswag.val.6384,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
mmlu-elementary-mathematics.val.279,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
consensus_summary.dev.153,mistralai/mixtral-8x7b-chat,0.75,0.0002123999999999,0.75,8.02e-05,0.75,0.0001185,0.75,0.0002123999999999,0.75,0.000299536,0.75,0.00668
mmlu-professional-law.val.575,mistralai/mistral-7b-chat,0.0,5.300000000000001e-05,0.0,5.300000000000001e-05,1.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00266
hellaswag.val.9121,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00245
mmlu-professional-law.val.242,mistralai/mixtral-8x7b-chat,0.0,0.0001146,1.0,3.820000000000001e-05,0.0,5.73e-05,0.0,0.0001146,0.0,0.000148216,0.0,0.00192
hellaswag.val.7370,mistralai/mixtral-8x7b-chat,0.0,0.0001314,0.0,4.380000000000001e-05,0.0,6.57e-05,0.0,0.0001314,0.0,0.0001699439999999,0.0,0.0022
grade-school-math.dev.590,mistralai/mixtral-8x7b-chat,0.75,0.0003287999999999,0.75,8.64e-05,0.75,0.0001536,0.75,0.0003287999999999,0.75,0.000308072,0.75,0.01087
mmlu-college-chemistry.val.48,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
winogrande.dev.110,mistralai/mixtral-8x7b-chat,1.0,3e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,0.0,3.802400000000001e-05,1.0,0.00054
hellaswag.val.3090,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
grade-school-math.dev.4389,WizardLM/WizardLM-13B-V1.2,0.5,0.0001605,0.25,0.0001564,0.5,0.0001605,0.25,0.0004362,0.25,0.000467928,0.75,0.00844
grade-school-math.dev.6336,mistralai/mixtral-8x7b-chat,0.75,0.0002243999999999,0.25,8.060000000000001e-05,0.75,0.0001224,0.75,0.0002243999999999,0.75,0.000292552,0.5,0.00539
mmlu-high-school-statistics.val.142,WizardLM/WizardLM-13B-V1.2,0.0,5.88e-05,1.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,0.0,0.00197
hellaswag.val.8549,mistralai/mixtral-8x7b-chat,0.0,0.0001776,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.00297
mmlu-abstract-algebra.val.48,mistralai/mixtral-8x7b-chat,0.0,7.439999999999999e-05,0.0,2.5e-05,0.0,3.75e-05,0.0,7.439999999999999e-05,0.0,9.7e-05,1.0,0.00129
grade-school-math.dev.6970,mistralai/mistral-7b-chat,0.0,0.0001292,0.0,0.0001292,0.25,0.0002084999999999,0.25,0.0003204,0.25,0.000441544,0.25,0.01621
hellaswag.val.3618,mistralai/mistral-7b-chat,1.0,5.7400000000000006e-05,1.0,5.7400000000000006e-05,1.0,8.61e-05,0.0,0.0001722,1.0,0.000222712,1.0,0.00291
mmlu-machine-learning.val.47,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
hellaswag.val.1427,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-professional-law.val.1085,WizardLM/WizardLM-13B-V1.2,1.0,0.0001035,0.0,6.900000000000001e-05,1.0,0.0001035,1.0,0.000207,0.0,0.00026772,1.0,0.00346
mmlu-logical-fallacies.val.65,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.4747,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00242
mmlu-professional-law.val.1074,WizardLM/WizardLM-13B-V1.2,0.0,9.21e-05,0.0,6.14e-05,0.0,9.21e-05,0.0,0.0001842,0.0,0.000238232,0.0,0.00311
arc-challenge.test.732,mistralai/mixtral-8x7b-chat,1.0,3.78e-05,0.0,1.26e-05,0.0,1.89e-05,1.0,3.78e-05,0.0,4.8888e-05,0.0,0.00067
mmlu-college-medicine.val.42,mistralai/mixtral-8x7b-chat,1.0,7.62e-05,0.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
hellaswag.val.4329,mistralai/mixtral-8x7b-chat,1.0,0.0001386,1.0,4.6200000000000005e-05,1.0,6.93e-05,1.0,0.0001386,1.0,0.000179256,1.0,0.00235
mmlu-college-biology.val.86,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.6376,meta/code-llama-instruct-34b-chat,0.25,0.00025608,0.25,8.26e-05,0.25,0.0001619999999999,0.25,0.0002286,0.25,0.00025608,0.75,0.00686
mtbench-reference.dev.5,meta/code-llama-instruct-34b-chat,0.1,0.000882312,0.1,0.0001375999999999,0.1,0.0003489,1.0,0.0004488,0.1,0.000882312,1.0,0.0263599999999999
mmlu-high-school-statistics.val.180,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-high-school-psychology.val.488,mistralai/mixtral-8x7b-chat,1.0,6.3e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-professional-psychology.val.459,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00126
hellaswag.val.2219,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.82e-05,1.0,5.7e-05,1.0,7.372e-05,1.0,0.00096
mmlu-miscellaneous.val.722,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.3470,WizardLM/WizardLM-13B-V1.2,0.75,0.0001266,0.5,6.74e-05,0.75,0.0001266,0.25,0.0002147999999999,0.5,0.000282464,0.5,0.00612
grade-school-math.dev.2189,mistralai/mistral-7b-chat,0.25,7.58e-05,0.25,7.58e-05,0.5,0.0001662,0.5,0.0002916,0.25,0.000324368,0.5,0.0087099999999999
mmlu-high-school-geography.val.142,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
hellaswag.val.6834,WizardLM/WizardLM-13B-V1.2,1.0,8.759999999999999e-05,1.0,5.860000000000001e-05,1.0,8.759999999999999e-05,1.0,0.0001758,1.0,0.0002273679999999,1.0,0.00297
hellaswag.val.419,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-marketing.val.69,mistralai/mistral-7b-chat,1.0,2.84e-05,1.0,2.84e-05,1.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00143
grade-school-math.dev.5508,mistralai/mistral-7b-chat,0.25,9.96e-05,0.25,9.96e-05,0.25,0.0001863,0.75,0.0002753999999999,0.75,0.000373256,0.75,0.00861
mmlu-professional-law.val.226,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,1.0,6.2e-05,0.0,9.3e-05,1.0,0.0001853999999999,0.0,0.00024056,1.0,0.00311
grade-school-math.dev.926,mistralai/mistral-7b-chat,0.75,9.84e-05,0.75,9.84e-05,0.5,0.0002052,0.25,0.0002964,0.75,0.000417488,0.75,0.00908
hellaswag.val.4793,WizardLM/WizardLM-13B-V1.2,1.0,7.47e-05,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,1.0,0.0001932239999999,1.0,0.00253
hellaswag.val.5401,WizardLM/WizardLM-13B-V1.2,1.0,8.34e-05,0.0,5.580000000000001e-05,1.0,8.34e-05,1.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
hellaswag.val.7791,WizardLM/WizardLM-13B-V1.2,0.0,6.96e-05,0.0,4.64e-05,0.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00236
mmlu-high-school-mathematics.val.209,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,0.0,0.00144
hellaswag.val.1766,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.3e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00115
mbpp.dev.206,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,5.88e-05,0.0,0.0001518,0.0,0.000132696,0.0,0.00938
mmlu-professional-law.val.897,WizardLM/WizardLM-13B-V1.2,0.0,0.0001149,0.0,7.66e-05,0.0,0.0001149,1.0,0.0002298,0.0,0.000297208,1.0,0.00384
hellaswag.val.4752,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,0.0,0.00249
grade-school-math.dev.7182,WizardLM/WizardLM-13B-V1.2,0.25,0.0001581,0.25,0.0005562,0.25,0.0001581,0.25,0.0002274,0.25,0.000313504,0.25,0.00832
hellaswag.val.6842,mistralai/mixtral-8x7b-chat,0.0,0.0001698,1.0,5.660000000000001e-05,1.0,8.46e-05,0.0,0.0001698,1.0,0.000219608,1.0,0.00287
mmlu-us-foreign-policy.val.61,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-high-school-chemistry.val.129,mistralai/mistral-7b-chat,0.0,4.24e-05,0.0,4.24e-05,0.0,6.36e-05,0.0,0.0001272,0.0,0.0001645119999999,0.0,0.00213
hellaswag.val.2487,WizardLM/WizardLM-13B-V1.2,0.0,2.97e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.9513,mistralai/mistral-7b-chat,1.0,4.880000000000001e-05,1.0,4.880000000000001e-05,1.0,7.319999999999999e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00245
hellaswag.val.3067,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,0.0,0.00149
mmlu-security-studies.val.163,mistralai/mistral-7b-chat,1.0,3.460000000000001e-05,1.0,3.460000000000001e-05,1.0,5.19e-05,1.0,0.0001038,0.0,0.0001342479999999,1.0,0.0017699999999999
mmlu-philosophy.val.22,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
mbpp.dev.138,mistralai/mistral-7b-chat,0.0,5.8e-05,0.0,5.8e-05,0.0,0.000123,0.0,0.0001889999999999,0.0,0.000297984,0.0,0.01073
mmlu-prehistory.val.138,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.5990,meta/code-llama-instruct-34b-chat,0.25,0.000282464,0.25,7.400000000000001e-05,0.25,0.0001467,0.25,0.0003396,0.25,0.000282464,0.5,0.00761
mmlu-medical-genetics.val.6,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.25e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
hellaswag.val.832,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
hellaswag.val.9858,mistralai/mistral-7b-chat,1.0,5.4600000000000006e-05,1.0,5.4600000000000006e-05,1.0,8.19e-05,1.0,0.0001638,1.0,0.0002118479999999,1.0,0.00277
grade-school-math.dev.4442,WizardLM/WizardLM-13B-V1.2,0.75,0.00018,0.25,9.16e-05,0.75,0.00018,0.5,0.0003162,0.25,0.000402744,0.75,0.01072
mmlu-professional-law.val.1080,mistralai/mistral-7b-chat,0.0,6.0200000000000006e-05,0.0,6.0200000000000006e-05,0.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
grade-school-math.dev.1588,mistralai/mixtral-8x7b-chat,0.75,0.0003606,0.25,0.0001152,0.75,0.0001848,0.75,0.0003606,0.25,0.000476464,0.75,0.01065
grade-school-math.dev.366,WizardLM/WizardLM-13B-V1.2,0.5,0.0001833,0.25,9.1e-05,0.5,0.0001833,0.5,0.0003426,1.0,0.000332904,0.5,0.01174
winogrande.dev.602,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,1.0,3.5696e-05,0.0,0.00047
grade-school-math.dev.2398,WizardLM/WizardLM-13B-V1.2,0.25,0.0001263,0.25,7.840000000000001e-05,0.25,0.0001263,0.25,0.0002538,0.25,0.00027548,0.75,0.00633
mmlu-human-aging.val.156,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.3143,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-law.val.1405,WizardLM/WizardLM-13B-V1.2,1.0,0.0001562999999999,0.0,0.0001042,1.0,0.0001562999999999,0.0,0.000312,0.0,0.000404296,1.0,0.00522
mbpp.dev.339,mistralai/mistral-7b-chat,0.0,5.480000000000001e-05,0.0,5.480000000000001e-05,0.0,9.39e-05,0.0,0.0001793999999999,0.0,9.6224e-05,0.0,0.00573
hellaswag.val.3056,mistralai/mixtral-8x7b-chat,0.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
mmlu-conceptual-physics.val.65,mistralai/mixtral-8x7b-chat,0.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
mmlu-electrical-engineering.val.79,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.00091
mmlu-econometrics.val.49,mistralai/mixtral-8x7b-chat,0.0,0.0001044,0.0,3.4599999999999994e-05,0.0,5.22e-05,0.0,0.0001044,0.0,0.000134248,1.0,0.00178
mmlu-elementary-mathematics.val.293,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.2968,WizardLM/WizardLM-13B-V1.2,0.0,4.05e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
grade-school-math.dev.5168,WizardLM/WizardLM-13B-V1.2,0.75,0.0001584,0.25,7.56e-05,0.75,0.0001584,0.5,0.0001938,0.5,0.000250648,0.5,0.00622
mmlu-professional-law.val.1198,WizardLM/WizardLM-13B-V1.2,0.0,4.98e-05,0.0,3.320000000000001e-05,0.0,4.98e-05,0.0,9.96e-05,0.0,0.000128816,0.0,0.00167
grade-school-math.dev.4808,WizardLM/WizardLM-13B-V1.2,0.75,0.0001274999999999,0.75,8.38e-05,0.75,0.0001274999999999,0.75,0.0002136,0.25,0.00027548,0.75,0.00673
hellaswag.val.4506,mistralai/mixtral-8x7b-chat,1.0,0.0001512,1.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00256
hellaswag.val.8302,mistralai/mixtral-8x7b-chat,1.0,0.0001752,1.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,1.0,0.000226592,1.0,0.00293
mmlu-business-ethics.val.99,mistralai/mistral-7b-chat,1.0,2.7600000000000003e-05,1.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
arc-challenge.test.932,mistralai/mixtral-8x7b-chat,1.0,3.6e-05,0.0,1.2e-05,1.0,1.8e-05,1.0,3.6e-05,1.0,4.656e-05,1.0,0.00061
mmlu-professional-psychology.val.220,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.5263,WizardLM/WizardLM-13B-V1.2,1.0,8.01e-05,1.0,5.360000000000001e-05,1.0,8.01e-05,1.0,0.0001608,1.0,0.0002079679999999,1.0,0.00269
mmlu-high-school-macroeconomics.val.195,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
grade-school-math.dev.3838,WizardLM/WizardLM-13B-V1.2,0.75,0.0001505999999999,0.75,7.2e-05,0.75,0.0001505999999999,0.75,0.0002628,0.75,0.000304968,0.75,0.00791
grade-school-math.dev.4608,WizardLM/WizardLM-13B-V1.2,0.25,0.0001484999999999,0.25,0.0001116,0.25,0.0001484999999999,0.75,0.0003132,0.25,0.000334456,0.5,0.00966
hellaswag.val.8502,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
winogrande.dev.803,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,1.0,1.95e-05,1.0,3.96e-05,1.0,5.1216000000000006e-05,1.0,0.0007
mmlu-prehistory.val.48,WizardLM/WizardLM-13B-V1.2,0.0,3.09e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-accounting.val.191,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
grade-school-math.dev.6905,WizardLM/WizardLM-13B-V1.2,0.75,0.0001803,0.75,6e-05,0.75,0.0001803,0.75,0.0002592,0.75,0.0002413359999999,0.75,0.00703
mmlu-moral-scenarios.val.471,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-moral-scenarios.val.391,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
mmlu-professional-law.val.760,WizardLM/WizardLM-13B-V1.2,1.0,8.58e-05,0.0,5.720000000000001e-05,1.0,8.58e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.00287
mmlu-elementary-mathematics.val.301,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.4774,WizardLM/WizardLM-13B-V1.2,0.75,0.0001869,0.75,9.02e-05,0.75,0.0001869,0.25,0.000312,0.75,0.000375584,0.75,0.00951
mtbench-reference.dev.0,mistralai/mistral-7b-chat,0.1,3.02e-05,0.1,3.02e-05,0.2,0.0001088999999999,0.2,0.0003149999999999,0.1,0.0003561839999999,0.9,0.00668
arc-challenge.test.302,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
grade-school-math.dev.6360,WizardLM/WizardLM-13B-V1.2,0.5,0.0001566,0.25,0.000115,0.5,0.0001566,0.25,0.0003132,0.75,0.000305744,0.75,0.0072
grade-school-math.dev.2595,mistralai/mistral-7b-chat,0.25,8.300000000000001e-05,0.25,8.300000000000001e-05,0.25,0.0001188,0.25,0.0002652,0.0,0.000324368,0.5,0.00814
grade-school-math.dev.3576,WizardLM/WizardLM-13B-V1.2,0.25,0.0002715,0.25,0.000122,0.25,0.0002715,0.25,0.0004091999999999,0.25,0.0003685999999999,0.75,0.01178
winogrande.dev.1111,mistralai/mistral-7b-chat,0.0,1.34e-05,0.0,1.34e-05,1.0,2.01e-05,0.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.00071
mmlu-professional-law.val.315,WizardLM/WizardLM-13B-V1.2,0.0,7.38e-05,1.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.0025
mmlu-professional-law.val.417,WizardLM/WizardLM-13B-V1.2,1.0,7.379999999999999e-05,0.0,4.94e-05,1.0,7.379999999999999e-05,1.0,0.0001482,0.0,0.000191672,1.0,0.00248
grade-school-math.dev.5609,WizardLM/WizardLM-13B-V1.2,0.25,0.0002049,0.0,9.96e-05,0.25,0.0002049,0.25,0.000318,0.25,0.000391104,0.75,0.01345
grade-school-math.dev.5475,WizardLM/WizardLM-13B-V1.2,0.25,0.000153,0.25,9.64e-05,0.25,0.000153,0.25,0.00024,0.25,0.000398864,0.75,0.00833
mmlu-human-aging.val.129,mistralai/mixtral-8x7b-chat,0.0,6.12e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,0.0,0.00103
mmlu-high-school-computer-science.val.6,mistralai/mistral-7b-chat,1.0,4.1200000000000005e-05,1.0,4.1200000000000005e-05,1.0,6.18e-05,0.0,0.0001229999999999,0.0,0.000159856,1.0,0.00207
grade-school-math.dev.4657,WizardLM/WizardLM-13B-V1.2,0.75,0.0001449,0.25,8.620000000000001e-05,0.75,0.0001449,0.25,0.0002304,0.25,0.000284016,0.5,0.0069999999999999
mmlu-high-school-psychology.val.415,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
abstract2title.test.137,mistralai/mixtral-8x7b-chat,1.0,0.000126,1.0,4.1200000000000005e-05,1.0,6.419999999999999e-05,1.0,0.000126,1.0,0.000160632,1.0,0.0027099999999999
hellaswag.val.227,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-professional-law.val.115,WizardLM/WizardLM-13B-V1.2,0.0,8.099999999999999e-05,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,1.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
grade-school-math.dev.5115,WizardLM/WizardLM-13B-V1.2,0.25,0.0001929,0.25,9.64e-05,0.25,0.0001929,0.25,0.0003336,0.25,0.000346872,0.75,0.00858
mmlu-clinical-knowledge.val.49,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-law.val.874,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-global-facts.val.38,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
hellaswag.val.9635,WizardLM/WizardLM-13B-V1.2,1.0,7.56e-05,1.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,1.0,0.000195552,1.0,0.00256
mmlu-professional-medicine.val.243,WizardLM/WizardLM-13B-V1.2,1.0,8.94e-05,0.0,5.9600000000000005e-05,1.0,8.94e-05,1.0,0.0001788,0.0,0.0002312479999999,0.0,0.00299
mmlu-professional-law.val.629,WizardLM/WizardLM-13B-V1.2,1.0,0.0001038,0.0,6.919999999999999e-05,1.0,0.0001038,1.0,0.0002076,0.0,0.000268496,1.0,0.00347
grade-school-math.dev.4306,mistralai/mixtral-8x7b-chat,0.5,0.0002622,0.75,8.86e-05,0.5,0.0001413,0.5,0.0002622,0.75,0.000297984,0.5,0.00676
mmlu-human-aging.val.180,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-high-school-physics.val.105,mistralai/mixtral-8x7b-chat,1.0,9.48e-05,0.0,3.160000000000001e-05,0.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00159
hellaswag.val.1466,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-jurisprudence.val.97,mistralai/mistral-7b-chat,1.0,2.28e-05,1.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-high-school-macroeconomics.val.370,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
bias_detection.dev.208,mistralai/mistral-7b-chat,0.0,5.7400000000000006e-05,0.0,5.7400000000000006e-05,0.0,0.0001253999999999,0.0,0.0001782,0.0,0.000249872,1.0,0.00825
mmlu-sociology.val.198,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
hellaswag.val.1358,WizardLM/WizardLM-13B-V1.2,0.0,4.26e-05,0.0,2.84e-05,0.0,4.26e-05,0.0,8.52e-05,0.0,0.000110192,1.0,0.00143
mmlu-professional-law.val.407,mistralai/mistral-7b-chat,0.0,5.780000000000001e-05,0.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
mmlu-college-mathematics.val.80,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.4630,WizardLM/WizardLM-13B-V1.2,0.75,0.0001725,0.25,0.000104,0.75,0.0001725,0.75,0.000321,0.75,0.00043068,0.75,0.00835
grade-school-math.dev.3177,mistralai/mistral-7b-chat,0.5,0.0001008,0.5,0.0001008,0.5,0.0001487999999999,0.5,0.0002856,0.5,0.000351528,0.5,0.00773
hellaswag.val.6340,mistralai/mixtral-8x7b-chat,1.0,0.0001266,0.0,4.220000000000001e-05,0.0,6.33e-05,1.0,0.0001266,0.0,0.000163736,1.0,0.00215
hellaswag.val.9262,mistralai/mixtral-8x7b-chat,1.0,0.0001674,1.0,5.580000000000001e-05,1.0,8.37e-05,1.0,0.0001674,1.0,0.0002165039999999,1.0,0.00283
mmlu-logical-fallacies.val.88,WizardLM/WizardLM-13B-V1.2,0.0,2.88e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,0.0,0.001
mmlu-logical-fallacies.val.59,WizardLM/WizardLM-13B-V1.2,1.0,2.61e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
arc-challenge.test.322,mistralai/mixtral-8x7b-chat,1.0,3.4800000000000006e-05,1.0,1.16e-05,1.0,1.7400000000000003e-05,1.0,3.4800000000000006e-05,1.0,4.500800000000001e-05,1.0,0.00062
hellaswag.val.4474,WizardLM/WizardLM-13B-V1.2,0.0,7.469999999999999e-05,0.0,5e-05,0.0,7.469999999999999e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
hellaswag.val.233,mistralai/mixtral-8x7b-chat,1.0,8.94e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-moral-scenarios.val.209,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00145
grade-school-math.dev.5082,WizardLM/WizardLM-13B-V1.2,0.5,0.0001557,0.75,9.04e-05,0.5,0.0001557,0.5,0.000276,0.5,0.000344544,0.5,0.00655
hellaswag.val.6776,WizardLM/WizardLM-13B-V1.2,0.0,8.01e-05,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-nutrition.val.44,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,0.0,0.00105
hellaswag.val.4370,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.35e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.0025
grade-school-math.dev.4646,WizardLM/WizardLM-13B-V1.2,0.25,0.0001413,0.75,8.880000000000002e-05,0.25,0.0001413,0.75,0.0002705999999999,0.75,0.000301088,0.75,0.00833
mmlu-college-medicine.val.44,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-high-school-statistics.val.82,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.6766,mistralai/mistral-7b-chat,0.0,3.92e-05,0.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,0.0,0.002
mmlu-high-school-mathematics.val.129,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,0.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
hellaswag.val.1984,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.15e-05,0.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
grade-school-math.dev.4840,WizardLM/WizardLM-13B-V1.2,0.75,0.0001479,0.75,8.78e-05,0.75,0.0001479,0.75,0.0002934,0.75,0.000383344,0.75,0.0075499999999999
hellaswag.val.4384,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,1.0,0.0001446,0.0,0.000187016,1.0,0.00242
mmlu-nutrition.val.222,mistralai/mixtral-8x7b-chat,0.0,6.12e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,0.0,0.00103
grade-school-math.dev.5228,mistralai/mistral-7b-chat,0.25,9.78e-05,0.25,9.78e-05,0.75,0.0001584,0.25,0.0002538,0.5,0.00031428,0.5,0.00633
hellaswag.val.1797,WizardLM/WizardLM-13B-V1.2,1.0,3.72e-05,0.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.0012799999999999
mmlu-college-medicine.val.77,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,0.0,0.00145
grade-school-math.dev.2082,meta/code-llama-instruct-34b-chat,0.5,0.00024832,0.75,6.24e-05,0.75,0.0001241999999999,0.75,0.0002375999999999,0.5,0.00024832,0.75,0.0044399999999999
grade-school-math.dev.3763,mistralai/mistral-7b-chat,0.75,8.840000000000001e-05,0.75,8.840000000000001e-05,0.5,0.0001205999999999,0.5,0.0002123999999999,0.75,0.00025996,0.5,0.00676
mmlu-jurisprudence.val.5,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
consensus_summary.dev.135,mistralai/mistral-7b-chat,0.0,4.66e-05,0.0,4.66e-05,1.0,7.47e-05,0.75,0.000267,0.25,0.000312728,0.75,0.0058
arc-challenge.val.224,mistralai/mistral-7b-chat,1.0,1.44e-05,1.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,1.0,5.5872e-05,1.0,0.00073
hellaswag.val.7813,mistralai/mixtral-8x7b-chat,0.0,0.0001422,0.0,4.74e-05,0.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,0.0,0.00241
mmlu-human-aging.val.11,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,0.0,0.00093
mmlu-miscellaneous.val.353,mistralai/mistral-7b-chat,0.0,1.28e-05,0.0,1.28e-05,0.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
grade-school-math.dev.4270,mistralai/mixtral-8x7b-chat,0.75,0.0002694,0.25,8.800000000000001e-05,0.75,0.0001452,0.75,0.0002694,0.75,0.000328248,0.75,0.00737
mmlu-moral-disputes.val.144,mistralai/mistral-7b-chat,1.0,2.18e-05,1.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-professional-law.val.1520,WizardLM/WizardLM-13B-V1.2,0.0,6.63e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,0.0,0.00222
hellaswag.val.6305,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
mmlu-high-school-statistics.val.151,mistralai/mixtral-8x7b-chat,1.0,7.02e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00121
winogrande.dev.306,mistralai/mistral-7b-chat,0.0,1.1e-05,0.0,1.1e-05,1.0,1.62e-05,0.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00059
grade-school-math.dev.369,WizardLM/WizardLM-13B-V1.2,0.25,0.0001431,0.25,6.560000000000001e-05,0.25,0.0001431,0.25,0.0002454,0.25,0.000265392,0.5,0.00707
hellaswag.val.9766,WizardLM/WizardLM-13B-V1.2,1.0,8.64e-05,1.0,5.76e-05,1.0,8.64e-05,1.0,0.0001728,1.0,0.0002234879999999,1.0,0.00292
hellaswag.val.3531,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,1.0,0.00229
hellaswag.val.558,WizardLM/WizardLM-13B-V1.2,1.0,3.3600000000000004e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
grade-school-math.dev.6027,mistralai/mistral-7b-chat,0.25,7.68e-05,0.25,7.68e-05,0.75,0.000129,0.75,0.0002322,0.75,0.000261512,0.75,0.00569
hellaswag.val.3765,mistralai/mixtral-8x7b-chat,1.0,0.0001458,1.0,4.860000000000001e-05,1.0,7.259999999999999e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00247
mmlu-moral-scenarios.val.460,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
mmlu-international-law.val.7,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-philosophy.val.7,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-moral-scenarios.val.520,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-statistics.val.193,mistralai/mistral-7b-chat,0.0,3.160000000000001e-05,0.0,3.160000000000001e-05,0.0,4.74e-05,0.0,9.42e-05,0.0,0.000122608,0.0,0.00159
hellaswag.val.4565,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,0.0,0.00295
mmlu-moral-disputes.val.279,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
winogrande.dev.297,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,1.0,1.62e-05,0.0,3.24e-05,0.0,4.1128e-05,0.0,0.0005499999999999
mmlu-professional-law.val.150,WizardLM/WizardLM-13B-V1.2,0.0,0.0001545,0.0,0.000103,0.0,0.0001545,1.0,0.000309,0.0,0.00039964,1.0,0.00516
mmlu-professional-law.val.1495,WizardLM/WizardLM-13B-V1.2,1.0,7.35e-05,0.0,4.9000000000000005e-05,1.0,7.35e-05,0.0,0.000147,0.0,0.00019012,0.0,0.00246
hellaswag.val.9738,WizardLM/WizardLM-13B-V1.2,0.0,9.21e-05,0.0,6.14e-05,0.0,9.21e-05,0.0,0.0001842,0.0,0.000238232,1.0,0.00311
hellaswag.val.4389,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
grade-school-math.dev.5413,mistralai/mistral-7b-chat,0.75,9.4e-05,0.75,9.4e-05,0.75,0.000138,0.75,0.0001931999999999,0.75,0.000278584,0.75,0.00771
arc-challenge.test.88,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-anatomy.val.103,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
bias_detection.dev.101,mistralai/mistral-7b-chat,1.0,6.58e-05,1.0,6.58e-05,1.0,0.0001304999999999,0.0,0.0002615999999999,0.0,0.000277032,1.0,0.00791
mmlu-professional-law.val.406,WizardLM/WizardLM-13B-V1.2,0.0,7.92e-05,1.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,0.0,0.00265
mmlu-moral-scenarios.val.235,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00141
mmlu-elementary-mathematics.val.47,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,1.0,2.07e-05,0.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-security-studies.val.77,mistralai/mistral-7b-chat,1.0,3.2000000000000005e-05,1.0,3.2000000000000005e-05,1.0,4.8e-05,1.0,9.6e-05,0.0,0.00012416,1.0,0.00161
grade-school-math.dev.6199,mistralai/mistral-7b-chat,0.5,6.16e-05,0.5,6.16e-05,0.25,0.0001442999999999,0.25,0.0003006,0.25,0.000305744,0.75,0.00695
mmlu-international-law.val.49,WizardLM/WizardLM-13B-V1.2,1.0,3.6e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-professional-law.val.654,WizardLM/WizardLM-13B-V1.2,1.0,0.0001433999999999,0.0,9.56e-05,1.0,0.0001433999999999,0.0,0.0002867999999999,0.0,0.000370928,1.0,0.00479
mmlu-professional-law.val.824,WizardLM/WizardLM-13B-V1.2,0.0,9.45e-05,0.0,6.3e-05,0.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
grade-school-math.dev.6263,mistralai/mistral-7b-chat,0.5,8.54e-05,0.5,8.54e-05,0.5,0.0001395,0.75,0.0002604,0.5,0.000339888,0.5,0.0089699999999999
grade-school-math.dev.2799,WizardLM/WizardLM-13B-V1.2,0.75,0.0001251,0.25,7.960000000000001e-05,0.75,0.0001251,0.75,0.0002316,0.75,0.00028712,0.75,0.00575
arc-challenge.val.55,mistralai/mixtral-8x7b-chat,1.0,6.06e-05,1.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,1.0,7.8376e-05,1.0,0.00105
mmlu-moral-scenarios.val.93,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
grade-school-math.dev.6494,mistralai/mistral-7b-chat,0.25,9.98e-05,0.25,9.98e-05,0.25,0.0001941,0.75,0.0003168,0.25,0.000377136,0.75,0.00922
hellaswag.val.2823,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,1.0,4.44e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-professional-law.val.1177,WizardLM/WizardLM-13B-V1.2,1.0,5.19e-05,1.0,3.460000000000001e-05,1.0,5.19e-05,1.0,0.0001038,0.0,0.0001342479999999,1.0,0.0017699999999999
mmlu-professional-law.val.98,WizardLM/WizardLM-13B-V1.2,1.0,0.0001905,1.0,0.000127,1.0,0.0001905,1.0,0.0003804,0.0,0.00049276,1.0,0.0063599999999999
grade-school-math.dev.625,WizardLM/WizardLM-13B-V1.2,0.75,0.0001373999999999,0.25,8e-05,0.75,0.0001373999999999,0.75,0.000246,0.75,0.000266168,0.75,0.00633
arc-challenge.test.61,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,1.0,5.5872e-05,1.0,0.00076
mmlu-jurisprudence.val.19,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
accounting_audit.dev.25,WizardLM/WizardLM-13B-V1.2,0.0,5.67e-05,0.0,5.92e-05,0.0,5.67e-05,0.0,0.0001133999999999,0.0,0.000146664,1.0,0.00185
grade-school-math.dev.7287,meta/code-llama-instruct-34b-chat,0.25,0.000304968,0.25,0.0001148,0.25,0.0001593,0.25,0.0002892,0.25,0.000304968,0.75,0.01213
grade-school-math.dev.3711,WizardLM/WizardLM-13B-V1.2,0.75,0.0001520999999999,0.25,8.320000000000002e-05,0.75,0.0001520999999999,0.5,0.0002196,0.75,0.000278584,0.5,0.00815
grade-school-math.dev.3282,meta/code-llama-instruct-34b-chat,0.75,0.00032204,0.25,7.48e-05,0.75,0.0001449,0.25,0.0002748,0.75,0.00032204,0.75,0.00678
hellaswag.val.3858,mistralai/mixtral-8x7b-chat,0.0,0.0001404,0.0,4.6800000000000006e-05,1.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00235
mmlu-electrical-engineering.val.11,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
mmlu-prehistory.val.307,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
grade-school-math.dev.4811,meta/code-llama-instruct-34b-chat,0.25,0.000303416,0.75,8.740000000000001e-05,0.25,0.0001491,0.25,0.000249,0.25,0.000303416,0.75,0.00898
grade-school-math.dev.2014,mistralai/mistral-7b-chat,0.75,9e-05,0.75,9e-05,0.75,0.0001449,0.25,0.0002772,0.75,0.000367048,0.5,0.0079499999999999
grade-school-math.dev.1389,WizardLM/WizardLM-13B-V1.2,0.75,0.0001293,0.25,8.219999999999999e-05,0.75,0.0001293,0.25,0.0003126,0.75,0.000305744,0.75,0.00675
winogrande.dev.299,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,0.0,1.62e-05,1.0,3.24e-05,1.0,4.1904e-05,1.0,0.00058
hellaswag.val.6671,mistralai/mixtral-8x7b-chat,0.0,0.0001704,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
mmlu-high-school-biology.val.208,mistralai/mixtral-8x7b-chat,1.0,0.0001104,0.0,3.68e-05,1.0,5.52e-05,1.0,0.0001104,0.0,0.000142784,1.0,0.00185
grade-school-math.dev.3527,WizardLM/WizardLM-13B-V1.2,0.75,0.0001491,0.25,8.14e-05,0.75,0.0001491,0.25,0.000264,0.75,0.000270048,0.75,0.00754
mmlu-professional-medicine.val.244,mistralai/mixtral-8x7b-chat,0.0,0.0001217999999999,0.0,4.06e-05,1.0,6.09e-05,0.0,0.0001217999999999,0.0,0.000157528,1.0,0.00207
mmlu-electrical-engineering.val.141,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,0.0,0.0007999999999999
mmlu-high-school-european-history.val.8,mistralai/mixtral-8x7b-chat,1.0,0.0002622,1.0,8.74e-05,1.0,0.0001311,1.0,0.0002622,0.0,0.000339112,1.0,0.0043799999999999
winogrande.dev.312,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,0.0,1.41e-05,0.0,2.82e-05,0.0,3.5696000000000005e-05,1.0,0.00048
grade-school-math.dev.5724,WizardLM/WizardLM-13B-V1.2,0.25,0.0001824,0.25,0.0001006,0.25,0.0001824,0.25,0.0003006,0.25,0.000383344,0.5,0.01022
mmlu-astronomy.val.113,mistralai/mixtral-8x7b-chat,1.0,7.5e-05,1.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-professional-psychology.val.241,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
mmlu-abstract-algebra.val.54,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
grade-school-math.dev.6784,mistralai/mistral-7b-chat,0.25,9.86e-05,0.25,9.86e-05,0.75,0.0001305,0.5,0.0002063999999999,0.75,0.000282464,0.75,0.0076399999999999
mmlu-high-school-macroeconomics.val.298,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-law.val.1051,WizardLM/WizardLM-13B-V1.2,0.0,5.91e-05,1.0,3.94e-05,0.0,5.91e-05,1.0,0.0001182,0.0,0.0001528719999999,1.0,0.00201
grade-school-math.dev.5678,mistralai/mistral-7b-chat,0.25,0.000101,0.25,0.000101,0.75,0.0001926,0.75,0.0002808,0.25,0.00032592,0.75,0.00997
mmlu-high-school-macroeconomics.val.316,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
grade-school-math.dev.6594,mistralai/mistral-7b-chat,0.25,5.5400000000000005e-05,0.25,5.5400000000000005e-05,0.5,0.0001317,0.25,0.0002052,0.75,0.000292552,0.5,0.00554
mmlu-high-school-mathematics.val.252,mistralai/mixtral-8x7b-chat,1.0,8.58e-05,1.0,2.8600000000000004e-05,1.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,0.0,0.00144
mmlu-human-aging.val.218,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-professional-law.val.914,WizardLM/WizardLM-13B-V1.2,0.0,6.3e-05,0.0,4.2e-05,0.0,6.3e-05,1.0,0.000126,0.0,0.00016296,0.0,0.00211
grade-school-math.dev.7037,WizardLM/WizardLM-13B-V1.2,0.25,0.0001917,0.25,9.92e-05,0.25,0.0001917,0.25,0.0003084,0.25,0.000424472,0.75,0.01275
mmlu-professional-law.val.1102,WizardLM/WizardLM-13B-V1.2,0.0,8.699999999999999e-05,1.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,0.0,0.00291
hellaswag.val.7835,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-high-school-psychology.val.496,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.7294,WizardLM/WizardLM-13B-V1.2,0.25,0.0001671,0.25,0.0001124,0.25,0.0001671,0.25,0.0003042,0.25,0.000393432,0.5,0.00913
hellaswag.val.2905,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,1.0,6e-05,1.0,7.76e-05,1.0,0.00104
grade-school-math.dev.2146,mistralai/mixtral-8x7b-chat,0.75,0.000267,0.25,9.34e-05,0.75,0.0001418999999999,0.75,0.000267,0.5,0.000254528,0.5,0.00537
arc-challenge.test.354,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,1.0,6.1304e-05,1.0,0.0007999999999999
arc-challenge.test.143,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
grade-school-math.dev.3312,mistralai/mistral-7b-chat,0.25,6.520000000000001e-05,0.25,6.520000000000001e-05,0.25,0.0001614,0.75,0.0002705999999999,0.25,0.000336784,0.5,0.00854
grade-school-math.dev.2437,WizardLM/WizardLM-13B-V1.2,0.25,0.0001532999999999,0.25,8.760000000000002e-05,0.25,0.0001532999999999,0.25,0.0002766,0.25,0.000290224,0.75,0.00933
hellaswag.val.6678,mistralai/mixtral-8x7b-chat,1.0,0.0001602,1.0,5.34e-05,0.0,7.979999999999999e-05,1.0,0.0001602,1.0,0.000207192,1.0,0.00268
hellaswag.val.6509,mistralai/mixtral-8x7b-chat,0.0,0.0001326,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00222
grade-school-math.dev.5824,WizardLM/WizardLM-13B-V1.2,0.75,0.0001428,0.75,6.780000000000001e-05,0.75,0.0001428,0.75,0.0002399999999999,0.75,0.000262288,0.75,0.00752
mmlu-high-school-physics.val.113,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00101
mmlu-professional-psychology.val.598,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
mmlu-moral-scenarios.val.371,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00148
consensus_summary.dev.284,mistralai/mixtral-8x7b-chat,0.75,0.0001949999999999,0.75,5.640000000000001e-05,0.0,0.0002913,0.75,0.0001949999999999,0.75,0.000252976,0.0,0.00203
mmlu-nutrition.val.133,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,0.0,0.00128
arc-challenge.test.1014,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,1.0,0.000100104,1.0,0.0013
mmlu-college-biology.val.67,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,1.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-professional-law.val.278,WizardLM/WizardLM-13B-V1.2,0.0,7.56e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,0.0,0.00253
mmlu-prehistory.val.79,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,0.0,0.00086
hellaswag.val.1586,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-high-school-geography.val.104,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
mmlu-clinical-knowledge.val.179,mistralai/mixtral-8x7b-chat,0.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00089
mmlu-professional-law.val.1364,WizardLM/WizardLM-13B-V1.2,1.0,0.0001029,0.0,6.86e-05,1.0,0.0001029,1.0,0.0002058,0.0,0.0002661679999999,0.0,0.00344
hellaswag.val.4497,mistralai/mixtral-8x7b-chat,0.0,0.0001458,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,0.0,0.00247
mbpp.dev.189,mistralai/mistral-7b-chat,1.0,5.22e-05,1.0,5.22e-05,1.0,8.73e-05,1.0,6.78e-05,1.0,9.1568e-05,1.0,0.00428
hellaswag.val.8525,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,0.0,7.409999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-moral-scenarios.val.263,mistralai/mistral-7b-chat,0.0,3.02e-05,0.0,3.02e-05,0.0,4.53e-05,0.0,9.06e-05,0.0,0.000117176,1.0,0.00155
mmlu-professional-psychology.val.437,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.7438,mistralai/mixtral-8x7b-chat,1.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.619999999999998e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00259
hellaswag.val.8261,mistralai/mixtral-8x7b-chat,1.0,0.0001487999999999,1.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
mmlu-marketing.val.229,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,0.0,0.00098
mmlu-management.val.7,mistralai/mistral-7b-chat,1.0,1.44e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
winogrande.dev.800,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,0.0,1.56e-05,0.0,3.12e-05,0.0,3.9576e-05,1.0,0.00053
grade-school-math.dev.2457,mistralai/mistral-7b-chat,0.25,0.000128,0.25,0.000128,0.25,0.0001914,0.75,0.0003102,0.25,0.0004190399999999,0.5,0.00943
grade-school-math.dev.5442,mistralai/mixtral-8x7b-chat,0.75,0.0002459999999999,0.75,0.0001018,0.75,0.0001803,0.75,0.0002459999999999,0.25,0.00042292,0.5,0.01028
mmlu-moral-scenarios.val.384,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00145
hellaswag.val.6886,WizardLM/WizardLM-13B-V1.2,0.0,7.71e-05,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
winogrande.dev.1040,mistralai/mixtral-8x7b-chat,1.0,3.4800000000000006e-05,1.0,1.16e-05,0.0,1.7400000000000003e-05,1.0,3.4800000000000006e-05,1.0,4.500800000000001e-05,1.0,0.00062
grade-school-math.dev.4722,mistralai/mistral-7b-chat,0.25,8.060000000000001e-05,0.25,8.060000000000001e-05,0.75,0.0001716,0.75,0.0002766,0.75,0.000320488,0.5,0.00739
hellaswag.val.9850,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00242
mmlu-electrical-engineering.val.97,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
hellaswag.val.4647,mistralai/mixtral-8x7b-chat,1.0,0.0001193999999999,1.0,3.980000000000001e-05,1.0,5.97e-05,1.0,0.0001193999999999,1.0,0.000154424,1.0,0.00203
hellaswag.val.8996,mistralai/mistral-7b-chat,0.0,5.300000000000001e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00266
winogrande.dev.401,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,0.0,4.1128e-05,1.0,0.00057
mmlu-high-school-world-history.val.59,WizardLM/WizardLM-13B-V1.2,1.0,7.89e-05,0.0,5.260000000000001e-05,1.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00264
hellaswag.val.9439,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
hellaswag.val.3857,mistralai/mistral-7b-chat,0.0,4.420000000000001e-05,0.0,4.420000000000001e-05,0.0,6.599999999999999e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00225
grade-school-math.dev.1844,mistralai/mixtral-8x7b-chat,0.75,0.0002219999999999,0.25,7.56e-05,0.75,0.0001305,0.75,0.0002219999999999,0.25,0.000285568,0.75,0.00673
hellaswag.val.1258,mistralai/mixtral-8x7b-chat,1.0,7.44e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,1.0,9.6224e-05,1.0,0.00125
mmlu-professional-law.val.678,WizardLM/WizardLM-13B-V1.2,0.0,6.39e-05,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00214
grade-school-math.dev.4614,WizardLM/WizardLM-13B-V1.2,0.25,0.0001257,0.25,8.36e-05,0.25,0.0001257,0.25,0.0003107999999999,0.75,0.000280136,0.75,0.00862
grade-school-math.dev.2950,WizardLM/WizardLM-13B-V1.2,0.5,0.0001719,0.25,9.86e-05,0.5,0.0001719,0.25,0.0002045999999999,0.25,0.00030652,0.75,0.00695
consensus_summary.dev.157,mistralai/mistral-7b-chat,0.25,4.100000000000001e-05,0.25,4.100000000000001e-05,0.25,9.48e-05,0.25,0.0001668,0.75,0.000323592,0.25,0.00213
mmlu-professional-law.val.1104,WizardLM/WizardLM-13B-V1.2,1.0,6.81e-05,0.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,0.0,0.0001761519999999,1.0,0.00228
mmlu-college-mathematics.val.70,mistralai/mixtral-8x7b-chat,0.0,0.0001104,0.0,3.7000000000000005e-05,1.0,5.55e-05,0.0,0.0001104,0.0,0.00014356,0.0,0.00186
mmlu-jurisprudence.val.104,mistralai/mistral-7b-chat,1.0,2.68e-05,1.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-elementary-mathematics.val.303,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6200000000000005e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-high-school-biology.val.119,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,1.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-professional-medicine.val.52,mistralai/mixtral-8x7b-chat,1.0,0.0001122,0.0,3.74e-05,1.0,5.61e-05,1.0,0.0001122,0.0,0.000145112,1.0,0.00188
mmlu-college-physics.val.56,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,0.0,0.00123
mmlu-high-school-mathematics.val.22,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,0.0,4.68e-05,0.0,6.1304e-05,0.0,0.0007999999999999
mmlu-elementary-mathematics.val.328,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.0015
mmlu-computer-security.val.80,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.52e-05,0.0,5.1e-05,1.0,6.596e-05,1.0,0.00089
grade-school-math.dev.5915,mistralai/mistral-7b-chat,0.25,7.36e-05,0.25,7.36e-05,0.75,0.000186,0.25,0.000237,0.75,0.000282464,0.75,0.00545
hellaswag.val.8699,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00271
arc-challenge.val.261,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
mmlu-professional-law.val.877,WizardLM/WizardLM-13B-V1.2,0.0,6.57e-05,0.0,4.380000000000001e-05,0.0,6.57e-05,1.0,0.0001314,0.0,0.0001699439999999,1.0,0.0022
mmlu-high-school-macroeconomics.val.244,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-professional-law.val.221,WizardLM/WizardLM-13B-V1.2,0.0,0.0001137,1.0,7.58e-05,0.0,0.0001137,0.0,0.0002274,0.0,0.000294104,1.0,0.0038
hellaswag.val.2107,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-prehistory.val.292,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.4773,mistralai/mixtral-8x7b-chat,0.0,0.0002196,1.0,7.34e-05,1.0,0.0001101,0.0,0.0002196,1.0,0.000284792,1.0,0.00371
grade-school-math.dev.2119,WizardLM/WizardLM-13B-V1.2,0.75,0.0001721999999999,0.75,8.78e-05,0.75,0.0001721999999999,0.75,0.0002934,0.75,0.000260736,0.75,0.00827
mmlu-high-school-mathematics.val.193,mistralai/mistral-7b-chat,1.0,3.08e-05,1.0,3.08e-05,0.0,4.6200000000000005e-05,0.0,9.24e-05,0.0,0.000119504,0.0,0.00155
grade-school-math.dev.482,WizardLM/WizardLM-13B-V1.2,0.5,0.0001593,0.5,0.0001024,0.5,0.0001593,0.75,0.0002663999999999,0.5,0.000325144,0.75,0.00709
hellaswag.val.7045,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.2e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00242
mmlu-professional-law.val.1226,WizardLM/WizardLM-13B-V1.2,0.0,9.6e-05,1.0,6.4e-05,0.0,9.6e-05,1.0,0.0001919999999999,0.0,0.00024832,1.0,0.00321
grade-school-math.dev.919,mistralai/mistral-7b-chat,0.25,7.92e-05,0.25,7.92e-05,0.25,0.0001593,0.25,0.000237,0.25,0.00035308,0.75,0.00831
grade-school-math.dev.7312,mistralai/mistral-7b-chat,0.25,9.64e-05,0.25,9.64e-05,0.25,0.0001584,0.75,0.0002694,0.75,0.000381016,0.75,0.0086299999999999
mmlu-high-school-psychology.val.327,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-marketing.val.198,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-professional-law.val.65,WizardLM/WizardLM-13B-V1.2,0.0,0.0001442999999999,1.0,9.62e-05,0.0,0.0001442999999999,0.0,0.0002885999999999,0.0,0.000373256,1.0,0.00482
grade-school-math.dev.4876,WizardLM/WizardLM-13B-V1.2,0.25,0.0001758,0.25,0.000101,0.25,0.0001758,0.25,0.0002736,0.25,0.000323592,0.75,0.01073
mmlu-professional-law.val.281,WizardLM/WizardLM-13B-V1.2,0.0,0.0001278,0.0,8.520000000000001e-05,0.0,0.0001278,1.0,0.0002556,0.0,0.000330576,1.0,0.0042699999999999
hellaswag.val.3289,WizardLM/WizardLM-13B-V1.2,0.0,6.69e-05,0.0,4.460000000000001e-05,0.0,6.69e-05,0.0,0.0001338,0.0,0.000173048,1.0,0.00227
grade-school-math.dev.2819,mistralai/mistral-7b-chat,0.25,8.26e-05,0.25,8.26e-05,0.25,0.0001437,0.25,0.0002885999999999,0.25,0.000325144,0.75,0.0070399999999999
hellaswag.val.1607,WizardLM/WizardLM-13B-V1.2,0.0,4.2e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
hellaswag.val.4464,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.9e-05,0.0,8.819999999999999e-05,0.0,0.000177,0.0,0.0002289199999999,0.0,0.00296
grade-school-math.dev.5595,mistralai/mistral-7b-chat,0.25,9.18e-05,0.25,9.18e-05,0.5,0.0001442999999999,0.75,0.0002598,0.25,0.000239008,0.75,0.00733
grade-school-math.dev.5361,WizardLM/WizardLM-13B-V1.2,0.25,0.000162,0.25,0.0001048,0.25,0.000162,0.5,0.0003318,0.5,0.000324368,0.75,0.01099
mmlu-management.val.48,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.9311,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
mmlu-moral-disputes.val.70,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-human-aging.val.84,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
grade-school-math.dev.4373,mistralai/mistral-7b-chat,0.25,9.48e-05,0.25,9.48e-05,0.0,0.0001737,0.75,0.0002916,0.25,0.000338336,0.5,0.00926
mmlu-logical-fallacies.val.14,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.4276,mistralai/mistral-7b-chat,0.0,9.06e-05,0.0,9.06e-05,0.25,0.0001592999999999,0.75,0.0003095999999999,0.75,0.00032592,0.75,0.00763
mmlu-professional-law.val.1025,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-high-school-biology.val.61,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,1.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00134
hellaswag.val.9690,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,1.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
mmlu-moral-scenarios.val.301,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-high-school-chemistry.val.146,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-moral-scenarios.val.280,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,0.0,0.00138
mmlu-high-school-psychology.val.430,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-philosophy.val.75,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-miscellaneous.val.768,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
grade-school-math.dev.2231,WizardLM/WizardLM-13B-V1.2,0.75,0.0001467,0.75,8.900000000000001e-05,0.75,0.0001467,0.25,0.0002232,0.25,0.00026384,0.75,0.00724
mmlu-miscellaneous.val.263,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.1742,mistralai/mixtral-8x7b-chat,0.0,8.1e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
grade-school-math.dev.1621,mistralai/mistral-7b-chat,0.0,9.28e-05,0.0,9.28e-05,0.75,0.0001205999999999,0.25,0.0002382,0.75,0.000340664,0.75,0.00503
arc-challenge.test.399,WizardLM/WizardLM-13B-V1.2,1.0,3.3e-05,1.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,1.0,8.536000000000001e-05,1.0,0.00114
mmlu-professional-law.val.1161,WizardLM/WizardLM-13B-V1.2,1.0,8.85e-05,0.0,5.9e-05,1.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
mmlu-moral-scenarios.val.478,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-virology.val.105,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00099
grade-school-math.dev.46,mistralai/mistral-7b-chat,0.75,7.560000000000001e-05,0.75,7.560000000000001e-05,0.25,0.0001704,0.5,0.0002544,0.25,0.00028712,0.75,0.00719
hellaswag.val.3492,mistralai/mixtral-8x7b-chat,1.0,0.0001422,1.0,4.74e-05,1.0,7.08e-05,1.0,0.0001422,1.0,0.000183912,1.0,0.00241
mmlu-nutrition.val.171,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
winogrande.dev.4,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,1.0,0.00052
mmlu-high-school-macroeconomics.val.173,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.8338,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
hellaswag.val.3473,WizardLM/WizardLM-13B-V1.2,1.0,6.569999999999998e-05,1.0,4.4000000000000006e-05,1.0,6.569999999999998e-05,1.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
grade-school-math.dev.6413,WizardLM/WizardLM-13B-V1.2,0.25,0.0001677,0.25,0.0001006,0.25,0.0001677,0.75,0.0003114,0.75,0.000301088,0.75,0.00799
grade-school-math.dev.4545,WizardLM/WizardLM-13B-V1.2,0.75,0.0001617,0.25,7.86e-05,0.75,0.0001617,0.25,0.0002502,0.25,0.000288672,0.75,0.0144199999999999
grade-school-math.dev.2694,mistralai/mixtral-8x7b-chat,0.75,0.0002063999999999,0.25,0.000114,0.75,0.0001539,0.75,0.0002063999999999,0.25,0.00027548,0.75,0.00872
mmlu-philosophy.val.293,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
mmlu-high-school-chemistry.val.27,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
grade-school-math.dev.6302,mistralai/mixtral-8x7b-chat,0.25,0.0002718,0.25,9.48e-05,0.25,0.0001944,0.25,0.0002718,0.25,0.000354632,0.75,0.00748
hellaswag.val.6718,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00242
grade-school-math.dev.6528,mistralai/mixtral-8x7b-chat,0.0,0.0002195999999999,0.5,7.82e-05,0.25,0.0001406999999999,0.0,0.0002195999999999,0.5,0.000270824,0.5,0.0065
grade-school-math.dev.2065,mistralai/mistral-7b-chat,0.5,8.2e-05,0.5,8.2e-05,0.5,0.0001407,0.25,0.0002339999999999,0.25,0.000317384,0.75,0.00739
grade-school-math.dev.1255,WizardLM/WizardLM-13B-V1.2,0.75,0.0001233,0.25,8.9e-05,0.75,0.0001233,0.25,0.0003042,0.25,0.00032204,0.25,0.0098
hellaswag.val.9435,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.0024
grade-school-math.dev.5218,WizardLM/WizardLM-13B-V1.2,0.25,0.0002111999999999,0.25,0.000101,0.25,0.0002111999999999,0.25,0.0002363999999999,0.25,0.000348424,0.25,0.01573
hellaswag.val.7475,mistralai/mixtral-8x7b-chat,1.0,0.000138,0.0,4.600000000000001e-05,0.0,6.869999999999999e-05,1.0,0.000138,0.0,0.0001784799999999,1.0,0.00234
mmlu-professional-law.val.1492,WizardLM/WizardLM-13B-V1.2,1.0,0.0001406999999999,0.0,9.38e-05,1.0,0.0001406999999999,1.0,0.0002813999999999,0.0,0.000363944,1.0,0.0046999999999999
mmlu-moral-scenarios.val.707,mistralai/mistral-7b-chat,0.0,3.24e-05,0.0,3.24e-05,0.0,4.86e-05,1.0,9.72e-05,0.0,0.000125712,0.0,0.00166
mmlu-college-computer-science.val.64,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.4740,WizardLM/WizardLM-13B-V1.2,0.0,6.989999999999999e-05,0.0,4.6800000000000006e-05,0.0,6.989999999999999e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.5845,WizardLM/WizardLM-13B-V1.2,0.25,0.0001746,0.25,0.0001032,0.25,0.0001746,0.75,0.0003054,0.25,0.000388776,0.5,0.0095
mmlu-professional-law.val.960,mistralai/mistral-7b-chat,0.0,7.96e-05,0.0,7.96e-05,1.0,0.0001194,0.0,0.0002382,0.0,0.0003088479999999,1.0,0.00399
hellaswag.val.7979,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-moral-disputes.val.213,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
hellaswag.val.9909,mistralai/mistral-7b-chat,1.0,5.64e-05,1.0,5.64e-05,1.0,8.429999999999999e-05,1.0,0.0001692,0.0,0.000218832,1.0,0.00286
mbpp.dev.123,mistralai/mixtral-8x7b-chat,1.0,0.0002795999999999,0.0,9.18e-05,0.0,0.0001460999999999,1.0,0.0002795999999999,0.0,0.000176928,1.0,0.01842
hellaswag.val.4084,mistralai/mistral-7b-chat,1.0,6.120000000000001e-05,1.0,6.120000000000001e-05,1.0,9.18e-05,1.0,0.0001836,0.0,0.0002374559999999,1.0,0.00307
hellaswag.val.7074,WizardLM/WizardLM-13B-V1.2,1.0,8.519999999999998e-05,0.0,5.7e-05,1.0,8.519999999999998e-05,0.0,0.0001703999999999,0.0,0.00022116,1.0,0.00289
mmlu-professional-law.val.1320,WizardLM/WizardLM-13B-V1.2,0.0,0.0001347,1.0,8.98e-05,0.0,0.0001347,0.0,0.0002694,0.0,0.000348424,0.0,0.0045
abstract2title.test.105,mistralai/mixtral-8x7b-chat,1.0,0.0001326,1.0,4.08e-05,1.0,6.69e-05,1.0,0.0001326,1.0,0.000168392,1.0,0.00272
mmlu-professional-law.val.562,WizardLM/WizardLM-13B-V1.2,1.0,7.56e-05,0.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00253
mmlu-high-school-physics.val.70,mistralai/mixtral-8x7b-chat,0.0,6.06e-05,1.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-high-school-psychology.val.2,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
mmlu-anatomy.val.59,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,0.0,0.00082
mmlu-professional-medicine.val.70,WizardLM/WizardLM-13B-V1.2,0.0,7.41e-05,0.0,4.94e-05,0.0,7.41e-05,1.0,0.0001482,0.0,0.000191672,1.0,0.00251
grade-school-math.dev.3788,mistralai/mistral-7b-chat,0.25,9.26e-05,0.25,9.26e-05,0.75,0.0001611,0.25,0.0002652,0.75,0.000478016,0.25,0.01059
hellaswag.val.7817,mistralai/mixtral-8x7b-chat,1.0,0.0001404,0.0,4.6800000000000006e-05,0.0,7.02e-05,1.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.157,mistralai/mistral-7b-chat,0.25,0.0001092,0.25,0.0001092,0.25,0.0001659,0.25,0.0002598,0.25,0.000355408,0.75,0.00893
hellaswag.val.6557,WizardLM/WizardLM-13B-V1.2,0.0,6.36e-05,0.0,4.24e-05,0.0,6.36e-05,1.0,0.0001272,0.0,0.0001645119999999,1.0,0.00216
grade-school-math.dev.5265,mistralai/mistral-7b-chat,0.25,8.14e-05,0.25,8.14e-05,0.5,0.0001487999999999,0.25,0.0002604,0.25,0.000351528,0.75,0.00825
hellaswag.val.5640,mistralai/mistral-7b-chat,0.0,5.420000000000001e-05,0.0,5.420000000000001e-05,0.0,8.13e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
mmlu-security-studies.val.183,mistralai/mistral-7b-chat,1.0,4.7e-05,1.0,4.7e-05,1.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
hellaswag.val.1269,mistralai/mixtral-8x7b-chat,0.0,0.000117,0.0,3.9000000000000006e-05,0.0,5.82e-05,0.0,0.000117,0.0,0.0001513199999999,1.0,0.00196
mmlu-professional-law.val.1378,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
arc-challenge.test.959,mistralai/mixtral-8x7b-chat,1.0,3.78e-05,1.0,1.26e-05,1.0,1.89e-05,1.0,3.78e-05,0.0,4.8888e-05,1.0,0.00067
hellaswag.val.5619,mistralai/mistral-7b-chat,1.0,4.860000000000001e-05,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00247
mmlu-professional-psychology.val.446,mistralai/mixtral-8x7b-chat,0.0,7.68e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
grade-school-math.dev.6565,WizardLM/WizardLM-13B-V1.2,0.75,0.0001302,0.75,7.680000000000001e-05,0.75,0.0001302,0.75,0.0002196,0.5,0.000273928,0.5,0.00628
mmlu-high-school-biology.val.101,mistralai/mixtral-8x7b-chat,1.0,0.0001086,0.0,3.6200000000000006e-05,1.0,5.43e-05,1.0,0.0001086,0.0,0.0001404559999999,1.0,0.00182
mmlu-high-school-world-history.val.134,mistralai/mixtral-8x7b-chat,1.0,0.0002735999999999,1.0,9.12e-05,1.0,0.0001367999999999,1.0,0.0002735999999999,0.0,0.000353856,1.0,0.0045699999999999
winogrande.dev.117,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,1.0,1.62e-05,0.0,3.24e-05,1.0,4.1904e-05,1.0,0.00058
mmlu-miscellaneous.val.86,mistralai/mixtral-8x7b-chat,1.0,3.72e-05,1.0,1.24e-05,1.0,1.83e-05,1.0,3.72e-05,0.0,4.8112e-05,1.0,0.0006299999999999
mmlu-anatomy.val.22,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00102
hellaswag.val.5679,mistralai/mistral-7b-chat,1.0,4.600000000000001e-05,1.0,4.600000000000001e-05,1.0,6.9e-05,1.0,0.000138,1.0,0.0001784799999999,1.0,0.00234
mmlu-professional-law.val.949,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,1.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
hellaswag.val.8790,mistralai/mixtral-8x7b-chat,1.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.95e-05,1.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
grade-school-math.dev.4491,mistralai/mistral-7b-chat,0.75,6.88e-05,0.75,6.88e-05,0.5,0.0001250999999999,0.75,0.0002303999999999,0.75,0.000253752,0.75,0.00502
grade-school-math.dev.909,meta/code-llama-instruct-34b-chat,0.5,0.000581224,0.25,0.000104,0.25,0.000183,0.5,0.0002616,0.5,0.000581224,0.5,0.01209
hellaswag.val.5920,mistralai/mixtral-8x7b-chat,1.0,0.0001649999999999,1.0,5.5e-05,1.0,8.249999999999999e-05,1.0,0.0001649999999999,1.0,0.0002134,1.0,0.00279
mmlu-professional-accounting.val.278,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,1.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
arc-challenge.val.281,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,1.0,5.5096e-05,1.0,0.0007199999999999
winogrande.dev.711,mistralai/mixtral-8x7b-chat,1.0,3.66e-05,1.0,1.22e-05,1.0,1.83e-05,1.0,3.66e-05,0.0,4.7336e-05,1.0,0.00065
hellaswag.val.8426,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,0.0,0.00273
mmlu-sociology.val.146,mistralai/mistral-7b-chat,1.0,2.4800000000000003e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
grade-school-math.dev.6017,WizardLM/WizardLM-13B-V1.2,0.25,0.0001376999999999,0.25,7.9e-05,0.25,0.0001376999999999,0.75,0.0002466,0.5,0.000284016,0.5,0.00879
consensus_summary.dev.342,mistralai/mixtral-8x7b-chat,0.75,0.0002142,0.75,7.860000000000001e-05,0.75,0.0001178999999999,0.75,0.0002142,0.75,0.000273152,0.75,0.0046099999999999
hellaswag.val.9338,mistralai/mistral-7b-chat,0.0,5.5400000000000005e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
grade-school-math.dev.1366,mistralai/mistral-7b-chat,0.25,5.4000000000000005e-05,0.25,5.4000000000000005e-05,0.75,0.000129,1.0,0.0002298,0.25,0.000222712,0.75,0.00549
grade-school-math.dev.5984,meta/code-llama-instruct-34b-chat,0.25,0.000299536,0.25,8.42e-05,0.25,0.0001491,0.75,0.0002838,0.25,0.000299536,0.75,0.00752
grade-school-math.dev.4070,mistralai/mistral-7b-chat,0.25,0.0001226,0.25,0.0001226,0.25,0.0002066999999999,0.0,0.0003648,0.25,0.000398864,0.25,0.01219
mmlu-elementary-mathematics.val.233,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
hellaswag.val.3013,WizardLM/WizardLM-13B-V1.2,0.0,3.54e-05,0.0,2.36e-05,0.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
hellaswag.val.8203,mistralai/mixtral-8x7b-chat,1.0,0.0001889999999999,1.0,6.3e-05,1.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,0.0,0.00316
grade-school-math.dev.417,WizardLM/WizardLM-13B-V1.2,0.75,0.0001368,0.25,7.88e-05,0.75,0.0001368,0.75,0.0002514,0.75,0.000277032,0.75,0.00662
mmlu-world-religions.val.146,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
grade-school-math.dev.7146,mistralai/mistral-7b-chat,0.25,0.0001072,0.25,0.0001072,0.25,0.000201,0.25,0.0003318,0.25,0.000353856,0.75,0.01129
hellaswag.val.7753,WizardLM/WizardLM-13B-V1.2,1.0,6.36e-05,1.0,4.24e-05,1.0,6.36e-05,1.0,0.0001272,1.0,0.0001645119999999,1.0,0.00216
hellaswag.val.3874,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,0.0,0.0024
hellaswag.val.9314,mistralai/mistral-7b-chat,0.0,5.64e-05,0.0,5.64e-05,0.0,8.46e-05,0.0,0.0001692,0.0,0.000218832,1.0,0.00286
grade-school-math.dev.4617,WizardLM/WizardLM-13B-V1.2,0.5,0.0001233,0.25,9.4e-05,0.5,0.0001233,0.25,0.0002634,0.75,0.000370152,0.75,0.0077399999999999
mmlu-miscellaneous.val.234,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-clinical-knowledge.val.257,mistralai/mistral-7b-chat,1.0,1.54e-05,1.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
hellaswag.val.5406,mistralai/mistral-7b-chat,0.0,4.84e-05,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00246
mmlu-professional-law.val.1461,mistralai/mistral-7b-chat,0.0,4.920000000000001e-05,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.00247
hellaswag.val.9580,mistralai/mistral-7b-chat,0.0,4.720000000000001e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,0.0,0.0024
mmlu-professional-law.val.1323,WizardLM/WizardLM-13B-V1.2,1.0,6.21e-05,0.0,4.14e-05,1.0,6.21e-05,1.0,0.0001242,0.0,0.000160632,1.0,0.00208
hellaswag.val.8690,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-philosophy.val.252,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-miscellaneous.val.634,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-sociology.val.58,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-prehistory.val.121,mistralai/mixtral-8x7b-chat,0.0,4.6200000000000005e-05,1.0,1.54e-05,1.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
grade-school-math.dev.4666,meta/code-llama-instruct-34b-chat,0.25,0.000305744,0.25,0.0001094,0.75,0.0001598999999999,0.75,0.0002496,0.25,0.000305744,0.75,0.00711
hellaswag.val.3010,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,1.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
grade-school-math.dev.1789,WizardLM/WizardLM-13B-V1.2,0.25,0.0001542,0.25,7.680000000000001e-05,0.25,0.0001542,0.25,0.0002472,0.75,0.0003298,0.5,0.00794
hellaswag.val.1528,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-professional-law.val.858,WizardLM/WizardLM-13B-V1.2,0.0,0.0001815,0.0,0.000121,0.0,0.0001815,1.0,0.000363,0.0,0.00046948,1.0,0.0060599999999999
hellaswag.val.668,WizardLM/WizardLM-13B-V1.2,1.0,3.78e-05,0.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
hellaswag.val.8573,WizardLM/WizardLM-13B-V1.2,0.0,8.099999999999999e-05,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,0.0,0.00274
grade-school-math.dev.4509,mistralai/mistral-7b-chat,0.25,0.0001064,0.25,0.0001064,0.25,0.0001998,0.25,0.0003156,0.25,0.00046172,0.5,0.00904
mmlu-international-law.val.119,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,1.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
grade-school-math.dev.5347,mistralai/mistral-7b-chat,0.5,8.620000000000001e-05,0.5,8.620000000000001e-05,0.75,0.0001728,0.75,0.0002454,0.5,0.00037636,0.75,0.00683
hellaswag.val.388,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,1.0,4.05e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-computer-security.val.77,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-professional-law.val.263,WizardLM/WizardLM-13B-V1.2,0.0,6.36e-05,1.0,4.24e-05,0.0,6.36e-05,0.0,0.0001272,0.0,0.0001645119999999,1.0,0.00213
grade-school-math.dev.5888,WizardLM/WizardLM-13B-V1.2,0.25,0.0001416,0.25,7.060000000000001e-05,0.25,0.0001416,0.25,0.0002712,0.25,0.000384896,0.25,0.00825
mmlu-professional-law.val.898,WizardLM/WizardLM-13B-V1.2,0.0,0.0001467,0.0,9.78e-05,0.0,0.0001467,0.0,0.0002934,0.0,0.000379464,0.0,0.0049
mmlu-high-school-macroeconomics.val.301,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-global-facts.val.98,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,0.0,0.00081
arc-challenge.test.1139,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,1.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,1.0,8.768799999999999e-05,1.0,0.00117
mmlu-world-religions.val.2,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-high-school-world-history.val.209,mistralai/mixtral-8x7b-chat,1.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,1.0,0.000156,0.0,0.00020176,1.0,0.00261
grade-school-math.dev.6315,mistralai/mistral-7b-chat,0.25,5.9600000000000005e-05,0.25,5.9600000000000005e-05,0.75,0.0001458,0.25,0.0001938,0.75,0.000245992,0.75,0.00624
arc-challenge.test.691,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,1.0,6.4408e-05,1.0,0.00087
bias_detection.dev.260,mistralai/mixtral-8x7b-chat,0.0,0.0001818,0.0,6.6e-05,0.0,9.48e-05,0.0,0.0001818,0.0,0.000277032,1.0,0.00809
mmlu-clinical-knowledge.val.65,mistralai/mixtral-8x7b-chat,0.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,0.0,0.0009
mmlu-miscellaneous.val.23,mistralai/mixtral-8x7b-chat,0.0,4.32e-05,1.0,1.44e-05,1.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,1.0,0.00076
grade-school-math.dev.563,mistralai/mistral-7b-chat,0.75,8.02e-05,0.75,8.02e-05,0.75,0.0001395,0.75,0.0002292,0.75,0.000320488,0.75,0.0064399999999999
winogrande.dev.761,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
grade-school-math.dev.2836,mistralai/mistral-7b-chat,0.75,6.08e-05,0.75,6.08e-05,0.75,0.0001059,0.75,0.0002052,0.25,0.0002421119999999,0.5,0.00562
mmlu-professional-law.val.171,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,1.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.0028
hellaswag.val.7041,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,0.0,0.00275
mmlu-professional-accounting.val.138,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.5468,mistralai/mixtral-8x7b-chat,0.0,0.0001409999999999,0.0,4.7e-05,0.0,7.019999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
mmlu-international-law.val.17,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-prehistory.val.68,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-global-facts.val.99,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,1.0,0.00076
grade-school-math.dev.2999,mistralai/mistral-7b-chat,0.25,9.86e-05,0.25,9.86e-05,0.25,0.0001430999999999,0.25,0.0003107999999999,0.25,0.000437664,0.75,0.00889
hellaswag.val.3483,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,0.0,0.00254
mmlu-professional-psychology.val.81,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-moral-scenarios.val.809,mistralai/mistral-7b-chat,0.0,3.02e-05,0.0,3.02e-05,0.0,4.53e-05,0.0,9.06e-05,0.0,0.000117176,1.0,0.00152
grade-school-math.dev.7010,WizardLM/WizardLM-13B-V1.2,0.5,0.0001748999999999,0.75,0.0001036,0.5,0.0001748999999999,0.25,0.0002339999999999,0.25,0.000384896,0.75,0.00985
hellaswag.val.8357,WizardLM/WizardLM-13B-V1.2,0.0,7.019999999999999e-05,0.0,4.7e-05,0.0,7.019999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,0.0,0.00239
mmlu-prehistory.val.130,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-jurisprudence.val.18,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,0.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
mmlu-professional-law.val.1432,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,1.0,8.76e-05,0.0,0.0001752,0.0,0.000226592,1.0,0.00293
mbpp.dev.4,mistralai/mistral-7b-chat,0.0,5.36e-05,0.0,5.36e-05,0.0,8.67e-05,1.0,0.0002064,0.0,0.0001164,0.0,0.00541
grade-school-math.dev.3831,mistralai/mistral-7b-chat,0.75,8.300000000000001e-05,0.75,8.300000000000001e-05,0.5,0.000174,0.5,0.0002934,0.25,0.0003561839999999,0.5,0.00681
hellaswag.val.9554,mistralai/mistral-7b-chat,0.0,6.2e-05,0.0,6.2e-05,0.0,9.27e-05,0.0,0.000186,0.0,0.00024056,1.0,0.00314
mmlu-professional-psychology.val.578,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-professional-law.val.1521,WizardLM/WizardLM-13B-V1.2,0.0,0.0001016999999999,0.0,6.780000000000001e-05,0.0,0.0001016999999999,0.0,0.0002033999999999,0.0,0.000263064,0.0,0.0034
winogrande.dev.432,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,1.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00048
hellaswag.val.7578,WizardLM/WizardLM-13B-V1.2,0.0,7.89e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,0.0,0.00267
hellaswag.val.657,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.45e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.0012
hellaswag.val.2983,WizardLM/WizardLM-13B-V1.2,1.0,2.52e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-high-school-macroeconomics.val.13,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,0.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,0.0,0.00119
mmlu-conceptual-physics.val.59,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,1.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
mmlu-moral-scenarios.val.723,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
grade-school-math.dev.2965,mistralai/mistral-7b-chat,0.25,8.12e-05,0.25,8.12e-05,0.25,0.0001368,0.25,0.000408,0.25,0.000394984,0.5,0.00998
mmlu-virology.val.83,mistralai/mixtral-8x7b-chat,0.0,5.34e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,0.0,0.0009
arc-challenge.val.62,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
hellaswag.val.6502,mistralai/mixtral-8x7b-chat,0.0,0.0001884,0.0,6.280000000000001e-05,0.0,9.42e-05,0.0,0.0001884,0.0,0.000243664,0.0,0.00318
grade-school-math.dev.7352,meta/code-llama-instruct-34b-chat,0.75,0.000311176,0.25,8.640000000000001e-05,0.75,0.0001467,0.75,0.0002525999999999,0.75,0.000311176,0.75,0.00815
mmlu-high-school-world-history.val.49,mistralai/mixtral-8x7b-chat,1.0,0.0001392,0.0,4.64e-05,1.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00233
hellaswag.val.1878,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.176,WizardLM/WizardLM-13B-V1.2,0.0,3.93e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mbpp.dev.187,mistralai/mistral-7b-chat,0.0,4.92e-05,0.0,4.92e-05,1.0,7.439999999999999e-05,1.0,0.0001902,1.0,0.000156752,1.0,0.00683
mmlu-professional-medicine.val.25,mistralai/mixtral-8x7b-chat,1.0,0.0001506,1.0,5.020000000000001e-05,1.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00255
mmlu-professional-law.val.255,mistralai/mistral-7b-chat,0.0,6.659999999999999e-05,0.0,6.659999999999999e-05,0.0,9.99e-05,1.0,0.0001998,0.0,0.0002584079999999,1.0,0.00337
mmlu-high-school-mathematics.val.72,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,0.0,0.00089
mmlu-world-religions.val.129,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,1.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
arc-challenge.test.175,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
winogrande.dev.446,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,0.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.492e-05,0.0,0.00047
hellaswag.val.9941,WizardLM/WizardLM-13B-V1.2,0.0,9.06e-05,0.0,6.06e-05,0.0,9.06e-05,0.0,0.0001818,0.0,0.0002351279999999,1.0,0.00307
hellaswag.val.3048,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-professional-law.val.19,WizardLM/WizardLM-13B-V1.2,0.0,6.12e-05,0.0,4.080000000000001e-05,0.0,6.12e-05,1.0,0.0001224,0.0,0.000158304,1.0,0.00205
hellaswag.val.5125,mistralai/mixtral-8x7b-chat,0.0,0.0001776,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.003
grade-school-math.dev.5064,mistralai/mistral-7b-chat,0.25,0.0001336,0.25,0.0001336,0.25,0.0002055,0.25,0.0003689999999999,0.5,0.000426024,0.75,0.01261
mmlu-high-school-world-history.val.156,mistralai/mixtral-8x7b-chat,1.0,0.0001062,1.0,3.54e-05,1.0,5.31e-05,1.0,0.0001062,0.0,0.000137352,1.0,0.00178
hellaswag.val.6397,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00249
hellaswag.val.4538,mistralai/mixtral-8x7b-chat,1.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
winogrande.dev.763,mistralai/mistral-7b-chat,0.0,1.02e-05,0.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,0.0,3.9576e-05,0.0,0.00055
mmlu-elementary-mathematics.val.157,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,0.0,0.0011899999999999
mmlu-professional-law.val.602,mistralai/mistral-7b-chat,1.0,6.76e-05,1.0,6.76e-05,0.0,0.0001014,0.0,0.0002028,0.0,0.0002622879999999,0.0,0.00339
mbpp.dev.252,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,7.74e-05,0.0,0.0001332,0.0,0.000179256,0.0,0.0180299999999999
mmlu-professional-law.val.740,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,0.0,0.00249
hellaswag.val.1881,WizardLM/WizardLM-13B-V1.2,0.0,4.74e-05,0.0,3.160000000000001e-05,0.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00159
mmlu-human-aging.val.37,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-marketing.val.134,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-college-physics.val.7,mistralai/mixtral-8x7b-chat,0.0,7.379999999999999e-05,0.0,2.46e-05,1.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.0012699999999999
arc-challenge.test.152,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,1.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,1.0,5.354400000000001e-05,1.0,0.00073
mmlu-professional-law.val.162,mistralai/mistral-7b-chat,0.0,6.120000000000001e-05,0.0,6.120000000000001e-05,0.0,9.18e-05,0.0,0.000183,0.0,0.0002374559999999,0.0,0.00307
mmlu-professional-law.val.1013,WizardLM/WizardLM-13B-V1.2,0.0,0.0001446,1.0,9.64e-05,0.0,0.0001446,0.0,0.0002892,0.0,0.000374032,0.0,0.0048299999999999
mmlu-miscellaneous.val.300,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-high-school-geography.val.176,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-biology.val.5,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
consensus_summary.dev.189,meta/code-llama-instruct-34b-chat,0.75,0.000150544,0.75,3.88e-05,1.0,5.58e-05,0.75,0.0001193999999999,0.75,0.000150544,0.5,0.00182
mmlu-professional-psychology.val.521,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-jurisprudence.val.2,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-college-computer-science.val.62,mistralai/mistral-7b-chat,1.0,2.2600000000000004e-05,1.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.2904,WizardLM/WizardLM-13B-V1.2,0.25,0.0001352999999999,0.25,8.5e-05,0.25,0.0001352999999999,0.75,0.0002873999999999,0.25,0.000342992,0.75,0.00713
hellaswag.val.922,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-jurisprudence.val.59,mistralai/mixtral-8x7b-chat,0.0,9.12e-05,0.0,3.04e-05,1.0,4.56e-05,0.0,9.12e-05,0.0,0.000117952,1.0,0.00153
mmlu-high-school-macroeconomics.val.226,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
mmlu-clinical-knowledge.val.61,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.5553,mistralai/mistral-7b-chat,0.75,8.04e-05,0.75,8.04e-05,0.75,0.0001263,0.75,0.0002352,0.75,0.00027936,0.75,0.00831
grade-school-math.dev.875,WizardLM/WizardLM-13B-V1.2,0.5,0.0001502999999999,0.5,9.48e-05,0.5,0.0001502999999999,0.25,0.0002129999999999,0.5,0.00030264,0.5,0.00662
mmlu-professional-law.val.560,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,1.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
hellaswag.val.9385,WizardLM/WizardLM-13B-V1.2,0.0,7.74e-05,1.0,5.160000000000001e-05,0.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00262
consensus_summary.dev.72,meta/code-llama-instruct-34b-chat,1.0,0.000197104,0.0,5.440000000000001e-05,0.0,7.649999999999999e-05,0.75,0.0001721999999999,1.0,0.000197104,1.0,0.0031799999999999
mmlu-miscellaneous.val.684,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,0.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
hellaswag.val.8083,mistralai/mistral-7b-chat,1.0,4.720000000000001e-05,1.0,4.720000000000001e-05,1.0,7.049999999999999e-05,1.0,0.0001416,1.0,0.000183136,1.0,0.00237
mmlu-professional-law.val.280,mistralai/mistral-7b-chat,1.0,5.34e-05,1.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
mmlu-high-school-psychology.val.244,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
hellaswag.val.4889,mistralai/mistral-7b-chat,0.0,5.5400000000000005e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00281
grade-school-math.dev.2953,WizardLM/WizardLM-13B-V1.2,0.5,0.0001449,0.75,9.36e-05,0.5,0.0001449,0.5,0.0002244,0.25,0.000340664,0.75,0.0091399999999999
mmlu-miscellaneous.val.760,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,1.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-high-school-chemistry.val.57,WizardLM/WizardLM-13B-V1.2,1.0,5.61e-05,0.0,3.74e-05,1.0,5.61e-05,0.0,0.0001122,0.0,0.000145112,1.0,0.00188
mmlu-elementary-mathematics.val.138,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-professional-law.val.237,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,1.0,5.080000000000001e-05,0.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
mmlu-electrical-engineering.val.113,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
grade-school-math.dev.1745,mistralai/mistral-7b-chat,0.75,0.000122,0.75,0.000122,0.75,0.0001749,0.75,0.0003054,0.25,0.000360064,0.75,0.00824
hellaswag.val.8636,mistralai/mistral-7b-chat,0.0,5.12e-05,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,0.0,0.00257
hellaswag.val.7669,mistralai/mistral-7b-chat,1.0,4.5400000000000006e-05,1.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,1.0,0.0001761519999999,1.0,0.00231
hellaswag.val.6356,mistralai/mixtral-8x7b-chat,0.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
hellaswag.val.601,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-clinical-knowledge.val.245,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,1.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-public-relations.val.90,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.6939,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
grade-school-math.dev.873,mistralai/mistral-7b-chat,0.75,0.0001088,0.75,0.0001088,0.25,0.0001494,0.5,0.0002568,0.75,0.000315832,0.75,0.0102
arc-challenge.val.285,mistralai/mistral-7b-chat,1.0,1.2e-05,1.0,1.2e-05,1.0,1.8e-05,1.0,3.6e-05,0.0,4.656e-05,1.0,0.00061
mmlu-security-studies.val.193,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,0.0,0.00256
mmlu-virology.val.102,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-medicine.val.27,WizardLM/WizardLM-13B-V1.2,0.0,7.110000000000001e-05,1.0,4.74e-05,0.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,0.0,0.00238
mmlu-human-aging.val.198,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
hellaswag.val.8483,mistralai/mistral-7b-chat,0.0,5.6000000000000006e-05,0.0,5.6000000000000006e-05,0.0,8.369999999999999e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00284
grade-school-math.dev.2320,WizardLM/WizardLM-13B-V1.2,0.25,0.0001503,0.25,7.66e-05,0.25,0.0001503,0.75,0.0003162,0.75,0.000315056,0.5,0.01015
mmlu-human-aging.val.140,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-professional-psychology.val.3,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mbpp.dev.239,mistralai/mistral-7b-chat,0.0,3.3600000000000004e-05,0.0,3.3600000000000004e-05,0.0,6.539999999999999e-05,1.0,0.0001164,0.0,0.000117952,0.0,0.00951
grade-school-math.dev.4377,meta/code-llama-instruct-34b-chat,0.25,0.000347648,0.25,7.780000000000001e-05,0.25,0.0002079,0.5,0.000333,0.25,0.000347648,0.75,0.00909
mmlu-high-school-psychology.val.251,WizardLM/WizardLM-13B-V1.2,0.0,2.61e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
arc-challenge.test.74,mistralai/mixtral-8x7b-chat,0.0,4.92e-05,1.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
hellaswag.val.5449,WizardLM/WizardLM-13B-V1.2,1.0,8.76e-05,1.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,1.0,0.000226592,1.0,0.00296
grade-school-math.dev.923,mistralai/mistral-7b-chat,0.5,8.54e-05,0.5,8.54e-05,0.75,0.0001227,0.75,0.0002352,0.75,0.000293328,0.75,0.00611
hellaswag.val.4043,WizardLM/WizardLM-13B-V1.2,0.0,8.46e-05,0.0,5.660000000000001e-05,0.0,8.46e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00287
grade-school-math.dev.626,WizardLM/WizardLM-13B-V1.2,0.25,0.000198,0.25,8.02e-05,0.25,0.000198,0.75,0.0002483999999999,0.25,0.000351528,0.5,0.00943
grade-school-math.dev.3792,mistralai/mistral-7b-chat,1.0,7.92e-05,1.0,7.92e-05,0.5,0.0001338,0.75,0.0002346,0.25,0.00030652,0.75,0.00677
hellaswag.val.1268,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,1.0,3.57e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00124
mmlu-college-chemistry.val.62,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.9405,WizardLM/WizardLM-13B-V1.2,0.0,8.7e-05,0.0,5.8200000000000005e-05,0.0,8.7e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
hellaswag.val.8394,WizardLM/WizardLM-13B-V1.2,1.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
hellaswag.val.2921,WizardLM/WizardLM-13B-V1.2,0.0,3.78e-05,0.0,2.54e-05,0.0,3.78e-05,0.0,7.62e-05,0.0,9.8552e-05,0.0,0.00131
mmlu-professional-law.val.490,WizardLM/WizardLM-13B-V1.2,1.0,7.110000000000001e-05,0.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00238
mmlu-philosophy.val.58,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-high-school-us-history.val.140,WizardLM/WizardLM-13B-V1.2,0.0,0.0001164,0.0,7.76e-05,0.0,0.0001164,0.0,0.0002328,0.0,0.000301088,1.0,0.00389
mmlu-international-law.val.3,mistralai/mistral-7b-chat,0.0,3.160000000000001e-05,0.0,3.160000000000001e-05,1.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00159
grade-school-math.dev.6038,mistralai/mixtral-8x7b-chat,0.25,0.0002208,0.75,8.400000000000001e-05,0.75,0.0001356,0.25,0.0002208,0.75,0.00025608,0.75,0.00493
hellaswag.val.857,WizardLM/WizardLM-13B-V1.2,0.0,3.27e-05,1.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,0.0,0.0011
mmlu-college-medicine.val.170,mistralai/mixtral-8x7b-chat,0.0,6.9e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.4547,WizardLM/WizardLM-13B-V1.2,0.75,0.0001439999999999,0.5,7.840000000000001e-05,0.75,0.0001439999999999,0.5,0.0002412,0.25,0.000285568,0.5,0.0073
mmlu-astronomy.val.14,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
consensus_summary.dev.179,mistralai/mixtral-8x7b-chat,0.75,0.0001842,0.75,6.2e-05,0.75,9.24e-05,0.75,0.0001842,0.75,0.000242888,0.75,0.00392
grade-school-math.dev.6244,WizardLM/WizardLM-13B-V1.2,0.25,0.0001664999999999,0.25,8.88e-05,0.25,0.0001664999999999,0.25,0.0002483999999999,0.75,0.000335232,0.75,0.0093099999999999
mmlu-professional-medicine.val.191,mistralai/mixtral-8x7b-chat,1.0,0.0001068,0.0,3.5600000000000005e-05,1.0,5.34e-05,1.0,0.0001068,0.0,0.0001381279999999,1.0,0.00182
consensus_summary.dev.51,mistralai/mixtral-8x7b-chat,0.75,0.0001818,0.75,6.240000000000001e-05,0.75,8.97e-05,0.75,0.0001818,0.75,0.000245216,0.75,0.00521
mmlu-high-school-physics.val.18,mistralai/mistral-7b-chat,0.0,3.5600000000000005e-05,0.0,3.5600000000000005e-05,0.0,5.34e-05,0.0,0.0001068,0.0,0.0001381279999999,1.0,0.00179
hellaswag.val.8505,mistralai/mixtral-8x7b-chat,0.0,0.0001698,1.0,5.660000000000001e-05,1.0,8.46e-05,0.0,0.0001698,1.0,0.000219608,1.0,0.00287
hellaswag.val.3105,WizardLM/WizardLM-13B-V1.2,1.0,3.48e-05,0.0,2.32e-05,1.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,1.0,0.0012
mmlu-nutrition.val.122,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-psychology.val.339,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
mmlu-global-facts.val.62,mistralai/mixtral-8x7b-chat,0.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
mmlu-security-studies.val.198,WizardLM/WizardLM-13B-V1.2,1.0,6.63e-05,0.0,4.420000000000001e-05,1.0,6.63e-05,1.0,0.0001326,0.0,0.000171496,1.0,0.00222
hellaswag.val.4838,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.139999999999999e-05,0.0,0.0001434,0.0,0.0001854639999999,0.0,0.0024
hellaswag.val.3966,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5.020000000000001e-05,0.0,7.5e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00255
hellaswag.val.1562,mistralai/mixtral-8x7b-chat,1.0,0.000102,1.0,3.4000000000000007e-05,1.0,5.1e-05,1.0,0.000102,1.0,0.0001319199999999,1.0,0.00171
hellaswag.val.6686,mistralai/mixtral-8x7b-chat,1.0,0.0001608,1.0,5.360000000000001e-05,1.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,0.0,0.00269
mmlu-security-studies.val.83,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,1.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
mmlu-high-school-world-history.val.151,mistralai/mixtral-8x7b-chat,1.0,0.0002178,0.0,7.26e-05,0.0,0.0001089,1.0,0.0002178,0.0,0.000281688,1.0,0.00364
mmlu-high-school-psychology.val.441,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
mmlu-high-school-government-and-politics.val.129,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
mmlu-high-school-biology.val.130,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,1.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
mmlu-high-school-us-history.val.86,WizardLM/WizardLM-13B-V1.2,0.0,0.0001382999999999,1.0,9.22e-05,0.0,0.0001382999999999,1.0,0.0002765999999999,0.0,0.000357736,1.0,0.00462
grade-school-math.dev.6435,mistralai/mistral-7b-chat,0.75,6.96e-05,0.75,6.96e-05,0.25,0.0001455,0.25,0.0001806,0.75,0.000262288,0.75,0.0083699999999999
hellaswag.val.8493,WizardLM/WizardLM-13B-V1.2,0.0,7.08e-05,0.0,4.74e-05,0.0,7.08e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00241
grade-school-math.dev.1234,mistralai/mistral-7b-chat,0.25,8.640000000000001e-05,0.25,8.640000000000001e-05,0.5,0.0001373999999999,0.75,0.0002652,0.75,0.000369376,0.75,0.00959
mmlu-philosophy.val.156,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
grade-school-math.dev.1771,WizardLM/WizardLM-13B-V1.2,0.75,0.0001799999999999,0.5,0.000113,0.75,0.0001799999999999,0.25,0.0002208,0.5,0.0003429919999999,0.5,0.00702
hellaswag.val.3850,mistralai/mistral-7b-chat,1.0,5.080000000000001e-05,1.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,1.0,0.0001971039999999,1.0,0.00255
mmlu-professional-law.val.350,WizardLM/WizardLM-13B-V1.2,1.0,0.0001376999999999,1.0,9.18e-05,1.0,0.0001376999999999,0.0,0.0002753999999999,0.0,0.000356184,1.0,0.0046
arc-challenge.test.570,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-security-studies.val.100,WizardLM/WizardLM-13B-V1.2,1.0,4.38e-05,0.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
hellaswag.val.2621,mistralai/mixtral-8x7b-chat,1.0,8.22e-05,0.0,2.74e-05,0.0,4.08e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
grade-school-math.dev.6219,WizardLM/WizardLM-13B-V1.2,0.75,0.0001806,0.25,9.14e-05,0.75,0.0001806,0.5,0.0003503999999999,0.25,0.000384896,0.5,0.01097
mmlu-moral-disputes.val.189,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
hellaswag.val.9788,mistralai/mixtral-8x7b-chat,0.0,0.0001518,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.4713,WizardLM/WizardLM-13B-V1.2,0.75,0.0001383,0.25,0.0005222,0.75,0.0001383,0.75,0.0002243999999999,0.75,0.000273152,0.75,0.00665
mmlu-clinical-knowledge.val.213,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,1.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-miscellaneous.val.617,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.7332,mistralai/mistral-7b-chat,0.25,9.26e-05,0.25,9.26e-05,0.25,0.0001584,0.75,0.0002592,0.5,0.000348424,0.75,0.01057
mmlu-professional-law.val.907,WizardLM/WizardLM-13B-V1.2,1.0,0.0001032,0.0,6.88e-05,1.0,0.0001032,0.0,0.0002064,0.0,0.0002669439999999,1.0,0.00345
grade-school-math.dev.614,mistralai/mixtral-8x7b-chat,0.75,0.0002274,0.25,6.12e-05,0.75,0.0001584,0.75,0.0002274,0.75,0.000322816,0.75,0.0055899999999999
grade-school-math.dev.6754,mistralai/mixtral-8x7b-chat,0.25,0.0002153999999999,0.25,7.38e-05,0.75,0.0001454999999999,0.25,0.0002153999999999,0.75,0.0003104,0.75,0.00882
mmlu-college-physics.val.49,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.0011799999999999
grade-school-math.dev.6630,mistralai/mistral-7b-chat,0.25,9.22e-05,0.25,9.22e-05,0.25,0.0002007,0.25,0.0002688,0.75,0.00036472,0.5,0.01105
mmlu-international-law.val.5,WizardLM/WizardLM-13B-V1.2,0.0,4.68e-05,0.0,3.1200000000000006e-05,0.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.00157
mmlu-high-school-psychology.val.250,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
bias_detection.dev.22,mistralai/mistral-7b-chat,0.0,5.16e-05,0.0,5.16e-05,0.0,0.0001071,1.0,0.0004548,0.0,0.000228144,0.0,0.00655
hellaswag.val.703,WizardLM/WizardLM-13B-V1.2,0.0,4.17e-05,1.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
winogrande.dev.103,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.00053
grade-school-math.dev.2234,WizardLM/WizardLM-13B-V1.2,0.75,0.0001688999999999,0.25,0.0001146,0.75,0.0001688999999999,0.5,0.0003048,0.25,0.000327472,0.75,0.01029
hellaswag.val.2702,mistralai/mistral-7b-chat,1.0,2.2600000000000004e-05,1.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,1.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.571,mistralai/mixtral-8x7b-chat,0.5,0.0002496,0.75,0.0001014,0.25,0.0001881,0.5,0.0002496,0.25,0.000377136,0.75,0.01278
mmlu-professional-law.val.397,WizardLM/WizardLM-13B-V1.2,1.0,7.53e-05,0.0,5.020000000000001e-05,1.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00255
mmlu-security-studies.val.75,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-professional-law.val.977,mistralai/mistral-7b-chat,0.0,4e-05,0.0,4e-05,0.0,6e-05,0.0,0.00012,0.0,0.0001551999999999,0.0,0.00201
hellaswag.val.6261,WizardLM/WizardLM-13B-V1.2,0.0,8.639999999999999e-05,0.0,5.780000000000001e-05,0.0,8.639999999999999e-05,0.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
winogrande.dev.449,mistralai/mistral-7b-chat,1.0,1.14e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,1.0,4.4232e-05,1.0,0.00061
hellaswag.val.1955,WizardLM/WizardLM-13B-V1.2,1.0,3.63e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
mbpp.dev.127,mistralai/mistral-7b-chat,0.0,4.08e-05,0.0,4.08e-05,0.0,6.659999999999999e-05,0.0,0.0001409999999999,1.0,0.0001358,1.0,0.00655
mmlu-conceptual-physics.val.72,mistralai/mistral-7b-chat,0.0,1.34e-05,0.0,1.34e-05,0.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
hellaswag.val.7818,mistralai/mixtral-8x7b-chat,0.0,0.0001296,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,0.0,0.00217
mmlu-marketing.val.8,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-college-medicine.val.88,mistralai/mistral-7b-chat,0.0,4.1800000000000006e-05,0.0,4.1800000000000006e-05,1.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,0.0,0.0021
hellaswag.val.3146,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,1.0,7.8376e-05,1.0,0.00102
mmlu-professional-law.val.1527,mistralai/mistral-7b-chat,0.0,6.84e-05,0.0,6.84e-05,0.0,0.0001026,1.0,0.0002052,0.0,0.000265392,1.0,0.00343
mmlu-jurisprudence.val.56,mistralai/mistral-7b-chat,1.0,3.180000000000001e-05,1.0,3.180000000000001e-05,1.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,0.0,0.0016
mmlu-high-school-government-and-politics.val.71,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.5780,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.00297
grade-school-math.dev.4465,mistralai/mistral-7b-chat,0.25,6.82e-05,0.25,6.82e-05,0.75,0.0001653,0.75,0.0002357999999999,0.75,0.00023668,0.5,0.00629
mmlu-sociology.val.73,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-professional-medicine.val.156,WizardLM/WizardLM-13B-V1.2,1.0,0.0001092,0.0,7.280000000000001e-05,1.0,0.0001092,0.0,0.0002184,0.0,0.000282464,1.0,0.00368
consensus_summary.dev.225,mistralai/mixtral-8x7b-chat,1.0,0.0001662,0.25,6.879999999999999e-05,0.75,8.97e-05,1.0,0.0001662,0.25,0.000312728,0.25,0.00422
mmlu-high-school-geography.val.133,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.9282,mistralai/mixtral-8x7b-chat,0.0,0.0001722,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00291
mmlu-miscellaneous.val.63,mistralai/mixtral-8x7b-chat,0.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
mmlu-professional-law.val.735,WizardLM/WizardLM-13B-V1.2,1.0,6.9e-05,0.0,4.600000000000001e-05,1.0,6.9e-05,1.0,0.000138,0.0,0.0001784799999999,1.0,0.00234
hellaswag.val.6992,mistralai/mixtral-8x7b-chat,1.0,0.0001578,1.0,5.260000000000001e-05,1.0,7.89e-05,1.0,0.0001578,1.0,0.000204088,1.0,0.00267
mmlu-professional-law.val.341,WizardLM/WizardLM-13B-V1.2,0.0,8.79e-05,1.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
mmlu-medical-genetics.val.77,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
grade-school-math.dev.1052,WizardLM/WizardLM-13B-V1.2,0.25,0.0001698,0.25,9.92e-05,0.25,0.0001698,0.25,0.0001997999999999,0.25,0.0003662719999999,0.25,0.00962
hellaswag.val.410,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-high-school-biology.val.239,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-law.val.1348,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-jurisprudence.val.107,mistralai/mistral-7b-chat,1.0,2.34e-05,1.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00121
mmlu-high-school-mathematics.val.170,mistralai/mixtral-8x7b-chat,0.0,7.02e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00118
mmlu-professional-law.val.559,mistralai/mistral-7b-chat,0.0,5.44e-05,0.0,5.44e-05,0.0,8.16e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00273
hellaswag.val.1352,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.1937,WizardLM/WizardLM-13B-V1.2,0.75,0.0001884,0.25,0.0001056,0.75,0.0001884,0.25,0.0003186,0.0,0.000377912,0.75,0.01079
bias_detection.dev.1,mistralai/mistral-7b-chat,1.0,5.56e-05,1.0,5.56e-05,0.0,9.45e-05,0.0,0.000246,0.0,0.00025608,1.0,0.0115
hellaswag.val.2559,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.8421,mistralai/mixtral-8x7b-chat,1.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00239
hellaswag.val.7095,mistralai/mixtral-8x7b-chat,0.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
mmlu-conceptual-physics.val.98,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00107
consensus_summary.dev.123,mistralai/mixtral-8x7b-chat,0.75,0.000201,0.75,7.04e-05,0.75,0.0001182,0.75,0.000201,0.75,0.000297208,0.75,0.00547
mmlu-professional-law.val.293,WizardLM/WizardLM-13B-V1.2,1.0,6.12e-05,0.0,4.080000000000001e-05,1.0,6.12e-05,1.0,0.0001224,0.0,0.000158304,1.0,0.00205
abstract2title.test.198,mistralai/mixtral-8x7b-chat,1.0,0.0002718,1.0,6.64e-05,1.0,0.0001007999999999,1.0,0.0002718,1.0,0.000257632,1.0,0.0038499999999999
mmlu-world-religions.val.88,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
winogrande.dev.1159,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,0.0,0.00053
mmlu-professional-law.val.928,WizardLM/WizardLM-13B-V1.2,0.0,9.6e-05,1.0,6.4e-05,0.0,9.6e-05,0.0,0.0001919999999999,0.0,0.00024832,0.0,0.00321
mmlu-elementary-mathematics.val.109,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.12e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
grade-school-math.dev.6135,mistralai/mistral-7b-chat,0.25,7.780000000000001e-05,0.25,7.780000000000001e-05,0.25,0.0001275,0.25,0.0002231999999999,0.25,0.000343768,0.75,0.00767
mmlu-professional-law.val.1000,WizardLM/WizardLM-13B-V1.2,0.0,8.19e-05,1.0,5.4600000000000006e-05,0.0,8.19e-05,0.0,0.0001638,0.0,0.0002118479999999,0.0,0.00274
mmlu-us-foreign-policy.val.98,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
arc-challenge.test.815,mistralai/mistral-7b-chat,0.0,1.26e-05,0.0,1.26e-05,1.0,1.89e-05,0.0,3.78e-05,0.0,4.8888e-05,1.0,0.00067
hellaswag.val.1539,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
arc-challenge.val.72,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.4187,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00275
mmlu-professional-law.val.78,WizardLM/WizardLM-13B-V1.2,0.0,0.0001233,0.0,8.22e-05,0.0,0.0001233,0.0,0.0002466,0.0,0.000318936,0.0,0.0041199999999999
grade-school-math.dev.1868,WizardLM/WizardLM-13B-V1.2,0.25,0.0001487999999999,0.25,0.000104,0.25,0.0001487999999999,0.25,0.0002808,0.25,0.000379464,0.25,0.00918
mmlu-professional-law.val.166,WizardLM/WizardLM-13B-V1.2,0.0,0.0001086,1.0,7.24e-05,0.0,0.0001086,1.0,0.0002165999999999,0.0,0.000280912,1.0,0.00363
grade-school-math.dev.1418,mistralai/mistral-7b-chat,0.75,0.0001038,0.75,0.0001038,0.75,0.0001688999999999,0.5,0.0003107999999999,0.25,0.000342216,0.5,0.0092
hellaswag.val.7492,mistralai/mixtral-8x7b-chat,1.0,0.0001608,1.0,5.360000000000001e-05,1.0,8.01e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
hellaswag.val.9041,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00268
grade-school-math.dev.3378,mistralai/mistral-7b-chat,0.25,6.0200000000000006e-05,0.25,6.0200000000000006e-05,0.25,0.0001721999999999,0.75,0.0003539999999999,0.25,0.000303416,0.75,0.0110199999999999
hellaswag.val.9969,mistralai/mistral-7b-chat,0.0,4.2600000000000005e-05,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00214
grade-school-math.dev.5255,WizardLM/WizardLM-13B-V1.2,0.25,0.0001418999999999,0.25,0.0001194,0.25,0.0001418999999999,0.25,0.0003258,0.25,0.000505176,0.75,0.01241
hellaswag.val.6586,WizardLM/WizardLM-13B-V1.2,0.0,8.369999999999999e-05,0.0,5.6000000000000006e-05,0.0,8.369999999999999e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00284
mmlu-high-school-geography.val.60,mistralai/mixtral-8x7b-chat,0.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,0.0,0.00076
hellaswag.val.4005,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
arc-challenge.val.40,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00122
mmlu-virology.val.93,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,0.0,0.00083
mmlu-professional-law.val.497,WizardLM/WizardLM-13B-V1.2,1.0,8.249999999999999e-05,0.0,5.5e-05,1.0,8.249999999999999e-05,1.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-nutrition.val.121,mistralai/mixtral-8x7b-chat,1.0,9.36e-05,1.0,3.1200000000000006e-05,1.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.0015999999999999
mmlu-elementary-mathematics.val.80,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.4253,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,1.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
grade-school-math.dev.787,mistralai/mixtral-8x7b-chat,0.5,0.0002472,0.25,8.860000000000001e-05,0.75,0.0001754999999999,0.5,0.0002472,0.75,0.000433784,0.75,0.00927
mmlu-prehistory.val.213,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00114
mmlu-philosophy.val.59,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
mbpp.dev.360,mistralai/mistral-7b-chat,0.0,4.100000000000001e-05,0.0,4.100000000000001e-05,0.0,5.879999999999999e-05,0.0,0.0002682,0.0,0.00026384,1.0,0.01357
hellaswag.val.4444,mistralai/mistral-7b-chat,1.0,4.9000000000000005e-05,1.0,4.9000000000000005e-05,1.0,7.35e-05,1.0,0.000147,1.0,0.00019012,1.0,0.00246
mmlu-professional-law.val.1202,WizardLM/WizardLM-13B-V1.2,0.0,8.79e-05,0.0,5.860000000000001e-05,0.0,8.79e-05,0.0,0.0001758,0.0,0.0002273679999999,1.0,0.00294
mmlu-moral-scenarios.val.646,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00142
hellaswag.val.8992,mistralai/mixtral-8x7b-chat,1.0,0.0001602,0.0,5.34e-05,0.0,8.01e-05,1.0,0.0001602,0.0,0.000207192,1.0,0.00268
grade-school-math.dev.876,WizardLM/WizardLM-13B-V1.2,0.25,0.0001632,0.75,8.24e-05,0.25,0.0001632,0.25,0.000225,0.25,0.000301864,0.75,0.01066
grade-school-math.dev.5657,mistralai/mistral-7b-chat,0.75,7.66e-05,0.75,7.66e-05,0.75,0.0001281,0.5,0.0002304,0.25,0.000266168,0.75,0.00765
mmlu-professional-medicine.val.193,mistralai/mixtral-8x7b-chat,1.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
grade-school-math.dev.5734,WizardLM/WizardLM-13B-V1.2,0.75,0.0001635,1.0,6.36e-05,0.75,0.0001635,0.5,0.0002316,0.5,0.000316608,0.5,0.00668
mmlu-professional-law.val.283,WizardLM/WizardLM-13B-V1.2,0.0,0.0001367999999999,0.0,9.12e-05,0.0,0.0001367999999999,0.0,0.0002735999999999,0.0,0.000353856,1.0,0.0045699999999999
mmlu-college-physics.val.88,mistralai/mixtral-8x7b-chat,0.0,7.5e-05,1.0,2.5e-05,0.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00126
mmlu-professional-law.val.1427,WizardLM/WizardLM-13B-V1.2,0.0,0.0001185,0.0,7.900000000000001e-05,0.0,0.0001185,1.0,0.000237,0.0,0.00030652,0.0,0.00396
grade-school-math.dev.3865,mistralai/mistral-7b-chat,0.0,8.72e-05,0.0,8.72e-05,0.75,0.0001959,0.75,0.0003114,0.25,0.000266168,0.75,0.0102
hellaswag.val.3153,mistralai/mistral-7b-chat,0.0,3.1e-05,0.0,3.1e-05,0.0,4.62e-05,0.0,9.3e-05,0.0,0.00012028,1.0,0.00156
grade-school-math.dev.57,mistralai/mistral-7b-chat,0.75,9.48e-05,0.75,9.48e-05,0.75,0.0001910999999999,0.5,0.0002724,0.25,0.00039188,0.75,0.01114
hellaswag.val.5464,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00265
hellaswag.val.7842,WizardLM/WizardLM-13B-V1.2,1.0,8.999999999999999e-05,1.0,6e-05,1.0,8.999999999999999e-05,1.0,0.0001799999999999,1.0,0.0002328,1.0,0.00304
hellaswag.val.807,WizardLM/WizardLM-13B-V1.2,0.0,3.03e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.6958,mistralai/mistral-7b-chat,0.75,7.880000000000002e-05,0.75,7.880000000000002e-05,0.75,0.0001473,0.25,0.0002916,0.25,0.000346872,0.75,0.00668
arc-challenge.test.1029,mistralai/mixtral-8x7b-chat,1.0,3.84e-05,0.0,1.28e-05,0.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
hellaswag.val.4960,mistralai/mixtral-8x7b-chat,0.0,0.0001349999999999,0.0,4.5e-05,0.0,6.719999999999998e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00226
mmlu-high-school-government-and-politics.val.142,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-high-school-microeconomics.val.193,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.5593,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00244
grade-school-math.dev.6313,WizardLM/WizardLM-13B-V1.2,0.75,0.0001305,0.25,7.88e-05,0.75,0.0001305,0.25,0.0002837999999999,0.25,0.0003104,0.75,0.0111399999999999
abstract2title.test.173,mistralai/mixtral-8x7b-chat,1.0,0.0002736,1.0,8.740000000000001e-05,1.0,0.0001422,1.0,0.0002736,1.0,0.000338336,1.0,0.00522
mmlu-jurisprudence.val.99,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-philosophy.val.29,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
mmlu-professional-law.val.909,WizardLM/WizardLM-13B-V1.2,0.0,6.599999999999999e-05,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,0.0,0.0001319999999999,0.0,0.00017072,0.0,0.00221
winogrande.dev.887,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,1.0,0.00052
grade-school-math.dev.1680,mistralai/mistral-7b-chat,0.25,7.1e-05,0.25,7.1e-05,0.75,0.0001344,0.75,0.0002646,0.5,0.00028324,0.75,0.00619
grade-school-math.dev.1635,WizardLM/WizardLM-13B-V1.2,0.75,0.0001806,0.25,9.48e-05,0.75,0.0001806,0.5,0.0002286,0.25,0.00031816,0.75,0.00879
hellaswag.val.583,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.947,WizardLM/WizardLM-13B-V1.2,0.25,0.0001632,0.25,0.0001212,0.25,0.0001632,0.25,0.000285,0.25,0.000287896,0.75,0.01228
bias_detection.dev.53,mistralai/mistral-7b-chat,0.0,6.96e-05,0.0,6.96e-05,0.0,0.000111,0.0,0.0001764,0.0,0.000251424,0.0,0.00792
mtbench-reference.dev.12,mistralai/mistral-7b-chat,0.1,9.76e-05,0.1,9.76e-05,0.1,0.0001133999999999,0.1,0.0001746,0.3,0.000281688,0.1,0.00722
mmlu-professional-law.val.84,WizardLM/WizardLM-13B-V1.2,1.0,6.66e-05,0.0,4.44e-05,1.0,6.66e-05,1.0,0.0001332,0.0,0.0001722719999999,1.0,0.00223
hellaswag.val.8558,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.609999999999999e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
grade-school-math.dev.6694,WizardLM/WizardLM-13B-V1.2,0.25,0.0001413,0.25,0.0001278,0.25,0.0001413,0.75,0.0002033999999999,0.25,0.000352304,0.75,0.01083
hellaswag.val.470,WizardLM/WizardLM-13B-V1.2,1.0,3.51e-05,0.0,2.34e-05,1.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.1140,WizardLM/WizardLM-13B-V1.2,0.0,3.81e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-clinical-knowledge.val.193,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
grade-school-math.dev.286,meta/code-llama-instruct-34b-chat,0.75,0.000410504,0.5,0.0001142,0.25,0.0001733999999999,0.25,0.000267,0.75,0.000410504,0.75,0.0072
mmlu-security-studies.val.113,WizardLM/WizardLM-13B-V1.2,1.0,6.269999999999999e-05,0.0,4.1800000000000006e-05,1.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
hellaswag.val.2536,mistralai/mistral-7b-chat,1.0,3.08e-05,1.0,3.08e-05,1.0,4.6200000000000005e-05,1.0,9.24e-05,0.0,0.000119504,1.0,0.00155
mmlu-college-medicine.val.137,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-miscellaneous.val.383,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
hellaswag.val.8495,WizardLM/WizardLM-13B-V1.2,0.0,8.549999999999999e-05,0.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001709999999999,0.0,0.00022116,0.0,0.00286
hellaswag.val.6618,mistralai/mistral-7b-chat,0.0,5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,0.0,0.00254
mmlu-professional-psychology.val.363,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-jurisprudence.val.39,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00101
mmlu-miscellaneous.val.520,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
winogrande.dev.874,mistralai/mistral-7b-chat,0.0,1.2e-05,0.0,1.2e-05,0.0,1.8e-05,0.0,3.6e-05,0.0,4.656e-05,1.0,0.00061
arc-challenge.test.275,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
arc-challenge.test.403,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
hellaswag.val.9361,WizardLM/WizardLM-13B-V1.2,1.0,7.62e-05,1.0,5.080000000000001e-05,1.0,7.62e-05,1.0,0.0001524,1.0,0.0001971039999999,1.0,0.00258
mmlu-high-school-mathematics.val.239,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
consensus_summary.dev.144,mistralai/mistral-7b-chat,0.75,4.600000000000001e-05,0.75,4.600000000000001e-05,0.25,6.06e-05,0.5,0.000135,0.75,0.000249096,0.75,0.00266
grade-school-math.dev.4146,meta/code-llama-instruct-34b-chat,0.75,0.000389552,0.25,0.0001024,0.5,0.0001959,0.5,0.000291,0.75,0.000389552,0.75,0.00872
mmlu-global-facts.val.80,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
grade-school-math.dev.6657,WizardLM/WizardLM-13B-V1.2,0.75,0.0001844999999999,0.5,8.580000000000001e-05,0.75,0.0001844999999999,0.25,0.0002837999999999,0.75,0.000363944,0.75,0.00998
mmlu-elementary-mathematics.val.285,mistralai/mistral-7b-chat,1.0,2.22e-05,1.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00115
mmlu-conceptual-physics.val.37,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
hellaswag.val.1106,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.4151,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00281
consensus_summary.dev.13,mistralai/mixtral-8x7b-chat,0.75,0.000168,0.75,5.98e-05,0.75,8.549999999999999e-05,0.75,0.000168,0.75,0.00020564,0.75,0.00313
mmlu-professional-law.val.1007,WizardLM/WizardLM-13B-V1.2,1.0,8.64e-05,0.0,5.76e-05,1.0,8.64e-05,1.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-moral-scenarios.val.685,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,1.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,0.0,0.0014299999999999
hellaswag.val.5493,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,0.0,0.00245
grade-school-math.dev.5410,WizardLM/WizardLM-13B-V1.2,0.75,0.0002028,0.25,0.0001374,0.75,0.0002028,0.75,0.0002916,0.25,0.000346872,0.75,0.01304
arc-challenge.test.621,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,1.0,7.9152e-05,1.0,0.00103
hellaswag.val.9277,mistralai/mistral-7b-chat,1.0,4.460000000000001e-05,1.0,4.460000000000001e-05,0.0,6.69e-05,1.0,0.0001338,0.0,0.000173048,1.0,0.00227
hellaswag.val.955,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
grade-school-math.dev.6087,mistralai/mistral-7b-chat,0.75,8.460000000000001e-05,0.75,8.460000000000001e-05,0.5,0.0001563,0.75,0.0002016,0.75,0.000269272,0.25,0.00962
winogrande.dev.983,mistralai/mistral-7b-chat,0.0,1.1e-05,0.0,1.1e-05,1.0,1.65e-05,0.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00059
hellaswag.val.7804,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,0.0,0.00282
grade-school-math.dev.3926,mistralai/mistral-7b-chat,0.25,7.28e-05,0.25,7.28e-05,0.75,0.0001368,0.25,0.0002058,0.75,0.000265392,0.5,0.0051
mmlu-high-school-geography.val.86,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.06e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-law.val.1421,WizardLM/WizardLM-13B-V1.2,1.0,9.9e-05,0.0,6.6e-05,1.0,9.9e-05,1.0,0.000198,0.0,0.00025608,1.0,0.00331
mmlu-professional-medicine.val.142,WizardLM/WizardLM-13B-V1.2,1.0,4.74e-05,0.0,3.160000000000001e-05,1.0,4.74e-05,0.0,9.48e-05,0.0,0.000122608,0.0,0.00162
hellaswag.val.1972,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.3353,mistralai/mixtral-8x7b-chat,1.0,0.0001548,1.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00262
hellaswag.val.8070,mistralai/mixtral-8x7b-chat,1.0,0.0001704,0.0,5.680000000000001e-05,0.0,8.489999999999999e-05,1.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
hellaswag.val.6472,mistralai/mixtral-8x7b-chat,1.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,1.0,0.0001416,0.0,0.000183136,1.0,0.00237
hellaswag.val.7781,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-high-school-biology.val.91,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
mmlu-high-school-psychology.val.66,mistralai/mixtral-8x7b-chat,0.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-professional-law.val.1118,WizardLM/WizardLM-13B-V1.2,0.0,6.21e-05,1.0,4.14e-05,0.0,6.21e-05,1.0,0.0001242,0.0,0.000160632,0.0,0.00208
mmlu-formal-logic.val.59,mistralai/mixtral-8x7b-chat,0.0,9.18e-05,0.0,3.0600000000000005e-05,0.0,4.59e-05,0.0,9.18e-05,0.0,0.000118728,0.0,0.00154
winogrande.dev.824,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.492e-05,1.0,0.00047
hellaswag.val.1304,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00096
grade-school-math.dev.284,WizardLM/WizardLM-13B-V1.2,0.25,0.0001593,0.5,0.0001136,0.25,0.0001593,0.5,0.0002832,0.75,0.000355408,0.5,0.00921
hellaswag.val.9482,mistralai/mixtral-8x7b-chat,1.0,0.0001176,0.0,3.92e-05,0.0,5.88e-05,1.0,0.0001176,0.0,0.000152096,0.0,0.002
hellaswag.val.650,mistralai/mixtral-8x7b-chat,1.0,7.62e-05,0.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
hellaswag.val.6309,WizardLM/WizardLM-13B-V1.2,0.0,7.53e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00252
winogrande.dev.562,mistralai/mixtral-8x7b-chat,1.0,3.3600000000000004e-05,1.0,1.12e-05,0.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,1.0,0.0006
mmlu-college-mathematics.val.97,mistralai/mixtral-8x7b-chat,0.0,7.08e-05,0.0,2.36e-05,0.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
mmlu-astronomy.val.27,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
grade-school-math.dev.441,WizardLM/WizardLM-13B-V1.2,0.5,0.0001809,0.25,0.0001,0.5,0.0001809,0.5,0.000339,0.75,0.000378688,0.75,0.0120399999999999
grade-school-math.dev.1553,WizardLM/WizardLM-13B-V1.2,0.25,0.0001572,0.25,9.84e-05,0.25,0.0001572,0.25,0.0002634,0.25,0.000530008,0.75,0.00921
mmlu-professional-law.val.524,mistralai/mistral-7b-chat,0.0,3.78e-05,0.0,3.78e-05,0.0,5.67e-05,0.0,0.0001134,0.0,0.000146664,1.0,0.0019299999999999
mmlu-moral-disputes.val.187,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-machine-learning.val.55,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-professional-law.val.699,WizardLM/WizardLM-13B-V1.2,1.0,6.69e-05,1.0,4.460000000000001e-05,1.0,6.69e-05,1.0,0.0001338,0.0,0.000173048,1.0,0.00224
grade-school-math.dev.7250,WizardLM/WizardLM-13B-V1.2,0.25,0.0001878,0.25,9.2e-05,0.25,0.0001878,0.25,0.0002316,0.25,0.000315832,0.5,0.00929
mmlu-international-law.val.52,mistralai/mixtral-8x7b-chat,1.0,7.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-human-sexuality.val.93,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-prehistory.val.127,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,0.0,1.98e-05,0.0,3.96e-05,0.0,5.1216000000000006e-05,0.0,0.00067
mmlu-professional-law.val.360,WizardLM/WizardLM-13B-V1.2,0.0,0.0001026,1.0,6.84e-05,0.0,0.0001026,0.0,0.0002052,0.0,0.000265392,1.0,0.00343
hellaswag.val.9893,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
winogrande.dev.1042,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00051
mmlu-high-school-psychology.val.138,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-high-school-biology.val.44,mistralai/mixtral-8x7b-chat,1.0,0.0001074,0.0,3.58e-05,0.0,5.37e-05,1.0,0.0001074,0.0,0.000138904,1.0,0.0018
mmlu-jurisprudence.val.32,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-high-school-mathematics.val.244,mistralai/mistral-7b-chat,0.0,3.54e-05,0.0,3.54e-05,0.0,5.31e-05,0.0,0.0001062,0.0,0.000137352,0.0,0.00181
hellaswag.val.2606,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
hellaswag.val.6244,mistralai/mistral-7b-chat,0.0,5.7400000000000006e-05,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,1.0,0.00288
hellaswag.val.3942,mistralai/mistral-7b-chat,1.0,5.44e-05,1.0,5.44e-05,1.0,8.16e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00273
bias_detection.dev.142,mistralai/mixtral-8x7b-chat,1.0,0.0001638,0.0,5.74e-05,0.0,0.0001158,1.0,0.0001638,0.0,0.000242888,0.0,0.00851
hellaswag.val.7227,WizardLM/WizardLM-13B-V1.2,0.0,7.89e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,0.0,0.00267
mmlu-professional-law.val.1343,WizardLM/WizardLM-13B-V1.2,1.0,0.0001635,0.0,0.000109,1.0,0.0001635,1.0,0.000327,0.0,0.0004229199999999,1.0,0.00549
grade-school-math.dev.1754,WizardLM/WizardLM-13B-V1.2,0.75,0.0001359,0.75,7.840000000000001e-05,0.75,0.0001359,0.75,0.0002184,0.75,0.000295656,0.75,0.00653
grade-school-math.dev.7257,WizardLM/WizardLM-13B-V1.2,0.5,0.0001578,0.25,7.94e-05,0.5,0.0001578,0.25,0.0002826,0.25,0.000295656,0.5,0.00828
mmlu-professional-psychology.val.465,WizardLM/WizardLM-13B-V1.2,0.0,4.95e-05,0.0,3.3e-05,0.0,4.95e-05,1.0,9.9e-05,0.0,0.00012804,1.0,0.00166
hellaswag.val.8855,mistralai/mistral-7b-chat,0.0,4.980000000000001e-05,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
arc-challenge.val.155,mistralai/mistral-7b-chat,1.0,1.36e-05,1.0,1.36e-05,1.0,2.04e-05,0.0,4.08e-05,1.0,5.2768e-05,1.0,0.00072
hellaswag.val.276,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,0.0,3.03e-05,1.0,6.12e-05,1.0,7.9152e-05,1.0,0.00106
grade-school-math.dev.6362,mistralai/mistral-7b-chat,0.25,9.82e-05,0.25,9.82e-05,0.25,0.0001635,0.75,0.000252,0.25,0.000412056,0.75,0.01376
mmlu-high-school-psychology.val.384,mistralai/mistral-7b-chat,0.0,4.480000000000001e-05,0.0,4.480000000000001e-05,1.0,6.72e-05,1.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
consensus_summary.dev.101,meta/code-llama-instruct-34b-chat,0.0,0.000195552,1.0,4.9600000000000006e-05,0.0,7.02e-05,1.0,0.0001668,0.0,0.000195552,0.0,0.00238
mmlu-nutrition.val.49,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.5329,WizardLM/WizardLM-13B-V1.2,0.75,0.0001524,0.75,8.54e-05,0.75,0.0001524,0.5,0.0002747999999999,0.25,0.000342216,0.25,0.00878
abstract2title.test.8,mistralai/mixtral-8x7b-chat,1.0,0.0001806,1.0,5.7e-05,1.0,8.73e-05,1.0,0.0001806,0.0,0.000232024,1.0,0.00353
hellaswag.val.589,mistralai/mistral-7b-chat,1.0,1.62e-05,1.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,1.0,6.285600000000001e-05,0.0,0.00082
hellaswag.val.6030,WizardLM/WizardLM-13B-V1.2,0.0,6.33e-05,0.0,4.220000000000001e-05,0.0,6.33e-05,0.0,0.0001266,0.0,0.000163736,1.0,0.00215
hellaswag.val.9592,mistralai/mistral-7b-chat,0.0,6.1000000000000005e-05,0.0,6.1000000000000005e-05,1.0,9.15e-05,1.0,0.0001829999999999,0.0,0.00023668,1.0,0.00306
mmlu-moral-scenarios.val.553,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-professional-law.val.1336,WizardLM/WizardLM-13B-V1.2,0.0,5.82e-05,0.0,3.880000000000001e-05,0.0,5.82e-05,0.0,0.0001164,0.0,0.000150544,0.0,0.00198
abstract2title.test.104,mistralai/mixtral-8x7b-chat,1.0,0.0002058,1.0,6.68e-05,1.0,0.000102,1.0,0.0002058,1.0,0.000276256,1.0,0.00406
hellaswag.val.3947,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,7.979999999999999e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
mmlu-professional-law.val.1003,WizardLM/WizardLM-13B-V1.2,1.0,7.59e-05,1.0,5.06e-05,1.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
hellaswag.val.5931,WizardLM/WizardLM-13B-V1.2,0.0,8.43e-05,0.0,5.62e-05,0.0,8.43e-05,0.0,0.0001686,0.0,0.000218056,0.0,0.00285
hellaswag.val.489,mistralai/mixtral-8x7b-chat,0.0,6.9e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.0011899999999999
hellaswag.val.8272,WizardLM/WizardLM-13B-V1.2,0.0,7.14e-05,0.0,4.7600000000000005e-05,0.0,7.14e-05,0.0,0.0001428,0.0,0.000184688,1.0,0.00242
mmlu-moral-scenarios.val.612,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-security-studies.val.29,WizardLM/WizardLM-13B-V1.2,0.0,9.48e-05,0.0,6.32e-05,0.0,9.48e-05,1.0,0.0001896,0.0,0.000245216,1.0,0.00317
hellaswag.val.5832,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,0.0,0.00258
mmlu-professional-law.val.435,mistralai/mixtral-8x7b-chat,1.0,0.0001356,0.0,4.520000000000001e-05,1.0,6.780000000000001e-05,1.0,0.0001356,0.0,0.000175376,0.0,0.00227
arc-challenge.test.1164,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-human-aging.val.49,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
hellaswag.val.5668,mistralai/mixtral-8x7b-chat,1.0,0.00015,1.0,5e-05,1.0,7.5e-05,1.0,0.00015,1.0,0.000194,1.0,0.00251
mmlu-professional-psychology.val.410,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
mmlu-high-school-psychology.val.82,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
winogrande.dev.172,mistralai/mistral-7b-chat,1.0,1.16e-05,1.0,1.16e-05,1.0,1.7400000000000003e-05,1.0,3.4800000000000006e-05,0.0,4.500800000000001e-05,1.0,0.0005899999999999
arc-challenge.test.393,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,1.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
mmlu-conceptual-physics.val.142,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.1324,mistralai/mixtral-8x7b-chat,1.0,8.7e-05,1.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-professional-law.val.476,WizardLM/WizardLM-13B-V1.2,0.0,0.0001092,0.0,7.280000000000001e-05,0.0,0.0001092,0.0,0.0002184,0.0,0.000282464,0.0,0.00368
hellaswag.val.910,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,0.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.10018,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
mmlu-high-school-world-history.val.137,WizardLM/WizardLM-13B-V1.2,0.0,0.0001197,0.0,7.98e-05,0.0,0.0001197,1.0,0.0002394,0.0,0.000309624,0.0,0.0039999999999999
grade-school-math.dev.2592,mistralai/mistral-7b-chat,0.25,0.0001078,0.25,0.0001078,0.5,0.0001569,0.25,0.000279,0.25,0.0003608399999999,0.75,0.01045
mmlu-professional-law.val.348,WizardLM/WizardLM-13B-V1.2,1.0,0.0001191,0.0,7.939999999999999e-05,1.0,0.0001191,0.0,0.0002375999999999,0.0,0.0003080719999999,1.0,0.00398
grade-school-math.dev.6590,WizardLM/WizardLM-13B-V1.2,0.75,0.0001184999999999,0.75,9.14e-05,0.75,0.0001184999999999,0.5,0.0003114,0.25,0.000247544,0.75,0.00894
arc-challenge.val.165,mistralai/mixtral-8x7b-chat,0.0,6.659999999999999e-05,0.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,0.0,0.00112
hellaswag.val.8564,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.00283
arc-challenge.test.629,WizardLM/WizardLM-13B-V1.2,0.0,3.4200000000000005e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-professional-accounting.val.218,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
mmlu-moral-scenarios.val.530,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00141
mmlu-high-school-mathematics.val.154,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
grade-school-math.dev.1033,WizardLM/WizardLM-13B-V1.2,0.75,0.0001698,0.25,8.4e-05,0.75,0.0001698,0.25,0.0002975999999999,0.25,0.00036472,0.75,0.00763
mmlu-clinical-knowledge.val.243,mistralai/mixtral-8x7b-chat,0.0,7.14e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.4654,meta/code-llama-instruct-34b-chat,0.25,0.000315056,0.25,8.779999999999999e-05,0.25,0.0001727999999999,0.25,0.0003078,0.25,0.000315056,0.75,0.0090599999999999
mmlu-professional-psychology.val.307,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,0.0,0.00127
hellaswag.val.7528,mistralai/mistral-7b-chat,0.0,4.1200000000000005e-05,0.0,4.1200000000000005e-05,0.0,6.18e-05,0.0,0.0001236,0.0,0.000159856,1.0,0.0021
hellaswag.val.9933,mistralai/mistral-7b-chat,0.0,4.780000000000001e-05,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,0.0,0.00243
arc-challenge.test.1111,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-business-ethics.val.48,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
hellaswag.val.9623,mistralai/mixtral-8x7b-chat,1.0,0.0001326,0.0,4.420000000000001e-05,0.0,6.63e-05,1.0,0.0001326,0.0,0.000171496,1.0,0.00225
grade-school-math.dev.1219,mistralai/mistral-7b-chat,0.75,9.94e-05,0.75,9.94e-05,0.75,0.0001677,0.75,0.0002994,0.5,0.000373256,0.75,0.00793
mmlu-moral-disputes.val.301,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,0.0,0.00141
mmlu-professional-law.val.344,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00252
grade-school-math.dev.2759,WizardLM/WizardLM-13B-V1.2,0.25,0.0001733999999999,0.25,7.980000000000002e-05,0.25,0.0001733999999999,0.25,0.0003138,0.25,0.0003429919999999,0.5,0.00875
hellaswag.val.4142,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
mmlu-virology.val.49,mistralai/mixtral-8x7b-chat,0.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
mmlu-professional-law.val.103,WizardLM/WizardLM-13B-V1.2,1.0,7.680000000000001e-05,0.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,0.0,0.000198656,1.0,0.00257
grade-school-math.dev.1676,mistralai/mixtral-8x7b-chat,0.25,0.0002975999999999,0.25,8.76e-05,0.25,0.0001574999999999,0.25,0.0002975999999999,0.25,0.000272376,0.75,0.0082899999999999
mmlu-high-school-psychology.val.301,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
arc-challenge.test.785,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-us-foreign-policy.val.70,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-high-school-physics.val.2,mistralai/mixtral-8x7b-chat,1.0,9.6e-05,0.0,3.2000000000000005e-05,1.0,4.8e-05,1.0,9.6e-05,0.0,0.00012416,1.0,0.00161
mmlu-high-school-physics.val.73,mistralai/mixtral-8x7b-chat,0.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-global-facts.val.54,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
hellaswag.val.4387,mistralai/mistral-7b-chat,0.0,4.7e-05,0.0,4.7e-05,0.0,7.019999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
mmlu-prehistory.val.35,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
hellaswag.val.6112,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-human-aging.val.137,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
mmlu-clinical-knowledge.val.46,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.4597,mistralai/mixtral-8x7b-chat,1.0,0.0001368,1.0,4.56e-05,1.0,6.84e-05,1.0,0.0001368,1.0,0.000176928,1.0,0.00232
mmlu-college-medicine.val.168,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.7391,WizardLM/WizardLM-13B-V1.2,0.25,0.0001548,0.5,9.320000000000002e-05,0.25,0.0001548,0.75,0.0003216,0.25,0.000301864,0.75,0.01042
arc-challenge.test.17,mistralai/mixtral-8x7b-chat,0.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
hellaswag.val.8140,mistralai/mixtral-8x7b-chat,0.0,0.0001818,0.0,6.06e-05,0.0,9.06e-05,0.0,0.0001818,0.0,0.0002351279999999,0.0,0.00307
grade-school-math.dev.3689,mistralai/mixtral-8x7b-chat,0.75,0.000318,0.25,9.3e-05,0.25,0.0001653,0.75,0.000318,0.25,0.000398088,0.75,0.0086299999999999
mmlu-professional-psychology.val.32,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00104
mmlu-professional-law.val.481,mistralai/mistral-7b-chat,0.0,8.64e-05,0.0,8.64e-05,0.0,0.0001295999999999,0.0,0.0002591999999999,0.0,0.000335232,0.0,0.00433
arc-challenge.test.980,mistralai/mixtral-8x7b-chat,1.0,7.02e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,1.0,9.0792e-05,1.0,0.00118
mmlu-miscellaneous.val.444,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,1.0,1.98e-05,0.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
mmlu-management.val.92,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,0.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
grade-school-math.dev.211,WizardLM/WizardLM-13B-V1.2,0.25,0.0001716,0.5,0.000113,0.25,0.0001716,0.25,0.0003306,0.25,0.000443096,0.75,0.01206
grade-school-math.dev.2622,mistralai/mistral-7b-chat,0.75,9.54e-05,0.75,9.54e-05,0.75,0.0001701,0.75,0.0002826,0.25,0.00050052,0.5,0.01053
mmlu-high-school-chemistry.val.140,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-business-ethics.val.6,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-psychology.val.13,mistralai/mistral-7b-chat,0.0,3.160000000000001e-05,0.0,3.160000000000001e-05,0.0,4.74e-05,0.0,9.48e-05,0.0,0.000122608,1.0,0.00159
grade-school-math.dev.1697,WizardLM/WizardLM-13B-V1.2,0.75,0.0001503,0.75,7.2e-05,0.75,0.0001503,0.75,0.0002478,0.75,0.000274704,0.75,0.00594
mmlu-security-studies.val.8,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00148
hellaswag.val.2737,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.7e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
mmlu-professional-law.val.715,WizardLM/WizardLM-13B-V1.2,1.0,0.0001026,0.0,6.84e-05,1.0,0.0001026,0.0,0.0002052,0.0,0.000265392,1.0,0.00343
mmlu-moral-disputes.val.121,mistralai/mistral-7b-chat,0.0,2.84e-05,0.0,2.84e-05,0.0,4.26e-05,0.0,8.46e-05,0.0,0.000110192,1.0,0.00143
grade-school-math.dev.3405,WizardLM/WizardLM-13B-V1.2,0.75,0.0001623,0.25,9.12e-05,0.75,0.0001623,0.25,0.0002856,0.75,0.000379464,0.75,0.0078599999999999
grade-school-math.dev.1634,WizardLM/WizardLM-13B-V1.2,0.25,0.0001404,0.25,0.0001056,0.25,0.0001404,0.25,0.0002676,0.25,0.00031428,0.75,0.00822
arc-challenge.test.65,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,1.0,7.8376e-05,1.0,0.00102
mmlu-prehistory.val.154,mistralai/mixtral-8x7b-chat,1.0,9e-05,0.0,3e-05,1.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-medical-genetics.val.50,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.9242,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,0.0,0.0001439999999999,1.0,0.00018624,1.0,0.00244
hellaswag.val.904,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
arc-challenge.test.136,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,0.0,0.0008
mmlu-high-school-mathematics.val.34,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
mmlu-high-school-psychology.val.153,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-high-school-psychology.val.90,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,0.0,0.00075
mmlu-moral-scenarios.val.551,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00141
grade-school-math.dev.3411,WizardLM/WizardLM-13B-V1.2,0.75,0.0001737,0.25,0.000112,0.75,0.0001737,0.75,0.0002718,0.5,0.0004368879999999,0.75,0.00939
grade-school-math.dev.1309,mistralai/mistral-7b-chat,0.25,0.0001217999999999,0.25,0.0001217999999999,0.75,0.0001362,0.25,0.0002634,0.25,0.000388,0.75,0.00924
mmlu-professional-law.val.972,WizardLM/WizardLM-13B-V1.2,1.0,6.3e-05,0.0,4.2e-05,1.0,6.3e-05,0.0,0.000126,0.0,0.00016296,1.0,0.00211
grade-school-math.dev.1692,WizardLM/WizardLM-13B-V1.2,0.25,0.000168,0.25,0.000111,0.25,0.000168,0.25,0.0003432,0.25,0.000502072,0.5,0.01115
hellaswag.val.4792,mistralai/mixtral-8x7b-chat,0.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
winogrande.dev.1087,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,1.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
mmlu-professional-law.val.538,WizardLM/WizardLM-13B-V1.2,1.0,7.26e-05,0.0,4.84e-05,1.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00246
mmlu-professional-law.val.1100,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,1.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-international-law.val.77,mistralai/mistral-7b-chat,1.0,3.44e-05,1.0,3.44e-05,1.0,5.16e-05,1.0,0.0001032,0.0,0.000133472,1.0,0.00173
mmlu-moral-scenarios.val.816,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-machine-learning.val.96,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
mmlu-high-school-european-history.val.44,mistralai/mixtral-8x7b-chat,1.0,0.000234,0.0,7.8e-05,1.0,0.000117,1.0,0.000234,0.0,0.00030264,1.0,0.00391
mmlu-professional-law.val.51,WizardLM/WizardLM-13B-V1.2,0.0,9.45e-05,1.0,6.3e-05,0.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,0.0,0.00316
mmlu-professional-law.val.1194,WizardLM/WizardLM-13B-V1.2,0.0,6.45e-05,0.0,4.3e-05,0.0,6.45e-05,1.0,0.000129,0.0,0.00016684,1.0,0.00216
arc-challenge.test.725,mistralai/mixtral-8x7b-chat,1.0,3.66e-05,1.0,1.22e-05,1.0,1.83e-05,1.0,3.66e-05,1.0,4.7336e-05,1.0,0.00065
arc-challenge.test.779,mistralai/mixtral-8x7b-chat,1.0,3.9e-05,1.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,1.0,5.044e-05,1.0,0.00069
grade-school-math.dev.6912,WizardLM/WizardLM-13B-V1.2,0.25,0.0001479,0.25,9.22e-05,0.25,0.0001479,0.25,0.0003672,0.25,0.000361616,0.75,0.01021
grade-school-math.dev.18,WizardLM/WizardLM-13B-V1.2,0.25,0.0001532999999999,0.25,0.0001092,0.25,0.0001532999999999,0.25,0.0002298,0.25,0.000339112,0.5,0.00861
mmlu-professional-law.val.950,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00232
grade-school-math.dev.1353,mistralai/mistral-7b-chat,0.75,7.88e-05,0.75,7.88e-05,0.75,0.0001395,0.75,0.0002298,0.25,0.0002328,0.75,0.0063999999999999
mmlu-high-school-european-history.val.77,mistralai/mixtral-8x7b-chat,0.0,0.0002292,0.0,7.64e-05,0.0,0.0001146,0.0,0.0002292,0.0,0.0002964319999999,0.0,0.00383
mmlu-high-school-computer-science.val.50,mistralai/mistral-7b-chat,0.0,3.2600000000000006e-05,0.0,3.2600000000000006e-05,0.0,4.89e-05,1.0,9.78e-05,0.0,0.0001264879999999,1.0,0.00164
mmlu-jurisprudence.val.86,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-high-school-macroeconomics.val.123,mistralai/mixtral-8x7b-chat,1.0,9.6e-05,0.0,3.2000000000000005e-05,0.0,4.8e-05,1.0,9.6e-05,0.0,0.00012416,1.0,0.00161
hellaswag.val.8137,mistralai/mixtral-8x7b-chat,0.0,0.0001602,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00268
hellaswag.val.6841,mistralai/mistral-7b-chat,1.0,4.280000000000001e-05,1.0,4.280000000000001e-05,1.0,6.42e-05,1.0,0.0001284,1.0,0.000166064,1.0,0.00218
mmlu-high-school-world-history.val.218,WizardLM/WizardLM-13B-V1.2,1.0,0.0001278,1.0,8.520000000000001e-05,1.0,0.0001278,1.0,0.0002556,0.0,0.000330576,1.0,0.0042699999999999
mmlu-miscellaneous.val.366,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-miscellaneous.val.67,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-world-religions.val.77,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
hellaswag.val.8474,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,0.0,0.00243
mmlu-elementary-mathematics.val.57,mistralai/mistral-7b-chat,1.0,2.54e-05,1.0,2.54e-05,1.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-professional-law.val.807,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00278
mmlu-philosophy.val.76,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-clinical-knowledge.val.129,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
grade-school-math.dev.2681,WizardLM/WizardLM-13B-V1.2,0.25,0.0001734,0.25,0.0001285999999999,0.25,0.0001734,0.75,0.0003102,0.25,0.000297984,0.75,0.01045
mmlu-elementary-mathematics.val.140,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,0.0,0.0011
hellaswag.val.8227,mistralai/mixtral-8x7b-chat,0.0,0.0001236,0.0,4.1200000000000005e-05,0.0,6.18e-05,0.0,0.0001236,0.0,0.000159856,1.0,0.0021
mmlu-high-school-biology.val.96,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,1.0,3.48e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
winogrande.dev.420,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,0.0,0.00053
hellaswag.val.8399,mistralai/mixtral-8x7b-chat,1.0,0.0001458,1.0,4.860000000000001e-05,1.0,7.29e-05,1.0,0.0001458,1.0,0.000188568,1.0,0.00247
hellaswag.val.8702,WizardLM/WizardLM-13B-V1.2,0.0,7.289999999999998e-05,0.0,4.880000000000001e-05,0.0,7.289999999999998e-05,1.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00248
grade-school-math.dev.5893,WizardLM/WizardLM-13B-V1.2,0.25,0.0001671,0.5,0.0001066,0.25,0.0001671,0.25,0.0003162,0.5,0.000401968,0.5,0.00928
mmlu-abstract-algebra.val.61,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,1.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
hellaswag.val.3917,WizardLM/WizardLM-13B-V1.2,0.0,8.34e-05,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
mmlu-professional-law.val.1183,WizardLM/WizardLM-13B-V1.2,0.0,7.199999999999999e-05,1.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-college-medicine.val.84,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.2504,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
hellaswag.val.6370,mistralai/mixtral-8x7b-chat,0.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.319999999999999e-05,0.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00248
grade-school-math.dev.1558,WizardLM/WizardLM-13B-V1.2,0.25,0.0001692,0.75,9.94e-05,0.25,0.0001692,0.75,0.0004223999999999,0.25,0.0004066239999999,0.75,0.0185
hellaswag.val.239,WizardLM/WizardLM-13B-V1.2,0.0,3.39e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-professional-psychology.val.280,WizardLM/WizardLM-13B-V1.2,1.0,5.97e-05,0.0,3.980000000000001e-05,1.0,5.97e-05,1.0,0.0001193999999999,0.0,0.000154424,1.0,0.00203
mmlu-jurisprudence.val.43,mistralai/mistral-7b-chat,1.0,2.56e-05,1.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
grade-school-math.dev.1211,WizardLM/WizardLM-13B-V1.2,0.5,0.0001917,0.75,0.0001088,0.5,0.0001917,0.25,0.0002345999999999,0.25,0.000329024,0.75,0.01094
grade-school-math.dev.7239,WizardLM/WizardLM-13B-V1.2,0.5,0.0001869,0.25,0.0001038,0.5,0.0001869,0.5,0.0003156,0.5,0.000366272,0.5,0.00891
grade-school-math.dev.4228,WizardLM/WizardLM-13B-V1.2,0.25,0.0001518,0.25,7.18e-05,0.25,0.0001518,0.75,0.0002556,0.25,0.00033368,0.5,0.00716
mmlu-college-biology.val.24,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-medical-genetics.val.48,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,0.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.6109,mistralai/mixtral-8x7b-chat,1.0,0.0001536,1.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,1.0,0.000198656,1.0,0.0026
mmlu-conceptual-physics.val.104,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.97,mistralai/mixtral-8x7b-chat,0.25,0.0002934,0.25,6.98e-05,0.25,0.0001775999999999,0.25,0.0002934,0.25,0.000423696,0.5,0.0113
hellaswag.val.7897,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,0.0,6.2e-05,0.0,9.3e-05,0.0,0.000186,0.0,0.00024056,1.0,0.00314
mmlu-professional-law.val.361,mistralai/mistral-7b-chat,1.0,5.7e-05,1.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001709999999999,0.0,0.00022116,0.0,0.00289
grade-school-math.dev.7086,WizardLM/WizardLM-13B-V1.2,0.25,0.0001632,0.25,7.960000000000001e-05,0.25,0.0001632,0.75,0.0003276,0.25,0.000307296,0.75,0.00927
grade-school-math.dev.1296,mistralai/mistral-7b-chat,0.75,8.42e-05,0.75,8.42e-05,0.75,0.0001331999999999,0.75,0.0002418,0.75,0.000264616,0.5,0.00745
grade-school-math.dev.7102,WizardLM/WizardLM-13B-V1.2,0.5,0.0001818,0.25,0.000103,0.5,0.0001818,0.5,0.0002904,0.5,0.000363168,0.5,0.0095
hellaswag.val.2843,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
abstract2title.test.62,mistralai/mixtral-8x7b-chat,1.0,0.0001133999999999,1.0,3.48e-05,1.0,5.58e-05,1.0,0.0001133999999999,1.0,0.000135024,1.0,0.00245
hellaswag.val.7002,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-international-law.val.42,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.00133
mmlu-miscellaneous.val.112,mistralai/mistral-7b-chat,1.0,2.36e-05,1.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
grade-school-math.dev.7205,mistralai/mixtral-8x7b-chat,0.25,0.00027,0.75,7.88e-05,0.75,0.0001598999999999,0.25,0.00027,0.75,0.00031816,0.75,0.00677
mmlu-professional-accounting.val.28,WizardLM/WizardLM-13B-V1.2,0.0,3.75e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
grade-school-math.dev.1847,WizardLM/WizardLM-13B-V1.2,0.5,0.0001365,0.75,7.02e-05,0.5,0.0001365,0.75,0.0002112,0.75,0.00028712,0.5,0.00667
hellaswag.val.8822,mistralai/mistral-7b-chat,0.0,5.4600000000000006e-05,0.0,5.4600000000000006e-05,1.0,8.19e-05,0.0,0.0001638,0.0,0.0002118479999999,0.0,0.00277
grade-school-math.dev.565,mistralai/mixtral-8x7b-chat,0.25,0.0002946,0.25,9.48e-05,0.25,0.0002568,0.25,0.0002946,0.25,0.000347648,0.75,0.01101
grade-school-math.dev.6721,WizardLM/WizardLM-13B-V1.2,0.25,0.0001677,0.25,9.84e-05,0.25,0.0001677,0.25,0.0002483999999999,0.25,0.000320488,0.75,0.0075099999999999
mmlu-elementary-mathematics.val.110,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
consensus_summary.dev.313,mistralai/mixtral-8x7b-chat,0.75,0.0001932,0.75,6.720000000000001e-05,0.75,0.0001031999999999,0.75,0.0001932,0.75,0.000250648,0.75,0.00543
mmlu-high-school-chemistry.val.34,WizardLM/WizardLM-13B-V1.2,0.0,4.11e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
hellaswag.val.9236,WizardLM/WizardLM-13B-V1.2,0.0,8.01e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00271
mmlu-high-school-microeconomics.val.133,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
hellaswag.val.4314,WizardLM/WizardLM-13B-V1.2,0.0,7.08e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-high-school-mathematics.val.191,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.16e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
grade-school-math.dev.7120,WizardLM/WizardLM-13B-V1.2,0.25,0.0001730999999999,0.25,0.0001106,0.25,0.0001730999999999,0.75,0.0003365999999999,0.25,0.000462496,0.75,0.01183
hellaswag.val.3210,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.6759,WizardLM/WizardLM-13B-V1.2,0.25,0.0001782,0.25,7.56e-05,0.25,0.0001782,0.25,0.0002946,0.25,0.000401192,0.75,0.00788
grade-school-math.dev.5735,WizardLM/WizardLM-13B-V1.2,0.75,0.000195,0.75,0.0001158,0.75,0.000195,0.75,0.0002724,0.75,0.00038024,0.75,0.00875
arc-challenge.test.906,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.5413,WizardLM/WizardLM-13B-V1.2,0.0,6.749999999999999e-05,0.0,4.5e-05,0.0,6.749999999999999e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00229
grade-school-math.dev.3158,WizardLM/WizardLM-13B-V1.2,0.25,0.0001716,0.25,8.499999999999999e-05,0.25,0.0001716,0.75,0.0002676,0.25,0.00033368,0.75,0.00802
hellaswag.val.9641,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00233
mmlu-international-law.val.47,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.7042,WizardLM/WizardLM-13B-V1.2,0.75,0.0001209,0.75,7.520000000000001e-05,0.75,0.0001209,0.75,0.0002334,0.75,0.0002948799999999,0.75,0.00703
mmlu-professional-accounting.val.90,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
hellaswag.val.3510,WizardLM/WizardLM-13B-V1.2,0.0,9.03e-05,0.0,6.04e-05,0.0,9.03e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00306
mmlu-global-facts.val.52,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.3781,mistralai/mixtral-8x7b-chat,1.0,0.000168,0.0,5.6000000000000006e-05,0.0,8.4e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00284
grade-school-math.dev.3067,mistralai/mixtral-8x7b-chat,0.75,0.0002718,0.25,8.82e-05,0.5,0.0001886999999999,0.75,0.0002718,0.75,0.000315056,0.75,0.0102499999999999
mmlu-high-school-macroeconomics.val.372,mistralai/mistral-7b-chat,1.0,1.82e-05,1.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
mmlu-miscellaneous.val.695,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.122,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,2.97e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-miscellaneous.val.645,mistralai/mistral-7b-chat,1.0,1.3e-05,1.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
hellaswag.val.8784,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00235
mmlu-high-school-chemistry.val.183,mistralai/mixtral-8x7b-chat,0.0,7.08e-05,1.0,2.36e-05,0.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,0.0,0.00119
mmlu-high-school-biology.val.76,mistralai/mixtral-8x7b-chat,0.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.00095
hellaswag.val.9612,mistralai/mixtral-8x7b-chat,1.0,0.0001632,1.0,5.44e-05,1.0,8.16e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00276
hellaswag.val.4494,mistralai/mixtral-8x7b-chat,1.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00256
grade-school-math.dev.641,mistralai/mistral-7b-chat,0.25,6.52e-05,0.25,6.52e-05,0.5,0.0001491,0.5,0.0002772,0.25,0.00029488,0.5,0.00689
winogrande.dev.1012,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,1.0,1.56e-05,1.0,3.12e-05,1.0,4.0352e-05,0.0,0.00056
grade-school-math.dev.7428,mistralai/mixtral-8x7b-chat,0.75,0.000234,0.75,6.3e-05,0.75,0.0001266,0.75,0.000234,0.75,0.000264616,0.75,0.00577
winogrande.dev.93,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,0.0,1.59e-05,0.0,3.18e-05,1.0,4.1128e-05,1.0,0.00054
mmlu-high-school-government-and-politics.val.179,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
consensus_summary.dev.298,WizardLM/WizardLM-13B-V1.2,0.0,0.0003159,0.25,4.0400000000000006e-05,0.0,0.0003159,0.25,0.0001505999999999,1.0,0.000154424,0.75,0.00276
hellaswag.val.853,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
hellaswag.val.7956,mistralai/mixtral-8x7b-chat,1.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00266
mmlu-security-studies.val.25,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-world-religions.val.168,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
grade-school-math.dev.4129,WizardLM/WizardLM-13B-V1.2,0.75,0.0001503,0.25,9.7e-05,0.75,0.0001503,0.75,0.0002118,0.5,0.000359288,0.75,0.01018
grade-school-math.dev.4728,mistralai/mistral-7b-chat,0.25,7.82e-05,0.25,7.82e-05,0.25,0.0001479,0.25,0.0002441999999999,0.5,0.00030652,0.75,0.00761
winogrande.dev.1017,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,0.0,0.00049
mmlu-moral-disputes.val.45,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
hellaswag.val.425,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
grade-school-math.dev.2969,WizardLM/WizardLM-13B-V1.2,0.25,0.0001796999999999,0.25,9.320000000000002e-05,0.25,0.0001796999999999,0.75,0.0002657999999999,0.25,0.000338336,0.75,0.00785
mmlu-professional-law.val.1107,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
consensus_summary.dev.187,mistralai/mistral-7b-chat,0.75,6.14e-05,0.75,6.14e-05,0.75,8.73e-05,0.75,0.0001572,0.75,0.000218056,0.75,0.00353
mmlu-professional-law.val.80,WizardLM/WizardLM-13B-V1.2,1.0,0.0001245,0.0,8.3e-05,1.0,0.0001245,0.0,0.0002484,0.0,0.00032204,0.0,0.00416
arc-challenge.test.71,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-professional-law.val.1115,WizardLM/WizardLM-13B-V1.2,0.0,9.3e-05,0.0,6.2e-05,0.0,9.3e-05,0.0,0.000186,0.0,0.00024056,1.0,0.00311
mmlu-high-school-microeconomics.val.98,mistralai/mixtral-8x7b-chat,0.0,6.06e-05,1.0,2.02e-05,1.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-high-school-geography.val.153,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-law.val.401,mistralai/mistral-7b-chat,0.0,6.72e-05,0.0,6.72e-05,1.0,0.0001008,1.0,0.0002016,0.0,0.000260736,1.0,0.00337
hellaswag.val.4374,mistralai/mistral-7b-chat,0.0,5.3200000000000006e-05,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,0.0,0.0027
mmlu-professional-law.val.1036,WizardLM/WizardLM-13B-V1.2,0.0,9.39e-05,0.0,6.26e-05,0.0,9.39e-05,1.0,0.0001877999999999,0.0,0.000242888,1.0,0.00314
hellaswag.val.3873,mistralai/mixtral-8x7b-chat,1.0,0.0001308,0.0,4.36e-05,0.0,6.51e-05,1.0,0.0001308,0.0,0.000169168,1.0,0.00219
hellaswag.val.9120,mistralai/mixtral-8x7b-chat,1.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.039999999999999e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-machine-learning.val.92,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,0.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.1015,WizardLM/WizardLM-13B-V1.2,0.75,0.0001587,0.75,0.0001022,0.75,0.0001587,0.75,0.0002964,0.75,0.000381792,0.75,0.00699
bias_detection.dev.57,mistralai/mistral-7b-chat,0.0,6.06e-05,0.0,6.06e-05,0.0,0.0001347,1.0,0.0001824,1.0,0.000252976,0.0,0.0063199999999999
hellaswag.val.4682,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-professional-psychology.val.26,mistralai/mistral-7b-chat,1.0,2.82e-05,1.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-electrical-engineering.val.14,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
winogrande.dev.358,mistralai/mixtral-8x7b-chat,0.0,2.76e-05,0.0,9.2e-06,1.0,1.3799999999999998e-05,0.0,2.76e-05,0.0,3.5696e-05,1.0,0.0005
mmlu-professional-law.val.116,mistralai/mixtral-8x7b-chat,0.0,0.0001524,0.0,5.080000000000001e-05,1.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,0.0,0.00255
grade-school-math.dev.4761,mistralai/mistral-7b-chat,0.25,9.100000000000002e-05,0.25,9.100000000000002e-05,0.75,0.0001344,0.75,0.000255,0.75,0.000293328,0.75,0.00675
mmlu-high-school-world-history.val.32,WizardLM/WizardLM-13B-V1.2,1.0,0.0002127,0.0,0.0001418,1.0,0.0002127,1.0,0.0004254,0.0,0.000550184,1.0,0.0070999999999999
hellaswag.val.7208,mistralai/mixtral-8x7b-chat,0.0,0.0001739999999999,0.0,5.800000000000001e-05,1.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
mmlu-high-school-geography.val.2,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.6204,WizardLM/WizardLM-13B-V1.2,0.0,7.83e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,1.0,0.00265
arc-challenge.test.816,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
mmlu-elementary-mathematics.val.123,mistralai/mistral-7b-chat,1.0,2.56e-05,1.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
mmlu-professional-law.val.727,WizardLM/WizardLM-13B-V1.2,0.0,7.47e-05,1.0,4.980000000000001e-05,0.0,7.47e-05,1.0,0.0001487999999999,0.0,0.0001932239999999,1.0,0.0025
mmlu-virology.val.151,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-high-school-biology.val.6,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-miscellaneous.val.766,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
winogrande.dev.643,mistralai/mixtral-8x7b-chat,1.0,3.12e-05,0.0,1.04e-05,1.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,0.0,0.00056
hellaswag.val.1070,mistralai/mistral-7b-chat,0.0,3.08e-05,0.0,3.08e-05,1.0,4.6200000000000005e-05,1.0,9.24e-05,0.0,0.000119504,1.0,0.00155
grade-school-math.dev.5501,WizardLM/WizardLM-13B-V1.2,0.25,0.0001566,0.25,0.0001046,0.25,0.0001566,0.5,0.0002736,0.25,0.000303416,0.75,0.00622
mmlu-miscellaneous.val.266,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
hellaswag.val.2511,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-moral-scenarios.val.214,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
mmlu-professional-law.val.963,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,0.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00238
hellaswag.val.4342,mistralai/mistral-7b-chat,1.0,4.6200000000000005e-05,1.0,4.6200000000000005e-05,1.0,6.93e-05,1.0,0.0001386,1.0,0.000179256,1.0,0.00235
grade-school-math.dev.1281,mistralai/mistral-7b-chat,0.25,7.98e-05,0.25,7.98e-05,0.5,0.0001503,0.75,0.0002322,0.75,0.000301864,0.75,0.00652
mmlu-world-religions.val.142,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-professional-medicine.val.218,mistralai/mixtral-8x7b-chat,1.0,9e-05,1.0,3e-05,1.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-high-school-chemistry.val.7,mistralai/mixtral-8x7b-chat,0.0,6.3e-05,0.0,2.1e-05,1.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-moral-disputes.val.292,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-prehistory.val.259,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-moral-disputes.val.110,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.2467,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
hellaswag.val.4335,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
mmlu-conceptual-physics.val.151,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.5495,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00246
grade-school-math.dev.4221,mistralai/mistral-7b-chat,0.75,5.380000000000001e-05,0.75,5.380000000000001e-05,0.75,0.0001196999999999,0.75,0.000198,0.5,0.0002522,0.75,0.00479
arc-challenge.test.1156,mistralai/mixtral-8x7b-chat,1.0,3.84e-05,0.0,1.28e-05,1.0,1.92e-05,1.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
mmlu-professional-psychology.val.553,mistralai/mixtral-8x7b-chat,1.0,7.44e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
mmlu-college-biology.val.10,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,1.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-nutrition.val.191,mistralai/mixtral-8x7b-chat,1.0,9.48e-05,0.0,3.160000000000001e-05,1.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,0.0,0.00159
mmlu-professional-psychology.val.263,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.7573,mistralai/mixtral-8x7b-chat,0.0,0.0001422,0.0,4.74e-05,0.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00238
grade-school-math.dev.3074,mistralai/mistral-7b-chat,0.75,8.82e-05,0.75,8.82e-05,0.75,0.0002045999999999,0.25,0.0003096,0.25,0.000311952,0.5,0.01001
hellaswag.val.1894,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.3e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-professional-law.val.176,WizardLM/WizardLM-13B-V1.2,0.0,8.46e-05,0.0,5.64e-05,0.0,8.46e-05,1.0,0.0001692,0.0,0.000218832,1.0,0.00283
hellaswag.val.7788,mistralai/mixtral-8x7b-chat,1.0,0.0001656,0.0,5.520000000000001e-05,1.0,8.25e-05,1.0,0.0001656,0.0,0.0002141759999999,1.0,0.0028
hellaswag.val.9978,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
hellaswag.val.1748,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.72e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00129
hellaswag.val.4245,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
mmlu-professional-law.val.36,WizardLM/WizardLM-13B-V1.2,0.0,0.0001217999999999,1.0,8.120000000000001e-05,0.0,0.0001217999999999,0.0,0.0002435999999999,0.0,0.000315056,0.0,0.0041
hellaswag.val.3235,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
mmlu-professional-law.val.783,WizardLM/WizardLM-13B-V1.2,0.0,6.81e-05,0.0,4.5400000000000006e-05,0.0,6.81e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00228
hellaswag.val.2245,mistralai/mixtral-8x7b-chat,0.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.36e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00117
hellaswag.val.6737,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,0.0,0.00252
arc-challenge.val.243,mistralai/mistral-7b-chat,1.0,1.14e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,1.0,4.4232e-05,1.0,0.00058
mmlu-miscellaneous.val.693,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-high-school-government-and-politics.val.183,mistralai/mixtral-8x7b-chat,1.0,6.12e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
consensus_summary.dev.292,mistralai/mistral-7b-chat,0.75,7.14e-05,0.75,7.14e-05,0.75,0.0001010999999999,0.75,0.0002166,0.75,0.000270824,0.0,0.00251
mmlu-miscellaneous.val.426,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
mmlu-logical-fallacies.val.46,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
winogrande.dev.75,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,1.0,1.62e-05,1.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
grade-school-math.dev.4162,WizardLM/WizardLM-13B-V1.2,0.75,0.0001659,0.5,8.78e-05,0.75,0.0001659,0.5,0.0002592,0.75,0.0002669439999999,0.75,0.00631
mmlu-professional-law.val.1281,WizardLM/WizardLM-13B-V1.2,1.0,5.76e-05,0.0,3.8400000000000005e-05,1.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00196
grade-school-math.dev.1782,mistralai/mistral-7b-chat,0.75,5.92e-05,0.75,5.92e-05,0.75,0.0001389,0.75,0.0001938,0.75,0.000243664,0.75,0.00566
mmlu-college-biology.val.50,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,1.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-professional-psychology.val.566,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
mmlu-miscellaneous.val.460,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,1.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
arc-challenge.test.978,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.9779,mistralai/mixtral-8x7b-chat,0.0,0.0001506,1.0,5.020000000000001e-05,1.0,7.53e-05,0.0,0.0001506,1.0,0.000194776,1.0,0.00255
hellaswag.val.6558,mistralai/mistral-7b-chat,0.0,4.780000000000001e-05,0.0,4.780000000000001e-05,0.0,7.139999999999999e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
hellaswag.val.6225,mistralai/mixtral-8x7b-chat,0.0,0.0001686,0.0,5.62e-05,0.0,8.43e-05,0.0,0.0001686,0.0,0.000218056,0.0,0.00285
arc-challenge.test.447,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,1.0,5.432e-05,1.0,0.00074
hellaswag.val.6672,WizardLM/WizardLM-13B-V1.2,0.0,6.869999999999999e-05,0.0,4.580000000000001e-05,0.0,6.869999999999999e-05,0.0,0.0001373999999999,0.0,0.000177704,1.0,0.0023
mmlu-professional-medicine.val.55,WizardLM/WizardLM-13B-V1.2,0.0,7.56e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00253
grade-school-math.dev.2786,WizardLM/WizardLM-13B-V1.2,0.75,0.0001446,0.75,7.400000000000001e-05,0.75,0.0001446,0.5,0.0002351999999999,0.75,0.000348424,0.75,0.00659
mmlu-prehistory.val.62,mistralai/mixtral-8x7b-chat,1.0,0.000108,0.0,3.600000000000001e-05,1.0,5.4e-05,1.0,0.000108,0.0,0.00013968,1.0,0.00181
mmlu-professional-law.val.1160,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.4830,WizardLM/WizardLM-13B-V1.2,0.5,0.0001704,0.75,9.06e-05,0.5,0.0001704,0.75,0.0002544,0.5,0.000287896,0.75,0.0070399999999999
grade-school-math.dev.6301,meta/code-llama-instruct-34b-chat,0.25,0.000239784,0.25,7.120000000000001e-05,0.75,0.0001053,0.25,0.0002052,0.25,0.000239784,0.75,0.00666
mmlu-astronomy.val.42,mistralai/mixtral-8x7b-chat,0.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-moral-disputes.val.239,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-abstract-algebra.val.50,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,0.0,0.0009199999999999
grade-school-math.dev.7362,mistralai/mistral-7b-chat,0.25,0.0001114,0.25,0.0001114,0.75,0.0001383,0.25,0.0002454,0.25,0.000291,0.75,0.00725
winogrande.dev.1180,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,0.0,0.00048
mmlu-high-school-geography.val.193,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.1818,mistralai/mistral-7b-chat,0.25,9.02e-05,0.25,9.02e-05,0.25,0.0001725,0.25,0.0002778,0.25,0.000359288,0.75,0.00833
mmlu-professional-law.val.1136,WizardLM/WizardLM-13B-V1.2,1.0,5.04e-05,0.0,3.3600000000000004e-05,1.0,5.04e-05,0.0,0.0001008,0.0,0.0001303679999999,0.0,0.00169
grade-school-math.dev.658,WizardLM/WizardLM-13B-V1.2,0.25,0.0002028,0.75,9.9e-05,0.25,0.0002028,1.0,0.0001998,0.25,0.000334456,0.25,0.01078
hellaswag.val.1779,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
grade-school-math.dev.5153,meta/code-llama-instruct-34b-chat,0.25,0.000398864,0.25,9.52e-05,0.75,0.0001541999999999,0.25,0.0002201999999999,0.25,0.000398864,0.75,0.0093899999999999
hellaswag.val.8871,WizardLM/WizardLM-13B-V1.2,0.0,9.42e-05,0.0,6.3e-05,0.0,9.42e-05,1.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
grade-school-math.dev.153,WizardLM/WizardLM-13B-V1.2,0.25,0.0001524,0.25,6.1000000000000005e-05,0.25,0.0001524,0.25,0.0002406,0.25,0.000277808,0.75,0.00959
mmlu-conceptual-physics.val.46,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-philosophy.val.69,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-professional-law.val.215,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.34e-05,1.0,0.0001668,0.0,0.000215728,1.0,0.00279
hellaswag.val.7064,mistralai/mistral-7b-chat,1.0,5.9e-05,1.0,5.9e-05,1.0,8.85e-05,1.0,0.000177,1.0,0.0002289199999999,1.0,0.00299
mmlu-high-school-macroeconomics.val.259,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,0.0,0.00151
mmlu-professional-law.val.1129,WizardLM/WizardLM-13B-V1.2,0.0,9.96e-05,1.0,6.64e-05,0.0,9.96e-05,1.0,0.0001992,0.0,0.000257632,1.0,0.00333
hellaswag.val.1663,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-professional-law.val.840,mistralai/mixtral-8x7b-chat,1.0,0.0001422,1.0,4.74e-05,0.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00238
mmlu-high-school-psychology.val.259,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
mmlu-moral-scenarios.val.672,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,1.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
mmlu-jurisprudence.val.46,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-law.val.900,WizardLM/WizardLM-13B-V1.2,0.0,0.0001133999999999,0.0,7.56e-05,0.0,0.0001133999999999,0.0,0.0002267999999999,0.0,0.000293328,0.0,0.00379
mmlu-high-school-microeconomics.val.146,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
arc-challenge.test.767,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,1.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,1.0,8.0704e-05,1.0,0.00108
grade-school-math.dev.1131,WizardLM/WizardLM-13B-V1.2,0.75,0.000159,0.25,5.6e-05,0.75,0.000159,0.75,0.0002213999999999,0.75,0.0002522,0.75,0.00727
winogrande.dev.241,mistralai/mistral-7b-chat,1.0,8.999999999999999e-06,1.0,8.999999999999999e-06,0.0,1.35e-05,1.0,2.7e-05,1.0,3.4920000000000004e-05,0.0,0.00046
consensus_summary.dev.293,mistralai/mixtral-8x7b-chat,0.75,0.0001967999999999,0.75,7.48e-05,0.75,0.0003197999999999,0.75,0.0001967999999999,0.25,0.000187792,0.0,0.00229
hellaswag.val.1498,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,0.0,4.2e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00142
arc-challenge.test.830,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
arc-challenge.test.499,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,1.0,7.5272e-05,1.0,0.00098
hellaswag.val.3761,mistralai/mixtral-8x7b-chat,1.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,1.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
arc-challenge.val.37,mistralai/mixtral-8x7b-chat,1.0,8.7e-05,0.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
hellaswag.val.1190,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
abstract2title.test.79,mistralai/mixtral-8x7b-chat,1.0,0.0001668,1.0,5.12e-05,1.0,7.949999999999998e-05,1.0,0.0001668,1.0,0.000200208,1.0,0.00316
grade-school-math.dev.1492,mistralai/mixtral-8x7b-chat,0.5,0.0001752,0.75,6.180000000000001e-05,0.75,0.0001275,0.5,0.0001752,0.75,0.000239008,0.75,0.00565
mbpp.dev.398,mistralai/mistral-7b-chat,0.0,6e-05,0.0,6e-05,1.0,0.0001323,1.0,0.0002382,1.0,0.000276256,1.0,0.00888
mmlu-moral-disputes.val.101,mistralai/mistral-7b-chat,1.0,2.54e-05,1.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-prehistory.val.161,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
mmlu-international-law.val.87,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-law.val.750,WizardLM/WizardLM-13B-V1.2,0.0,0.0001152,0.0,7.68e-05,0.0,0.0001152,1.0,0.0002304,0.0,0.000297984,1.0,0.00385
hellaswag.val.2426,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.9e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.0013499999999999
hellaswag.val.952,mistralai/mistral-7b-chat,1.0,2.56e-05,1.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
hellaswag.val.8623,WizardLM/WizardLM-13B-V1.2,1.0,6.39e-05,1.0,4.2600000000000005e-05,1.0,6.39e-05,1.0,0.0001278,1.0,0.000165288,1.0,0.00214
mmlu-college-computer-science.val.60,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,0.0,0.00252
mmlu-professional-accounting.val.27,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00238
consensus_summary.dev.184,mistralai/mistral-7b-chat,1.0,4.7600000000000005e-05,1.0,4.7600000000000005e-05,0.5,0.000288,0.75,0.0001596,0.75,0.000231248,0.0,0.00183
arc-challenge.test.786,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,1.0,6.751200000000001e-05,1.0,0.00091
hellaswag.val.1696,WizardLM/WizardLM-13B-V1.2,1.0,4.08e-05,1.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,1.0,0.000105536,1.0,0.00137
winogrande.dev.1038,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
mmlu-professional-law.val.472,WizardLM/WizardLM-13B-V1.2,0.0,8.999999999999999e-05,1.0,6e-05,0.0,8.999999999999999e-05,1.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
mmlu-high-school-macroeconomics.val.285,mistralai/mistral-7b-chat,1.0,1.54e-05,1.0,1.54e-05,1.0,2.28e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-econometrics.val.25,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
winogrande.dev.428,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,0.0,0.00049
winogrande.dev.1007,mistralai/mistral-7b-chat,0.0,9.6e-06,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
hellaswag.val.1937,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
hellaswag.val.9604,mistralai/mixtral-8x7b-chat,0.0,0.0001308,0.0,4.36e-05,0.0,6.54e-05,0.0,0.0001308,0.0,0.000169168,1.0,0.00222
grade-school-math.dev.3902,WizardLM/WizardLM-13B-V1.2,0.5,0.0001952999999999,0.25,0.000106,0.5,0.0001952999999999,0.25,0.0003528,0.25,0.000415936,0.75,0.0093099999999999
mmlu-international-law.val.54,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-college-chemistry.val.70,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.9585,mistralai/mistral-7b-chat,1.0,4.9600000000000006e-05,1.0,4.9600000000000006e-05,1.0,7.409999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
grade-school-math.dev.7173,WizardLM/WizardLM-13B-V1.2,0.5,0.0001578,0.5,8.879999999999999e-05,0.5,0.0001578,1.0,0.0002256,0.5,0.0003298,0.75,0.00633
hellaswag.val.4267,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.189999999999998e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
mmlu-jurisprudence.val.4,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,0.0,0.00109
mmlu-high-school-physics.val.11,mistralai/mixtral-8x7b-chat,0.0,0.0001049999999999,1.0,3.520000000000001e-05,1.0,5.28e-05,0.0,0.0001049999999999,0.0,0.000136576,1.0,0.00177
mmlu-miscellaneous.val.500,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.3339,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.00243
mmlu-nutrition.val.0,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.3429,mistralai/mistral-7b-chat,0.0,3.94e-05,0.0,3.94e-05,0.0,5.91e-05,0.0,0.0001182,0.0,0.0001528719999999,1.0,0.00198
hellaswag.val.4835,mistralai/mixtral-8x7b-chat,0.0,0.0001704,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00288
hellaswag.val.8423,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00261
mmlu-high-school-government-and-politics.val.153,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
abstract2title.test.64,mistralai/mixtral-8x7b-chat,1.0,0.0001524,1.0,4.98e-05,1.0,7.47e-05,1.0,0.0001524,1.0,0.000194776,1.0,0.0031999999999999
mmlu-moral-scenarios.val.645,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00142
hellaswag.val.3736,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,0.0,0.00264
mmlu-high-school-physics.val.53,mistralai/mixtral-8x7b-chat,1.0,7.44e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.0012799999999999
mmlu-professional-law.val.884,WizardLM/WizardLM-13B-V1.2,0.0,7.89e-05,1.0,5.260000000000001e-05,0.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00264
winogrande.dev.16,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,1.0,3.7248e-05,0.0,0.00049
hellaswag.val.6528,mistralai/mistral-7b-chat,1.0,5.4000000000000005e-05,1.0,5.4000000000000005e-05,1.0,8.099999999999999e-05,1.0,0.0001619999999999,1.0,0.00020952,1.0,0.00274
mmlu-logical-fallacies.val.102,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
hellaswag.val.8431,WizardLM/WizardLM-13B-V1.2,0.0,7.74e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,1.0,0.0001548,0.0,0.000200208,1.0,0.00259
mmlu-miscellaneous.val.78,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
grade-school-math.dev.6983,WizardLM/WizardLM-13B-V1.2,0.25,0.0001806,0.75,8.779999999999999e-05,0.25,0.0001806,0.75,0.0002094,0.25,0.000313504,0.75,0.00933
mmlu-astronomy.val.59,mistralai/mistral-7b-chat,1.0,2.22e-05,1.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
grade-school-math.dev.1474,WizardLM/WizardLM-13B-V1.2,0.75,0.0001365,0.25,9.26e-05,0.75,0.0001365,0.75,0.000243,0.25,0.000280912,0.75,0.00648
hellaswag.val.4882,WizardLM/WizardLM-13B-V1.2,0.0,5.88e-05,0.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,0.0,0.00197
mmlu-miscellaneous.val.191,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,1.0,2.07e-05,0.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
grade-school-math.dev.6489,WizardLM/WizardLM-13B-V1.2,0.75,0.0001449,0.25,9.92e-05,0.75,0.0001449,0.25,0.0002892,0.25,0.000405072,0.75,0.00814
mmlu-professional-psychology.val.481,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
grade-school-math.dev.3744,mistralai/mistral-7b-chat,0.25,7.34e-05,0.25,7.34e-05,0.25,0.0001428,0.25,0.0002748,0.25,0.000291,0.75,0.00789
grade-school-math.dev.7054,mistralai/mistral-7b-chat,0.25,9.3e-05,0.25,9.3e-05,0.75,0.0001716,0.25,0.0002412,0.25,0.000301864,0.75,0.0089
hellaswag.val.9601,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,0.0,5.5e-05,0.0,8.219999999999998e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-moral-disputes.val.108,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
hellaswag.val.3802,WizardLM/WizardLM-13B-V1.2,0.0,9.689999999999998e-05,0.0,6.48e-05,0.0,9.689999999999998e-05,0.0,0.0001943999999999,0.0,0.000251424,0.0,0.00328
mmlu-moral-scenarios.val.35,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-miscellaneous.val.739,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.1079,mistralai/mistral-7b-chat,0.25,7.56e-05,0.25,7.56e-05,0.75,0.0001574999999999,0.25,0.0001769999999999,0.25,0.000291,0.75,0.00793
hellaswag.val.2046,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00109
mmlu-moral-scenarios.val.434,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
arc-challenge.test.563,mistralai/mixtral-8x7b-chat,1.0,9.6e-05,1.0,3.2000000000000005e-05,0.0,4.8e-05,1.0,9.6e-05,1.0,0.00012416,1.0,0.00161
mmlu-professional-psychology.val.123,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,1.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-abstract-algebra.val.38,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,0.0,0.00071
mmlu-college-medicine.val.151,mistralai/mistral-7b-chat,0.0,3.180000000000001e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,1.0,0.0016
mmlu-college-mathematics.val.77,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.978,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,1.0,3.96e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00134
mmlu-world-religions.val.63,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-marketing.val.170,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
hellaswag.val.8207,mistralai/mistral-7b-chat,1.0,5.34e-05,1.0,5.34e-05,1.0,8.01e-05,0.0,0.0001602,1.0,0.000207192,1.0,0.00268
mmlu-moral-disputes.val.220,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
mmlu-miscellaneous.val.35,mistralai/mistral-7b-chat,1.0,1.46e-05,1.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-professional-law.val.311,WizardLM/WizardLM-13B-V1.2,0.0,8.61e-05,0.0,5.7400000000000006e-05,0.0,8.61e-05,0.0,0.0001716,0.0,0.000222712,0.0,0.00291
mmlu-professional-law.val.188,WizardLM/WizardLM-13B-V1.2,0.0,8.85e-05,0.0,5.9e-05,0.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
mmlu-moral-scenarios.val.811,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00145
mmlu-moral-scenarios.val.687,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00137
mmlu-professional-law.val.494,WizardLM/WizardLM-13B-V1.2,1.0,8.88e-05,0.0,5.920000000000001e-05,1.0,8.88e-05,1.0,0.0001776,0.0,0.000229696,1.0,0.00297
mmlu-professional-law.val.1330,WizardLM/WizardLM-13B-V1.2,1.0,0.0001107,0.0,7.38e-05,1.0,0.0001107,1.0,0.0002214,0.0,0.000286344,1.0,0.0037
grade-school-math.dev.4585,mistralai/mixtral-8x7b-chat,0.75,0.000216,0.75,8.120000000000001e-05,0.5,0.0001275,0.75,0.000216,0.75,0.000261512,0.75,0.0062
grade-school-math.dev.3017,meta/code-llama-instruct-34b-chat,0.25,0.000297984,0.75,7.120000000000001e-05,0.75,0.0001548,0.75,0.0002304,0.25,0.000297984,0.75,0.00556
grade-school-math.dev.5245,WizardLM/WizardLM-13B-V1.2,0.75,0.0001769999999999,0.25,8.86e-05,0.75,0.0001769999999999,0.75,0.0002634,0.25,0.000336784,0.75,0.0087999999999999
mmlu-professional-law.val.926,mistralai/mixtral-8x7b-chat,1.0,0.0001752,1.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,0.0,0.000226592,1.0,0.00296
mmlu-professional-law.val.211,WizardLM/WizardLM-13B-V1.2,0.0,8.58e-05,0.0,5.720000000000001e-05,0.0,8.58e-05,1.0,0.0001716,0.0,0.000221936,1.0,0.00287
mmlu-college-biology.val.11,mistralai/mixtral-8x7b-chat,0.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-computer-science.val.97,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.2114,WizardLM/WizardLM-13B-V1.2,0.0,3.93e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.4270,mistralai/mixtral-8x7b-chat,1.0,0.0001776,1.0,5.920000000000001e-05,1.0,8.88e-05,1.0,0.0001776,1.0,0.000229696,1.0,0.003
grade-school-math.dev.5801,WizardLM/WizardLM-13B-V1.2,0.25,0.0001565999999999,0.25,0.0001226,0.25,0.0001565999999999,0.75,0.0002699999999999,0.25,0.000343768,0.5,0.00909
hellaswag.val.804,WizardLM/WizardLM-13B-V1.2,0.0,5.1e-05,0.0,3.4000000000000007e-05,0.0,5.1e-05,0.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
mmlu-machine-learning.val.97,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,0.0,0.00151
grade-school-math.dev.4217,mistralai/mistral-7b-chat,0.25,8.659999999999999e-05,0.25,8.659999999999999e-05,0.75,0.0001518,0.25,0.0003078,0.25,0.000327472,0.75,0.00988
grade-school-math.dev.1645,mistralai/mistral-7b-chat,0.25,7.32e-05,0.25,7.32e-05,0.75,0.0001539,0.75,0.0002646,0.75,0.000343768,0.75,0.00848
mmlu-moral-disputes.val.322,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.734,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-high-school-macroeconomics.val.127,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.1145,WizardLM/WizardLM-13B-V1.2,0.5,0.0001418999999999,0.25,6.0200000000000006e-05,0.5,0.0001418999999999,0.25,0.0002556,0.75,0.000295656,0.75,0.00713
abstract2title.test.113,mistralai/mixtral-8x7b-chat,1.0,0.0001164,1.0,3.7000000000000005e-05,1.0,5.97e-05,1.0,0.0001164,1.0,0.0001513199999999,1.0,0.0028199999999999
grade-school-math.dev.2362,mistralai/mistral-7b-chat,0.25,9.9e-05,0.25,9.9e-05,0.5,0.000165,0.25,0.000261,0.25,0.000320488,0.75,0.00924
hellaswag.val.4837,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00257
grade-school-math.dev.5016,mistralai/mixtral-8x7b-chat,0.25,0.0002568,0.25,0.000114,0.0,0.0001809,0.25,0.0002568,0.25,0.000427576,0.75,0.00824
mtbench-reference.dev.14,mistralai/mistral-7b-chat,1.0,7.6e-05,1.0,7.6e-05,0.1,0.0003329999999999,0.8,0.0002328,0.2,0.000301864,1.0,0.00955
grade-school-math.dev.704,mistralai/mistral-7b-chat,0.25,8.66e-05,0.25,8.66e-05,0.75,0.0001356,0.5,0.0002826,0.75,0.000318936,0.75,0.00818
mmlu-professional-accounting.val.59,WizardLM/WizardLM-13B-V1.2,0.0,3.33e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
hellaswag.val.5558,WizardLM/WizardLM-13B-V1.2,0.0,7.38e-05,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.0025
grade-school-math.dev.89,mistralai/mistral-7b-chat,0.5,9.2e-05,0.5,9.2e-05,0.25,0.0001883999999999,0.75,0.0002712,0.25,0.000448528,0.5,0.00942
hellaswag.val.8820,mistralai/mixtral-8x7b-chat,0.0,0.000165,0.0,5.520000000000001e-05,1.0,8.280000000000001e-05,0.0,0.000165,0.0,0.0002141759999999,1.0,0.0028
bias_detection.dev.284,mistralai/mistral-7b-chat,0.0,5.52e-05,0.0,5.52e-05,0.0,9.21e-05,0.0,0.0001914,0.0,0.000241336,0.0,0.00772
mmlu-moral-scenarios.val.832,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
grade-school-math.dev.7261,WizardLM/WizardLM-13B-V1.2,0.25,0.000219,0.25,0.0001028,0.25,0.000219,0.25,0.0003984,0.5,0.00048112,0.5,0.01287
hellaswag.val.2660,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00101
mmlu-professional-law.val.1109,WizardLM/WizardLM-13B-V1.2,1.0,0.0001098,0.0,7.319999999999999e-05,1.0,0.0001098,0.0,0.0002196,0.0,0.000284016,1.0,0.00367
mmlu-miscellaneous.val.208,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,0.0,0.00095
grade-school-math.dev.1500,mistralai/mistral-7b-chat,0.75,9.86e-05,0.75,9.86e-05,0.75,0.0001791,0.25,0.0003132,0.75,0.000339112,0.75,0.00904
hellaswag.val.4973,mistralai/mixtral-8x7b-chat,0.0,0.000126,1.0,4.2e-05,1.0,6.269999999999999e-05,0.0,0.000126,1.0,0.00016296,1.0,0.00214
grade-school-math.dev.6042,mistralai/mistral-7b-chat,0.25,6.340000000000001e-05,0.25,6.340000000000001e-05,0.25,0.0001643999999999,0.25,0.0002639999999999,0.5,0.000354632,0.75,0.01178
hellaswag.val.7954,WizardLM/WizardLM-13B-V1.2,0.0,8.489999999999999e-05,0.0,5.680000000000001e-05,0.0,8.489999999999999e-05,0.0,0.0001704,0.0,0.0002203839999999,0.0,0.00288
hellaswag.val.7640,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-high-school-geography.val.129,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-professional-psychology.val.411,mistralai/mistral-7b-chat,1.0,2.34e-05,1.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00121
grade-school-math.dev.1862,WizardLM/WizardLM-13B-V1.2,0.5,0.0001275,0.5,7.200000000000002e-05,0.5,0.0001275,0.75,0.0002184,0.5,0.000266944,0.75,0.0060999999999999
mtbench-reference.dev.17,mistralai/mistral-7b-chat,0.1,7.42e-05,0.1,7.42e-05,0.2,0.0001953,0.9,0.0002411999999999,0.2,0.000332128,1.0,0.01672
grade-school-math.dev.347,WizardLM/WizardLM-13B-V1.2,0.75,0.0001262999999999,0.25,5.440000000000001e-05,0.75,0.0001262999999999,0.5,0.0001974,0.25,0.00023668,0.75,0.00577
mmlu-high-school-chemistry.val.100,mistralai/mixtral-8x7b-chat,0.0,9.12e-05,1.0,3.04e-05,0.0,4.56e-05,0.0,9.12e-05,0.0,0.000117952,1.0,0.00156
mmlu-high-school-government-and-politics.val.140,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
winogrande.dev.1131,mistralai/mixtral-8x7b-chat,0.0,2.82e-05,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00048
grade-school-math.dev.7387,WizardLM/WizardLM-13B-V1.2,0.25,0.000174,0.75,7.26e-05,0.25,0.000174,0.75,0.0002652,0.75,0.000313504,0.75,0.00764
mmlu-moral-disputes.val.93,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,0.0,7.08e-05,0.0,9.1568e-05,0.0,0.00119
grade-school-math.dev.4673,mistralai/mistral-7b-chat,0.5,8.72e-05,0.5,8.72e-05,0.75,0.0001637999999999,0.75,0.0003126,0.25,0.000321264,0.5,0.00839
bias_detection.dev.27,mistralai/mistral-7b-chat,0.0,6.88e-05,0.0,6.88e-05,0.0,9.42e-05,0.0,0.000174,0.0,0.0002312479999999,0.0,0.00489
arc-challenge.test.225,mistralai/mixtral-8x7b-chat,1.0,3.96e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.0007
grade-school-math.dev.5233,WizardLM/WizardLM-13B-V1.2,0.25,0.0001442999999999,0.25,6.34e-05,0.25,0.0001442999999999,0.75,0.0002279999999999,0.25,0.000305744,0.5,0.00711
mmlu-college-biology.val.141,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-high-school-world-history.val.140,WizardLM/WizardLM-13B-V1.2,1.0,0.0001352999999999,1.0,9.02e-05,1.0,0.0001352999999999,1.0,0.0002705999999999,0.0,0.000349976,1.0,0.00452
grade-school-math.dev.4019,mistralai/mistral-7b-chat,0.25,0.0001036,0.25,0.0001036,0.25,0.0001532999999999,0.75,0.0002652,0.75,0.000332128,0.75,0.0099899999999999
grade-school-math.dev.2091,WizardLM/WizardLM-13B-V1.2,0.25,0.0001281,0.25,6.52e-05,0.25,0.0001281,0.25,0.0002076,0.25,0.000285568,0.75,0.0096
hellaswag.val.7077,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
winogrande.dev.281,mistralai/mixtral-8x7b-chat,0.0,2.82e-05,1.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00048
hellaswag.val.770,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-professional-law.val.117,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
winogrande.dev.1031,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
hellaswag.val.6156,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,1.0,0.00232
hellaswag.val.8688,WizardLM/WizardLM-13B-V1.2,0.0,9.48e-05,0.0,6.34e-05,0.0,9.48e-05,0.0,0.0001902,0.0,0.000245992,1.0,0.00318
mmlu-high-school-us-history.val.173,WizardLM/WizardLM-13B-V1.2,1.0,0.0001008,1.0,6.72e-05,1.0,0.0001008,1.0,0.0002016,0.0,0.000260736,1.0,0.00337
mmlu-high-school-psychology.val.541,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,1.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
grade-school-math.dev.7380,meta/code-llama-instruct-34b-chat,0.75,0.000318936,0.5,8.620000000000001e-05,0.75,0.0001404,1.0,0.0001872,0.75,0.000318936,0.75,0.00701
grade-school-math.dev.4245,mistralai/mistral-7b-chat,0.25,7.92e-05,0.25,7.92e-05,0.25,0.0002031,0.5,0.0002519999999999,0.25,0.000340664,0.75,0.0092199999999999
grade-school-math.dev.4772,mistralai/mistral-7b-chat,0.5,8.840000000000001e-05,0.5,8.840000000000001e-05,0.25,0.0001841999999999,0.5,0.0002622,0.25,0.000323592,0.75,0.0070999999999999
hellaswag.val.1087,mistralai/mistral-7b-chat,1.0,3.160000000000001e-05,1.0,3.160000000000001e-05,1.0,4.71e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00162
mmlu-human-aging.val.216,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.167,mistralai/mistral-7b-chat,1.0,2.68e-05,1.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00138
grade-school-math.dev.4669,mistralai/mistral-7b-chat,0.75,8.72e-05,0.75,8.72e-05,0.75,0.0001461,0.75,0.0002742,0.75,0.000332128,0.75,0.00727
grade-school-math.dev.71,mistralai/mistral-7b-chat,0.25,6.220000000000001e-05,0.25,6.220000000000001e-05,0.75,0.0001449,0.75,0.0002262,0.75,0.000285568,0.5,0.00641
mmlu-electrical-engineering.val.17,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
mmlu-us-foreign-policy.val.80,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
grade-school-math.dev.5736,mistralai/mixtral-8x7b-chat,0.25,0.0002004,0.25,6.98e-05,0.75,0.0001269,0.25,0.0002004,0.75,0.000232024,0.75,0.00578
mmlu-professional-law.val.554,mistralai/mistral-7b-chat,1.0,5.4000000000000005e-05,1.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,0.0,0.00271
mmlu-marketing.val.138,WizardLM/WizardLM-13B-V1.2,0.0,3.09e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00107
mmlu-moral-disputes.val.47,mistralai/mistral-7b-chat,1.0,2.44e-05,1.0,2.44e-05,1.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.0012599999999999
mmlu-moral-scenarios.val.191,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
mmlu-public-relations.val.89,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
consensus_summary.dev.105,mistralai/mixtral-8x7b-chat,0.75,0.0002045999999999,0.75,8.34e-05,0.75,0.0001109999999999,0.75,0.0002045999999999,0.75,0.000232024,1.0,0.00259
arc-challenge.test.408,mistralai/mixtral-8x7b-chat,0.0,6.6e-05,1.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,1.0,8.536000000000001e-05,1.0,0.00111
mmlu-high-school-world-history.val.235,mistralai/mixtral-8x7b-chat,1.0,0.000111,0.0,3.7000000000000005e-05,0.0,5.55e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00186
mmlu-computer-security.val.54,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-high-school-microeconomics.val.11,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,1.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.00141
hellaswag.val.1102,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,1.0,2.67e-05,1.0,5.4e-05,1.0,6.984e-05,1.0,0.00091
grade-school-math.dev.1412,mistralai/mistral-7b-chat,0.25,0.0001076,0.25,0.0001076,0.25,0.000222,0.25,0.000258,0.25,0.000458616,0.75,0.01351
mmlu-high-school-psychology.val.241,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,0.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
arc-challenge.val.182,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-world-religions.val.102,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
grade-school-math.dev.412,mistralai/mistral-7b-chat,0.5,7.4e-05,0.5,7.4e-05,0.25,0.0001317,0.25,0.0002267999999999,0.25,0.000324368,0.5,0.0072499999999999
hellaswag.val.5476,mistralai/mixtral-8x7b-chat,1.0,0.0001739999999999,0.0,5.78e-05,0.0,8.699999999999999e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
hellaswag.val.3414,mistralai/mistral-7b-chat,1.0,5e-05,1.0,5e-05,1.0,7.469999999999999e-05,1.0,0.00015,1.0,0.000194,1.0,0.00254
mmlu-high-school-macroeconomics.val.156,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
hellaswag.val.8154,mistralai/mistral-7b-chat,0.0,5.580000000000001e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.00283
grade-school-math.dev.5049,mistralai/mistral-7b-chat,0.25,8.400000000000001e-05,0.25,8.400000000000001e-05,0.25,0.0001652999999999,0.25,0.0002573999999999,0.25,0.000276256,0.75,0.00646
winogrande.dev.431,mistralai/mistral-7b-chat,0.0,1.14e-05,0.0,1.14e-05,0.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,1.0,4.4232e-05,1.0,0.00058
mmlu-sociology.val.183,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,0.0,0.0007999999999999
mmlu-high-school-computer-science.val.46,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,1.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
hellaswag.val.5728,mistralai/mistral-7b-chat,0.0,5.580000000000001e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,1.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
mmlu-high-school-biology.val.108,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,0.0,0.00094
mmlu-elementary-mathematics.val.259,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
grade-school-math.dev.2701,WizardLM/WizardLM-13B-V1.2,0.75,0.0001977,0.25,0.0001112,0.75,0.0001977,0.75,0.000267,0.25,0.000369376,0.75,0.00761
mmlu-nutrition.val.138,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.9372,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
mmlu-astronomy.val.100,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,1.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
hellaswag.val.2773,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-college-medicine.val.102,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
hellaswag.val.9502,mistralai/mistral-7b-chat,0.0,4.920000000000001e-05,0.0,4.920000000000001e-05,0.0,7.35e-05,0.0,0.0001476,0.0,0.0001908959999999,0.0,0.0025
hellaswag.val.6977,mistralai/mixtral-8x7b-chat,0.0,0.0001392,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,0.0,0.00233
mmlu-professional-law.val.1273,mistralai/mistral-7b-chat,0.0,6.18e-05,0.0,6.18e-05,1.0,9.27e-05,1.0,0.0001853999999999,0.0,0.000239784,0.0,0.0031
mmlu-moral-disputes.val.251,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.00075
mmlu-high-school-physics.val.147,mistralai/mistral-7b-chat,0.0,3.04e-05,0.0,3.04e-05,0.0,4.56e-05,0.0,9.12e-05,0.0,0.000117952,0.0,0.00153
mmlu-sociology.val.163,mistralai/mixtral-8x7b-chat,0.0,4.6800000000000006e-05,1.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
mmlu-conceptual-physics.val.140,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-logical-fallacies.val.24,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.3294,mistralai/mistral-7b-chat,0.25,9.56e-05,0.25,9.56e-05,0.25,0.0001496999999999,0.25,0.0002963999999999,0.25,0.000262288,0.5,0.00963
grade-school-math.dev.6665,mistralai/mistral-7b-chat,0.25,8.92e-05,0.25,8.92e-05,0.75,0.0001817999999999,0.75,0.000258,0.75,0.000295656,0.75,0.00934
mmlu-professional-law.val.47,mistralai/mistral-7b-chat,0.0,3.720000000000001e-05,0.0,3.720000000000001e-05,1.0,5.58e-05,1.0,0.0001115999999999,0.0,0.0001443359999999,1.0,0.0019
mmlu-high-school-statistics.val.30,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-elementary-mathematics.val.321,mistralai/mistral-7b-chat,1.0,4.020000000000001e-05,1.0,4.020000000000001e-05,0.0,6.03e-05,1.0,0.0001205999999999,0.0,0.000155976,1.0,0.00202
hellaswag.val.9722,mistralai/mixtral-8x7b-chat,0.0,0.0001386,0.0,4.6200000000000005e-05,1.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,1.0,0.00235
hellaswag.val.9384,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
mmlu-elementary-mathematics.val.7,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.8611,mistralai/mistral-7b-chat,1.0,4.7600000000000005e-05,1.0,4.7600000000000005e-05,1.0,7.14e-05,1.0,0.0001428,1.0,0.000184688,1.0,0.00242
hellaswag.val.4613,mistralai/mistral-7b-chat,0.0,5.420000000000001e-05,0.0,5.420000000000001e-05,0.0,8.099999999999999e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00275
mmlu-professional-medicine.val.5,mistralai/mixtral-8x7b-chat,1.0,8.159999999999999e-05,1.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-high-school-macroeconomics.val.7,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,0.0,0.00091
mmlu-world-religions.val.7,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-law.val.1459,WizardLM/WizardLM-13B-V1.2,1.0,9.3e-05,0.0,6.2e-05,1.0,9.3e-05,1.0,0.000186,0.0,0.00024056,1.0,0.00311
hellaswag.val.3115,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.24e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
winogrande.dev.73,mistralai/mistral-7b-chat,0.0,1.02e-05,0.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,0.0,3.88e-05,1.0,0.00055
grade-school-math.dev.3682,mistralai/mistral-7b-chat,0.25,5.78e-05,0.25,5.78e-05,0.5,0.0001844999999999,0.25,0.000264,0.25,0.000311952,0.75,0.00904
mmlu-high-school-physics.val.103,mistralai/mixtral-8x7b-chat,1.0,7.2e-05,0.0,2.4e-05,0.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-high-school-macroeconomics.val.98,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-moral-scenarios.val.7,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.00153
mmlu-professional-law.val.489,mistralai/mistral-7b-chat,0.0,5.4000000000000005e-05,0.0,5.4000000000000005e-05,1.0,8.099999999999999e-05,1.0,0.0001619999999999,0.0,0.00020952,0.0,0.00271
hellaswag.val.7841,WizardLM/WizardLM-13B-V1.2,0.0,7.289999999999998e-05,0.0,4.880000000000001e-05,0.0,7.289999999999998e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,0.0,0.00248
hellaswag.val.4247,mistralai/mistral-7b-chat,1.0,5.56e-05,1.0,5.56e-05,1.0,8.309999999999999e-05,1.0,0.0001668,1.0,0.000215728,1.0,0.00282
hellaswag.val.5771,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
mmlu-computer-security.val.48,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,1.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-medical-genetics.val.46,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
grade-school-math.dev.6921,WizardLM/WizardLM-13B-V1.2,0.25,0.0001286999999999,0.75,8.560000000000001e-05,0.25,0.0001286999999999,0.25,0.0002538,0.25,0.000277808,0.75,0.00807
mmlu-high-school-statistics.val.35,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,0.0,0.00149
grade-school-math.dev.2290,mistralai/mixtral-8x7b-chat,0.25,0.0002129999999999,0.25,5.4000000000000005e-05,0.75,0.0001262999999999,0.25,0.0002129999999999,1.0,0.000277032,0.5,0.0051
mmlu-professional-law.val.536,mistralai/mistral-7b-chat,0.0,6e-05,0.0,6e-05,1.0,8.999999999999999e-05,0.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
mmlu-college-mathematics.val.6,mistralai/mixtral-8x7b-chat,0.0,9.54e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,0.0,9.54e-05,0.0,0.000123384,0.0,0.0016
mmlu-moral-scenarios.val.130,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,0.0,7.92e-05,0.0,0.000102432,0.0,0.00133
hellaswag.val.2841,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
winogrande.dev.287,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
grade-school-math.dev.3971,mistralai/mistral-7b-chat,0.75,0.0001112,0.75,0.0001112,0.75,0.0001578,0.25,0.0002922,0.75,0.00030652,0.75,0.00966
arc-challenge.test.847,WizardLM/WizardLM-13B-V1.2,1.0,3.66e-05,0.0,2.44e-05,1.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
mmlu-professional-law.val.1470,WizardLM/WizardLM-13B-V1.2,1.0,8.4e-05,0.0,5.6000000000000006e-05,1.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
arc-challenge.test.180,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
abstract2title.test.216,mistralai/mixtral-8x7b-chat,1.0,0.0002334,1.0,7.64e-05,1.0,0.0001155,1.0,0.0002334,1.0,0.00029488,1.0,0.00451
mmlu-conceptual-physics.val.83,mistralai/mistral-7b-chat,1.0,1.72e-05,1.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
hellaswag.val.5091,mistralai/mistral-7b-chat,1.0,4.5e-05,1.0,4.5e-05,1.0,6.749999999999999e-05,0.0,0.0001349999999999,1.0,0.0001746,1.0,0.00229
hellaswag.val.4566,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00261
hellaswag.val.7429,mistralai/mixtral-8x7b-chat,0.0,0.0001998,0.0,6.659999999999999e-05,0.0,9.96e-05,0.0,0.0001998,0.0,0.0002584079999999,1.0,0.00337
mmlu-world-religions.val.84,mistralai/mixtral-8x7b-chat,0.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
grade-school-math.dev.627,mistralai/mistral-7b-chat,0.25,8.34e-05,0.25,8.34e-05,0.5,0.0001344,0.75,0.0002483999999999,0.75,0.000257632,0.75,0.0085
mmlu-professional-law.val.1480,mistralai/mistral-7b-chat,0.0,4.9600000000000006e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
mmlu-professional-law.val.523,WizardLM/WizardLM-13B-V1.2,0.0,9.24e-05,1.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00309
hellaswag.val.6870,mistralai/mixtral-8x7b-chat,0.0,0.0001794,0.0,5.980000000000001e-05,0.0,8.939999999999999e-05,0.0,0.0001794,0.0,0.000232024,1.0,0.003
consensus_summary.dev.81,mistralai/mixtral-8x7b-chat,0.75,0.0001806,1.0,4.56e-05,0.75,9.9e-05,0.75,0.0001806,0.75,0.000219608,0.0,0.00209
mmlu-high-school-government-and-politics.val.105,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00138
mmlu-professional-law.val.393,WizardLM/WizardLM-13B-V1.2,0.0,0.0001197,0.0,7.98e-05,0.0,0.0001197,0.0,0.0002394,0.0,0.000309624,1.0,0.0039999999999999
mmlu-professional-law.val.1087,mistralai/mistral-7b-chat,0.0,6.18e-05,0.0,6.18e-05,1.0,9.27e-05,1.0,0.0001853999999999,0.0,0.000239784,1.0,0.0031
hellaswag.val.2618,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00099
mmlu-professional-law.val.49,WizardLM/WizardLM-13B-V1.2,1.0,0.0001071,0.0,7.14e-05,1.0,0.0001071,0.0,0.0002142,0.0,0.000277032,0.0,0.00361
hellaswag.val.769,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.5499,mistralai/mixtral-8x7b-chat,1.0,0.0001536,1.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,1.0,0.000198656,1.0,0.00257
hellaswag.val.2389,WizardLM/WizardLM-13B-V1.2,0.0,2.73e-05,1.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,1.0,7.0616e-05,0.0,0.0009199999999999
mmlu-professional-law.val.1434,mistralai/mistral-7b-chat,0.0,6.32e-05,0.0,6.32e-05,1.0,9.48e-05,1.0,0.0001896,0.0,0.000245216,1.0,0.00317
mmlu-world-religions.val.25,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.742,WizardLM/WizardLM-13B-V1.2,1.0,2.79e-05,0.0,1.86e-05,1.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00097
mmlu-conceptual-physics.val.63,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
grade-school-math.dev.5523,WizardLM/WizardLM-13B-V1.2,0.25,0.0002028,0.25,0.0001154,0.25,0.0002028,0.75,0.0003048,0.25,0.0003887759999999,0.75,0.00718
mmlu-professional-medicine.val.161,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,1.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
grade-school-math.dev.294,WizardLM/WizardLM-13B-V1.2,0.75,0.0001217999999999,0.75,6.56e-05,0.75,0.0001217999999999,0.75,0.0002172,0.75,0.000246768,0.75,0.0060999999999999
grade-school-math.dev.908,WizardLM/WizardLM-13B-V1.2,0.75,0.0001733999999999,0.25,9.9e-05,0.75,0.0001733999999999,0.5,0.0003233999999999,0.75,0.000415936,0.5,0.01021
mmlu-professional-law.val.1070,WizardLM/WizardLM-13B-V1.2,0.0,6.749999999999999e-05,0.0,4.5e-05,0.0,6.749999999999999e-05,1.0,0.0001349999999999,0.0,0.0001746,1.0,0.00226
hellaswag.val.4388,mistralai/mixtral-8x7b-chat,0.0,0.000129,0.0,4.3e-05,0.0,6.419999999999999e-05,0.0,0.000129,0.0,0.00016684,1.0,0.00219
hellaswag.val.9689,WizardLM/WizardLM-13B-V1.2,1.0,8.13e-05,1.0,5.420000000000001e-05,1.0,8.13e-05,0.0,0.0001626,1.0,0.0002102959999999,1.0,0.00275
mmlu-miscellaneous.val.611,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-professional-law.val.607,WizardLM/WizardLM-13B-V1.2,1.0,0.0001083,0.0,7.219999999999999e-05,1.0,0.0001083,1.0,0.0002166,0.0,0.000280136,1.0,0.00362
mmlu-professional-law.val.1425,WizardLM/WizardLM-13B-V1.2,0.0,0.0001026,1.0,6.84e-05,0.0,0.0001026,0.0,0.0002052,0.0,0.000265392,0.0,0.00343
hellaswag.val.2935,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.0009
grade-school-math.dev.5591,WizardLM/WizardLM-13B-V1.2,0.25,0.0001899,0.25,9.92e-05,0.25,0.0001899,0.25,0.0002592,0.25,0.000459392,0.25,0.0091
grade-school-math.dev.1069,mistralai/mixtral-8x7b-chat,0.25,0.0002694,0.25,7.98e-05,0.25,0.0001902,0.25,0.0002694,0.25,0.000313504,0.75,0.01013
grade-school-math.dev.2728,WizardLM/WizardLM-13B-V1.2,0.25,0.000204,0.25,0.0001238,0.25,0.000204,0.25,0.00033,0.25,0.000394984,0.25,0.0120299999999999
mmlu-college-mathematics.val.62,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.00132
hellaswag.val.3505,mistralai/mixtral-8x7b-chat,1.0,0.0001722,0.0,5.7400000000000006e-05,0.0,8.58e-05,1.0,0.0001722,0.0,0.000222712,1.0,0.00291
mmlu-jurisprudence.val.15,mistralai/mistral-7b-chat,1.0,4.080000000000001e-05,1.0,4.080000000000001e-05,1.0,6.12e-05,1.0,0.0001224,0.0,0.000158304,1.0,0.00205
winogrande.dev.1049,mistralai/mixtral-8x7b-chat,0.0,3.3e-05,1.0,1.1e-05,0.0,1.65e-05,0.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00059
hellaswag.val.8289,mistralai/mixtral-8x7b-chat,1.0,0.0001368,1.0,4.56e-05,1.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00232
mmlu-moral-disputes.val.6,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00099
hellaswag.val.4568,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,0.0,0.00258
winogrande.dev.1139,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
mmlu-professional-law.val.1380,WizardLM/WizardLM-13B-V1.2,1.0,0.0001224,0.0,8.16e-05,1.0,0.0001224,0.0,0.0002448,0.0,0.0003166079999999,0.0,0.00409
mmlu-moral-scenarios.val.810,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.7036,mistralai/mixtral-8x7b-chat,1.0,0.0001572,1.0,5.24e-05,1.0,7.86e-05,1.0,0.0001572,1.0,0.000203312,1.0,0.00263
mmlu-high-school-statistics.val.22,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
grade-school-math.dev.4609,WizardLM/WizardLM-13B-V1.2,0.25,0.0001049999999999,0.25,0.0001022,0.25,0.0001049999999999,0.25,0.0002712,0.25,0.000293328,0.75,0.0095
hellaswag.val.7683,WizardLM/WizardLM-13B-V1.2,0.0,9.63e-05,0.0,6.42e-05,0.0,9.63e-05,1.0,0.0001926,0.0,0.000249096,1.0,0.00322
grade-school-math.dev.2545,mistralai/mistral-7b-chat,0.5,5.86e-05,0.5,5.86e-05,0.75,0.0001236,0.75,0.0001884,0.75,0.000273928,0.75,0.00465
mmlu-jurisprudence.val.26,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
mmlu-professional-law.val.463,WizardLM/WizardLM-13B-V1.2,0.0,9.69e-05,1.0,6.46e-05,0.0,9.69e-05,0.0,0.0001938,0.0,0.000250648,1.0,0.00324
mmlu-professional-law.val.980,mistralai/mistral-7b-chat,0.0,4.6200000000000005e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00235
winogrande.dev.1140,mistralai/mixtral-8x7b-chat,1.0,2.94e-05,0.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,0.0,0.0005
mmlu-professional-law.val.1286,WizardLM/WizardLM-13B-V1.2,1.0,8.4e-05,0.0,5.6000000000000006e-05,1.0,8.4e-05,0.0,0.000168,0.0,0.00021728,1.0,0.00281
hellaswag.val.1348,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
bias_detection.dev.278,mistralai/mistral-7b-chat,0.0,7.640000000000001e-05,0.0,7.640000000000001e-05,0.0,0.0001086,0.0,0.0002076,0.0,0.0002522,1.0,0.00554
mmlu-professional-accounting.val.122,WizardLM/WizardLM-13B-V1.2,0.0,3.51e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.5405,mistralai/mixtral-8x7b-chat,1.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,1.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
mmlu-marketing.val.35,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-philosophy.val.213,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00082
hellaswag.val.2319,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.44e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
hellaswag.val.1283,WizardLM/WizardLM-13B-V1.2,0.0,4.29e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-prehistory.val.191,mistralai/mixtral-8x7b-chat,1.0,7.5e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
hellaswag.val.224,WizardLM/WizardLM-13B-V1.2,1.0,3.3900000000000004e-05,0.0,2.28e-05,1.0,3.3900000000000004e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
hellaswag.val.9654,mistralai/mixtral-8x7b-chat,0.0,0.0001458,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,1.0,0.00247
consensus_summary.dev.209,mistralai/mistral-7b-chat,1.0,4.2600000000000005e-05,1.0,4.2600000000000005e-05,0.75,9.33e-05,0.75,0.000174,0.75,0.00023668,0.75,0.00347
hellaswag.val.327,mistralai/mistral-7b-chat,1.0,2.2600000000000004e-05,1.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
grade-school-math.dev.6878,mistralai/mixtral-8x7b-chat,0.5,0.0002483999999999,0.25,0.0001006,0.5,0.0001347,0.5,0.0002483999999999,0.25,0.000305744,0.5,0.00761
hellaswag.val.5202,WizardLM/WizardLM-13B-V1.2,0.0,7.829999999999999e-05,0.0,5.24e-05,0.0,7.829999999999999e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
hellaswag.val.9683,WizardLM/WizardLM-13B-V1.2,1.0,7.89e-05,0.0,5.260000000000001e-05,1.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
arc-challenge.test.103,WizardLM/WizardLM-13B-V1.2,0.0,2.3400000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00082
hellaswag.val.8603,WizardLM/WizardLM-13B-V1.2,0.0,7.38e-05,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
mmlu-professional-law.val.1307,mistralai/mistral-7b-chat,1.0,5.2e-05,1.0,5.2e-05,0.0,7.8e-05,1.0,0.000156,0.0,0.00020176,1.0,0.00261
hellaswag.val.3498,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,0.0,0.00249
hellaswag.val.7324,mistralai/mixtral-8x7b-chat,0.0,0.0001458,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,1.0,0.00247
hellaswag.val.652,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.1264,mistralai/mistral-7b-chat,0.25,7.7e-05,0.25,7.7e-05,0.75,0.0001319999999999,0.25,0.0002171999999999,0.25,0.000287896,0.75,0.00732
hellaswag.val.8028,mistralai/mistral-7b-chat,0.0,4.5400000000000006e-05,0.0,4.5400000000000006e-05,0.0,6.78e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00231
hellaswag.val.8039,mistralai/mixtral-8x7b-chat,1.0,0.000168,1.0,5.6000000000000006e-05,1.0,8.369999999999999e-05,1.0,0.000168,1.0,0.00021728,1.0,0.00281
mmlu-professional-law.val.1519,WizardLM/WizardLM-13B-V1.2,1.0,6.66e-05,0.0,4.44e-05,1.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00223
mmlu-professional-psychology.val.209,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.9451,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
mmlu-high-school-statistics.val.53,mistralai/mixtral-8x7b-chat,1.0,0.000105,0.0,3.5000000000000004e-05,1.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00176
mmlu-moral-scenarios.val.141,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
grade-school-math.dev.4979,WizardLM/WizardLM-13B-V1.2,0.25,0.0001563,0.25,9.74e-05,0.25,0.0001563,1.0,0.0002082,0.25,0.000346872,0.25,0.00777
mmlu-moral-scenarios.val.654,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,0.0,0.00137
mmlu-professional-law.val.1165,mistralai/mistral-7b-chat,1.0,5.780000000000001e-05,1.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001727999999999,0.0,0.000224264,1.0,0.0029
mmlu-conceptual-physics.val.134,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.4900,mistralai/mixtral-8x7b-chat,1.0,0.0001553999999999,1.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,1.0,0.000200984,0.0,0.00263
mmlu-high-school-mathematics.val.218,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.983,WizardLM/WizardLM-13B-V1.2,0.75,0.000156,0.75,6.46e-05,0.75,0.000156,0.75,0.0002646,0.5,0.000273152,0.75,0.00913
grade-school-math.dev.1504,WizardLM/WizardLM-13B-V1.2,0.5,0.0001494,0.5,0.0001078,0.5,0.0001494,0.75,0.0002328,0.5,0.000336008,0.75,0.01025
hellaswag.val.1579,WizardLM/WizardLM-13B-V1.2,0.0,3.81e-05,0.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-high-school-government-and-politics.val.94,mistralai/mistral-7b-chat,1.0,2.4800000000000003e-05,1.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
hellaswag.val.3596,mistralai/mixtral-8x7b-chat,1.0,0.0001686,0.0,5.62e-05,0.0,8.43e-05,1.0,0.0001686,0.0,0.000218056,0.0,0.00282
mmlu-high-school-microeconomics.val.218,mistralai/mistral-7b-chat,1.0,2.42e-05,1.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
mmlu-professional-law.val.1315,WizardLM/WizardLM-13B-V1.2,1.0,5.55e-05,0.0,3.7000000000000005e-05,1.0,5.55e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00189
grade-school-math.dev.2285,mistralai/mistral-7b-chat,0.25,8.280000000000001e-05,0.25,8.280000000000001e-05,0.25,0.0001344,0.25,0.0002729999999999,0.75,0.000338336,0.5,0.00649
bias_detection.dev.222,mistralai/mixtral-8x7b-chat,0.0,0.000183,0.0,7.000000000000001e-05,0.0,0.0001139999999999,0.0,0.000183,0.0,0.000253752,0.0,0.00748
grade-school-math.dev.3635,mistralai/mistral-7b-chat,0.25,8.98e-05,0.25,8.98e-05,0.75,0.0001664999999999,0.75,0.0002441999999999,0.25,0.0003686,0.75,0.01136
grade-school-math.dev.997,WizardLM/WizardLM-13B-V1.2,0.25,0.0002279999999999,0.25,0.0001216,0.25,0.0002279999999999,0.25,0.0003185999999999,0.25,0.0005540639999999,0.75,0.00866
grade-school-math.dev.4293,WizardLM/WizardLM-13B-V1.2,0.25,0.0002025,0.25,0.0001148,0.25,0.0002025,0.75,0.0003234,0.25,0.000470256,0.75,0.0104999999999999
hellaswag.val.6061,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
hellaswag.val.1177,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
mmlu-moral-scenarios.val.545,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-astronomy.val.85,mistralai/mixtral-8x7b-chat,1.0,8.52e-05,0.0,2.84e-05,1.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00143
hellaswag.val.516,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-professional-law.val.74,WizardLM/WizardLM-13B-V1.2,1.0,6.18e-05,0.0,4.1200000000000005e-05,1.0,6.18e-05,0.0,0.0001236,0.0,0.000159856,1.0,0.00207
grade-school-math.dev.1363,mistralai/mistral-7b-chat,0.25,9.74e-05,0.25,9.74e-05,0.25,0.0001701,0.25,0.0002448,0.25,0.00041128,0.25,0.01455
hellaswag.val.92,mistralai/mistral-7b-chat,0.0,3.3e-05,0.0,3.3e-05,0.0,4.95e-05,0.0,9.9e-05,0.0,0.00012804,1.0,0.00166
hellaswag.val.1826,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.3399,mistralai/mistral-7b-chat,0.25,9.06e-05,0.25,9.06e-05,0.25,0.0001241999999999,0.25,0.0002568,0.25,0.000286344,0.5,0.00836
grade-school-math.dev.4789,WizardLM/WizardLM-13B-V1.2,0.25,0.0001578,0.25,6.62e-05,0.25,0.0001578,0.25,0.0002538,0.25,0.000329024,0.5,0.00753
consensus_summary.dev.222,mistralai/mixtral-8x7b-chat,0.75,0.0001631999999999,0.75,4.42e-05,0.0,0.0002996999999999,0.75,0.0001631999999999,0.75,0.000203312,0.5,0.00238
mmlu-high-school-psychology.val.284,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
arc-challenge.test.515,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
winogrande.dev.689,mistralai/mixtral-8x7b-chat,1.0,2.82e-05,0.0,9.4e-06,1.0,1.41e-05,1.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00051
hellaswag.val.3865,mistralai/mistral-7b-chat,0.0,5.520000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
hellaswag.val.9040,mistralai/mixtral-8x7b-chat,1.0,0.000147,1.0,4.9000000000000005e-05,1.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-college-computer-science.val.54,mistralai/mistral-7b-chat,1.0,2.62e-05,1.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
grade-school-math.dev.3304,WizardLM/WizardLM-13B-V1.2,0.25,0.0001587,0.25,9.44e-05,0.25,0.0001587,0.25,0.0002988,0.25,0.000317384,0.25,0.01261
mmlu-professional-law.val.455,mistralai/mistral-7b-chat,0.0,6.76e-05,0.0,6.76e-05,0.0,0.0001014,0.0,0.0002028,0.0,0.0002622879999999,1.0,0.00339
mmlu-miscellaneous.val.100,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.9951,mistralai/mistral-7b-chat,0.0,4.520000000000001e-05,0.0,4.520000000000001e-05,1.0,6.780000000000001e-05,1.0,0.0001356,0.0,0.000175376,1.0,0.0023
hellaswag.val.6884,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-human-sexuality.val.32,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
arc-challenge.test.665,mistralai/mixtral-8x7b-chat,0.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
grade-school-math.dev.465,WizardLM/WizardLM-13B-V1.2,0.25,0.0001463999999999,0.25,8.3e-05,0.25,0.0001463999999999,0.75,0.0002844,0.25,0.000272376,0.75,0.01064
hellaswag.val.9356,WizardLM/WizardLM-13B-V1.2,1.0,0.0001011,1.0,6.74e-05,1.0,0.0001011,1.0,0.0002022,0.0,0.000261512,1.0,0.00341
mmlu-prehistory.val.222,mistralai/mixtral-8x7b-chat,1.0,9e-05,0.0,3e-05,0.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-professional-law.val.467,WizardLM/WizardLM-13B-V1.2,0.0,0.0001331999999999,0.0,8.88e-05,0.0,0.0001331999999999,0.0,0.0002663999999999,0.0,0.000344544,1.0,0.00445
mmlu-professional-medicine.val.239,mistralai/mixtral-8x7b-chat,0.0,0.0001733999999999,0.0,5.780000000000001e-05,0.0,8.669999999999999e-05,0.0,0.0001733999999999,0.0,0.000224264,1.0,0.00293
mmlu-professional-law.val.921,WizardLM/WizardLM-13B-V1.2,0.0,0.0001011,0.0,6.74e-05,0.0,0.0001011,0.0,0.0002022,0.0,0.000261512,0.0,0.00338
grade-school-math.dev.2156,WizardLM/WizardLM-13B-V1.2,0.75,0.0001629,0.25,7.92e-05,0.75,0.0001629,0.25,0.000207,0.75,0.000335232,0.75,0.01026
grade-school-math.dev.7374,mistralai/mistral-7b-chat,0.75,7.78e-05,0.75,7.78e-05,0.75,0.0001707,0.25,0.0002394,0.75,0.00036084,0.75,0.00767
mmlu-college-biology.val.143,mistralai/mixtral-8x7b-chat,1.0,8.94e-05,1.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
arc-challenge.test.771,WizardLM/WizardLM-13B-V1.2,1.0,2.55e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,1.0,6.596e-05,1.0,0.00086
mmlu-professional-psychology.val.495,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,1.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.5260,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.619999999999998e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
grade-school-math.dev.7113,WizardLM/WizardLM-13B-V1.2,0.25,0.0001841999999999,0.25,0.00013,0.25,0.0001841999999999,0.25,0.000303,0.25,0.0003298,0.5,0.00927
grade-school-math.dev.4084,mistralai/mixtral-8x7b-chat,0.5,0.000261,0.25,8.9e-05,0.75,0.00015,0.5,0.000261,0.75,0.000460944,0.75,0.00677
grade-school-math.dev.5364,mistralai/mistral-7b-chat,0.25,0.0001146,0.25,0.0001146,0.25,0.0001730999999999,1.0,0.0002753999999999,0.25,0.000351528,0.5,0.01585
hellaswag.val.1655,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.7434,mistralai/mistral-7b-chat,0.0,4.920000000000001e-05,0.0,4.920000000000001e-05,0.0,7.35e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.2126,WizardLM/WizardLM-13B-V1.2,0.25,0.0001133999999999,0.25,9.14e-05,0.25,0.0001133999999999,0.25,0.0001973999999999,0.25,0.000273152,0.5,0.0068
mmlu-professional-law.val.733,mistralai/mistral-7b-chat,0.0,5.920000000000001e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,0.0,0.003
hellaswag.val.9021,mistralai/mixtral-8x7b-chat,0.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
hellaswag.val.5835,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,1.0,7.83e-05,0.0,0.0001566,1.0,0.000202536,1.0,0.00265
mmlu-international-law.val.39,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-virology.val.21,mistralai/mixtral-8x7b-chat,1.0,6.96e-05,0.0,2.32e-05,1.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
hellaswag.val.8600,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.2376,WizardLM/WizardLM-13B-V1.2,1.0,4.38e-05,1.0,2.94e-05,1.0,4.38e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
mmlu-moral-scenarios.val.32,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
hellaswag.val.6464,mistralai/mixtral-8x7b-chat,0.0,0.0001452,1.0,4.84e-05,1.0,7.26e-05,0.0,0.0001452,1.0,0.000187792,1.0,0.00243
mmlu-miscellaneous.val.700,WizardLM/WizardLM-13B-V1.2,0.0,2.3400000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.2713,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,1.0,7.372e-05,1.0,0.00096
winogrande.dev.1035,mistralai/mixtral-8x7b-chat,1.0,3e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,0.0,3.880000000000001e-05,0.0,0.00051
grade-school-math.dev.3204,WizardLM/WizardLM-13B-V1.2,0.25,0.0001220999999999,0.75,6.340000000000001e-05,0.25,0.0001220999999999,0.75,0.0001896,0.25,0.0002770319999999,0.75,0.00577
mmlu-security-studies.val.156,WizardLM/WizardLM-13B-V1.2,1.0,6.9e-05,0.0,4.600000000000001e-05,1.0,6.9e-05,1.0,0.000138,0.0,0.0001784799999999,1.0,0.00231
mmlu-formal-logic.val.83,mistralai/mistral-7b-chat,1.0,4.14e-05,1.0,4.14e-05,1.0,6.21e-05,1.0,0.0001242,0.0,0.000160632,1.0,0.00211
grade-school-math.dev.1351,WizardLM/WizardLM-13B-V1.2,0.25,0.0001484999999999,0.75,8.82e-05,0.25,0.0001484999999999,0.75,0.0002165999999999,0.75,0.00039188,0.75,0.00801
mmlu-high-school-chemistry.val.134,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.4530,WizardLM/WizardLM-13B-V1.2,0.0,9.09e-05,0.0,6.06e-05,0.0,9.09e-05,0.0,0.0001818,0.0,0.0002351279999999,1.0,0.00307
hellaswag.val.5081,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.65e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
hellaswag.val.6735,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
grade-school-math.dev.6447,WizardLM/WizardLM-13B-V1.2,0.75,0.0001275,0.5,8.72e-05,0.75,0.0001275,0.75,0.0001931999999999,0.75,0.000247544,0.5,0.00487
hellaswag.val.1592,mistralai/mistral-7b-chat,1.0,2.22e-05,1.0,2.22e-05,1.0,3.3e-05,1.0,6.659999999999999e-05,1.0,8.6136e-05,1.0,0.00115
hellaswag.val.907,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,1.0,4.47e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-sociology.val.57,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
grade-school-math.dev.3910,meta/code-llama-instruct-34b-chat,0.25,0.000373256,0.25,7.8e-05,0.25,0.0001266,0.25,0.000405,0.25,0.000373256,0.75,0.0059299999999999
mmlu-high-school-us-history.val.193,WizardLM/WizardLM-13B-V1.2,1.0,0.0001257,1.0,8.38e-05,1.0,0.0001257,1.0,0.0002508,0.0,0.000325144,1.0,0.0042
grade-school-math.dev.3258,mistralai/mistral-7b-chat,0.25,9.74e-05,0.25,9.74e-05,0.75,0.0001989,0.5,0.0002681999999999,0.75,0.000377912,0.75,0.01054
mmlu-high-school-computer-science.val.61,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,1.0,4.17e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
arc-challenge.test.707,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.6357,mistralai/mistral-7b-chat,1.0,5.14e-05,1.0,5.14e-05,1.0,7.71e-05,1.0,0.0001542,1.0,0.0001994319999999,1.0,0.00261
bias_detection.dev.46,mistralai/mixtral-8x7b-chat,0.0,0.000228,0.0,6.94e-05,0.0,0.0001269,0.0,0.000228,0.0,0.000261512,0.0,0.01005
mmlu-high-school-biology.val.297,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00082
mmlu-prehistory.val.184,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
grade-school-math.dev.5978,mistralai/mistral-7b-chat,0.25,0.0001038,0.25,0.0001038,0.75,0.0001494,0.25,0.0003168,0.25,0.000361616,0.0,0.00876
mmlu-professional-law.val.414,WizardLM/WizardLM-13B-V1.2,0.0,7.26e-05,1.0,4.84e-05,0.0,7.26e-05,1.0,0.0001446,0.0,0.000187792,1.0,0.00243
mmlu-moral-disputes.val.222,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.6124,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
mmlu-professional-accounting.val.245,WizardLM/WizardLM-13B-V1.2,0.0,5.16e-05,1.0,3.44e-05,0.0,5.16e-05,0.0,0.0001032,0.0,0.000133472,1.0,0.0017599999999999
mmlu-moral-scenarios.val.650,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,0.0,0.0014399999999999
mmlu-professional-law.val.675,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
mmlu-high-school-computer-science.val.99,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.5540,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,1.0,0.00018624,1.0,0.00244
mmlu-high-school-geography.val.105,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.52e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
hellaswag.val.2594,mistralai/mistral-7b-chat,1.0,3.3600000000000004e-05,1.0,3.3600000000000004e-05,1.0,5.01e-05,1.0,0.0001008,0.0,0.0001303679999999,1.0,0.00169
hellaswag.val.8117,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-international-law.val.114,mistralai/mistral-7b-chat,1.0,2.64e-05,1.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-high-school-european-history.val.65,WizardLM/WizardLM-13B-V1.2,0.0,0.0001131,0.0,7.539999999999999e-05,0.0,0.0001131,1.0,0.0002262,0.0,0.000292552,1.0,0.00378
mmlu-professional-law.val.328,WizardLM/WizardLM-13B-V1.2,0.0,0.0001416,0.0,9.44e-05,0.0,0.0001416,0.0,0.0002832,0.0,0.000366272,0.0,0.00473
mmlu-miscellaneous.val.280,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
winogrande.dev.14,mistralai/mistral-7b-chat,1.0,1.14e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.4232e-05,1.0,0.00061
mmlu-formal-logic.val.14,mistralai/mistral-7b-chat,1.0,2.9800000000000003e-05,1.0,2.9800000000000003e-05,1.0,4.47e-05,0.0,8.88e-05,0.0,0.000115624,0.0,0.0015
hellaswag.val.1712,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.22e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-philosophy.val.47,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-elementary-mathematics.val.134,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.7152,mistralai/mixtral-8x7b-chat,0.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
grade-school-math.dev.2441,mistralai/mistral-7b-chat,0.25,7.4e-05,0.25,7.4e-05,0.75,0.0001185,0.75,0.000219,0.5,0.000342216,0.75,0.00585
hellaswag.val.2650,mistralai/mistral-7b-chat,1.0,2.9e-05,1.0,2.9e-05,1.0,4.32e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
mmlu-human-sexuality.val.3,mistralai/mixtral-8x7b-chat,1.0,8.04e-05,0.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
winogrande.dev.456,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
hellaswag.val.4152,mistralai/mistral-7b-chat,0.0,5.44e-05,0.0,5.44e-05,0.0,8.16e-05,1.0,0.0001632,0.0,0.000211072,1.0,0.00273
winogrande.dev.605,mistralai/mixtral-8x7b-chat,1.0,3.18e-05,0.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,0.0,4.1128e-05,1.0,0.00054
mmlu-human-sexuality.val.103,mistralai/mixtral-8x7b-chat,1.0,8.340000000000001e-05,0.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
winogrande.dev.15,mistralai/mixtral-8x7b-chat,1.0,3.4200000000000005e-05,1.0,1.14e-05,1.0,1.7100000000000002e-05,1.0,3.4200000000000005e-05,1.0,4.4232e-05,1.0,0.00061
hellaswag.val.314,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-electrical-engineering.val.135,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.86e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.6217,mistralai/mixtral-8x7b-chat,0.5,0.0002742,0.25,0.000114,0.25,0.0001401,0.5,0.0002742,0.25,0.000405848,0.5,0.00908
mmlu-world-religions.val.100,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.1285,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.36e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00117
grade-school-math.dev.3499,WizardLM/WizardLM-13B-V1.2,0.25,0.0001161,0.25,9.04e-05,0.25,0.0001161,0.25,0.0002484,0.25,0.000308848,0.75,0.00867
mmlu-security-studies.val.180,WizardLM/WizardLM-13B-V1.2,0.0,9.18e-05,0.0,6.120000000000001e-05,0.0,9.18e-05,1.0,0.0001836,0.0,0.0002374559999999,0.0,0.00307
arc-challenge.test.1145,mistralai/mixtral-8x7b-chat,0.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.4207,meta/code-llama-instruct-34b-chat,0.25,0.000295656,0.25,7.520000000000001e-05,0.25,0.0001509,0.75,0.0002508,0.25,0.000295656,0.75,0.00748
hellaswag.val.9321,mistralai/mistral-7b-chat,1.0,4.600000000000001e-05,1.0,4.600000000000001e-05,0.0,6.9e-05,1.0,0.000138,1.0,0.0001784799999999,1.0,0.00234
winogrande.dev.519,mistralai/mistral-7b-chat,0.0,9.2e-06,0.0,9.2e-06,1.0,1.3799999999999998e-05,1.0,2.76e-05,0.0,3.5696e-05,1.0,0.00047
grade-school-math.dev.2611,meta/code-llama-instruct-34b-chat,0.25,0.00028324,0.25,9.34e-05,0.25,0.000156,0.25,0.0002394,0.25,0.00028324,0.75,0.01063
mmlu-moral-disputes.val.343,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00131
hellaswag.val.9426,mistralai/mistral-7b-chat,1.0,5.44e-05,1.0,5.44e-05,1.0,8.16e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00276
mmlu-anatomy.val.127,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
arc-challenge.test.698,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
bias_detection.dev.134,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,6.9e-05,0.0,0.0001065,0.0,0.0001728,0.0,0.000265392,0.0,0.00537
hellaswag.val.10032,mistralai/mistral-7b-chat,1.0,6.52e-05,1.0,6.52e-05,1.0,9.75e-05,1.0,0.0001956,1.0,0.0002529759999999,0.0,0.0033
grade-school-math.dev.824,mistralai/mistral-7b-chat,0.75,9.58e-05,0.75,9.58e-05,0.75,0.0001838999999999,0.5,0.0003323999999999,0.25,0.00039964,0.5,0.01397
mmlu-professional-law.val.731,mistralai/mistral-7b-chat,1.0,5.220000000000001e-05,1.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,1.0,0.00262
mmlu-high-school-mathematics.val.40,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.58e-05,0.0,7.2944e-05,0.0,0.00095
mmlu-professional-psychology.val.463,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.3250,WizardLM/WizardLM-13B-V1.2,0.75,0.000138,0.75,7.38e-05,0.75,0.000138,0.75,0.0002345999999999,0.75,0.000293328,0.75,0.0057599999999999
arc-challenge.test.948,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.8069,mistralai/mistral-7b-chat,0.0,5.4000000000000005e-05,0.0,5.4000000000000005e-05,1.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
grade-school-math.dev.5060,WizardLM/WizardLM-13B-V1.2,0.75,0.0001865999999999,0.25,0.0001002,0.75,0.0001865999999999,0.75,0.000303,0.25,0.000349976,0.25,0.00837
hellaswag.val.8672,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.4600,WizardLM/WizardLM-13B-V1.2,0.5,0.0001878,0.25,8.66e-05,0.5,0.0001878,0.5,0.000246,0.25,0.000268496,0.5,0.00794
hellaswag.val.8945,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00288
mmlu-miscellaneous.val.782,mistralai/mixtral-8x7b-chat,1.0,8.22e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-microeconomics.val.163,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.4400,WizardLM/WizardLM-13B-V1.2,0.0,7.02e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
hellaswag.val.2765,WizardLM/WizardLM-13B-V1.2,0.0,3.51e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.9273,WizardLM/WizardLM-13B-V1.2,0.0,6.9e-05,0.0,4.600000000000001e-05,0.0,6.9e-05,0.0,0.000138,0.0,0.0001784799999999,1.0,0.00231
mmlu-moral-scenarios.val.655,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,1.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
hellaswag.val.8946,mistralai/mixtral-8x7b-chat,1.0,0.0001566,1.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,1.0,0.000202536,1.0,0.00262
hellaswag.val.7667,mistralai/mistral-7b-chat,1.0,5.1000000000000006e-05,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,1.0,0.00019788,1.0,0.00259
mmlu-moral-scenarios.val.877,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.00141
grade-school-math.dev.5344,meta/code-llama-instruct-34b-chat,0.25,0.000323592,0.25,7.640000000000001e-05,0.75,0.0001512,0.75,0.000249,0.25,0.000323592,0.75,0.00761
hellaswag.val.4206,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.0001776,0.0,0.000229696,1.0,0.00297
mmlu-high-school-macroeconomics.val.48,WizardLM/WizardLM-13B-V1.2,1.0,3.24e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-college-medicine.val.13,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-professional-law.val.1499,WizardLM/WizardLM-13B-V1.2,1.0,0.0001298999999999,0.0,8.66e-05,1.0,0.0001298999999999,0.0,0.0002597999999999,0.0,0.000336008,1.0,0.0043399999999999
hellaswag.val.3101,mistralai/mixtral-8x7b-chat,0.0,7.32e-05,1.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,1.0,9.4672e-05,1.0,0.0012599999999999
hellaswag.val.7846,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.2e-05,0.0,7.8e-05,0.0,0.0001553999999999,0.0,0.00020176,1.0,0.00264
hellaswag.val.5758,mistralai/mistral-7b-chat,1.0,4.980000000000001e-05,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
grade-school-math.dev.3058,mistralai/mistral-7b-chat,0.25,7.44e-05,0.25,7.44e-05,0.25,0.0001203,0.25,0.0001944,0.25,0.000316608,0.75,0.00557
hellaswag.val.6601,mistralai/mixtral-8x7b-chat,1.0,0.0001308,0.0,4.36e-05,1.0,6.51e-05,1.0,0.0001308,0.0,0.000169168,1.0,0.00222
mmlu-professional-law.val.1048,WizardLM/WizardLM-13B-V1.2,0.0,6.09e-05,0.0,4.06e-05,0.0,6.09e-05,0.0,0.0001217999999999,0.0,0.000157528,0.0,0.00207
mmlu-professional-law.val.1172,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
winogrande.dev.882,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,1.0,1.59e-05,1.0,3.18e-05,1.0,4.1128e-05,1.0,0.00057
winogrande.dev.742,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,1.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00052
grade-school-math.dev.2842,WizardLM/WizardLM-13B-V1.2,0.5,0.0001323,0.5,7.24e-05,0.5,0.0001323,0.5,0.0001836,0.75,0.00029876,0.5,0.00614
grade-school-math.dev.500,WizardLM/WizardLM-13B-V1.2,0.75,0.0001553999999999,0.25,7.640000000000001e-05,0.75,0.0001553999999999,0.75,0.0002795999999999,0.25,0.000315056,0.75,0.0074
mmlu-professional-law.val.1289,WizardLM/WizardLM-13B-V1.2,0.0,9.81e-05,0.0,6.539999999999999e-05,0.0,9.81e-05,0.0,0.0001962,0.0,0.000253752,0.0,0.00328
hellaswag.val.8626,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
hellaswag.val.5441,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,1.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,0.0,0.0001553999999999,1.0,0.000200984,1.0,0.0026
mmlu-professional-law.val.1064,WizardLM/WizardLM-13B-V1.2,0.0,0.0001725,0.0,0.000115,0.0,0.0001725,0.0,0.000345,0.0,0.0004462,1.0,0.0057599999999999
abstract2title.test.45,mistralai/mixtral-8x7b-chat,1.0,0.0002052,1.0,6.620000000000001e-05,1.0,0.0001053,1.0,0.0002052,1.0,0.000255304,1.0,0.00383
mmlu-college-medicine.val.129,mistralai/mistral-7b-chat,1.0,2.74e-05,1.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,0.0,0.00138
mmlu-college-physics.val.44,mistralai/mixtral-8x7b-chat,1.0,7.92e-05,1.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,0.0,0.00133
hellaswag.val.3285,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00249
arc-challenge.test.826,mistralai/mistral-7b-chat,0.0,1.24e-05,0.0,1.24e-05,0.0,1.86e-05,0.0,3.72e-05,0.0,4.8112e-05,1.0,0.00066
mmlu-professional-law.val.1099,mistralai/mistral-7b-chat,1.0,6.22e-05,1.0,6.22e-05,0.0,9.33e-05,0.0,0.0001866,0.0,0.000241336,0.0,0.00312
mmlu-philosophy.val.0,mistralai/mistral-7b-chat,1.0,1.54e-05,1.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,1.0,5.9752000000000007e-05,1.0,0.00081
hellaswag.val.5952,mistralai/mistral-7b-chat,0.0,5.8800000000000006e-05,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00298
hellaswag.val.6063,WizardLM/WizardLM-13B-V1.2,0.0,8.04e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
abstract2title.test.138,mistralai/mixtral-8x7b-chat,1.0,0.000177,1.0,5.74e-05,1.0,8.879999999999999e-05,1.0,0.000177,1.0,0.000229696,1.0,0.0037099999999999
mmlu-professional-law.val.1285,WizardLM/WizardLM-13B-V1.2,0.0,8.88e-05,0.0,5.920000000000001e-05,0.0,8.88e-05,0.0,0.000177,0.0,0.000229696,0.0,0.00297
mmlu-professional-law.val.1209,mistralai/mistral-7b-chat,0.0,3.24e-05,0.0,3.24e-05,1.0,4.86e-05,0.0,9.72e-05,0.0,0.000125712,1.0,0.00163
mmlu-professional-law.val.957,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,1.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
mmlu-econometrics.val.64,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,0.0,6.36e-05,0.0,8.2256e-05,0.0,0.00107
mmlu-prehistory.val.314,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.2125,WizardLM/WizardLM-13B-V1.2,0.25,0.0001118999999999,0.25,7.12e-05,0.25,0.0001118999999999,0.25,0.0003083999999999,0.25,0.000228144,0.75,0.00792
grade-school-math.dev.6314,mistralai/mistral-7b-chat,0.25,6.6e-05,0.25,6.6e-05,0.25,0.00015,0.25,0.0003953999999999,0.25,0.0003298,0.25,0.0115
grade-school-math.dev.6163,WizardLM/WizardLM-13B-V1.2,0.25,0.0001293,0.75,8.16e-05,0.25,0.0001293,0.75,0.0002502,0.25,0.000291776,0.75,0.01627
grade-school-math.dev.3228,WizardLM/WizardLM-13B-V1.2,0.75,0.0001674,0.25,7.060000000000001e-05,0.75,0.0001674,0.75,0.0002466,0.75,0.0003127279999999,0.75,0.00826
hellaswag.val.1280,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,1.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
hellaswag.val.2826,WizardLM/WizardLM-13B-V1.2,1.0,5.31e-05,1.0,3.54e-05,1.0,5.31e-05,1.0,0.0001062,1.0,0.000137352,0.0,0.00178
mmlu-professional-accounting.val.193,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,1.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
grade-school-math.dev.3233,mistralai/mistral-7b-chat,0.25,8.94e-05,0.25,8.94e-05,0.75,0.0001683,0.75,0.0003162,0.75,0.000360064,0.75,0.00843
mmlu-astronomy.val.103,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-law.val.90,WizardLM/WizardLM-13B-V1.2,1.0,7.26e-05,0.0,4.84e-05,1.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
winogrande.dev.596,mistralai/mistral-7b-chat,0.0,1.26e-05,0.0,1.26e-05,0.0,1.89e-05,0.0,3.78e-05,0.0,4.8888e-05,1.0,0.0006399999999999
hellaswag.val.70,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
grade-school-math.dev.3869,WizardLM/WizardLM-13B-V1.2,0.25,0.000216,0.25,0.0001132,0.25,0.000216,0.25,0.0003191999999999,0.25,0.000342992,0.75,0.01073
hellaswag.val.7957,mistralai/mixtral-8x7b-chat,0.0,0.0001632,0.0,5.44e-05,1.0,8.13e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00273
grade-school-math.dev.5349,WizardLM/WizardLM-13B-V1.2,0.25,0.0001697999999999,0.25,6.280000000000001e-05,0.25,0.0001697999999999,0.75,0.0002381999999999,0.5,0.000339112,0.5,0.00903
mmlu-high-school-biology.val.0,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
hellaswag.val.1134,WizardLM/WizardLM-13B-V1.2,0.0,2.79e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-logical-fallacies.val.86,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,1.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
hellaswag.val.3006,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.0013499999999999
mmlu-high-school-biology.val.293,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,1.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-jurisprudence.val.102,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-prehistory.val.61,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.1624,mistralai/mistral-7b-chat,0.25,0.0001098,0.25,0.0001098,0.75,0.0001695,0.75,0.0002628,0.25,0.000297984,0.5,0.00574
hellaswag.val.7357,WizardLM/WizardLM-13B-V1.2,1.0,8.999999999999999e-05,1.0,6.0200000000000006e-05,1.0,8.999999999999999e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00305
mmlu-professional-law.val.624,mistralai/mistral-7b-chat,0.0,5.980000000000001e-05,0.0,5.980000000000001e-05,0.0,8.97e-05,0.0,0.0001787999999999,0.0,0.000232024,1.0,0.003
grade-school-math.dev.3126,mistralai/mistral-7b-chat,0.25,0.0001262,0.25,0.0001262,0.25,0.0001674,0.25,0.0002994,0.25,0.000697624,0.75,0.0130699999999999
arc-challenge.test.319,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
abstract2title.test.239,mistralai/mixtral-8x7b-chat,1.0,0.0001758,0.0,5.86e-05,1.0,8.88e-05,1.0,0.0001758,1.0,0.000223488,1.0,0.00351
grade-school-math.dev.7095,mistralai/mistral-7b-chat,0.25,9.780000000000002e-05,0.25,9.780000000000002e-05,0.25,0.0001764,0.75,0.0002597999999999,0.25,0.000346872,0.5,0.00934
mmlu-high-school-computer-science.val.98,mistralai/mistral-7b-chat,0.0,3.24e-05,0.0,3.24e-05,1.0,4.86e-05,1.0,9.72e-05,0.0,0.000125712,1.0,0.00163
hellaswag.val.6311,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00259
mmlu-professional-law.val.173,mistralai/mistral-7b-chat,0.0,5.76e-05,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
mmlu-international-law.val.100,mistralai/mistral-7b-chat,0.0,3.2800000000000004e-05,0.0,3.2800000000000004e-05,0.0,4.92e-05,1.0,9.84e-05,0.0,0.0001272639999999,1.0,0.00165
grade-school-math.dev.296,mistralai/mixtral-8x7b-chat,0.75,0.0002357999999999,0.25,7.56e-05,0.75,0.0001479,0.75,0.0002357999999999,0.75,0.000336008,0.75,0.00885
grade-school-math.dev.7232,WizardLM/WizardLM-13B-V1.2,0.75,0.0001281,0.5,7.900000000000001e-05,0.75,0.0001281,0.5,0.0002033999999999,0.25,0.000290224,0.75,0.00581
hellaswag.val.2937,mistralai/mistral-7b-chat,1.0,2.08e-05,1.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.4533,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00262
grade-school-math.dev.4844,WizardLM/WizardLM-13B-V1.2,0.25,0.0001791,0.25,0.0001048,0.25,0.0001791,0.5,0.0003204,0.25,0.000365496,0.75,0.00994
mmlu-high-school-mathematics.val.142,mistralai/mixtral-8x7b-chat,0.0,0.000126,1.0,4.2e-05,1.0,6.3e-05,0.0,0.000126,0.0,0.00016296,1.0,0.00211
mmlu-high-school-us-history.val.151,WizardLM/WizardLM-13B-V1.2,1.0,9.9e-05,0.0,6.6e-05,1.0,9.9e-05,1.0,0.000198,0.0,0.00025608,1.0,0.00334
grade-school-math.dev.528,mistralai/mistral-7b-chat,0.75,8.9e-05,0.75,8.9e-05,0.5,0.0001725,0.25,0.0001896,0.25,0.000309624,0.75,0.00753
hellaswag.val.3637,mistralai/mistral-7b-chat,1.0,5.1800000000000005e-05,1.0,5.1800000000000005e-05,1.0,7.739999999999998e-05,1.0,0.0001553999999999,1.0,0.000200984,1.0,0.0026
mmlu-professional-medicine.val.32,mistralai/mixtral-8x7b-chat,1.0,0.0001055999999999,1.0,3.520000000000001e-05,1.0,5.28e-05,1.0,0.0001055999999999,0.0,0.000136576,1.0,0.0018
hellaswag.val.6721,mistralai/mixtral-8x7b-chat,0.0,0.0001709999999999,0.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001709999999999,0.0,0.00022116,1.0,0.00289
hellaswag.val.13,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.63e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
mmlu-professional-law.val.82,WizardLM/WizardLM-13B-V1.2,0.0,0.0001418999999999,0.0,9.46e-05,0.0,0.0001418999999999,0.0,0.0002837999999999,0.0,0.000367048,1.0,0.0047399999999999
mmlu-security-studies.val.216,mistralai/mistral-7b-chat,1.0,3.08e-05,1.0,3.08e-05,0.0,4.6200000000000005e-05,1.0,9.24e-05,0.0,0.000119504,0.0,0.00155
mmlu-college-biology.val.103,mistralai/mixtral-8x7b-chat,0.0,5.88e-05,1.0,1.96e-05,1.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-professional-psychology.val.206,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
grade-school-math.dev.6559,mistralai/mixtral-8x7b-chat,0.5,0.0002826,0.25,9.84e-05,0.75,0.0001508999999999,0.5,0.0002826,0.75,0.000340664,0.75,0.00819
grade-school-math.dev.7132,mistralai/mistral-7b-chat,0.75,8.32e-05,0.75,8.32e-05,0.75,0.0001758,0.75,0.0002712,0.25,0.000381016,0.5,0.00611
hellaswag.val.2152,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.1029,mistralai/mistral-7b-chat,0.5,9.18e-05,0.5,9.18e-05,0.75,0.000201,0.75,0.000303,0.75,0.0003492,0.75,0.00879
mmlu-professional-medicine.val.146,mistralai/mixtral-8x7b-chat,0.0,9.42e-05,0.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
mmlu-marketing.val.100,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.541,mistralai/mistral-7b-chat,0.25,7.500000000000001e-05,0.25,7.500000000000001e-05,0.25,0.0001845,0.25,0.000252,0.25,0.000336784,0.75,0.00717
mmlu-professional-law.val.641,mistralai/mistral-7b-chat,0.0,3.74e-05,0.0,3.74e-05,0.0,5.61e-05,0.0,0.0001122,0.0,0.000145112,0.0,0.00188
hellaswag.val.5396,mistralai/mixtral-8x7b-chat,1.0,0.0001578,1.0,5.260000000000001e-05,1.0,7.859999999999999e-05,1.0,0.0001578,1.0,0.000204088,1.0,0.00267
grade-school-math.dev.6478,WizardLM/WizardLM-13B-V1.2,0.5,0.0001578,0.25,9.08e-05,0.5,0.0001578,0.75,0.0002748,0.25,0.000383344,0.75,0.00779
mmlu-professional-law.val.411,mistralai/mistral-7b-chat,0.0,4e-05,0.0,4e-05,1.0,6e-05,1.0,0.00012,0.0,0.0001551999999999,1.0,0.00204
mmlu-elementary-mathematics.val.284,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
grade-school-math.dev.7191,mistralai/mistral-7b-chat,0.5,7.180000000000001e-05,0.5,7.180000000000001e-05,0.75,0.0001314,0.5,0.0002172,0.25,0.000290224,0.75,0.00831
arc-challenge.test.564,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,1.0,5.1216000000000006e-05,1.0,0.0007
mmlu-nutrition.val.45,mistralai/mixtral-8x7b-chat,1.0,9.54e-05,0.0,3.180000000000001e-05,0.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,1.0,0.0016
grade-school-math.dev.7434,WizardLM/WizardLM-13B-V1.2,0.75,0.0001305,0.75,8.42e-05,0.75,0.0001305,0.75,0.0002538,0.75,0.000326696,0.75,0.00755
winogrande.dev.1000,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.7248e-05,0.0,0.00053
hellaswag.val.5214,mistralai/mistral-7b-chat,0.0,5.5400000000000005e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-computer-security.val.7,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.6627,WizardLM/WizardLM-13B-V1.2,0.0,7.08e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-professional-law.val.1345,mistralai/mixtral-8x7b-chat,1.0,0.0001763999999999,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,1.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
mmlu-high-school-microeconomics.val.72,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00106
arc-challenge.test.194,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,1.0,7.0616e-05,1.0,0.00095
hellaswag.val.6976,WizardLM/WizardLM-13B-V1.2,0.0,6.269999999999999e-05,0.0,4.2e-05,0.0,6.269999999999999e-05,0.0,0.000126,0.0,0.00016296,1.0,0.00214
grade-school-math.dev.5134,WizardLM/WizardLM-13B-V1.2,0.25,0.0001512,0.25,0.0001006,0.25,0.0001512,0.25,0.0003083999999999,0.25,0.000420592,0.25,0.0121299999999999
grade-school-math.dev.2895,WizardLM/WizardLM-13B-V1.2,0.25,0.0001575,0.25,0.0001054,0.25,0.0001575,0.75,0.0002472,0.25,0.000332904,0.5,0.01079
grade-school-math.dev.2223,mistralai/mistral-7b-chat,0.75,7.46e-05,0.75,7.46e-05,0.75,0.0001203,0.75,0.0002153999999999,0.75,0.00026772,0.75,0.00536
mmlu-professional-law.val.354,mistralai/mistral-7b-chat,1.0,3.7600000000000006e-05,1.0,3.7600000000000006e-05,1.0,5.64e-05,1.0,0.0001127999999999,0.0,0.000145888,1.0,0.00189
arc-challenge.val.249,mistralai/mixtral-8x7b-chat,1.0,7.62e-05,1.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
hellaswag.val.263,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
hellaswag.val.1956,WizardLM/WizardLM-13B-V1.2,0.0,4.11e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-moral-scenarios.val.879,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
hellaswag.val.2395,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
grade-school-math.dev.35,WizardLM/WizardLM-13B-V1.2,0.75,0.000159,0.75,9.2e-05,0.75,0.000159,0.75,0.0003017999999999,0.5,0.000394984,0.75,0.00706
hellaswag.val.1610,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.3900000000000004e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
hellaswag.val.4795,mistralai/mistral-7b-chat,1.0,6.04e-05,1.0,6.04e-05,1.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
hellaswag.val.7625,mistralai/mixtral-8x7b-chat,1.0,0.0001656,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,1.0,0.0001656,0.0,0.0002141759999999,0.0,0.00277
mmlu-human-sexuality.val.97,mistralai/mistral-7b-chat,0.0,2.5e-05,0.0,2.5e-05,1.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,1.0,0.00129
grade-school-math.dev.2491,mistralai/mistral-7b-chat,0.25,0.0001132,0.25,0.0001132,0.75,0.0002063999999999,0.75,0.0002622,0.25,0.000349976,0.75,0.0124
mmlu-nutrition.val.108,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,1.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
mmlu-high-school-chemistry.val.83,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.2774,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
grade-school-math.dev.798,WizardLM/WizardLM-13B-V1.2,0.25,0.0001998,0.25,9.38e-05,0.25,0.0001998,0.75,0.0003336,0.25,0.000363168,0.5,0.01126
hellaswag.val.6782,mistralai/mistral-7b-chat,0.0,5.520000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,0.0,0.0028
mmlu-high-school-mathematics.val.46,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.9994,mistralai/mistral-7b-chat,0.0,4.36e-05,0.0,4.36e-05,0.0,6.54e-05,0.0,0.0001308,0.0,0.000169168,1.0,0.00222
mmlu-professional-law.val.384,WizardLM/WizardLM-13B-V1.2,0.0,9.24e-05,0.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,0.0,0.00309
mmlu-nutrition.val.295,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
hellaswag.val.811,mistralai/mixtral-8x7b-chat,1.0,8.159999999999999e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-logical-fallacies.val.67,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.1383,mistralai/mistral-7b-chat,0.0,3.720000000000001e-05,0.0,3.720000000000001e-05,1.0,5.58e-05,0.0,0.0001115999999999,0.0,0.0001443359999999,0.0,0.00187
arc-challenge.val.231,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
hellaswag.val.6186,mistralai/mistral-7b-chat,0.0,4.420000000000001e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00222
mmlu-high-school-microeconomics.val.31,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-high-school-statistics.val.11,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.0015
mmlu-human-aging.val.105,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-security-studies.val.151,mistralai/mixtral-8x7b-chat,1.0,0.0002009999999999,0.0,6.7e-05,1.0,0.0001004999999999,1.0,0.0002009999999999,0.0,0.00025996,1.0,0.00336
arc-challenge.val.272,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.6611,mistralai/mistral-7b-chat,1.0,4.8e-05,1.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,1.0,0.00018624,0.0,0.00241
mmlu-professional-law.val.190,WizardLM/WizardLM-13B-V1.2,0.0,7.71e-05,0.0,5.14e-05,0.0,7.71e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
grade-school-math.dev.3852,WizardLM/WizardLM-13B-V1.2,0.75,0.000192,0.0,0.0001204,0.75,0.000192,0.75,0.0003312,0.25,0.000412056,0.5,0.01142
grade-school-math.dev.1397,mistralai/mistral-7b-chat,0.25,9.4e-05,0.25,9.4e-05,0.25,0.0001536,0.75,0.0002586,0.25,0.0003810159999999,0.75,0.00826
mmlu-miscellaneous.val.199,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.1275,mistralai/mixtral-8x7b-chat,0.5,0.0003042,0.25,9.1e-05,0.75,0.0001652999999999,0.5,0.0003042,0.75,0.00025996,0.5,0.00868
grade-school-math.dev.1538,mistralai/mistral-7b-chat,0.25,0.0001032,0.25,0.0001032,0.5,0.0001664999999999,0.5,0.0002544,0.25,0.000406624,0.5,0.0102499999999999
hellaswag.val.2955,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-jurisprudence.val.95,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-miscellaneous.val.70,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
winogrande.dev.454,mistralai/mistral-7b-chat,1.0,9.2e-06,1.0,9.2e-06,0.0,1.3799999999999998e-05,0.0,2.76e-05,1.0,3.5696e-05,1.0,0.0005
mmlu-human-sexuality.val.36,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00116
hellaswag.val.7524,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
hellaswag.val.4584,mistralai/mistral-7b-chat,0.0,5.3200000000000006e-05,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.00267
hellaswag.val.8901,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
grade-school-math.dev.1224,WizardLM/WizardLM-13B-V1.2,0.25,0.0001676999999999,0.25,8.6e-05,0.25,0.0001676999999999,0.5,0.0002423999999999,0.25,0.000312728,0.5,0.00987
arc-challenge.test.1000,mistralai/mixtral-8x7b-chat,0.0,5.52e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
grade-school-math.dev.3685,WizardLM/WizardLM-13B-V1.2,0.5,0.0001338,0.25,8.88e-05,0.5,0.0001338,0.25,0.0003084,0.25,0.0002522,0.25,0.0092
hellaswag.val.9564,mistralai/mistral-7b-chat,1.0,5.520000000000001e-05,1.0,5.520000000000001e-05,1.0,8.280000000000001e-05,1.0,0.000165,1.0,0.0002141759999999,1.0,0.0028
grade-school-math.dev.5514,mistralai/mixtral-8x7b-chat,0.75,0.0002429999999999,0.75,8.56e-05,0.75,0.0001613999999999,0.75,0.0002429999999999,0.25,0.000274704,0.75,0.0075
abstract2title.test.11,mistralai/mixtral-8x7b-chat,1.0,0.0002189999999999,1.0,7.280000000000001e-05,1.0,0.0001076999999999,1.0,0.0002189999999999,1.0,0.00028324,1.0,0.00428
mmlu-college-medicine.val.154,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
hellaswag.val.1340,mistralai/mixtral-8x7b-chat,1.0,8.46e-05,0.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-human-sexuality.val.49,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-computer-security.val.6,mistralai/mistral-7b-chat,1.0,4.420000000000001e-05,1.0,4.420000000000001e-05,1.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,1.0,0.00222
winogrande.dev.380,mistralai/mixtral-8x7b-chat,1.0,3.3600000000000004e-05,1.0,1.12e-05,1.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,1.0,4.3456000000000005e-05,1.0,0.0006
mmlu-high-school-mathematics.val.1,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.3128,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,1.0,9.312e-05,1.0,0.00121
mmlu-us-foreign-policy.val.99,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.7915,mistralai/mixtral-8x7b-chat,1.0,0.0001524,1.0,5.080000000000001e-05,1.0,7.589999999999999e-05,1.0,0.0001524,1.0,0.0001971039999999,1.0,0.00258
hellaswag.val.2979,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
grade-school-math.dev.1976,WizardLM/WizardLM-13B-V1.2,0.75,0.0001365,0.75,6.8e-05,0.75,0.0001365,0.75,0.0002784,0.75,0.000270824,0.5,0.00642
hellaswag.val.8356,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,1.0,0.0001649999999999,0.0,0.0002134,1.0,0.00279
hellaswag.val.4440,mistralai/mistral-7b-chat,0.0,5.4600000000000006e-05,0.0,5.4600000000000006e-05,0.0,8.159999999999999e-05,0.0,0.0001638,0.0,0.0002118479999999,1.0,0.00274
grade-school-math.dev.6607,WizardLM/WizardLM-13B-V1.2,0.25,0.0001722,0.25,8.5e-05,0.25,0.0001722,0.25,0.000285,0.25,0.000297208,0.25,0.01306
mmlu-professional-law.val.464,mistralai/mistral-7b-chat,1.0,3.8400000000000005e-05,1.0,3.8400000000000005e-05,1.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00196
mmlu-elementary-mathematics.val.298,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.5175,mistralai/mixtral-8x7b-chat,0.0,0.0001632,0.0,5.44e-05,0.0,8.16e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00273
hellaswag.val.8834,mistralai/mistral-7b-chat,1.0,5.62e-05,1.0,5.62e-05,1.0,8.43e-05,0.0,0.0001686,1.0,0.000218056,1.0,0.00285
grade-school-math.dev.4362,WizardLM/WizardLM-13B-V1.2,0.5,0.0001638,0.5,7.4e-05,0.5,0.0001638,0.75,0.0002705999999999,0.75,0.000282464,0.75,0.00713
mbpp.dev.43,mistralai/mistral-7b-chat,1.0,3.5e-05,1.0,3.5e-05,0.0,6.269999999999999e-05,1.0,0.0002459999999999,1.0,0.00010864,1.0,0.00894
mmlu-professional-law.val.1449,mistralai/mistral-7b-chat,0.0,3.7000000000000005e-05,0.0,3.7000000000000005e-05,0.0,5.52e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00186
grade-school-math.dev.568,mistralai/mistral-7b-chat,0.25,0.000159,0.25,0.000159,0.75,0.000159,0.25,0.0002892,0.0,0.000363168,0.75,0.0108799999999999
consensus_summary.dev.301,mistralai/mistral-7b-chat,0.75,5.120000000000001e-05,0.75,5.120000000000001e-05,0.75,8.609999999999999e-05,0.75,0.0001578,0.75,0.000218832,0.75,0.00398
mmlu-sociology.val.151,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
mmlu-professional-law.val.21,WizardLM/WizardLM-13B-V1.2,0.0,0.0001271999999999,0.0,8.48e-05,0.0,0.0001271999999999,0.0,0.0002543999999999,0.0,0.000329024,1.0,0.0042499999999999
grade-school-math.dev.5803,WizardLM/WizardLM-13B-V1.2,0.25,0.0001368,0.75,7.840000000000001e-05,0.25,0.0001368,0.0,0.000225,0.25,0.00027936,0.75,0.00619
mmlu-miscellaneous.val.691,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
mmlu-professional-law.val.1069,WizardLM/WizardLM-13B-V1.2,0.0,5.1e-05,0.0,3.4000000000000007e-05,0.0,5.1e-05,0.0,0.000102,0.0,0.0001319199999999,0.0,0.00174
mmlu-nutrition.val.213,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
mmlu-high-school-world-history.val.8,mistralai/mixtral-8x7b-chat,1.0,0.000225,1.0,7.500000000000001e-05,1.0,0.0001125,1.0,0.000225,0.0,0.000291,1.0,0.00376
mmlu-moral-disputes.val.0,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
hellaswag.val.8285,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-professional-law.val.1267,WizardLM/WizardLM-13B-V1.2,1.0,8.49e-05,0.0,5.660000000000001e-05,1.0,8.49e-05,1.0,0.0001698,0.0,0.000219608,1.0,0.00284
hellaswag.val.518,mistralai/mistral-7b-chat,0.0,2.52e-05,0.0,2.52e-05,0.0,3.78e-05,0.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
mmlu-conceptual-physics.val.137,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
mmlu-professional-accounting.val.280,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
hellaswag.val.4809,WizardLM/WizardLM-13B-V1.2,1.0,7.919999999999999e-05,1.0,5.300000000000001e-05,1.0,7.919999999999999e-05,1.0,0.000159,1.0,0.00020564,1.0,0.00266
mmlu-moral-disputes.val.40,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-miscellaneous.val.391,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
hellaswag.val.1697,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.54e-05,0.0,7.14e-05,0.0,9.2344e-05,0.0,0.0012
mmlu-high-school-world-history.val.30,WizardLM/WizardLM-13B-V1.2,0.0,0.0001029,1.0,6.86e-05,0.0,0.0001029,1.0,0.0002058,0.0,0.0002661679999999,1.0,0.00344
hellaswag.val.9442,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,6.989999999999999e-05,1.0,0.0001404,0.0,0.000181584,0.0,0.00238
hellaswag.val.5121,mistralai/mixtral-8x7b-chat,0.0,0.000156,0.0,5.2e-05,0.0,7.769999999999999e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
mmlu-high-school-geography.val.100,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-security-studies.val.171,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
hellaswag.val.2679,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,1.0,6.984e-05,1.0,0.00094
mmlu-high-school-psychology.val.444,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-philosophy.val.298,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.6260,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-professional-law.val.1235,WizardLM/WizardLM-13B-V1.2,0.0,0.0001064999999999,0.0,7.1e-05,0.0,0.0001064999999999,1.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
mmlu-high-school-psychology.val.355,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
hellaswag.val.7826,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,1.0,5.5e-05,1.0,8.249999999999999e-05,0.0,0.0001649999999999,1.0,0.0002134,1.0,0.00276
mmlu-conceptual-physics.val.119,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
grade-school-math.dev.2430,mistralai/mistral-7b-chat,0.25,5.7e-05,0.25,5.7e-05,0.75,0.00015,0.75,0.0002106,0.5,0.000321264,0.5,0.00642
mmlu-prehistory.val.135,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
hellaswag.val.8013,mistralai/mixtral-8x7b-chat,0.0,0.0001668,1.0,5.56e-05,1.0,8.34e-05,0.0,0.0001668,1.0,0.000215728,1.0,0.00282
grade-school-math.dev.3560,mistralai/mistral-7b-chat,0.75,7.8e-05,0.75,7.8e-05,0.75,0.0001643999999999,0.75,0.0002214,0.25,0.000325144,0.75,0.0067
mmlu-professional-law.val.956,WizardLM/WizardLM-13B-V1.2,0.0,0.0001152,0.0,7.68e-05,0.0,0.0001152,0.0,0.0002304,0.0,0.000297984,0.0,0.00385
mmlu-professional-law.val.249,mistralai/mistral-7b-chat,0.0,4.720000000000001e-05,0.0,4.720000000000001e-05,1.0,7.08e-05,1.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-high-school-mathematics.val.245,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00096
mmlu-college-biology.val.21,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.6367,mistralai/mixtral-8x7b-chat,0.0,0.0001566,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,0.0,0.00265
grade-school-math.dev.2309,WizardLM/WizardLM-13B-V1.2,0.25,0.000192,0.25,0.0001218,0.25,0.000192,0.25,0.000345,0.25,0.000385672,0.5,0.01234
mmlu-moral-disputes.val.42,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,0.0,0.00128
mmlu-professional-law.val.819,WizardLM/WizardLM-13B-V1.2,1.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-professional-law.val.1009,WizardLM/WizardLM-13B-V1.2,1.0,6.42e-05,0.0,4.280000000000001e-05,1.0,6.42e-05,1.0,0.0001284,0.0,0.000166064,1.0,0.00218
mmlu-sociology.val.98,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-moral-scenarios.val.37,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-clinical-knowledge.val.40,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
hellaswag.val.1202,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3e-05,1.0,6.06e-05,1.0,7.8376e-05,1.0,0.00105
grade-school-math.dev.5129,meta/code-llama-instruct-34b-chat,0.25,0.00031816,0.25,8.92e-05,0.25,0.0001587,0.25,0.0003198,0.25,0.00031816,0.75,0.01765
mmlu-moral-disputes.val.105,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
mmlu-high-school-government-and-politics.val.170,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
mmlu-professional-law.val.1211,WizardLM/WizardLM-13B-V1.2,0.0,0.0001947,0.0,0.0001298,0.0,0.0001947,0.0,0.0003888,0.0,0.000503624,0.0,0.0065
grade-school-math.dev.4153,meta/code-llama-instruct-34b-chat,0.75,0.00028324,0.25,9.8e-05,0.25,0.0001494,0.75,0.0002153999999999,0.75,0.00028324,0.75,0.00597
mmlu-professional-law.val.799,WizardLM/WizardLM-13B-V1.2,0.0,6.780000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,1.0,0.0001356,0.0,0.000175376,1.0,0.00227
mmlu-clinical-knowledge.val.180,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
mmlu-professional-law.val.309,WizardLM/WizardLM-13B-V1.2,0.0,9.54e-05,1.0,6.36e-05,0.0,9.54e-05,1.0,0.0001908,0.0,0.000246768,1.0,0.00319
hellaswag.val.7602,WizardLM/WizardLM-13B-V1.2,0.0,9.24e-05,0.0,6.159999999999999e-05,0.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00312
hellaswag.val.4260,mistralai/mixtral-8x7b-chat,1.0,0.0001319999999999,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,1.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
grade-school-math.dev.5232,mistralai/mistral-7b-chat,0.25,0.0001148,0.25,0.0001148,0.5,0.0001791,0.25,0.0003395999999999,0.25,0.000428352,0.75,0.00864
mmlu-college-biology.val.78,mistralai/mixtral-8x7b-chat,0.0,7.2e-05,1.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-elementary-mathematics.val.154,mistralai/mixtral-8x7b-chat,0.0,6.48e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,0.0,0.00112
grade-school-math.dev.4394,mistralai/mistral-7b-chat,0.25,0.0001036,0.25,0.0001036,0.25,0.0001629,0.25,0.0001908,0.25,0.00034144,0.75,0.01138
mmlu-professional-psychology.val.227,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
grade-school-math.dev.6547,mistralai/mistral-7b-chat,0.5,8.14e-05,0.5,8.14e-05,0.75,0.000132,0.5,0.0001962,0.75,0.000297208,0.75,0.0060999999999999
hellaswag.val.1312,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
grade-school-math.dev.4341,WizardLM/WizardLM-13B-V1.2,0.25,0.0001659,0.25,0.0001072,0.25,0.0001659,0.5,0.000261,0.75,0.000339888,0.75,0.00853
hellaswag.val.5215,mistralai/mixtral-8x7b-chat,1.0,0.000156,1.0,5.2e-05,1.0,7.769999999999999e-05,1.0,0.000156,0.0,0.00020176,1.0,0.00261
mmlu-conceptual-physics.val.129,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-high-school-psychology.val.135,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
grade-school-math.dev.7009,mistralai/mistral-7b-chat,0.25,9.02e-05,0.25,9.02e-05,0.25,0.0001305,0.75,0.000264,0.25,0.00035696,0.75,0.00919
mmlu-professional-law.val.69,mistralai/mistral-7b-chat,0.0,5.94e-05,0.0,5.94e-05,0.0,8.91e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
grade-school-math.dev.2761,mistralai/mistral-7b-chat,0.5,7.98e-05,0.5,7.98e-05,0.25,0.0001518,0.25,0.0002454,0.75,0.000304192,0.75,0.00923
mmlu-human-aging.val.51,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-law.val.128,WizardLM/WizardLM-13B-V1.2,1.0,9.9e-05,0.0,6.6e-05,1.0,9.9e-05,0.0,0.0001973999999999,0.0,0.00025608,0.0,0.00331
hellaswag.val.1373,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,1.0,6.828800000000001e-05,0.0,0.00089
hellaswag.val.4178,mistralai/mixtral-8x7b-chat,1.0,0.000138,1.0,4.600000000000001e-05,0.0,6.869999999999999e-05,1.0,0.000138,1.0,0.0001784799999999,1.0,0.00234
grade-school-math.dev.2312,WizardLM/WizardLM-13B-V1.2,0.25,0.0001803,0.25,0.0001128,0.25,0.0001803,0.25,0.000312,0.25,0.00036084,0.75,0.01257
grade-school-math.dev.695,WizardLM/WizardLM-13B-V1.2,0.75,0.0001293,0.75,8.46e-05,0.75,0.0001293,0.75,0.0002556,0.25,0.000300312,0.5,0.00589
hellaswag.val.5201,mistralai/mixtral-8x7b-chat,1.0,0.0001428,1.0,4.7600000000000005e-05,1.0,7.11e-05,1.0,0.0001428,1.0,0.000184688,1.0,0.00242
mmlu-business-ethics.val.61,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,1.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00115
mmlu-professional-medicine.val.236,WizardLM/WizardLM-13B-V1.2,0.0,0.0001076999999999,0.0,7.18e-05,0.0,0.0001076999999999,1.0,0.0002153999999999,0.0,0.0002785839999999,1.0,0.0036
mmlu-high-school-microeconomics.val.219,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
grade-school-math.dev.3348,mistralai/mistral-7b-chat,0.25,9.54e-05,0.25,9.54e-05,0.25,0.0001545,0.25,0.0002718,0.25,0.000329024,0.5,0.00805
hellaswag.val.7504,mistralai/mixtral-8x7b-chat,0.0,0.0001716,0.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001716,0.0,0.000221936,1.0,0.0029
mmlu-anatomy.val.30,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
mmlu-moral-scenarios.val.673,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
mmlu-professional-law.val.1274,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-high-school-mathematics.val.75,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.5011,WizardLM/WizardLM-13B-V1.2,0.75,0.0001512,0.75,9.54e-05,0.75,0.0001512,0.75,0.0002208,0.25,0.000355408,0.75,0.0086
mmlu-high-school-psychology.val.316,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.2242,mistralai/mixtral-8x7b-chat,0.75,0.0002033999999999,0.25,8.58e-05,0.25,0.0001677,0.75,0.0002033999999999,0.25,0.000294104,0.75,0.0068
bias_detection.dev.140,mistralai/mistral-7b-chat,0.0,5.6800000000000005e-05,0.0,5.6800000000000005e-05,1.0,0.0001083,0.0,0.0001794,0.0,0.000252976,0.0,0.00852
mmlu-high-school-physics.val.79,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.9152e-05,0.0,0.00104
hellaswag.val.5162,mistralai/mistral-7b-chat,1.0,5.580000000000001e-05,1.0,5.580000000000001e-05,1.0,8.34e-05,1.0,0.0001674,0.0,0.0002165039999999,1.0,0.00283
mmlu-prehistory.val.252,mistralai/mixtral-8x7b-chat,1.0,6e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-high-school-government-and-politics.val.146,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.972,WizardLM/WizardLM-13B-V1.2,0.75,0.0001074,0.25,0.000106,0.75,0.0001074,0.75,0.0002544,0.75,0.000277808,0.75,0.00701
hellaswag.val.5532,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,0.0,0.0026
mmlu-college-medicine.val.58,WizardLM/WizardLM-13B-V1.2,1.0,4.14e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00142
mmlu-abstract-algebra.val.62,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00116
hellaswag.val.5279,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,0.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,0.0,0.00241
hellaswag.val.4051,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
hellaswag.val.8728,mistralai/mixtral-8x7b-chat,0.0,0.000159,0.0,5.300000000000001e-05,1.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
mmlu-high-school-physics.val.86,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,0.0,0.00091
winogrande.dev.984,mistralai/mistral-7b-chat,0.0,1.12e-05,0.0,1.12e-05,1.0,1.6800000000000002e-05,0.0,3.3600000000000004e-05,0.0,4.3456000000000005e-05,1.0,0.0006
grade-school-math.dev.2751,mistralai/mixtral-8x7b-chat,0.75,0.0002508,0.75,8.180000000000001e-05,0.75,0.0001505999999999,0.75,0.0002508,0.75,0.00028712,0.5,0.0063199999999999
grade-school-math.dev.1915,mistralai/mistral-7b-chat,0.75,7.8e-05,0.75,7.8e-05,0.75,0.0001758,0.75,0.000276,0.75,0.00026772,0.5,0.00778
hellaswag.val.6893,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.35e-05,1.0,0.000147,0.0,0.00019012,1.0,0.00246
grade-school-math.dev.6695,WizardLM/WizardLM-13B-V1.2,0.25,0.000159,0.25,0.0001026,0.25,0.000159,0.75,0.0003156,0.25,0.000320488,0.75,0.00859
arc-challenge.test.851,mistralai/mixtral-8x7b-chat,0.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-jurisprudence.val.20,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
arc-challenge.test.506,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,1.0,6.208e-05,1.0,0.00084
mmlu-professional-law.val.703,WizardLM/WizardLM-13B-V1.2,1.0,4.53e-05,0.0,3.02e-05,1.0,4.53e-05,0.0,9.06e-05,0.0,0.000117176,0.0,0.00155
grade-school-math.dev.838,mistralai/mistral-7b-chat,0.25,9.68e-05,0.25,9.68e-05,0.25,0.000156,0.5,0.0002975999999999,0.25,0.000390328,0.75,0.00982
hellaswag.val.4625,mistralai/mixtral-8x7b-chat,0.0,0.0001829999999999,0.0,6.1000000000000005e-05,0.0,9.15e-05,0.0,0.0001829999999999,0.0,0.00023668,1.0,0.00309
grade-school-math.dev.5775,WizardLM/WizardLM-13B-V1.2,0.75,0.0001455,0.75,8.580000000000001e-05,0.75,0.0001455,0.25,0.0002022,0.75,0.000425248,0.75,0.00601
hellaswag.val.6952,mistralai/mistral-7b-chat,1.0,4.94e-05,1.0,4.94e-05,1.0,7.41e-05,1.0,0.0001482,1.0,0.000191672,1.0,0.00251
hellaswag.val.4240,mistralai/mistral-7b-chat,0.0,5.2e-05,0.0,5.2e-05,0.0,7.769999999999999e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
consensus_summary.dev.233,mistralai/mistral-7b-chat,0.75,3.540000000000001e-05,0.75,3.540000000000001e-05,0.75,6.840000000000001e-05,0.75,0.0001284,0.75,0.00018624,0.75,0.0030299999999999
mmlu-professional-law.val.548,WizardLM/WizardLM-13B-V1.2,1.0,0.0001269,1.0,8.46e-05,1.0,0.0001269,1.0,0.0002538,0.0,0.000328248,0.0,0.00424
mmlu-formal-logic.val.53,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
hellaswag.val.7598,mistralai/mistral-7b-chat,0.0,5.680000000000001e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00288
grade-school-math.dev.6830,WizardLM/WizardLM-13B-V1.2,0.25,0.000195,0.75,8.24e-05,0.25,0.000195,0.75,0.0002856,0.75,0.000366272,0.75,0.01155
grade-school-math.dev.6702,meta/code-llama-instruct-34b-chat,0.5,0.000344544,0.75,8.060000000000001e-05,0.75,0.0001494,0.75,0.0002208,0.5,0.000344544,0.5,0.0097
grade-school-math.dev.2961,WizardLM/WizardLM-13B-V1.2,0.5,0.0001362,0.75,0.000105,0.5,0.0001362,0.25,0.0002316,0.5,0.000363168,0.5,0.00613
mmlu-marketing.val.142,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.902,mistralai/mixtral-8x7b-chat,1.0,9.48e-05,0.0,3.160000000000001e-05,1.0,4.74e-05,1.0,9.48e-05,0.0,0.000122608,1.0,0.00159
grade-school-math.dev.2317,WizardLM/WizardLM-13B-V1.2,0.25,0.0002115,0.25,0.0001055999999999,0.25,0.0002115,0.25,0.0003246,0.25,0.000429128,0.5,0.0111
mmlu-professional-law.val.946,WizardLM/WizardLM-13B-V1.2,0.0,6.780000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,1.0,0.00227
grade-school-math.dev.5367,WizardLM/WizardLM-13B-V1.2,0.25,0.0002124,0.25,0.0001042,0.25,0.0002124,0.25,0.0003624,0.25,0.000412056,0.75,0.01338
mmlu-moral-scenarios.val.234,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,0.0,0.00139
mmlu-sociology.val.42,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-law.val.1034,WizardLM/WizardLM-13B-V1.2,0.0,9.12e-05,0.0,6.080000000000001e-05,0.0,9.12e-05,0.0,0.0001817999999999,0.0,0.000235904,0.0,0.00305
grade-school-math.dev.5046,WizardLM/WizardLM-13B-V1.2,0.75,0.0001902,0.75,0.0001114,0.75,0.0001902,0.75,0.0003312,0.75,0.000370152,0.75,0.01077
mmlu-machine-learning.val.35,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.8968,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.00273
grade-school-math.dev.3108,WizardLM/WizardLM-13B-V1.2,0.5,0.0001767,0.5,8.32e-05,0.5,0.0001767,0.5,0.000264,0.5,0.000342216,0.5,0.00794
mmlu-professional-law.val.413,WizardLM/WizardLM-13B-V1.2,0.0,0.0001137,0.0,7.58e-05,0.0,0.0001137,0.0,0.0002274,0.0,0.000294104,1.0,0.0038
hellaswag.val.2851,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
hellaswag.val.6682,WizardLM/WizardLM-13B-V1.2,0.0,7.049999999999999e-05,0.0,4.720000000000001e-05,0.0,7.049999999999999e-05,0.0,0.0001416,0.0,0.000183136,0.0,0.00237
mmlu-sociology.val.100,mistralai/mixtral-8x7b-chat,1.0,7.14e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
grade-school-math.dev.2847,mistralai/mistral-7b-chat,0.25,9.48e-05,0.25,9.48e-05,0.25,0.0001605,0.75,0.0003084,0.5,0.0004687039999999,0.5,0.00845
mmlu-elementary-mathematics.val.327,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,1.0,2.2e-05,0.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-law.val.483,WizardLM/WizardLM-13B-V1.2,1.0,0.0001361999999999,0.0,9.08e-05,1.0,0.0001361999999999,0.0,0.0002723999999999,0.0,0.000352304,1.0,0.0045499999999999
hellaswag.val.2115,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,0.0,0.00144
hellaswag.val.7332,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-high-school-microeconomics.val.134,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
grade-school-math.dev.305,mistralai/mistral-7b-chat,0.25,7.7e-05,0.25,7.7e-05,0.75,0.0001401,0.25,0.0002021999999999,0.5,0.0002568559999999,0.5,0.00632
hellaswag.val.103,mistralai/mistral-7b-chat,1.0,2.8e-05,1.0,2.8e-05,1.0,4.17e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
mmlu-econometrics.val.103,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,0.0,8.28e-05,0.0,0.000106312,0.0,0.00139
mmlu-professional-law.val.808,mistralai/mistral-7b-chat,0.0,3.94e-05,0.0,3.94e-05,0.0,5.91e-05,0.0,0.0001182,0.0,0.0001528719999999,0.0,0.00198
mmlu-us-foreign-policy.val.52,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-security-studies.val.229,mistralai/mistral-7b-chat,1.0,2.88e-05,1.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-professional-law.val.534,mistralai/mistral-7b-chat,0.0,4.94e-05,0.0,4.94e-05,0.0,7.41e-05,1.0,0.0001482,0.0,0.000191672,0.0,0.00248
hellaswag.val.3410,mistralai/mixtral-8x7b-chat,1.0,0.0001487999999999,1.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,1.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
hellaswag.val.9694,WizardLM/WizardLM-13B-V1.2,1.0,8.699999999999999e-05,1.0,5.800000000000001e-05,1.0,8.699999999999999e-05,1.0,0.0001739999999999,1.0,0.00022504,1.0,0.00291
mmlu-public-relations.val.85,mistralai/mistral-7b-chat,0.0,3.1200000000000006e-05,0.0,3.1200000000000006e-05,1.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.0015999999999999
hellaswag.val.6730,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,0.0,0.00257
hellaswag.val.555,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
mmlu-professional-law.val.91,mistralai/mistral-7b-chat,0.0,4.1800000000000006e-05,0.0,4.1800000000000006e-05,1.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
mmlu-philosophy.val.93,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
winogrande.dev.828,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
grade-school-math.dev.2259,mistralai/mistral-7b-chat,0.75,6.9e-05,0.75,6.9e-05,0.75,0.0001398,0.75,0.0002022,0.25,0.000272376,0.75,0.00507
hellaswag.val.9348,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.319999999999999e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-philosophy.val.105,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
mmlu-professional-law.val.1108,mistralai/mistral-7b-chat,1.0,5.5e-05,1.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00279
grade-school-math.dev.6543,WizardLM/WizardLM-13B-V1.2,0.75,0.0001428,0.25,8.5e-05,0.75,0.0001428,0.75,0.0002561999999999,0.5,0.000308072,0.75,0.00621
mbpp.dev.352,mistralai/mistral-7b-chat,1.0,6.280000000000001e-05,1.0,6.280000000000001e-05,1.0,0.0001341,1.0,0.0001884,1.0,0.000173048,1.0,0.00789
mmlu-professional-law.val.460,WizardLM/WizardLM-13B-V1.2,1.0,5.73e-05,0.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00192
mmlu-professional-law.val.1317,mistralai/mistral-7b-chat,1.0,4.1200000000000005e-05,1.0,4.1200000000000005e-05,0.0,6.18e-05,1.0,0.0001236,0.0,0.000159856,1.0,0.00207
hellaswag.val.7259,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
grade-school-math.dev.2342,WizardLM/WizardLM-13B-V1.2,0.5,0.0001401,0.5,9.28e-05,0.5,0.0001401,0.75,0.0002861999999999,0.25,0.000327472,0.75,0.00753
grade-school-math.dev.3350,WizardLM/WizardLM-13B-V1.2,0.75,0.0001631999999999,0.25,0.0001028,0.75,0.0001631999999999,0.75,0.0002478,0.25,0.000297984,0.75,0.00684
mmlu-college-medicine.val.113,mistralai/mixtral-8x7b-chat,1.0,8.1e-05,1.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
hellaswag.val.6259,WizardLM/WizardLM-13B-V1.2,1.0,6.84e-05,1.0,4.56e-05,1.0,6.84e-05,0.0,0.0001368,1.0,0.000176928,0.0,0.00232
hellaswag.val.6369,mistralai/mixtral-8x7b-chat,1.0,0.000138,0.0,4.600000000000001e-05,0.0,6.9e-05,1.0,0.000138,0.0,0.0001784799999999,1.0,0.00234
mmlu-high-school-microeconomics.val.235,mistralai/mixtral-8x7b-chat,1.0,7.56e-05,0.0,2.52e-05,0.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.00127
hellaswag.val.8809,WizardLM/WizardLM-13B-V1.2,0.0,7.8e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,0.0,0.00264
hellaswag.val.8171,WizardLM/WizardLM-13B-V1.2,1.0,6.81e-05,1.0,4.5400000000000006e-05,1.0,6.81e-05,1.0,0.0001362,1.0,0.0001761519999999,1.0,0.00231
hellaswag.val.1677,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
arc-challenge.val.148,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-high-school-microeconomics.val.79,mistralai/mistral-7b-chat,0.0,2.12e-05,0.0,2.12e-05,0.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
hellaswag.val.592,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-miscellaneous.val.30,mistralai/mixtral-8x7b-chat,0.0,4.2e-05,0.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.8001,WizardLM/WizardLM-13B-V1.2,1.0,7.02e-05,1.0,4.6800000000000006e-05,1.0,7.02e-05,1.0,0.0001404,1.0,0.000181584,1.0,0.00238
hellaswag.val.1105,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.12e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-international-law.val.66,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
hellaswag.val.4205,mistralai/mixtral-8x7b-chat,1.0,0.0001649999999999,1.0,5.5e-05,1.0,8.219999999999998e-05,1.0,0.0001649999999999,1.0,0.0002134,1.0,0.00276
hellaswag.val.4569,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
grade-school-math.dev.3811,mistralai/mistral-7b-chat,0.75,9.18e-05,0.75,9.18e-05,0.25,0.0001761,0.25,0.0002868,0.5,0.00038412,0.75,0.0088899999999999
hellaswag.val.7599,WizardLM/WizardLM-13B-V1.2,1.0,7.74e-05,1.0,5.160000000000001e-05,1.0,7.74e-05,0.0,0.0001548,1.0,0.000200208,1.0,0.00262
mmlu-miscellaneous.val.723,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
mmlu-management.val.93,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00079
hellaswag.val.1363,WizardLM/WizardLM-13B-V1.2,0.0,4.17e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,0.0,0.0014299999999999
mmlu-high-school-geography.val.43,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-professional-law.val.985,WizardLM/WizardLM-13B-V1.2,0.0,0.0001016999999999,0.0,6.780000000000001e-05,0.0,0.0001016999999999,0.0,0.0002033999999999,0.0,0.000263064,1.0,0.0034
mmlu-moral-scenarios.val.667,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
grade-school-math.dev.770,WizardLM/WizardLM-13B-V1.2,0.25,0.0001487999999999,0.75,0.0001094,0.25,0.0001487999999999,0.25,0.0002964,0.75,0.000344544,0.75,0.00972
hellaswag.val.9039,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.309999999999999e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
mmlu-college-medicine.val.11,mistralai/mixtral-8x7b-chat,1.0,9.36e-05,0.0,3.1200000000000006e-05,0.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.00157
mmlu-electrical-engineering.val.48,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.00079
hellaswag.val.3616,mistralai/mixtral-8x7b-chat,1.0,0.0001482,1.0,4.94e-05,1.0,7.379999999999999e-05,1.0,0.0001482,1.0,0.000191672,1.0,0.00248
hellaswag.val.5097,WizardLM/WizardLM-13B-V1.2,1.0,7.65e-05,1.0,5.12e-05,1.0,7.65e-05,1.0,0.0001536,1.0,0.000198656,1.0,0.0026
mmlu-moral-scenarios.val.505,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,0.0,7.98e-05,0.0,0.000103208,1.0,0.00137
hellaswag.val.9391,mistralai/mistral-7b-chat,0.0,4.420000000000001e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,0.0,0.00225
arc-challenge.val.125,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,0.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00069
grade-school-math.dev.3734,mistralai/mistral-7b-chat,0.25,0.0001154,0.25,0.0001154,0.25,0.0001971,0.75,0.000324,0.25,0.00030264,0.5,0.01081
mmlu-professional-law.val.1044,WizardLM/WizardLM-13B-V1.2,1.0,6.12e-05,0.0,4.080000000000001e-05,1.0,6.12e-05,0.0,0.0001224,0.0,0.000158304,0.0,0.00205
hellaswag.val.4070,mistralai/mixtral-8x7b-chat,0.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,0.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
hellaswag.val.9504,mistralai/mixtral-8x7b-chat,0.0,0.0001362,0.0,4.5400000000000006e-05,0.0,6.78e-05,0.0,0.0001362,0.0,0.0001761519999999,1.0,0.00231
arc-challenge.test.605,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.73e-05,0.0,5.52e-05,1.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.6560,mistralai/mixtral-8x7b-chat,0.0,0.0001344,0.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,1.0,0.00228
mmlu-nutrition.val.77,mistralai/mistral-7b-chat,1.0,2.54e-05,1.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-machine-learning.val.4,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
grade-school-math.dev.7306,WizardLM/WizardLM-13B-V1.2,0.75,0.0001596,0.75,8.18e-05,0.75,0.0001596,0.75,0.0002298,0.5,0.000273928,0.75,0.0078599999999999
mmlu-prehistory.val.225,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
grade-school-math.dev.4193,mistralai/mistral-7b-chat,0.25,6.68e-05,0.25,6.68e-05,0.75,0.0001397999999999,0.75,0.000252,0.75,0.000346872,0.5,0.00689
grade-school-math.dev.6116,mistralai/mistral-7b-chat,0.25,9.26e-05,0.25,9.26e-05,0.5,0.0001581,0.5,0.000261,0.75,0.000404296,0.75,0.00767
mmlu-professional-law.val.258,mistralai/mistral-7b-chat,0.0,5.8200000000000005e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
grade-school-math.dev.5761,mistralai/mistral-7b-chat,0.5,8.280000000000001e-05,0.5,8.280000000000001e-05,0.5,0.0001286999999999,0.75,0.0002472,0.75,0.000354632,0.5,0.0062699999999999
grade-school-math.dev.941,WizardLM/WizardLM-13B-V1.2,0.75,0.0001269,0.25,5.64e-05,0.75,0.0001269,0.75,0.0002514,0.75,0.000241336,0.75,0.00501
mmlu-philosophy.val.208,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
hellaswag.val.9922,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
mmlu-nutrition.val.286,mistralai/mixtral-8x7b-chat,1.0,8.82e-05,0.0,2.94e-05,1.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
hellaswag.val.4326,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-college-chemistry.val.52,mistralai/mixtral-8x7b-chat,0.0,0.0001344,0.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,0.0,0.00225
hellaswag.val.2489,mistralai/mistral-7b-chat,0.0,2.14e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
arc-challenge.test.185,mistralai/mixtral-8x7b-chat,1.0,3.96e-05,1.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,1.0,5.1216000000000006e-05,1.0,0.0007
mmlu-professional-law.val.664,WizardLM/WizardLM-13B-V1.2,0.0,0.0001578,0.0,0.0001052,0.0,0.0001578,1.0,0.0003156,0.0,0.000408176,1.0,0.0052699999999999
hellaswag.val.6404,mistralai/mixtral-8x7b-chat,1.0,0.0001164,1.0,3.880000000000001e-05,1.0,5.82e-05,1.0,0.0001164,1.0,0.000150544,1.0,0.00198
winogrande.dev.193,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,1.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00048
mmlu-clinical-knowledge.val.133,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.8585,mistralai/mistral-7b-chat,0.0,5.780000000000001e-05,0.0,5.780000000000001e-05,0.0,8.639999999999999e-05,0.0,0.0001733999999999,0.0,0.000224264,1.0,0.00293
grade-school-math.dev.3699,meta/code-llama-instruct-34b-chat,0.25,0.000277032,0.25,9.54e-05,0.25,0.000171,0.25,0.0002538,0.25,0.000277032,0.75,0.00924
hellaswag.val.7383,mistralai/mixtral-8x7b-chat,0.0,0.0001829999999999,0.0,6.1000000000000005e-05,0.0,9.15e-05,0.0,0.0001829999999999,0.0,0.00023668,1.0,0.00306
grade-school-math.dev.5397,mistralai/mistral-7b-chat,0.25,7.7e-05,0.25,7.7e-05,0.25,0.0001100999999999,0.25,0.0002544,0.5,0.000257632,0.75,0.00989
grade-school-math.dev.6058,WizardLM/WizardLM-13B-V1.2,0.25,0.0001865999999999,0.25,0.000116,0.25,0.0001865999999999,0.75,0.0003072,0.25,0.00039576,0.5,0.01332
mmlu-high-school-mathematics.val.161,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
hellaswag.val.4942,WizardLM/WizardLM-13B-V1.2,1.0,7.68e-05,1.0,5.14e-05,1.0,7.68e-05,1.0,0.0001542,1.0,0.0001994319999999,1.0,0.00261
mmlu-professional-law.val.60,WizardLM/WizardLM-13B-V1.2,0.0,8.49e-05,0.0,5.660000000000001e-05,0.0,8.49e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00284
hellaswag.val.6297,mistralai/mistral-7b-chat,0.0,4.56e-05,0.0,4.56e-05,0.0,6.869999999999999e-05,0.0,0.0001373999999999,0.0,0.000177704,1.0,0.0023
grade-school-math.dev.6785,mistralai/mistral-7b-chat,0.25,5.7400000000000006e-05,0.25,5.7400000000000006e-05,0.75,0.0001404,0.25,0.0002298,0.75,0.000304192,0.75,0.00736
hellaswag.val.9723,mistralai/mixtral-8x7b-chat,0.0,0.0001422,0.0,4.74e-05,1.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00238
hellaswag.val.1282,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,1.0,8.380800000000001e-05,0.0,0.00109
mmlu-econometrics.val.76,mistralai/mixtral-8x7b-chat,1.0,0.0001229999999999,0.0,4.100000000000001e-05,1.0,6.149999999999999e-05,1.0,0.0001229999999999,0.0,0.0001583039999999,1.0,0.00206
grade-school-math.dev.3796,WizardLM/WizardLM-13B-V1.2,0.75,0.0001341,0.25,5.56e-05,0.75,0.0001341,0.75,0.0002208,0.75,0.000257632,0.75,0.00559
grade-school-math.dev.3961,WizardLM/WizardLM-13B-V1.2,0.25,0.0001812,0.25,0.0001052,0.25,0.0001812,0.25,0.0002436,0.25,0.000319712,0.75,0.01183
mmlu-miscellaneous.val.326,mistralai/mistral-7b-chat,1.0,1.5e-05,1.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
mmlu-college-mathematics.val.98,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
winogrande.dev.757,mistralai/mistral-7b-chat,0.0,9.2e-06,0.0,9.2e-06,1.0,1.3799999999999998e-05,0.0,2.76e-05,0.0,3.5696e-05,0.0,0.00047
hellaswag.val.9839,mistralai/mistral-7b-chat,0.0,5e-05,0.0,5e-05,1.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00251
mmlu-public-relations.val.37,mistralai/mistral-7b-chat,1.0,1.48e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
grade-school-math.dev.6211,mistralai/mistral-7b-chat,0.25,8.34e-05,0.25,8.34e-05,0.25,0.0002087999999999,0.25,0.0001967999999999,0.25,0.000363168,0.75,0.00817
grade-school-math.dev.2676,WizardLM/WizardLM-13B-V1.2,0.75,0.0001299,0.5,7.54e-05,0.75,0.0001299,0.75,0.000252,0.25,0.000296432,0.5,0.00659
hellaswag.val.8286,mistralai/mixtral-8x7b-chat,1.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.739999999999998e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
consensus_summary.dev.8,mistralai/mistral-7b-chat,0.25,3.540000000000001e-05,0.25,3.540000000000001e-05,0.0,0.0003048,0.0,0.0001524,0.75,0.000212624,0.5,0.00402
grade-school-math.dev.7039,WizardLM/WizardLM-13B-V1.2,0.25,0.0001857,0.25,0.000101,0.25,0.0001857,0.25,0.0003036,0.25,0.000489656,0.5,0.0137
grade-school-math.dev.1410,mistralai/mistral-7b-chat,0.25,7.900000000000001e-05,0.25,7.900000000000001e-05,0.75,0.0001616999999999,0.75,0.0002075999999999,0.75,0.000338336,0.75,0.00887
hellaswag.val.7713,WizardLM/WizardLM-13B-V1.2,0.0,9.21e-05,0.0,6.159999999999999e-05,0.0,9.21e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00309
mmlu-professional-law.val.38,mistralai/mistral-7b-chat,0.0,3.2800000000000004e-05,0.0,3.2800000000000004e-05,0.0,4.92e-05,0.0,9.84e-05,0.0,0.0001272639999999,0.0,0.0016799999999999
hellaswag.val.5227,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
grade-school-math.dev.6469,WizardLM/WizardLM-13B-V1.2,0.75,0.0001428,0.75,7.42e-05,0.75,0.0001428,0.25,0.0002195999999999,0.75,0.000259184,0.75,0.00636
mmlu-elementary-mathematics.val.184,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-professional-law.val.828,WizardLM/WizardLM-13B-V1.2,1.0,9.21e-05,0.0,6.14e-05,1.0,9.21e-05,1.0,0.0001842,0.0,0.000238232,0.0,0.00308
hellaswag.val.8916,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-professional-psychology.val.434,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
arc-challenge.test.684,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.7693,mistralai/mistral-7b-chat,1.0,5.64e-05,1.0,5.64e-05,1.0,8.429999999999999e-05,1.0,0.0001692,1.0,0.000218832,1.0,0.00283
hellaswag.val.8835,mistralai/mixtral-8x7b-chat,0.0,0.0001704,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
hellaswag.val.6867,mistralai/mixtral-8x7b-chat,1.0,0.0001397999999999,0.0,4.660000000000001e-05,1.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
hellaswag.val.7733,WizardLM/WizardLM-13B-V1.2,0.0,7.26e-05,0.0,4.84e-05,0.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00246
mmlu-professional-law.val.616,mistralai/mistral-7b-chat,0.0,4.24e-05,0.0,4.24e-05,0.0,6.36e-05,1.0,0.0001272,0.0,0.0001645119999999,1.0,0.00213
grade-school-math.dev.5493,meta/code-llama-instruct-34b-chat,0.25,0.000268496,0.25,9.46e-05,0.25,0.0001529999999999,0.25,0.0002657999999999,0.25,0.000268496,0.75,0.00906
winogrande.dev.370,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,1.0,3.24e-05,1.0,4.1904e-05,1.0,0.00058
grade-school-math.dev.4337,WizardLM/WizardLM-13B-V1.2,0.75,0.0001386,0.25,9.100000000000002e-05,0.75,0.0001386,0.25,0.0002766,0.75,0.000284792,0.5,0.00692
arc-challenge.val.68,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,1.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.1956,WizardLM/WizardLM-13B-V1.2,0.5,0.0001434,0.25,9.3e-05,0.5,0.0001434,0.75,0.0002136,0.75,0.000308072,0.75,0.00652
grade-school-math.dev.2216,WizardLM/WizardLM-13B-V1.2,0.25,0.0001539,0.75,8.24e-05,0.25,0.0001539,0.75,0.0002819999999999,0.75,0.000348424,0.75,0.00853
mmlu-professional-psychology.val.90,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.4776,WizardLM/WizardLM-13B-V1.2,0.75,0.0001685999999999,0.75,9.6e-05,0.75,0.0001685999999999,0.75,0.0002171999999999,0.25,0.000412832,0.75,0.00879
grade-school-math.dev.5343,WizardLM/WizardLM-13B-V1.2,0.25,0.0001506,0.25,0.0001438,0.25,0.0001506,0.75,0.0002166,0.75,0.000253752,0.5,0.00659
mmlu-professional-law.val.169,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
hellaswag.val.5494,WizardLM/WizardLM-13B-V1.2,1.0,6.57e-05,0.0,4.380000000000001e-05,1.0,6.57e-05,0.0,0.0001314,0.0,0.0001699439999999,1.0,0.0022
grade-school-math.dev.942,mistralai/mistral-7b-chat,0.25,9.52e-05,0.25,9.52e-05,0.25,0.0001323,1.0,0.0002435999999999,0.25,0.000381792,0.75,0.0077
mmlu-moral-disputes.val.295,mistralai/mistral-7b-chat,1.0,2.6e-05,1.0,2.6e-05,1.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00134
mmlu-nutrition.val.7,mistralai/mistral-7b-chat,1.0,1.42e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-college-computer-science.val.77,mistralai/mistral-7b-chat,0.0,4.860000000000001e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,0.0,0.0001458,0.0,0.000188568,0.0,0.00244
arc-challenge.test.689,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.6258,mistralai/mixtral-8x7b-chat,0.0,0.0001542,0.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,0.0,0.00258
mmlu-high-school-statistics.val.198,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
hellaswag.val.8240,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00242
mmlu-professional-law.val.1318,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
arc-challenge.test.764,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-professional-law.val.862,WizardLM/WizardLM-13B-V1.2,0.0,8.91e-05,0.0,5.94e-05,0.0,8.91e-05,0.0,0.0001775999999999,0.0,0.000230472,0.0,0.00298
mmlu-business-ethics.val.62,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-moral-scenarios.val.814,mistralai/mistral-7b-chat,0.0,3.1200000000000006e-05,0.0,3.1200000000000006e-05,0.0,4.68e-05,0.0,9.36e-05,0.0,0.000121056,0.0,0.0015999999999999
mmlu-professional-law.val.1304,mistralai/mistral-7b-chat,1.0,5.020000000000001e-05,1.0,5.020000000000001e-05,0.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00255
winogrande.dev.564,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,1.0,0.00055
mmlu-professional-law.val.720,WizardLM/WizardLM-13B-V1.2,0.0,8.819999999999999e-05,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,1.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
hellaswag.val.128,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-jurisprudence.val.47,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
hellaswag.val.3651,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
mmlu-high-school-biology.val.252,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
grade-school-math.dev.769,WizardLM/WizardLM-13B-V1.2,0.75,0.0001311,0.25,5.62e-05,0.75,0.0001311,0.75,0.0002226,0.75,0.000250648,0.5,0.00685
hellaswag.val.2620,WizardLM/WizardLM-13B-V1.2,0.0,4.02e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-marketing.val.119,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
hellaswag.val.9991,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00252
consensus_summary.dev.290,mistralai/mistral-7b-chat,0.5,5.380000000000001e-05,0.5,5.380000000000001e-05,1.0,7.439999999999999e-05,0.5,0.0001614,0.75,0.000249872,0.5,0.00252
mmlu-miscellaneous.val.557,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-elementary-mathematics.val.252,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.395,mistralai/mixtral-8x7b-chat,0.0,0.0001176,0.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,1.0,0.00197
mmlu-high-school-european-history.val.84,mistralai/mixtral-8x7b-chat,1.0,0.0002286,0.0,7.62e-05,0.0,0.0001143,1.0,0.0002286,0.0,0.000295656,0.0,0.00382
mmlu-professional-law.val.1329,WizardLM/WizardLM-13B-V1.2,0.0,8.94e-05,0.0,5.9600000000000005e-05,0.0,8.94e-05,0.0,0.0001788,0.0,0.0002312479999999,1.0,0.00299
mmlu-moral-scenarios.val.285,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,0.0,0.00142
arc-challenge.val.134,mistralai/mistral-7b-chat,1.0,1.42e-05,1.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,1.0,5.5096e-05,1.0,0.0007199999999999
mmlu-anatomy.val.79,mistralai/mixtral-8x7b-chat,1.0,6.9e-05,1.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
grade-school-math.dev.478,meta/code-llama-instruct-34b-chat,0.25,0.000300312,0.5,7.740000000000001e-05,0.25,0.0001259999999999,0.75,0.0002129999999999,0.25,0.000300312,0.5,0.009
mmlu-college-mathematics.val.99,mistralai/mixtral-8x7b-chat,1.0,7.86e-05,0.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,0.0,0.00132
hellaswag.val.4426,mistralai/mixtral-8x7b-chat,0.0,0.0001397999999999,0.0,4.660000000000001e-05,0.0,6.989999999999999e-05,0.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
mmlu-anatomy.val.26,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-professional-law.val.890,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00281
mmlu-philosophy.val.91,mistralai/mistral-7b-chat,0.0,3.820000000000001e-05,0.0,3.820000000000001e-05,0.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00192
hellaswag.val.8131,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
hellaswag.val.10016,mistralai/mistral-7b-chat,0.0,4.5e-05,0.0,4.5e-05,0.0,6.749999999999999e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00229
hellaswag.val.11,WizardLM/WizardLM-13B-V1.2,0.0,3.39e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
mmlu-professional-psychology.val.384,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-high-school-macroeconomics.val.365,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.4230,WizardLM/WizardLM-13B-V1.2,0.0,7.919999999999999e-05,0.0,5.300000000000001e-05,0.0,7.919999999999999e-05,0.0,0.000159,0.0,0.00020564,0.0,0.00269
mmlu-professional-law.val.1173,WizardLM/WizardLM-13B-V1.2,1.0,9.9e-05,0.0,6.6e-05,1.0,9.9e-05,1.0,0.000198,0.0,0.00025608,1.0,0.00331
winogrande.dev.578,mistralai/mixtral-8x7b-chat,0.0,3.6e-05,0.0,1.2e-05,0.0,1.8e-05,0.0,3.6e-05,0.0,4.656e-05,1.0,0.00061
hellaswag.val.2637,WizardLM/WizardLM-13B-V1.2,0.0,4.44e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
mbpp.dev.259,mistralai/mistral-7b-chat,0.0,4.4e-05,0.0,4.4e-05,0.0,7.05e-05,0.0,0.0002142,0.0,0.000156752,0.0,0.00988
bias_detection.dev.100,mistralai/mistral-7b-chat,0.0,5.04e-05,0.0,5.04e-05,0.0,0.0001052999999999,0.0,0.0001547999999999,0.0,0.000224264,0.0,0.00592
mmlu-electrical-engineering.val.67,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
mmlu-professional-law.val.1340,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,0.0,0.00254
hellaswag.val.5073,mistralai/mistral-7b-chat,1.0,5.62e-05,1.0,5.62e-05,1.0,8.43e-05,1.0,0.0001686,1.0,0.000218056,1.0,0.00285
hellaswag.val.3043,mistralai/mistral-7b-chat,1.0,2.5e-05,1.0,2.5e-05,0.0,3.72e-05,1.0,7.5e-05,1.0,9.7e-05,0.0,0.00126
grade-school-math.dev.497,WizardLM/WizardLM-13B-V1.2,0.75,0.0001656,0.75,9.66e-05,0.75,0.0001656,0.75,0.0002934,0.25,0.000421368,0.75,0.00925
winogrande.dev.348,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.47e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
arc-challenge.test.436,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.4374,WizardLM/WizardLM-13B-V1.2,0.75,0.0001391999999999,0.25,0.0005434,0.75,0.0001391999999999,0.75,0.0002417999999999,0.25,0.000332128,0.75,0.00732
mmlu-high-school-psychology.val.493,mistralai/mixtral-8x7b-chat,1.0,5.16e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-psychology.val.489,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
hellaswag.val.9617,mistralai/mixtral-8x7b-chat,1.0,0.0001446,1.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,1.0,0.0001446,1.0,0.000187016,1.0,0.00242
mbpp.dev.246,mistralai/mistral-7b-chat,0.0,5.900000000000001e-05,0.0,5.900000000000001e-05,1.0,5.19e-05,0.0,0.0002136,1.0,7.682400000000001e-05,0.0,0.00907
arc-challenge.test.30,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,1.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.7917,WizardLM/WizardLM-13B-V1.2,1.0,7.56e-05,1.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,1.0,0.000195552,1.0,0.00256
mmlu-elementary-mathematics.val.60,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
hellaswag.val.1423,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.774,WizardLM/WizardLM-13B-V1.2,0.0,5.34e-05,0.0,3.58e-05,0.0,5.34e-05,0.0,0.0001074,0.0,0.000138904,1.0,0.0018
hellaswag.val.3025,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,1.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-machine-learning.val.74,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,1.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mbpp.dev.101,mistralai/mistral-7b-chat,0.0,6.08e-05,0.0,6.08e-05,1.0,5.8800000000000006e-05,1.0,5.88e-05,1.0,8.148000000000001e-05,1.0,0.00649
mmlu-moral-scenarios.val.260,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,1.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-moral-scenarios.val.663,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
grade-school-math.dev.3554,mistralai/mixtral-8x7b-chat,0.75,0.0002399999999999,0.75,7.58e-05,0.75,0.0001503,0.75,0.0002399999999999,0.75,0.000285568,0.75,0.00698
grade-school-math.dev.4568,mistralai/mistral-7b-chat,0.75,8.14e-05,0.75,8.14e-05,0.75,0.0001376999999999,0.25,0.000222,0.25,0.000260736,0.75,0.00789
hellaswag.val.3513,mistralai/mistral-7b-chat,0.0,4.880000000000001e-05,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
hellaswag.val.6313,mistralai/mixtral-8x7b-chat,1.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.1965,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-philosophy.val.239,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
grade-school-math.dev.1306,mistralai/mistral-7b-chat,0.25,8.420000000000001e-05,0.25,8.420000000000001e-05,0.75,0.0001896,0.75,0.000204,0.25,0.000291776,0.75,0.00878
hellaswag.val.2054,WizardLM/WizardLM-13B-V1.2,1.0,3.66e-05,1.0,2.46e-05,1.0,3.66e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
grade-school-math.dev.1113,meta/code-llama-instruct-34b-chat,0.25,0.0003429919999999,0.25,7.6e-05,0.25,0.000165,0.25,0.000207,0.25,0.0003429919999999,0.75,0.01413
grade-school-math.dev.5917,mistralai/mistral-7b-chat,0.25,6.58e-05,0.25,6.58e-05,0.25,0.0001317,0.5,0.0002472,0.25,0.000263064,0.5,0.00783
hellaswag.val.663,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
arc-challenge.test.535,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.7735,mistralai/mixtral-8x7b-chat,0.0,0.0001217999999999,0.0,4.06e-05,0.0,6.09e-05,0.0,0.0001217999999999,0.0,0.000157528,1.0,0.00204
winogrande.dev.121,mistralai/mistral-7b-chat,0.0,1.14e-05,0.0,1.14e-05,1.0,1.7100000000000002e-05,0.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00061
hellaswag.val.1181,mistralai/mistral-7b-chat,0.0,2.2e-05,0.0,2.2e-05,0.0,3.3e-05,0.0,6.6e-05,0.0,8.536000000000001e-05,0.0,0.00111
mmlu-moral-scenarios.val.300,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,1.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00135
hellaswag.val.321,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-electrical-engineering.val.50,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,0.0,0.00075
hellaswag.val.7881,mistralai/mistral-7b-chat,1.0,4.8200000000000006e-05,1.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,1.0,0.0001446,1.0,0.000187016,1.0,0.00245
grade-school-math.dev.338,WizardLM/WizardLM-13B-V1.2,0.25,0.0001754999999999,0.25,0.0001168,0.25,0.0001754999999999,0.25,0.0003294,0.25,0.0004299039999999,0.75,0.01029
hellaswag.val.7609,mistralai/mixtral-8x7b-chat,1.0,0.0001349999999999,1.0,4.5e-05,1.0,6.749999999999999e-05,1.0,0.0001349999999999,1.0,0.0001746,1.0,0.00229
hellaswag.val.121,mistralai/mistral-7b-chat,0.0,3.2000000000000005e-05,0.0,3.2000000000000005e-05,0.0,4.77e-05,1.0,9.6e-05,0.0,0.00012416,1.0,0.00161
mmlu-human-aging.val.161,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
grade-school-math.dev.6384,WizardLM/WizardLM-13B-V1.2,0.75,0.0001508999999999,0.75,8.68e-05,0.75,0.0001508999999999,0.75,0.0002958,0.75,0.000428352,0.75,0.01246
hellaswag.val.8054,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
mmlu-machine-learning.val.67,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-moral-scenarios.val.233,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,0.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.0015
mmlu-logical-fallacies.val.113,mistralai/mixtral-8x7b-chat,0.0,4.2e-05,1.0,1.4e-05,0.0,2.1e-05,0.0,4.2e-05,0.0,5.432e-05,0.0,0.00071
mmlu-high-school-psychology.val.411,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.8507,mistralai/mixtral-8x7b-chat,1.0,0.0001452,1.0,4.84e-05,1.0,7.26e-05,1.0,0.0001452,1.0,0.000187792,1.0,0.00246
mmlu-professional-law.val.323,WizardLM/WizardLM-13B-V1.2,1.0,0.0001226999999999,0.0,8.18e-05,1.0,0.0001226999999999,1.0,0.0002453999999999,0.0,0.000317384,1.0,0.0040999999999999
mmlu-nutrition.val.154,mistralai/mixtral-8x7b-chat,1.0,8.879999999999999e-05,0.0,2.96e-05,1.0,4.44e-05,1.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
consensus_summary.dev.127,mistralai/mixtral-8x7b-chat,0.75,0.0001703999999999,0.75,6.98e-05,0.75,0.0001040999999999,0.75,0.0001703999999999,0.75,0.000276256,0.25,0.00217
mmlu-professional-law.val.257,WizardLM/WizardLM-13B-V1.2,1.0,0.0001425,0.0,9.5e-05,1.0,0.0001425,0.0,0.0002844,0.0,0.0003686,1.0,0.0047599999999999
mmlu-nutrition.val.293,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
grade-school-math.dev.1799,WizardLM/WizardLM-13B-V1.2,0.25,0.0001779,0.25,0.0001056,0.25,0.0001779,0.75,0.000312,0.25,0.000355408,0.75,0.01028
consensus_summary.dev.154,mistralai/mistral-7b-chat,1.0,4.84e-05,1.0,4.84e-05,0.0,5.97e-05,0.75,0.0001626,0.75,0.000207968,0.0,0.00195
hellaswag.val.8692,mistralai/mistral-7b-chat,0.0,5.14e-05,0.0,5.14e-05,0.0,7.68e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00261
grade-school-math.dev.1489,mistralai/mistral-7b-chat,0.75,7.14e-05,0.75,7.14e-05,0.75,0.0001607999999999,0.75,0.0002021999999999,0.75,0.000311952,0.75,0.00819
grade-school-math.dev.1241,mistralai/mixtral-8x7b-chat,0.75,0.000273,0.25,8.58e-05,0.75,0.0001332,0.75,0.000273,0.75,0.000344544,0.75,0.0110499999999999
mmlu-high-school-chemistry.val.170,mistralai/mixtral-8x7b-chat,0.0,8.94e-05,0.0,2.9800000000000003e-05,1.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.00153
mmlu-professional-law.val.1079,WizardLM/WizardLM-13B-V1.2,0.0,8.85e-05,0.0,5.9e-05,0.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00296
grade-school-math.dev.1009,mistralai/mistral-7b-chat,0.25,9.98e-05,0.25,9.98e-05,0.25,0.0002538,0.75,0.0004169999999999,0.25,0.000338336,0.75,0.00796
mbpp.dev.30,mistralai/mistral-7b-chat,0.0,3.74e-05,0.0,3.74e-05,0.0,0.0001935,1.0,0.0002111999999999,0.0,0.000157528,1.0,0.01123
arc-challenge.test.1042,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.326,mistralai/mistral-7b-chat,1.0,2.68e-05,1.0,2.68e-05,1.0,4.02e-05,1.0,8.04e-05,1.0,0.000103984,1.0,0.00135
mmlu-international-law.val.65,mistralai/mistral-7b-chat,1.0,2.7600000000000003e-05,1.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mbpp.dev.213,mistralai/mistral-7b-chat,0.0,5.88e-05,0.0,5.88e-05,1.0,6.33e-05,0.0,0.0001686,1.0,0.000401968,1.0,0.00726
hellaswag.val.9336,mistralai/mixtral-8x7b-chat,0.0,0.0001308,0.0,4.36e-05,0.0,6.54e-05,0.0,0.0001308,0.0,0.000169168,1.0,0.00222
grade-school-math.dev.2505,WizardLM/WizardLM-13B-V1.2,0.75,0.0001571999999999,0.75,7.84e-05,0.75,0.0001571999999999,0.25,0.0002874,0.75,0.000292552,0.5,0.00724
mmlu-nutrition.val.59,mistralai/mixtral-8x7b-chat,0.0,7.379999999999999e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
grade-school-math.dev.214,meta/code-llama-instruct-34b-chat,0.25,0.000227368,0.25,8.200000000000001e-05,0.25,0.0001302,0.25,0.0001997999999999,0.25,0.000227368,0.75,0.00833
mmlu-virology.val.31,mistralai/mixtral-8x7b-chat,1.0,4.8e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-law.val.614,WizardLM/WizardLM-13B-V1.2,1.0,9.78e-05,0.0,6.52e-05,1.0,9.78e-05,0.0,0.0001956,0.0,0.0002529759999999,1.0,0.00327
grade-school-math.dev.6310,mistralai/mixtral-8x7b-chat,0.25,0.0002868,0.25,8.999999999999999e-05,0.25,0.0001610999999999,0.25,0.0002868,0.25,0.000347648,0.75,0.01017
mmlu-high-school-psychology.val.30,WizardLM/WizardLM-13B-V1.2,1.0,5.58e-05,0.0,3.720000000000001e-05,1.0,5.58e-05,1.0,0.0001115999999999,0.0,0.0001443359999999,1.0,0.00187
winogrande.dev.1234,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
mmlu-philosophy.val.171,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.00079
arc-challenge.test.56,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,1.0,8.3032e-05,1.0,0.00108
mmlu-professional-law.val.1305,WizardLM/WizardLM-13B-V1.2,1.0,6.93e-05,1.0,4.6200000000000005e-05,1.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00235
hellaswag.val.9515,mistralai/mixtral-8x7b-chat,1.0,0.0001704,0.0,5.680000000000001e-05,0.0,8.52e-05,1.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
mmlu-professional-law.val.1397,mistralai/mistral-7b-chat,1.0,5.020000000000001e-05,1.0,5.020000000000001e-05,1.0,7.53e-05,1.0,0.0001506,0.0,0.000194776,1.0,0.00252
grade-school-math.dev.4800,WizardLM/WizardLM-13B-V1.2,0.75,0.0001578,0.5,7.58e-05,0.75,0.0001578,0.5,0.0002615999999999,0.75,0.00027548,0.75,0.00895
hellaswag.val.552,WizardLM/WizardLM-13B-V1.2,1.0,3.69e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
hellaswag.val.3298,mistralai/mixtral-8x7b-chat,1.0,0.0001716,0.0,5.720000000000001e-05,0.0,8.58e-05,1.0,0.0001716,0.0,0.000221936,0.0,0.00287
hellaswag.val.843,mistralai/mistral-7b-chat,1.0,2.46e-05,1.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-global-facts.val.58,mistralai/mistral-7b-chat,1.0,2.46e-05,1.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
grade-school-math.dev.880,WizardLM/WizardLM-13B-V1.2,0.75,0.0001431,0.75,8.98e-05,0.75,0.0001431,0.75,0.0002525999999999,0.5,0.000311952,0.75,0.00714
mmlu-college-physics.val.58,mistralai/mixtral-8x7b-chat,1.0,8.1e-05,1.0,2.7e-05,0.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
grade-school-math.dev.3220,WizardLM/WizardLM-13B-V1.2,0.25,0.0001584,0.25,0.000104,0.25,0.0001584,0.75,0.000327,0.5,0.0004074,0.5,0.0110999999999999
mmlu-professional-law.val.784,WizardLM/WizardLM-13B-V1.2,0.0,7.41e-05,1.0,4.94e-05,0.0,7.41e-05,1.0,0.0001482,0.0,0.000191672,1.0,0.00248
hellaswag.val.2510,mistralai/mistral-7b-chat,1.0,1.92e-05,1.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,1.0,7.4496e-05,1.0,0.001
winogrande.dev.723,mistralai/mistral-7b-chat,1.0,1.1e-05,1.0,1.1e-05,0.0,1.65e-05,0.0,3.3e-05,1.0,4.2680000000000005e-05,1.0,0.00059
mmlu-professional-law.val.1350,mistralai/mistral-7b-chat,0.0,3.94e-05,0.0,3.94e-05,0.0,5.91e-05,1.0,0.0001182,0.0,0.0001528719999999,0.0,0.00198
hellaswag.val.3764,mistralai/mixtral-8x7b-chat,1.0,0.0001619999999999,1.0,5.4000000000000005e-05,1.0,8.069999999999998e-05,1.0,0.0001619999999999,0.0,0.00020952,1.0,0.00274
mmlu-professional-accounting.val.100,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-high-school-mathematics.val.7,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,0.0,5.22e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-professional-law.val.704,WizardLM/WizardLM-13B-V1.2,0.0,0.0001425,0.0,9.5e-05,0.0,0.0001425,1.0,0.000285,0.0,0.0003686,1.0,0.0047599999999999
hellaswag.val.9479,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.7e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
mmlu-professional-medicine.val.68,WizardLM/WizardLM-13B-V1.2,1.0,4.68e-05,1.0,3.1200000000000006e-05,1.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.00157
grade-school-math.dev.1182,mistralai/mistral-7b-chat,0.75,9.42e-05,0.75,9.42e-05,0.5,0.0001827,0.75,0.0002766,0.5,0.000381792,0.5,0.01047
grade-school-math.dev.1016,mistralai/mixtral-8x7b-chat,0.5,0.0002328,0.25,7.180000000000001e-05,0.75,0.0001164,0.5,0.0002328,0.75,0.000257632,0.75,0.00597
hellaswag.val.4380,mistralai/mixtral-8x7b-chat,1.0,0.0001344,1.0,4.480000000000001e-05,1.0,6.72e-05,1.0,0.0001344,1.0,0.0001738239999999,1.0,0.00225
mmlu-professional-law.val.729,mistralai/mistral-7b-chat,0.0,4e-05,0.0,4e-05,0.0,6e-05,1.0,0.00012,0.0,0.0001551999999999,1.0,0.00201
hellaswag.val.6881,mistralai/mistral-7b-chat,1.0,4.9600000000000006e-05,1.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,0.0,0.0001487999999999,1.0,0.000192448,1.0,0.00252
mmlu-moral-scenarios.val.444,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
grade-school-math.dev.2255,mistralai/mixtral-8x7b-chat,0.75,0.0003191999999999,0.25,0.0001086,0.25,0.0001833,0.75,0.0003191999999999,0.25,0.000375584,0.75,0.01207
mmlu-professional-law.val.1134,mistralai/mistral-7b-chat,0.0,4.480000000000001e-05,0.0,4.480000000000001e-05,0.0,6.72e-05,1.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
hellaswag.val.8543,mistralai/mixtral-8x7b-chat,0.0,0.0001668,1.0,5.56e-05,1.0,8.34e-05,0.0,0.0001668,1.0,0.000215728,1.0,0.00279
mmlu-professional-law.val.1066,WizardLM/WizardLM-13B-V1.2,1.0,6.93e-05,0.0,4.6200000000000005e-05,1.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,1.0,0.00235
mmlu-professional-law.val.1086,WizardLM/WizardLM-13B-V1.2,1.0,5.19e-05,0.0,3.460000000000001e-05,1.0,5.19e-05,1.0,0.0001038,0.0,0.0001342479999999,1.0,0.00174
hellaswag.val.3951,mistralai/mixtral-8x7b-chat,0.0,0.000168,0.0,5.62e-05,0.0,8.43e-05,0.0,0.000168,0.0,0.000218056,1.0,0.00282
mmlu-nutrition.val.81,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
mmlu-high-school-computer-science.val.7,mistralai/mistral-7b-chat,1.0,3.820000000000001e-05,1.0,3.820000000000001e-05,0.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,1.0,0.00192
grade-school-math.dev.2451,mistralai/mistral-7b-chat,0.25,8.520000000000001e-05,0.25,8.520000000000001e-05,0.25,0.0001502999999999,0.25,0.0002736,0.75,0.000335232,0.5,0.00645
grade-school-math.dev.2251,WizardLM/WizardLM-13B-V1.2,0.75,0.0001737,0.5,9.48e-05,0.75,0.0001737,0.75,0.0002525999999999,0.25,0.000360064,0.5,0.00785
mmlu-high-school-psychology.val.314,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
arc-challenge.test.709,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
mmlu-nutrition.val.134,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-professional-medicine.val.100,mistralai/mixtral-8x7b-chat,1.0,0.0001326,0.0,4.420000000000001e-05,0.0,6.63e-05,1.0,0.0001326,0.0,0.000171496,1.0,0.00222
arc-challenge.test.117,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.9378,WizardLM/WizardLM-13B-V1.2,0.0,7.92e-05,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00265
hellaswag.val.5975,mistralai/mixtral-8x7b-chat,1.0,0.0001733999999999,1.0,5.780000000000001e-05,1.0,8.669999999999999e-05,1.0,0.0001733999999999,1.0,0.000224264,1.0,0.00293
mmlu-conceptual-physics.val.138,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-miscellaneous.val.335,mistralai/mistral-7b-chat,1.0,1.34e-05,1.0,1.34e-05,1.0,1.98e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
mmlu-high-school-statistics.val.105,mistralai/mistral-7b-chat,1.0,3.0600000000000005e-05,1.0,3.0600000000000005e-05,1.0,4.59e-05,1.0,9.18e-05,0.0,0.000118728,1.0,0.00154
hellaswag.val.8363,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
hellaswag.val.1084,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,1.0,3.51e-05,1.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.4143,mistralai/mixtral-8x7b-chat,1.0,0.0001709999999999,0.0,5.7e-05,1.0,8.519999999999998e-05,1.0,0.0001709999999999,0.0,0.00022116,1.0,0.00286
mmlu-professional-law.val.317,mistralai/mistral-7b-chat,1.0,4.980000000000001e-05,1.0,4.980000000000001e-05,0.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,0.0,0.0025
grade-school-math.dev.2446,WizardLM/WizardLM-13B-V1.2,0.25,0.0001619999999999,0.25,6.66e-05,0.25,0.0001619999999999,0.75,0.0002472,0.75,0.000274704,0.75,0.007
hellaswag.val.9812,WizardLM/WizardLM-13B-V1.2,0.0,7.26e-05,0.0,4.84e-05,0.0,7.26e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
grade-school-math.dev.4850,WizardLM/WizardLM-13B-V1.2,0.75,0.0001458,0.25,8.78e-05,0.75,0.0001458,0.75,0.0002837999999999,0.75,0.000326696,0.75,0.0104099999999999
mmlu-anatomy.val.19,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.829,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-professional-law.val.908,mistralai/mixtral-8x7b-chat,0.0,9.9e-05,0.0,3.3e-05,0.0,4.95e-05,0.0,9.9e-05,0.0,0.00012804,0.0,0.0016899999999999
mmlu-sociology.val.180,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
hellaswag.val.9709,mistralai/mistral-7b-chat,0.0,5.4600000000000006e-05,0.0,5.4600000000000006e-05,0.0,8.159999999999999e-05,0.0,0.0001638,0.0,0.0002118479999999,1.0,0.00274
mmlu-formal-logic.val.86,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,0.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
mbpp.dev.13,mistralai/mistral-7b-chat,1.0,3.8400000000000005e-05,1.0,3.8400000000000005e-05,1.0,7.859999999999999e-05,1.0,0.0001799999999999,1.0,0.000142008,1.0,0.00763
hellaswag.val.4161,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
mmlu-elementary-mathematics.val.241,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.2e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.3130,WizardLM/WizardLM-13B-V1.2,0.5,0.0001449,0.5,0.0001006,0.5,0.0001449,0.25,0.0002177999999999,0.75,0.000294104,0.5,0.0069
grade-school-math.dev.3037,meta/code-llama-instruct-34b-chat,0.75,0.000300312,0.75,7.640000000000001e-05,0.75,0.0001386,0.75,0.0002406,0.75,0.000300312,0.75,0.005
abstract2title.test.209,mistralai/mixtral-8x7b-chat,1.0,0.000234,1.0,6.54e-05,1.0,0.0001029,1.0,0.000234,1.0,0.000246768,1.0,0.004
hellaswag.val.4545,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,1.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,1.0,0.00019788,1.0,0.00256
mmlu-high-school-psychology.val.464,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-law.val.199,WizardLM/WizardLM-13B-V1.2,0.0,7.02e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,1.0,0.0001404,0.0,0.000181584,0.0,0.00235
mmlu-professional-accounting.val.85,WizardLM/WizardLM-13B-V1.2,1.0,5.1e-05,1.0,3.4000000000000007e-05,1.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00174
consensus_summary.dev.138,mistralai/mixtral-8x7b-chat,0.0,0.000177,0.75,6.3e-05,0.75,8.309999999999999e-05,0.0,0.000177,0.75,0.000292552,0.75,0.0037
hellaswag.val.9873,mistralai/mixtral-8x7b-chat,0.0,0.0001668,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00282
arc-challenge.test.979,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
arc-challenge.test.390,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,1.0,5.432e-05,1.0,0.00074
mmlu-us-foreign-policy.val.97,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
grade-school-math.dev.6725,WizardLM/WizardLM-13B-V1.2,0.5,0.0001359,0.25,7.44e-05,0.5,0.0001359,0.25,0.0002316,0.25,0.000277808,0.75,0.00713
grade-school-math.dev.212,WizardLM/WizardLM-13B-V1.2,0.25,0.0002153999999999,0.25,0.0001309999999999,0.25,0.0002153999999999,0.25,0.0003138,0.25,0.000450856,0.75,0.01128
mmlu-security-studies.val.43,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00268
mmlu-astronomy.val.9,mistralai/mixtral-8x7b-chat,0.0,0.0001253999999999,1.0,4.1800000000000006e-05,1.0,6.269999999999999e-05,0.0,0.0001253999999999,0.0,0.000162184,1.0,0.0021
mmlu-human-sexuality.val.38,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,0.0,0.00112
grade-school-math.dev.3476,WizardLM/WizardLM-13B-V1.2,0.75,0.0001233,0.75,7.48e-05,0.75,0.0001233,0.75,0.0002279999999999,0.75,0.000261512,0.5,0.00531
mmlu-professional-law.val.390,WizardLM/WizardLM-13B-V1.2,0.0,8.280000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
grade-school-math.dev.2930,WizardLM/WizardLM-13B-V1.2,0.25,0.0001422,0.25,0.0001148,0.25,0.0001422,0.25,0.0002663999999999,0.25,0.000260736,0.75,0.00927
mmlu-professional-law.val.905,WizardLM/WizardLM-13B-V1.2,0.0,4.95e-05,0.0,3.3e-05,0.0,4.95e-05,1.0,9.9e-05,0.0,0.00012804,1.0,0.00166
mmlu-virology.val.44,mistralai/mixtral-8x7b-chat,1.0,0.0001092,0.0,3.64e-05,1.0,5.46e-05,1.0,0.0001092,0.0,0.000141232,1.0,0.00183
hellaswag.val.2761,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
mmlu-professional-law.val.160,WizardLM/WizardLM-13B-V1.2,1.0,4.89e-05,1.0,3.2600000000000006e-05,1.0,4.89e-05,1.0,9.78e-05,0.0,0.0001264879999999,1.0,0.00167
grade-school-math.dev.6509,WizardLM/WizardLM-13B-V1.2,0.25,0.0001725,0.75,0.000103,0.25,0.0001725,0.75,0.0002676,0.25,0.000353856,0.75,0.01023
mmlu-international-law.val.36,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-elementary-mathematics.val.187,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-public-relations.val.29,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
mmlu-professional-law.val.1284,mistralai/mistral-7b-chat,0.0,4.3e-05,0.0,4.3e-05,0.0,6.45e-05,0.0,0.000129,0.0,0.00016684,0.0,0.00216
grade-school-math.dev.5838,mistralai/mistral-7b-chat,0.75,8.14e-05,0.75,8.14e-05,0.75,0.0001389,0.75,0.0002573999999999,0.75,0.000301864,0.75,0.00827
hellaswag.val.6933,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-professional-law.val.837,WizardLM/WizardLM-13B-V1.2,0.0,7.95e-05,1.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00266
grade-school-math.dev.2518,WizardLM/WizardLM-13B-V1.2,0.75,0.0001595999999999,0.75,7.68e-05,0.75,0.0001595999999999,0.75,0.0002472,0.25,0.000277808,0.5,0.00771
mmlu-jurisprudence.val.50,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
mmlu-formal-logic.val.57,mistralai/mistral-7b-chat,0.0,3.54e-05,0.0,3.54e-05,0.0,5.31e-05,0.0,0.0001062,0.0,0.000137352,0.0,0.00178
grade-school-math.dev.4058,WizardLM/WizardLM-13B-V1.2,0.25,0.0001452,0.75,7.840000000000001e-05,0.25,0.0001452,0.75,0.0002508,0.75,0.000292552,0.75,0.00815
grade-school-math.dev.564,meta/code-llama-instruct-34b-chat,0.75,0.000256856,0.5,6.94e-05,0.25,0.0001329,0.75,0.0002628,0.75,0.000256856,0.75,0.00804
mmlu-logical-fallacies.val.85,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
winogrande.dev.1229,mistralai/mistral-7b-chat,0.0,1.14e-05,0.0,1.14e-05,0.0,1.7100000000000002e-05,0.0,3.4200000000000005e-05,0.0,4.4232e-05,1.0,0.00058
winogrande.dev.693,mistralai/mistral-7b-chat,0.0,1.1e-05,0.0,1.1e-05,1.0,1.65e-05,0.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00059
consensus_summary.dev.92,meta/code-llama-instruct-34b-chat,0.75,0.000180808,0.75,4.64e-05,1.0,6.45e-05,0.5,0.0001409999999999,0.75,0.000180808,0.5,0.00219
winogrande.dev.638,mistralai/mistral-7b-chat,1.0,1.08e-05,1.0,1.08e-05,1.0,1.62e-05,1.0,3.24e-05,1.0,4.1904e-05,1.0,0.0005499999999999
mbpp.dev.356,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.98e-05,0.0,0.0001932,0.0,0.000225816,1.0,0.01319
hellaswag.val.9100,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
mmlu-clinical-knowledge.val.100,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.5385,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-professional-psychology.val.528,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
mmlu-professional-law.val.504,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,1.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-professional-law.val.617,WizardLM/WizardLM-13B-V1.2,0.0,0.0001520999999999,0.0,0.0001014,0.0,0.0001520999999999,1.0,0.0003041999999999,0.0,0.000393432,1.0,0.0050799999999999
mmlu-computer-security.val.50,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-human-aging.val.7,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
mmlu-clinical-knowledge.val.218,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
grade-school-math.dev.4218,mistralai/mixtral-8x7b-chat,0.25,0.0002694,0.25,7.14e-05,0.75,0.00015,0.25,0.0002694,0.75,0.00031428,0.75,0.00874
mmlu-econometrics.val.77,mistralai/mistral-7b-chat,1.0,1.94e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
mmlu-conceptual-physics.val.216,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-professional-law.val.1035,WizardLM/WizardLM-13B-V1.2,1.0,0.0001331999999999,0.0,8.88e-05,1.0,0.0001331999999999,0.0,0.0002663999999999,0.0,0.000344544,1.0,0.00445
mmlu-astronomy.val.73,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
grade-school-math.dev.1212,mistralai/mistral-7b-chat,0.25,7.04e-05,0.25,7.04e-05,0.25,0.0001796999999999,0.75,0.0002651999999999,0.75,0.000381792,0.75,0.00909
mmlu-high-school-geography.val.179,mistralai/mistral-7b-chat,1.0,1.48e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
winogrande.dev.511,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00051
mmlu-professional-accounting.val.45,WizardLM/WizardLM-13B-V1.2,0.0,3.12e-05,0.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,0.0,0.00108
arc-challenge.test.298,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00094
grade-school-math.dev.340,WizardLM/WizardLM-13B-V1.2,0.25,0.0001526999999999,0.25,8.860000000000001e-05,0.25,0.0001526999999999,0.75,0.0003263999999999,0.75,0.00033368,0.75,0.00959
mmlu-high-school-us-history.val.113,mistralai/mixtral-8x7b-chat,1.0,0.0001853999999999,0.0,6.18e-05,0.0,9.27e-05,1.0,0.0001853999999999,0.0,0.000239784,1.0,0.0031
hellaswag.val.6154,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,1.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
grade-school-math.dev.3746,WizardLM/WizardLM-13B-V1.2,0.75,0.0001467,0.75,8.26e-05,0.75,0.0001467,0.75,0.0002286,0.75,0.000281688,0.75,0.0078
mmlu-professional-law.val.1322,WizardLM/WizardLM-13B-V1.2,0.0,8.249999999999999e-05,1.0,5.5e-05,0.0,8.249999999999999e-05,1.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
hellaswag.val.7488,mistralai/mixtral-8x7b-chat,0.0,0.0001889999999999,0.0,6.3e-05,0.0,9.42e-05,0.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
hellaswag.val.9270,mistralai/mistral-7b-chat,1.0,6.42e-05,1.0,6.42e-05,1.0,9.6e-05,1.0,0.0001926,1.0,0.000249096,1.0,0.00325
arc-challenge.test.49,WizardLM/WizardLM-13B-V1.2,0.0,3.69e-05,0.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.9855,mistralai/mixtral-8x7b-chat,0.0,0.0001908,0.0,6.36e-05,0.0,9.54e-05,0.0,0.0001908,0.0,0.000246768,0.0,0.00319
hellaswag.val.4523,mistralai/mixtral-8x7b-chat,0.0,0.0001278,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00217
mmlu-professional-law.val.1116,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,1.0,7.02e-05,1.0,0.0001404,0.0,0.000181584,1.0,0.00235
hellaswag.val.2273,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.73e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
mmlu-jurisprudence.val.100,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
grade-school-math.dev.5322,mistralai/mixtral-8x7b-chat,0.75,0.0002106,0.25,7.22e-05,0.75,0.0001422,0.75,0.0002106,0.5,0.000260736,0.75,0.00481
mmlu-high-school-world-history.val.193,mistralai/mixtral-8x7b-chat,1.0,0.0002064,0.0,6.88e-05,1.0,0.0001032,1.0,0.0002064,0.0,0.0002669439999999,0.0,0.00345
mmlu-professional-accounting.val.142,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00135
hellaswag.val.5381,mistralai/mixtral-8x7b-chat,0.0,0.0001806,0.0,6.0200000000000006e-05,0.0,8.999999999999999e-05,0.0,0.0001806,0.0,0.000233576,1.0,0.00305
mmlu-miscellaneous.val.633,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-high-school-macroeconomics.val.161,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-high-school-mathematics.val.57,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,0.0,0.0009699999999999
mmlu-professional-law.val.72,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-elementary-mathematics.val.290,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-anatomy.val.20,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.8926,mistralai/mixtral-8x7b-chat,1.0,0.0001602,1.0,5.34e-05,1.0,8.01e-05,1.0,0.0001602,1.0,0.000207192,1.0,0.00271
mmlu-professional-law.val.1128,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,0.0,5.24e-05,0.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00263
hellaswag.val.8078,mistralai/mixtral-8x7b-chat,0.0,0.0001649999999999,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,0.0,0.00276
arc-challenge.test.917,mistralai/mixtral-8x7b-chat,1.0,3.96e-05,0.0,1.32e-05,0.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.0007
hellaswag.val.8504,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.039999999999999e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
grade-school-math.dev.3346,mistralai/mistral-7b-chat,0.25,0.0001008,0.25,0.0001008,0.25,0.0001668,0.25,0.0003528,0.25,0.000349976,0.75,0.016
grade-school-math.dev.4311,mistralai/mixtral-8x7b-chat,0.25,0.0002345999999999,0.75,0.0001118,0.75,0.0001338,0.25,0.0002345999999999,0.25,0.0003686,0.5,0.00602
hellaswag.val.6534,mistralai/mixtral-8x7b-chat,0.0,0.0001548,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,0.0,0.00262
hellaswag.val.4407,mistralai/mixtral-8x7b-chat,1.0,0.0001434,1.0,4.780000000000001e-05,1.0,7.139999999999999e-05,1.0,0.0001434,1.0,0.0001854639999999,1.0,0.00243
arc-challenge.test.1104,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,1.0,6.751200000000001e-05,1.0,0.00091
hellaswag.val.1402,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
grade-school-math.dev.4043,mistralai/mistral-7b-chat,0.25,7.6e-05,0.25,7.6e-05,0.25,0.0001557,0.25,0.0001931999999999,0.25,0.00039964,0.75,0.00913
hellaswag.val.6033,mistralai/mistral-7b-chat,0.0,6.280000000000001e-05,0.0,6.280000000000001e-05,0.0,9.42e-05,0.0,0.0001884,0.0,0.000243664,1.0,0.00318
mmlu-high-school-world-history.val.163,WizardLM/WizardLM-13B-V1.2,1.0,0.0001358999999999,1.0,9.06e-05,1.0,0.0001358999999999,1.0,0.0002717999999999,0.0,0.000351528,1.0,0.00454
hellaswag.val.9644,mistralai/mixtral-8x7b-chat,1.0,0.0001643999999999,1.0,5.480000000000001e-05,1.0,8.189999999999998e-05,1.0,0.0001643999999999,1.0,0.000212624,1.0,0.00278
mmlu-high-school-chemistry.val.104,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-professional-law.val.250,mistralai/mistral-7b-chat,0.0,7.1e-05,0.0,7.1e-05,1.0,0.0001064999999999,1.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
hellaswag.val.3626,mistralai/mistral-7b-chat,1.0,5.860000000000001e-05,1.0,5.860000000000001e-05,1.0,8.759999999999999e-05,1.0,0.0001758,1.0,0.0002273679999999,1.0,0.00297
mmlu-high-school-european-history.val.142,WizardLM/WizardLM-13B-V1.2,1.0,0.000183,0.0,0.000122,1.0,0.000183,1.0,0.000366,0.0,0.00047336,1.0,0.00611
arc-challenge.test.626,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
grade-school-math.dev.7164,mistralai/mixtral-8x7b-chat,0.25,0.0002808,0.75,8.24e-05,0.75,0.0001299,0.25,0.0002808,0.75,0.0002747039999999,0.75,0.00484
mmlu-international-law.val.109,WizardLM/WizardLM-13B-V1.2,0.0,3.99e-05,1.0,2.6600000000000003e-05,0.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
hellaswag.val.4529,mistralai/mixtral-8x7b-chat,1.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,1.0,0.0001434,0.0,0.0001854639999999,1.0,0.00243
winogrande.dev.58,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,1.0,1.56e-05,0.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
arc-challenge.test.1052,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-moral-disputes.val.244,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.66e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.2962,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00111
hellaswag.val.3368,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
grade-school-math.dev.4117,WizardLM/WizardLM-13B-V1.2,0.25,0.0001574999999999,0.25,9.1e-05,0.25,0.0001574999999999,0.25,0.0002718,0.25,0.000304968,0.75,0.01261
hellaswag.val.1447,mistralai/mistral-7b-chat,0.0,4.020000000000001e-05,0.0,4.020000000000001e-05,1.0,6.03e-05,1.0,0.0001205999999999,0.0,0.000155976,1.0,0.00202
mmlu-marketing.val.98,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.1036,WizardLM/WizardLM-13B-V1.2,1.0,3.75e-05,0.0,2.5e-05,1.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,0.0,0.00129
grade-school-math.dev.2932,mistralai/mixtral-8x7b-chat,0.25,0.0002153999999999,0.25,8.400000000000001e-05,0.25,0.0001631999999999,0.25,0.0002153999999999,0.25,0.000296432,0.75,0.00844
hellaswag.val.2919,mistralai/mistral-7b-chat,0.0,3.2200000000000003e-05,0.0,3.2200000000000003e-05,0.0,4.8e-05,0.0,9.66e-05,0.0,0.000124936,1.0,0.00165
winogrande.dev.815,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,1.0,3e-05,1.0,3.880000000000001e-05,1.0,0.00054
grade-school-math.dev.7240,mistralai/mistral-7b-chat,0.25,0.000112,0.25,0.000112,0.25,0.0002156999999999,0.25,0.0003384,0.25,0.000377912,0.25,0.01145
mmlu-professional-medicine.val.209,mistralai/mixtral-8x7b-chat,1.0,0.0002166,1.0,7.219999999999999e-05,0.0,0.0001083,1.0,0.0002166,0.0,0.000280136,1.0,0.00365
hellaswag.val.964,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.58e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
grade-school-math.dev.2817,WizardLM/WizardLM-13B-V1.2,0.25,0.0001725,0.75,8.74e-05,0.25,0.0001725,0.25,0.0002592,0.25,0.000441544,0.75,0.01129
hellaswag.val.5993,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
hellaswag.val.6805,mistralai/mistral-7b-chat,1.0,5.2e-05,1.0,5.2e-05,1.0,7.8e-05,1.0,0.000156,1.0,0.00020176,1.0,0.00261
hellaswag.val.790,WizardLM/WizardLM-13B-V1.2,1.0,3.4200000000000005e-05,1.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-moral-disputes.val.293,mistralai/mixtral-8x7b-chat,0.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,0.0,0.00083
mmlu-international-law.val.67,mistralai/mistral-7b-chat,0.0,3.1200000000000006e-05,0.0,3.1200000000000006e-05,1.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,0.0,0.00157
grade-school-math.dev.7140,WizardLM/WizardLM-13B-V1.2,0.25,0.0001302,0.25,7.38e-05,0.25,0.0001302,0.75,0.0002063999999999,0.25,0.000266168,0.75,0.00755
winogrande.dev.727,mistralai/mistral-7b-chat,0.0,1.08e-05,0.0,1.08e-05,0.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
mmlu-clinical-knowledge.val.66,mistralai/mistral-7b-chat,1.0,1.96e-05,1.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.1531,WizardLM/WizardLM-13B-V1.2,0.25,0.0001853999999999,0.25,8e-05,0.25,0.0001853999999999,0.25,0.0003773999999999,0.25,0.000332904,0.75,0.01302
mmlu-professional-psychology.val.374,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,1.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
grade-school-math.dev.2199,meta/code-llama-instruct-34b-chat,0.5,0.000339888,0.75,7.98e-05,0.5,0.0001323,0.25,0.0002094,0.5,0.000339888,0.5,0.00664
grade-school-math.dev.5970,WizardLM/WizardLM-13B-V1.2,0.75,0.0001539,0.75,8.280000000000001e-05,0.75,0.0001539,0.5,0.0002478,0.5,0.000308072,0.75,0.0078
hellaswag.val.7739,mistralai/mixtral-8x7b-chat,0.0,0.0001619999999999,0.0,5.4000000000000005e-05,0.0,8.099999999999999e-05,0.0,0.0001619999999999,0.0,0.00020952,1.0,0.00271
winogrande.dev.860,mistralai/mistral-7b-chat,1.0,1.18e-05,1.0,1.18e-05,1.0,1.77e-05,1.0,3.54e-05,1.0,4.5784e-05,1.0,0.0006
mmlu-clinical-knowledge.val.183,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,0.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,0.0,0.00077
mmlu-professional-psychology.val.146,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.5381,WizardLM/WizardLM-13B-V1.2,0.75,0.0001685999999999,0.25,7.740000000000001e-05,0.75,0.0001685999999999,0.75,0.0002616,0.75,0.000287896,0.75,0.00918
mmlu-nutrition.val.22,mistralai/mixtral-8x7b-chat,0.0,5.8200000000000005e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
hellaswag.val.2129,WizardLM/WizardLM-13B-V1.2,1.0,3.12e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.3566,mistralai/mixtral-8x7b-chat,1.0,0.0001608,0.0,5.360000000000001e-05,1.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
hellaswag.val.8520,mistralai/mixtral-8x7b-chat,1.0,0.0001782,1.0,5.94e-05,1.0,8.879999999999999e-05,1.0,0.0001782,1.0,0.000230472,1.0,0.00301
grade-school-math.dev.4352,mistralai/mistral-7b-chat,0.25,9.32e-05,0.25,9.32e-05,0.25,0.0001896,0.5,0.0002862,0.25,0.000362392,0.75,0.01202
hellaswag.val.9840,mistralai/mixtral-8x7b-chat,1.0,0.0001842,0.0,6.14e-05,0.0,9.18e-05,1.0,0.0001842,0.0,0.000238232,1.0,0.00311
mmlu-high-school-psychology.val.339,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
grade-school-math.dev.1488,mistralai/mixtral-8x7b-chat,0.25,0.0003138,0.25,0.0001034,0.75,0.0001635,0.25,0.0003138,0.5,0.000322816,0.75,0.00987
mmlu-professional-law.val.1288,WizardLM/WizardLM-13B-V1.2,1.0,8.61e-05,1.0,5.7400000000000006e-05,1.0,8.61e-05,1.0,0.0001722,0.0,0.000222712,1.0,0.00288
grade-school-math.dev.4279,WizardLM/WizardLM-13B-V1.2,0.5,0.0001254,0.75,9.54e-05,0.5,0.0001254,0.75,0.0002628,0.25,0.000326696,0.75,0.00763
hellaswag.val.7355,mistralai/mistral-7b-chat,0.0,4.780000000000001e-05,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
mmlu-professional-law.val.227,mistralai/mixtral-8x7b-chat,0.0,0.0001692,0.0,5.64e-05,1.0,8.46e-05,0.0,0.0001692,0.0,0.000218832,1.0,0.00283
mmlu-professional-law.val.312,WizardLM/WizardLM-13B-V1.2,1.0,0.0001448999999999,1.0,9.66e-05,1.0,0.0001448999999999,1.0,0.0002897999999999,0.0,0.000374808,1.0,0.00484
hellaswag.val.6646,WizardLM/WizardLM-13B-V1.2,0.0,7.83e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,1.0,0.00262
arc-challenge.test.456,mistralai/mixtral-8x7b-chat,0.0,5.94e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.00103
mmlu-high-school-macroeconomics.val.314,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-philosophy.val.310,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,0.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00084
mmlu-high-school-macroeconomics.val.105,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-management.val.87,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
mmlu-high-school-world-history.val.104,WizardLM/WizardLM-13B-V1.2,0.0,0.0002082,1.0,0.0001388,0.0,0.0002082,1.0,0.0004164,0.0,0.000538544,1.0,0.00698
grade-school-math.dev.2525,mistralai/mistral-7b-chat,0.25,7.38e-05,0.25,7.38e-05,0.5,0.0001532999999999,0.75,0.000249,0.25,0.000301864,0.5,0.0087199999999999
mmlu-high-school-government-and-politics.val.79,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-electrical-engineering.val.105,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,0.0,0.0009
grade-school-math.dev.4203,WizardLM/WizardLM-13B-V1.2,0.25,0.0001743,0.25,9.46e-05,0.25,0.0001743,0.25,0.0002826,0.25,0.000363168,0.75,0.00936
mmlu-professional-law.val.10,WizardLM/WizardLM-13B-V1.2,0.0,0.0001101,0.0,7.34e-05,0.0,0.0001101,0.0,0.0002202,0.0,0.000284792,1.0,0.00368
bias_detection.dev.209,mistralai/mixtral-8x7b-chat,0.0,0.0001889999999999,0.0,6.440000000000001e-05,0.0,0.0001035,0.0,0.0001889999999999,0.0,0.0002134,0.0,0.00868
grade-school-math.dev.2210,mistralai/mistral-7b-chat,0.25,0.0001028,0.25,0.0001028,0.75,0.0001329,0.25,0.0002334,0.75,0.000356184,0.75,0.00718
hellaswag.val.3508,mistralai/mixtral-8x7b-chat,0.0,0.0001632,0.0,5.44e-05,0.0,8.16e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00276
mmlu-management.val.5,mistralai/mistral-7b-chat,1.0,1.46e-05,1.0,1.46e-05,1.0,2.16e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00077
mmlu-public-relations.val.51,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
mmlu-professional-law.val.933,WizardLM/WizardLM-13B-V1.2,1.0,6.21e-05,0.0,4.14e-05,1.0,6.21e-05,0.0,0.0001242,0.0,0.000160632,0.0,0.00211
grade-school-math.dev.7437,WizardLM/WizardLM-13B-V1.2,0.75,0.0002031,0.25,0.000114,0.75,0.0002031,1.0,0.0002334,0.25,0.00034532,0.5,0.01419
mmlu-virology.val.85,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-high-school-macroeconomics.val.320,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-moral-scenarios.val.675,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-high-school-us-history.val.129,WizardLM/WizardLM-13B-V1.2,1.0,0.0001146,1.0,7.64e-05,1.0,0.0001146,0.0,0.0002292,0.0,0.000295656,0.0,0.00386
grade-school-math.dev.2624,WizardLM/WizardLM-13B-V1.2,0.25,0.0001373999999999,0.25,8.280000000000001e-05,0.25,0.0001373999999999,0.75,0.0002441999999999,0.25,0.000317384,0.5,0.0076
mmlu-global-facts.val.60,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
hellaswag.val.2752,WizardLM/WizardLM-13B-V1.2,0.0,4.17e-05,1.0,2.78e-05,0.0,4.17e-05,1.0,8.340000000000001e-05,1.0,0.000107864,0.0,0.0014
mmlu-logical-fallacies.val.146,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-high-school-microeconomics.val.34,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00104
mmlu-miscellaneous.val.658,mistralai/mistral-7b-chat,1.0,2.28e-05,1.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
grade-school-math.dev.3764,mistralai/mixtral-8x7b-chat,0.25,0.000243,0.25,8.94e-05,0.25,0.0001487999999999,0.25,0.000243,0.25,0.000312728,0.25,0.0070799999999999
mmlu-miscellaneous.val.24,mistralai/mixtral-8x7b-chat,0.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.102,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.08e-05,0.0,8.22e-05,0.0,0.000106312,1.0,0.00138
arc-challenge.test.1012,mistralai/mixtral-8x7b-chat,1.0,6.12e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.387,WizardLM/WizardLM-13B-V1.2,0.75,0.0001869,0.75,0.0001004,0.75,0.0001869,0.75,0.0003216,0.25,0.000391104,0.75,0.0093899999999999
mmlu-electrical-engineering.val.5,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-miscellaneous.val.362,mistralai/mistral-7b-chat,1.0,2.88e-05,1.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
mmlu-professional-medicine.val.46,WizardLM/WizardLM-13B-V1.2,0.0,5.25e-05,0.0,3.5000000000000004e-05,0.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00176
hellaswag.val.3634,WizardLM/WizardLM-13B-V1.2,0.0,8.49e-05,0.0,5.660000000000001e-05,0.0,8.49e-05,0.0,0.0001698,0.0,0.000219608,1.0,0.00284
hellaswag.val.7887,mistralai/mixtral-8x7b-chat,0.0,0.0001602,0.0,5.34e-05,0.0,8.01e-05,0.0,0.0001602,0.0,0.000207192,1.0,0.00268
mmlu-philosophy.val.121,mistralai/mistral-7b-chat,1.0,2.18e-05,1.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-professional-law.val.369,WizardLM/WizardLM-13B-V1.2,1.0,9.69e-05,0.0,6.46e-05,1.0,9.69e-05,1.0,0.0001938,0.0,0.000250648,1.0,0.00324
hellaswag.val.7994,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.8812,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
grade-school-math.dev.718,mistralai/mistral-7b-chat,0.25,0.0001038,0.25,0.0001038,0.75,0.0001643999999999,0.25,0.0002753999999999,0.75,0.0003298,0.75,0.01098
hellaswag.val.1188,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
arc-challenge.test.1131,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-professional-law.val.1276,WizardLM/WizardLM-13B-V1.2,0.0,7.199999999999999e-05,1.0,4.8e-05,0.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
grade-school-math.dev.4455,WizardLM/WizardLM-13B-V1.2,0.25,0.0001952999999999,0.25,9.82e-05,0.25,0.0001952999999999,0.25,0.0002988,0.25,0.000367824,0.75,0.01045
grade-school-math.dev.7045,WizardLM/WizardLM-13B-V1.2,0.75,0.0001695,0.25,9.38e-05,0.75,0.0001695,0.75,0.0003054,0.5,0.000370928,0.75,0.00917
mmlu-medical-genetics.val.7,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
mmlu-high-school-us-history.val.104,mistralai/mixtral-8x7b-chat,1.0,0.0001494,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
hellaswag.val.2704,WizardLM/WizardLM-13B-V1.2,0.0,4.05e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-miscellaneous.val.781,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
winogrande.dev.74,mistralai/mistral-7b-chat,0.0,1.02e-05,0.0,1.02e-05,1.0,1.53e-05,1.0,3.06e-05,0.0,3.9576e-05,1.0,0.00052
mmlu-clinical-knowledge.val.104,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
abstract2title.test.9,mistralai/mixtral-8x7b-chat,1.0,0.0001121999999999,1.0,3.62e-05,1.0,6.03e-05,1.0,0.0001121999999999,1.0,0.000140456,1.0,0.00234
mmlu-professional-law.val.871,WizardLM/WizardLM-13B-V1.2,0.0,8.91e-05,0.0,5.94e-05,0.0,8.91e-05,1.0,0.0001782,0.0,0.000230472,1.0,0.00298
grade-school-math.dev.1190,WizardLM/WizardLM-13B-V1.2,0.75,0.0001527,0.25,0.0001118,0.75,0.0001527,0.75,0.0002166,0.25,0.000441544,0.75,0.00854
grade-school-math.dev.4975,mistralai/mixtral-8x7b-chat,0.75,0.0002243999999999,0.75,7.3e-05,0.75,0.0001323,0.75,0.0002243999999999,0.25,0.000286344,0.75,0.00786
hellaswag.val.9735,mistralai/mistral-7b-chat,0.0,4.920000000000001e-05,0.0,4.920000000000001e-05,0.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
grade-school-math.dev.1327,mistralai/mistral-7b-chat,0.25,0.0001084,0.25,0.0001084,0.25,0.0001482,0.25,0.000252,0.75,0.000435336,0.25,0.00878
winogrande.dev.588,mistralai/mixtral-8x7b-chat,0.0,3.4800000000000006e-05,0.0,1.16e-05,0.0,1.7100000000000002e-05,0.0,3.4800000000000006e-05,0.0,4.4232000000000006e-05,1.0,0.00062
mmlu-professional-law.val.23,WizardLM/WizardLM-13B-V1.2,0.0,5.64e-05,0.0,3.7600000000000006e-05,0.0,5.64e-05,0.0,0.0001127999999999,0.0,0.000145888,0.0,0.00192
mmlu-formal-logic.val.37,mistralai/mistral-7b-chat,1.0,2.18e-05,1.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
hellaswag.val.325,mistralai/mistral-7b-chat,1.0,2.3e-05,1.0,2.3e-05,0.0,3.45e-05,0.0,6.9e-05,1.0,8.924e-05,0.0,0.00116
winogrande.dev.962,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
grade-school-math.dev.5834,WizardLM/WizardLM-13B-V1.2,0.5,0.0001806,0.5,9.4e-05,0.5,0.0001806,0.25,0.0002591999999999,0.5,0.000301088,0.25,0.00859
mmlu-clinical-knowledge.val.89,mistralai/mistral-7b-chat,0.0,1.3e-05,0.0,1.3e-05,0.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,0.0,0.00069
hellaswag.val.9545,WizardLM/WizardLM-13B-V1.2,0.0,6.96e-05,0.0,4.64e-05,0.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,1.0,0.00233
grade-school-math.dev.1021,WizardLM/WizardLM-13B-V1.2,0.75,0.0001569,0.25,6.46e-05,0.75,0.0001569,0.75,0.0002964,0.25,0.000308072,0.75,0.0081
mmlu-professional-law.val.183,WizardLM/WizardLM-13B-V1.2,0.0,8.699999999999999e-05,1.0,5.800000000000001e-05,0.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
mmlu-marketing.val.44,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00098
grade-school-math.dev.3314,WizardLM/WizardLM-13B-V1.2,0.75,0.000126,0.75,8.68e-05,0.75,0.000126,0.5,0.0002406,0.75,0.0003127279999999,0.75,0.00592
grade-school-math.dev.1035,meta/code-llama-instruct-34b-chat,0.75,0.0003965359999999,0.25,9.3e-05,0.25,0.0001521,0.75,0.0002694,0.75,0.0003965359999999,0.5,0.01005
hellaswag.val.4339,mistralai/mixtral-8x7b-chat,0.0,0.0001763999999999,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00298
grade-school-math.dev.676,WizardLM/WizardLM-13B-V1.2,0.75,0.0001571999999999,0.75,7.54e-05,0.75,0.0001571999999999,0.75,0.0002663999999999,0.75,0.000331352,0.75,0.00993
hellaswag.val.9484,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,1.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00268
grade-school-math.dev.6897,WizardLM/WizardLM-13B-V1.2,0.25,0.0001643999999999,0.25,9.04e-05,0.25,0.0001643999999999,0.25,0.0002705999999999,0.25,0.00032592,0.75,0.00813
mmlu-professional-law.val.338,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,1.0,5.24e-05,0.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,0.0,0.00263
winogrande.dev.1193,mistralai/mistral-7b-chat,0.0,1.04e-05,0.0,1.04e-05,1.0,1.53e-05,0.0,3.12e-05,0.0,4.0352e-05,1.0,0.00056
arc-challenge.val.48,mistralai/mixtral-8x7b-chat,0.0,7.68e-05,0.0,2.56e-05,0.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
mmlu-high-school-physics.val.81,mistralai/mixtral-8x7b-chat,0.0,7.86e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.0013499999999999
grade-school-math.dev.4315,mistralai/mistral-7b-chat,0.5,8.58e-05,0.5,8.58e-05,0.5,0.000144,0.5,0.0002412,0.5,0.000303416,0.5,0.0069099999999999
mmlu-professional-law.val.515,WizardLM/WizardLM-13B-V1.2,0.0,5.82e-05,1.0,3.880000000000001e-05,0.0,5.82e-05,0.0,0.0001164,0.0,0.000150544,0.0,0.00195
mmlu-professional-psychology.val.493,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
hellaswag.val.2912,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.76e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-professional-medicine.val.72,mistralai/mixtral-8x7b-chat,1.0,0.000105,1.0,3.5000000000000004e-05,1.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00179
mmlu-prehistory.val.134,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-high-school-psychology.val.292,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.2072,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-college-biology.val.60,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-high-school-psychology.val.305,WizardLM/WizardLM-13B-V1.2,1.0,2.07e-05,0.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mbpp.dev.68,mistralai/mistral-7b-chat,1.0,4.14e-05,1.0,4.14e-05,1.0,4.62e-05,1.0,7.26e-05,0.0,9.312e-05,1.0,0.00513
grade-school-math.dev.6963,WizardLM/WizardLM-13B-V1.2,0.5,0.0001286999999999,0.75,8.020000000000001e-05,0.5,0.0001286999999999,0.75,0.0002423999999999,0.5,0.000276256,0.5,0.00674
mmlu-high-school-biology.val.48,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-miscellaneous.val.459,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-high-school-mathematics.val.213,mistralai/mixtral-8x7b-chat,0.0,7.2e-05,0.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,0.0,0.00124
mmlu-high-school-european-history.val.30,WizardLM/WizardLM-13B-V1.2,1.0,0.0001757999999999,1.0,0.0001172,1.0,0.0001757999999999,1.0,0.0003515999999999,0.0,0.000454736,1.0,0.0058699999999999
mmlu-miscellaneous.val.434,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-high-school-biology.val.43,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-miscellaneous.val.27,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-professional-law.val.234,WizardLM/WizardLM-13B-V1.2,0.0,9.15e-05,0.0,6.1000000000000005e-05,0.0,9.15e-05,1.0,0.0001829999999999,0.0,0.00023668,1.0,0.00306
mmlu-elementary-mathematics.val.333,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.26e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-high-school-macroeconomics.val.49,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,0.0,0.0011
hellaswag.val.3027,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-conceptual-physics.val.34,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.0008799999999999
mbpp.dev.417,mistralai/mistral-7b-chat,1.0,3.1e-05,1.0,3.1e-05,0.0,5.46e-05,0.0,9.78e-05,1.0,8.6912e-05,1.0,0.00954
grade-school-math.dev.7142,WizardLM/WizardLM-13B-V1.2,0.75,0.0001446,0.75,7.38e-05,0.75,0.0001446,0.5,0.0002549999999999,0.5,0.000268496,0.75,0.00556
winogrande.dev.131,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,0.0,0.00054
mmlu-jurisprudence.val.93,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
hellaswag.val.4415,mistralai/mixtral-8x7b-chat,1.0,0.0001458,0.0,4.860000000000001e-05,0.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,1.0,0.00247
mmlu-high-school-microeconomics.val.179,mistralai/mistral-7b-chat,1.0,2.42e-05,1.0,2.42e-05,0.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
abstract2title.test.179,mistralai/mixtral-8x7b-chat,1.0,0.0001199999999999,1.0,3.7600000000000006e-05,1.0,6.3e-05,1.0,0.0001199999999999,1.0,0.000153648,1.0,0.00267
mmlu-clinical-knowledge.val.239,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.3848,WizardLM/WizardLM-13B-V1.2,0.25,0.000135,0.25,8.7e-05,0.25,0.000135,0.75,0.0002333999999999,0.25,0.000317384,0.75,0.01025
grade-school-math.dev.2112,WizardLM/WizardLM-13B-V1.2,0.25,0.0001724999999999,0.25,8.060000000000001e-05,0.25,0.0001724999999999,0.25,0.0002892,0.25,0.000342992,0.75,0.00966
arc-challenge.val.282,mistralai/mixtral-8x7b-chat,1.0,6e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
grade-school-math.dev.444,WizardLM/WizardLM-13B-V1.2,0.75,0.0002018999999999,0.75,8.240000000000001e-05,0.75,0.0002018999999999,0.75,0.0002724,0.25,0.00027936,0.75,0.0086
mmlu-moral-disputes.val.271,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
mmlu-professional-law.val.1290,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,0.0,5.24e-05,0.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-professional-law.val.830,WizardLM/WizardLM-13B-V1.2,1.0,8.4e-05,0.0,5.6000000000000006e-05,1.0,8.4e-05,1.0,0.000168,0.0,0.00021728,1.0,0.00281
grade-school-math.dev.6637,WizardLM/WizardLM-13B-V1.2,0.5,0.0001356,0.25,7.020000000000001e-05,0.5,0.0001356,0.5,0.0001866,0.5,0.000252976,0.75,0.00793
hellaswag.val.7170,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,1.0,7.110000000000001e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00241
mmlu-professional-law.val.129,WizardLM/WizardLM-13B-V1.2,0.0,0.0001014,1.0,6.76e-05,0.0,0.0001014,0.0,0.0002028,0.0,0.0002622879999999,1.0,0.00339
grade-school-math.dev.1892,WizardLM/WizardLM-13B-V1.2,0.75,0.0001568999999999,0.75,6.06e-05,0.75,0.0001568999999999,0.75,0.0002718,0.75,0.00028324,0.75,0.00747
arc-challenge.val.235,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,1.0,6.828800000000001e-05,1.0,0.00092
hellaswag.val.2045,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
hellaswag.val.9800,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.739999999999998e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
grade-school-math.dev.7065,WizardLM/WizardLM-13B-V1.2,0.5,0.0001806,0.5,9.880000000000002e-05,0.5,0.0001806,0.5,0.0003096,0.5,0.000392656,0.5,0.0095599999999999
hellaswag.val.7172,mistralai/mistral-7b-chat,1.0,4.980000000000001e-05,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,1.0,0.0001932239999999,1.0,0.00253
grade-school-math.dev.6436,WizardLM/WizardLM-13B-V1.2,0.75,9.54e-05,0.25,7.840000000000001e-05,0.75,9.54e-05,0.25,0.000294,0.75,0.000328248,0.75,0.00734
mmlu-high-school-psychology.val.213,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
hellaswag.val.9410,mistralai/mixtral-8x7b-chat,0.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,0.0,0.0001476,0.0,0.0001908959999999,1.0,0.0025
hellaswag.val.3894,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,0.0,0.00244
hellaswag.val.5542,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-high-school-geography.val.73,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
grade-school-math.dev.187,mistralai/mistral-7b-chat,0.25,0.0001342,0.25,0.0001342,0.25,0.0001998,0.25,0.0003648,0.25,0.00041904,0.25,0.01529
mmlu-professional-psychology.val.5,mistralai/mistral-7b-chat,1.0,2.34e-05,1.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
mmlu-professional-accounting.val.236,WizardLM/WizardLM-13B-V1.2,0.0,3.72e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.0012799999999999
hellaswag.val.6703,WizardLM/WizardLM-13B-V1.2,0.0,8.28e-05,0.0,5.5400000000000005e-05,0.0,8.28e-05,0.0,0.0001662,0.0,0.000214952,1.0,0.00278
mmlu-miscellaneous.val.776,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,1.0,1.6800000000000002e-05,1.0,2.49e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-security-studies.val.209,mistralai/mistral-7b-chat,1.0,3.2600000000000006e-05,1.0,3.2600000000000006e-05,1.0,4.89e-05,1.0,9.78e-05,0.0,0.0001264879999999,1.0,0.00164
mmlu-miscellaneous.val.420,mistralai/mistral-7b-chat,1.0,1.52e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
mmlu-professional-law.val.97,mistralai/mistral-7b-chat,0.0,6.120000000000001e-05,0.0,6.120000000000001e-05,0.0,9.18e-05,1.0,0.0001836,0.0,0.0002374559999999,1.0,0.00307
grade-school-math.dev.4090,WizardLM/WizardLM-13B-V1.2,0.75,0.0001356,0.75,9.36e-05,0.75,0.0001356,0.75,0.0002435999999999,0.75,0.000255304,0.75,0.00574
mmlu-professional-law.val.638,WizardLM/WizardLM-13B-V1.2,0.0,8.04e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,1.0,0.0001602,0.0,0.0002079679999999,1.0,0.00269
mmlu-international-law.val.56,mistralai/mistral-7b-chat,1.0,2.18e-05,1.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-professional-law.val.1220,WizardLM/WizardLM-13B-V1.2,0.0,6.48e-05,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,1.0,0.00217
hellaswag.val.9609,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.619999999999998e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-high-school-psychology.val.84,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.3672,WizardLM/WizardLM-13B-V1.2,0.0,8.879999999999999e-05,0.0,5.94e-05,0.0,8.879999999999999e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00301
mmlu-high-school-microeconomics.val.142,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,1.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00106
mmlu-high-school-microeconomics.val.83,mistralai/mistral-7b-chat,0.0,3.1200000000000006e-05,0.0,3.1200000000000006e-05,0.0,4.68e-05,1.0,9.36e-05,0.0,0.000121056,1.0,0.0015999999999999
abstract2title.test.28,mistralai/mixtral-8x7b-chat,1.0,0.0001872,1.0,6.220000000000001e-05,1.0,9.42e-05,1.0,0.0001872,1.0,0.00024056,1.0,0.00356
grade-school-math.dev.3832,mistralai/mistral-7b-chat,0.25,9.78e-05,0.25,9.78e-05,0.25,0.0002333999999999,0.5,0.0002922,0.75,0.0003507519999999,0.75,0.00874
hellaswag.val.7455,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,0.0,0.00241
mmlu-moral-scenarios.val.682,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00138
grade-school-math.dev.4297,mistralai/mistral-7b-chat,0.75,9.96e-05,0.75,9.96e-05,0.75,0.0001965,0.25,0.0002663999999999,0.75,0.000327472,0.75,0.01027
hellaswag.val.2079,WizardLM/WizardLM-13B-V1.2,1.0,4.17e-05,0.0,2.78e-05,1.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,0.0,0.0014299999999999
mmlu-moral-scenarios.val.876,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,1.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,1.0,0.00148
hellaswag.val.7721,mistralai/mixtral-8x7b-chat,1.0,0.0001752,1.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,1.0,0.000226592,1.0,0.00296
mmlu-high-school-government-and-politics.val.44,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
grade-school-math.dev.1740,WizardLM/WizardLM-13B-V1.2,0.5,0.0001401,0.75,6.38e-05,0.5,0.0001401,0.25,0.0002399999999999,0.75,0.000270048,0.75,0.00638
hellaswag.val.7853,mistralai/mistral-7b-chat,0.0,5.76e-05,0.0,5.76e-05,0.0,8.609999999999999e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00292
mmlu-logical-fallacies.val.21,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,0.0,0.00082
grade-school-math.dev.1523,WizardLM/WizardLM-13B-V1.2,0.75,0.0001463999999999,0.75,6.1000000000000005e-05,0.75,0.0001463999999999,0.75,0.0002322,0.5,0.00028324,0.5,0.0068
hellaswag.val.8726,mistralai/mistral-7b-chat,1.0,5.680000000000001e-05,1.0,5.680000000000001e-05,1.0,8.52e-05,1.0,0.0001704,1.0,0.0002203839999999,1.0,0.00285
mmlu-miscellaneous.val.725,mistralai/mistral-7b-chat,1.0,1.36e-05,1.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-miscellaneous.val.726,mistralai/mixtral-8x7b-chat,1.0,4.02e-05,1.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
grade-school-math.dev.4685,mistralai/mistral-7b-chat,0.25,6.24e-05,0.25,6.24e-05,0.25,0.0001278,0.75,0.0002472,0.25,0.000264616,0.5,0.00638
grade-school-math.dev.3878,WizardLM/WizardLM-13B-V1.2,0.75,0.0001452,0.75,8.1e-05,0.75,0.0001452,0.75,0.0002532,0.75,0.000315832,0.75,0.00668
hellaswag.val.444,WizardLM/WizardLM-13B-V1.2,0.0,2.52e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,1.0,6.5184e-05,0.0,0.00085
mmlu-public-relations.val.95,mistralai/mistral-7b-chat,1.0,2.08e-05,1.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
hellaswag.val.9903,WizardLM/WizardLM-13B-V1.2,1.0,9.18e-05,0.0,6.14e-05,1.0,9.18e-05,0.0,0.0001842,0.0,0.000238232,1.0,0.00308
mmlu-professional-law.val.544,WizardLM/WizardLM-13B-V1.2,0.0,0.0001047,1.0,6.98e-05,0.0,0.0001047,0.0,0.0002094,0.0,0.0002708239999999,0.0,0.0035
hellaswag.val.5877,mistralai/mixtral-8x7b-chat,0.0,0.000159,0.0,5.300000000000001e-05,1.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
mmlu-sociology.val.193,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
arc-challenge.test.372,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,1.0,6.208e-05,1.0,0.00084
winogrande.dev.611,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,1.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,0.0,0.00052
hellaswag.val.4476,mistralai/mixtral-8x7b-chat,0.0,0.0001338,0.0,4.460000000000001e-05,0.0,6.659999999999999e-05,0.0,0.0001338,0.0,0.000173048,1.0,0.00227
arc-challenge.test.533,WizardLM/WizardLM-13B-V1.2,1.0,4.26e-05,1.0,2.84e-05,1.0,4.26e-05,1.0,8.52e-05,1.0,0.000110192,1.0,0.00146
mmlu-professional-law.val.1426,mistralai/mistral-7b-chat,0.0,7.14e-05,0.0,7.14e-05,0.0,0.0001071,0.0,0.0002142,0.0,0.000277032,0.0,0.00358
grade-school-math.dev.1045,mistralai/mixtral-8x7b-chat,0.25,0.000243,0.25,7.12e-05,0.75,0.0001647,0.25,0.000243,0.25,0.000414384,0.75,0.0081
mmlu-sociology.val.142,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-nutrition.val.96,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
hellaswag.val.6252,mistralai/mistral-7b-chat,1.0,4.460000000000001e-05,1.0,4.460000000000001e-05,1.0,6.69e-05,1.0,0.0001338,1.0,0.000173048,1.0,0.00227
mmlu-professional-law.val.1142,WizardLM/WizardLM-13B-V1.2,1.0,0.0001688999999999,1.0,0.0001126,1.0,0.0001688999999999,1.0,0.0003377999999999,0.0,0.000436888,1.0,0.00564
hellaswag.val.3449,mistralai/mixtral-8x7b-chat,1.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.529999999999999e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00256
grade-school-math.dev.2332,mistralai/mixtral-8x7b-chat,0.5,0.0002526,0.25,7.22e-05,0.25,0.0001266,0.5,0.0002526,0.75,0.000301864,0.75,0.00706
mmlu-professional-law.val.363,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,0.0,0.00104
mmlu-high-school-biology.val.233,mistralai/mixtral-8x7b-chat,0.0,8.340000000000001e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-high-school-psychology.val.532,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-geography.val.174,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
grade-school-math.dev.7417,mistralai/mistral-7b-chat,0.25,7.060000000000001e-05,0.25,7.060000000000001e-05,0.5,0.0001695,0.75,0.0002298,0.25,0.000320488,0.5,0.00865
mmlu-high-school-psychology.val.520,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-high-school-geography.val.170,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00082
hellaswag.val.5036,mistralai/mixtral-8x7b-chat,0.0,0.0001338,1.0,4.460000000000001e-05,1.0,6.69e-05,0.0,0.0001338,1.0,0.000173048,1.0,0.00227
mmlu-professional-law.val.741,WizardLM/WizardLM-13B-V1.2,0.0,9.09e-05,1.0,6.06e-05,0.0,9.09e-05,1.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
bias_detection.dev.170,mistralai/mistral-7b-chat,0.0,6.94e-05,0.0,6.94e-05,0.0,0.0001283999999999,0.0,0.0002183999999999,0.0,0.000296432,0.0,0.0141
abstract2title.test.83,mistralai/mixtral-8x7b-chat,1.0,0.0002075999999999,1.0,6.88e-05,1.0,0.0001053,1.0,0.0002075999999999,1.0,0.00026772,1.0,0.00392
mmlu-professional-law.val.584,WizardLM/WizardLM-13B-V1.2,0.0,0.0001119,1.0,7.46e-05,0.0,0.0001119,1.0,0.0002231999999999,0.0,0.000289448,1.0,0.00374
hellaswag.val.6994,WizardLM/WizardLM-13B-V1.2,0.0,8.730000000000001e-05,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00295
hellaswag.val.3378,WizardLM/WizardLM-13B-V1.2,0.0,8.58e-05,0.0,5.720000000000001e-05,0.0,8.58e-05,0.0,0.0001709999999999,0.0,0.000221936,1.0,0.00287
mmlu-moral-scenarios.val.97,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
arc-challenge.test.1115,mistralai/mistral-7b-chat,0.0,1.06e-05,0.0,1.06e-05,0.0,1.59e-05,0.0,3.18e-05,0.0,4.1128e-05,1.0,0.00054
mmlu-professional-law.val.1135,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-high-school-microeconomics.val.209,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-professional-law.val.1471,mistralai/mistral-7b-chat,0.0,6.0200000000000006e-05,0.0,6.0200000000000006e-05,1.0,9.03e-05,0.0,0.0001806,0.0,0.000233576,0.0,0.00302
mmlu-security-studies.val.6,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,1.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00134
grade-school-math.dev.140,WizardLM/WizardLM-13B-V1.2,0.75,0.0001869,0.25,9.88e-05,0.75,0.0001869,0.25,0.0003287999999999,0.75,0.00036472,0.5,0.00965
mmlu-medical-genetics.val.98,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-professional-law.val.1253,mistralai/mistral-7b-chat,0.0,5.220000000000001e-05,0.0,5.220000000000001e-05,1.0,7.83e-05,1.0,0.0001566,0.0,0.000202536,1.0,0.00262
mmlu-high-school-macroeconomics.val.6,mistralai/mistral-7b-chat,1.0,1.98e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-professional-law.val.1244,mistralai/mixtral-8x7b-chat,1.0,0.0001584,1.0,5.280000000000001e-05,0.0,7.92e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00265
hellaswag.val.520,mistralai/mistral-7b-chat,0.0,3.08e-05,0.0,3.08e-05,0.0,4.6200000000000005e-05,1.0,9.24e-05,0.0,0.000119504,1.0,0.00155
mmlu-high-school-computer-science.val.62,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.16e-05,0.0,0.000106312,0.0,0.00138
hellaswag.val.9126,mistralai/mistral-7b-chat,0.0,5.980000000000001e-05,0.0,5.980000000000001e-05,0.0,8.97e-05,0.0,0.0001794,0.0,0.000232024,1.0,0.00303
grade-school-math.dev.3401,WizardLM/WizardLM-13B-V1.2,0.75,0.0001331999999999,0.5,8.16e-05,0.75,0.0001331999999999,0.75,0.0002345999999999,0.5,0.00028324,0.75,0.00714
arc-challenge.test.797,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,1.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.7053,mistralai/mistral-7b-chat,0.25,9.48e-05,0.25,9.48e-05,0.75,0.0001529999999999,0.75,0.0002393999999999,0.75,0.000289448,0.75,0.00823
mmlu-us-foreign-policy.val.77,mistralai/mistral-7b-chat,1.0,2.58e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
abstract2title.test.218,mistralai/mixtral-8x7b-chat,1.0,0.0002009999999999,1.0,6.26e-05,1.0,9.3e-05,1.0,0.0002009999999999,1.0,0.000242112,1.0,0.00359
mmlu-moral-scenarios.val.304,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.0013499999999999
mmlu-high-school-psychology.val.206,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
mmlu-miscellaneous.val.515,mistralai/mixtral-8x7b-chat,1.0,6.720000000000001e-05,1.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-human-sexuality.val.18,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,1.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
mmlu-marketing.val.156,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
mmlu-machine-learning.val.5,mistralai/mixtral-8x7b-chat,0.0,7.02e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,0.0,0.00118
hellaswag.val.6486,mistralai/mixtral-8x7b-chat,0.0,0.0001674,0.0,5.580000000000001e-05,0.0,8.37e-05,0.0,0.0001674,0.0,0.0002165039999999,0.0,0.00283
hellaswag.val.9165,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.65e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
mmlu-machine-learning.val.51,mistralai/mixtral-8x7b-chat,1.0,6e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,0.0,0.00101
grade-school-math.dev.5995,mistralai/mixtral-8x7b-chat,0.5,0.0002357999999999,0.25,7.14e-05,0.25,0.0001484999999999,0.5,0.0002357999999999,0.5,0.000342992,0.5,0.00856
mmlu-professional-law.val.172,WizardLM/WizardLM-13B-V1.2,0.0,0.0001391999999999,0.0,9.28e-05,0.0,0.0001391999999999,0.0,0.0002783999999999,0.0,0.000360064,1.0,0.00465
hellaswag.val.6066,WizardLM/WizardLM-13B-V1.2,0.0,7.26e-05,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00243
mmlu-professional-law.val.498,WizardLM/WizardLM-13B-V1.2,0.0,6.18e-05,0.0,4.1200000000000005e-05,0.0,6.18e-05,1.0,0.0001236,0.0,0.000159856,1.0,0.00207
mmlu-philosophy.val.271,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
winogrande.dev.1198,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,0.0,3.6472e-05,0.0,0.00052
grade-school-math.dev.3473,mistralai/mistral-7b-chat,0.25,7.86e-05,0.25,7.86e-05,0.5,0.0001761,0.5,0.0002814,0.75,0.000311952,0.75,0.00808
hellaswag.val.6,mistralai/mixtral-8x7b-chat,0.0,6.24e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.1360,mistralai/mistral-7b-chat,0.25,9.100000000000002e-05,0.25,9.100000000000002e-05,0.5,0.0001269,0.25,0.0002076,0.75,0.000308072,0.5,0.0058899999999999
mmlu-professional-psychology.val.563,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-econometrics.val.65,mistralai/mistral-7b-chat,1.0,1.44e-05,1.0,1.44e-05,1.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,0.0,0.00073
mmlu-moral-scenarios.val.113,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,0.0,0.0015199999999999
mmlu-conceptual-physics.val.170,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,0.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-conceptual-physics.val.79,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
grade-school-math.dev.2378,mistralai/mistral-7b-chat,0.25,6.06e-05,0.25,6.06e-05,0.75,0.0001701,0.5,0.000297,0.5,0.000339112,0.75,0.00667
winogrande.dev.841,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,1.0,1.53e-05,1.0,3.06e-05,1.0,3.9576e-05,1.0,0.00052
grade-school-math.dev.5611,WizardLM/WizardLM-13B-V1.2,0.75,0.0001647,0.25,9.24e-05,0.75,0.0001647,0.75,0.0002586,0.25,0.00032204,0.75,0.00721
grade-school-math.dev.66,WizardLM/WizardLM-13B-V1.2,0.25,0.000192,0.25,9.94e-05,0.25,0.000192,0.25,0.0002111999999999,0.25,0.00033368,0.5,0.00923
hellaswag.val.5934,mistralai/mixtral-8x7b-chat,1.0,0.0001709999999999,0.0,5.7e-05,0.0,8.519999999999998e-05,1.0,0.0001709999999999,0.0,0.00022116,1.0,0.00289
hellaswag.val.2711,WizardLM/WizardLM-13B-V1.2,0.0,3.81e-05,0.0,2.56e-05,0.0,3.81e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-professional-law.val.1291,WizardLM/WizardLM-13B-V1.2,1.0,8.04e-05,1.0,5.360000000000001e-05,1.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,0.0,0.00269
mmlu-miscellaneous.val.230,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.1072,WizardLM/WizardLM-13B-V1.2,1.0,0.0001076999999999,0.0,7.18e-05,1.0,0.0001076999999999,1.0,0.0002153999999999,0.0,0.0002785839999999,0.0,0.0036
hellaswag.val.8314,mistralai/mistral-7b-chat,1.0,5.44e-05,1.0,5.44e-05,1.0,8.13e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00276
mmlu-professional-law.val.653,WizardLM/WizardLM-13B-V1.2,0.0,0.0001502999999999,1.0,0.0001002,0.0,0.0001502999999999,0.0,0.0003005999999999,0.0,0.0003887759999999,0.0,0.0050199999999999
winogrande.dev.465,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.4699999999999998e-05,1.0,2.94e-05,1.0,3.8024e-05,1.0,0.00053
mmlu-nutrition.val.252,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
mmlu-college-mathematics.val.46,WizardLM/WizardLM-13B-V1.2,0.0,3.15e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
hellaswag.val.6347,mistralai/mixtral-8x7b-chat,1.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,1.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
mmlu-miscellaneous.val.227,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.1293,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
grade-school-math.dev.847,WizardLM/WizardLM-13B-V1.2,0.25,0.0001848,0.75,9.84e-05,0.25,0.0001848,0.5,0.0003041999999999,0.25,0.000359288,0.5,0.01027
grade-school-math.dev.2905,mistralai/mistral-7b-chat,0.25,7.92e-05,0.25,7.92e-05,0.75,0.0001508999999999,0.75,0.0002322,0.25,0.000389552,0.75,0.00785
mmlu-moral-scenarios.val.735,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.0015
hellaswag.val.9972,WizardLM/WizardLM-13B-V1.2,0.0,8.939999999999999e-05,0.0,5.980000000000001e-05,0.0,8.939999999999999e-05,0.0,0.0001794,0.0,0.000232024,1.0,0.00303
winogrande.dev.626,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,0.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,0.0,0.00048
grade-school-math.dev.4521,WizardLM/WizardLM-13B-V1.2,0.25,0.0001413,0.75,7.24e-05,0.25,0.0001413,0.75,0.0002123999999999,0.75,0.000325144,0.75,0.00922
hellaswag.val.2353,mistralai/mistral-7b-chat,1.0,2.52e-05,1.0,2.52e-05,0.0,3.78e-05,1.0,7.56e-05,0.0,9.7776e-05,1.0,0.0013
arc-challenge.test.997,mistralai/mixtral-8x7b-chat,0.0,3.84e-05,0.0,1.28e-05,0.0,1.92e-05,0.0,3.84e-05,0.0,4.9664e-05,1.0,0.00065
mmlu-professional-law.val.558,WizardLM/WizardLM-13B-V1.2,0.0,0.0001397999999999,0.0,9.32e-05,0.0,0.0001397999999999,0.0,0.0002795999999999,0.0,0.000361616,1.0,0.00467
arc-challenge.test.772,mistralai/mistral-7b-chat,1.0,1.58e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,1.0,6.1304e-05,1.0,0.00083
mmlu-professional-law.val.399,mistralai/mixtral-8x7b-chat,0.0,0.0002094,0.0,6.98e-05,0.0,0.0001047,0.0,0.0002094,0.0,0.0002708239999999,0.0,0.0035
grade-school-math.dev.2846,WizardLM/WizardLM-13B-V1.2,0.25,0.0001614,0.75,9.12e-05,0.25,0.0001614,0.75,0.0002099999999999,0.75,0.0003049679999999,0.75,0.00673
arc-challenge.test.1031,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.3928,WizardLM/WizardLM-13B-V1.2,0.75,0.0001197,0.75,7.34e-05,0.75,0.0001197,0.75,0.000234,0.25,0.000334456,0.75,0.00537
hellaswag.val.8857,mistralai/mixtral-8x7b-chat,1.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00256
winogrande.dev.849,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,1.0,4.0352e-05,1.0,0.00053
mmlu-professional-law.val.541,WizardLM/WizardLM-13B-V1.2,0.0,6.96e-05,0.0,4.64e-05,0.0,6.96e-05,1.0,0.0001392,0.0,0.000180032,1.0,0.00233
hellaswag.val.5919,mistralai/mixtral-8x7b-chat,0.0,0.000147,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00249
hellaswag.val.9702,mistralai/mixtral-8x7b-chat,1.0,0.0001397999999999,1.0,4.660000000000001e-05,1.0,6.989999999999999e-05,1.0,0.0001397999999999,1.0,0.000180808,1.0,0.00234
mmlu-college-biology.val.113,mistralai/mixtral-8x7b-chat,1.0,9.66e-05,1.0,3.2200000000000003e-05,1.0,4.83e-05,1.0,9.66e-05,0.0,0.000124936,1.0,0.00162
mmlu-global-facts.val.61,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
grade-school-math.dev.1828,WizardLM/WizardLM-13B-V1.2,0.25,0.0002166,0.25,0.0001098,0.25,0.0002166,0.25,0.0002844,0.25,0.000369376,0.25,0.02321
mmlu-moral-disputes.val.53,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00139
grade-school-math.dev.1385,WizardLM/WizardLM-13B-V1.2,0.25,0.0002007,0.25,0.0001064,0.25,0.0002007,0.75,0.0002729999999999,0.25,0.000433784,0.75,0.0125499999999999
mmlu-virology.val.19,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-human-aging.val.54,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.3375,meta/code-llama-instruct-34b-chat,0.75,0.000331352,0.5,9.16e-05,0.75,0.0001481999999999,0.75,0.0002819999999999,0.75,0.000331352,0.5,0.0069599999999999
grade-school-math.dev.933,mistralai/mistral-7b-chat,0.5,9.58e-05,0.5,9.58e-05,0.75,0.0001487999999999,0.75,0.0002622,0.75,0.00035308,0.75,0.00884
mmlu-high-school-macroeconomics.val.252,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.6985,mistralai/mistral-7b-chat,1.0,6.2e-05,1.0,6.2e-05,1.0,9.3e-05,1.0,0.000186,0.0,0.00024056,1.0,0.00314
hellaswag.val.3963,WizardLM/WizardLM-13B-V1.2,0.0,6.599999999999999e-05,0.0,4.4000000000000006e-05,0.0,6.599999999999999e-05,1.0,0.0001319999999999,0.0,0.00017072,1.0,0.00221
hellaswag.val.1123,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.9e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.6670,mistralai/mixtral-8x7b-chat,0.0,0.0001416,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-nutrition.val.93,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
grade-school-math.dev.4478,meta/code-llama-instruct-34b-chat,0.25,0.000396536,0.25,0.0001292,0.25,0.0001782,1.0,0.0002111999999999,0.25,0.000396536,0.75,0.00902
hellaswag.val.7529,mistralai/mixtral-8x7b-chat,1.0,0.0001344,1.0,4.480000000000001e-05,1.0,6.689999999999999e-05,1.0,0.0001344,1.0,0.0001738239999999,1.0,0.00228
grade-school-math.dev.4519,mistralai/mixtral-8x7b-chat,0.25,0.0002232,0.25,7.9e-05,0.25,0.0001392,0.25,0.0002232,0.25,0.000272376,0.75,0.00846
mmlu-formal-logic.val.39,mistralai/mixtral-8x7b-chat,1.0,9.96e-05,0.0,3.320000000000001e-05,0.0,4.98e-05,1.0,9.96e-05,0.0,0.000128816,0.0,0.00167
mmlu-high-school-microeconomics.val.105,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
arc-challenge.test.90,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-college-medicine.val.161,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.3114,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.45e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
hellaswag.val.4062,mistralai/mixtral-8x7b-chat,0.0,0.0001709999999999,0.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001709999999999,0.0,0.00022116,0.0,0.00286
grade-school-math.dev.6584,mistralai/mistral-7b-chat,0.25,9.26e-05,0.25,9.26e-05,0.75,0.0001733999999999,0.5,0.0002562,0.75,0.000344544,0.75,0.00969
mmlu-moral-scenarios.val.720,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00139
mmlu-professional-law.val.787,WizardLM/WizardLM-13B-V1.2,0.0,5.64e-05,1.0,3.7600000000000006e-05,0.0,5.64e-05,1.0,0.0001127999999999,0.0,0.000145888,1.0,0.00189
grade-school-math.dev.6473,WizardLM/WizardLM-13B-V1.2,0.75,0.0001545,0.25,8.16e-05,0.75,0.0001545,0.75,0.0003323999999999,0.25,0.000346872,0.75,0.00937
mmlu-high-school-us-history.val.142,WizardLM/WizardLM-13B-V1.2,0.0,0.0001047,0.0,6.98e-05,0.0,0.0001047,1.0,0.0002094,0.0,0.0002708239999999,1.0,0.0035
mmlu-professional-medicine.val.252,WizardLM/WizardLM-13B-V1.2,0.0,7.649999999999999e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-prehistory.val.101,mistralai/mixtral-8x7b-chat,0.0,6.12e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.7021,WizardLM/WizardLM-13B-V1.2,0.75,0.0001331999999999,0.25,0.0001248,0.75,0.0001331999999999,0.75,0.0002616,0.25,0.000292552,0.75,0.00723
hellaswag.val.9113,mistralai/mixtral-8x7b-chat,0.0,0.0001572,0.0,5.24e-05,0.0,7.829999999999999e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
mmlu-sociology.val.119,mistralai/mistral-7b-chat,1.0,1.6000000000000003e-05,1.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-professional-law.val.732,WizardLM/WizardLM-13B-V1.2,1.0,0.0001356,0.0,9.04e-05,1.0,0.0001356,1.0,0.0002712,0.0,0.0003507519999999,1.0,0.0045299999999999
mmlu-marketing.val.6,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
hellaswag.val.2757,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,0.0,3.69e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
arc-challenge.test.687,mistralai/mistral-7b-chat,1.0,1.18e-05,1.0,1.18e-05,1.0,1.77e-05,1.0,3.54e-05,1.0,4.5784e-05,1.0,0.00063
mmlu-computer-security.val.70,mistralai/mixtral-8x7b-chat,1.0,9.3e-05,1.0,3.1e-05,0.0,4.65e-05,1.0,9.3e-05,0.0,0.00012028,1.0,0.0015899999999999
grade-school-math.dev.317,WizardLM/WizardLM-13B-V1.2,0.25,0.0001461,0.25,6.98e-05,0.25,0.0001461,0.75,0.0003228,0.25,0.000305744,0.75,0.01073
arc-challenge.test.6,mistralai/mixtral-8x7b-chat,1.0,8.1e-05,1.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,1.0,0.0001047599999999,1.0,0.00136
hellaswag.val.9303,mistralai/mixtral-8x7b-chat,0.0,0.0001518,0.0,5.06e-05,0.0,7.59e-05,0.0,0.0001518,0.0,0.000196328,0.0,0.00257
hellaswag.val.5080,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.00253
winogrande.dev.1238,mistralai/mixtral-8x7b-chat,0.0,3.12e-05,0.0,1.04e-05,0.0,1.56e-05,0.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
winogrande.dev.71,mistralai/mixtral-8x7b-chat,0.0,3.24e-05,0.0,1.08e-05,0.0,1.62e-05,0.0,3.24e-05,0.0,4.1904e-05,1.0,0.0005499999999999
mmlu-philosophy.val.289,mistralai/mixtral-8x7b-chat,1.0,0.0001278,1.0,4.2600000000000005e-05,1.0,6.39e-05,1.0,0.0001278,0.0,0.000165288,1.0,0.00214
grade-school-math.dev.3374,mistralai/mixtral-8x7b-chat,0.5,0.0002634,0.5,7.98e-05,0.75,0.0001329,0.5,0.0002634,0.5,0.000297984,0.75,0.00723
mmlu-machine-learning.val.85,mistralai/mixtral-8x7b-chat,0.0,6.3e-05,0.0,2.1e-05,0.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,0.0,0.00106
mmlu-global-facts.val.97,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
arc-challenge.test.1017,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-anatomy.val.42,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-elementary-mathematics.val.153,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.3808e-05,1.0,0.0011
mmlu-professional-law.val.576,WizardLM/WizardLM-13B-V1.2,1.0,7.439999999999999e-05,0.0,4.9600000000000006e-05,1.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00249
hellaswag.val.7750,WizardLM/WizardLM-13B-V1.2,0.0,6.48e-05,0.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,0.0,0.0022
grade-school-math.dev.1568,WizardLM/WizardLM-13B-V1.2,0.75,0.0002034,0.75,9.12e-05,0.75,0.0002034,0.5,0.0003138,0.25,0.000324368,0.75,0.01226
mmlu-professional-law.val.473,mistralai/mistral-7b-chat,0.0,5.1800000000000005e-05,0.0,5.1800000000000005e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-high-school-chemistry.val.133,mistralai/mixtral-8x7b-chat,0.0,0.0001248,0.0,4.160000000000001e-05,1.0,6.24e-05,0.0,0.0001248,0.0,0.0001614079999999,0.0,0.00209
mmlu-moral-disputes.val.184,mistralai/mixtral-8x7b-chat,1.0,0.000108,0.0,3.600000000000001e-05,0.0,5.4e-05,1.0,0.000108,0.0,0.00013968,1.0,0.00181
mmlu-moral-scenarios.val.63,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00149
mmlu-high-school-computer-science.val.52,WizardLM/WizardLM-13B-V1.2,1.0,2.13e-05,0.0,1.42e-05,1.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.6252,WizardLM/WizardLM-13B-V1.2,0.25,0.0001638,0.25,9.92e-05,0.25,0.0001638,0.25,0.0003006,0.25,0.000371704,0.75,0.01042
mmlu-moral-disputes.val.209,mistralai/mistral-7b-chat,1.0,2.2600000000000004e-05,1.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.6153,WizardLM/WizardLM-13B-V1.2,0.25,0.0001626,0.25,0.0001016,0.25,0.0001626,0.75,0.0002322,0.25,0.000315832,0.5,0.00845
mmlu-miscellaneous.val.596,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
grade-school-math.dev.487,mistralai/mistral-7b-chat,0.25,8.38e-05,0.25,8.38e-05,0.25,0.0001595999999999,0.25,0.0002514,0.25,0.000284016,0.25,0.00884
grade-school-math.dev.2301,mistralai/mistral-7b-chat,0.75,9.74e-05,0.75,9.74e-05,0.25,0.0001754999999999,0.25,0.000261,0.25,0.0002824639999999,0.75,0.0088
mmlu-professional-law.val.846,WizardLM/WizardLM-13B-V1.2,0.0,0.0001250999999999,0.0,8.34e-05,0.0,0.0001250999999999,0.0,0.0002501999999999,0.0,0.000323592,0.0,0.00418
hellaswag.val.3986,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.92e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00268
grade-school-math.dev.7024,mistralai/mixtral-8x7b-chat,0.25,0.0002934,0.75,8.82e-05,0.25,0.0001797,0.25,0.0002934,0.25,0.000320488,0.5,0.0060199999999999
grade-school-math.dev.7106,mistralai/mixtral-8x7b-chat,0.5,0.0002045999999999,0.75,6.92e-05,0.75,0.0001352999999999,0.5,0.0002045999999999,0.75,0.000257632,0.75,0.00499
grade-school-math.dev.235,mistralai/mistral-7b-chat,0.25,9.24e-05,0.25,9.24e-05,0.25,0.0001505999999999,0.25,0.0002885999999999,0.25,0.000328248,0.25,0.0076
hellaswag.val.2298,mistralai/mixtral-8x7b-chat,0.0,7.02e-05,0.0,2.34e-05,0.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00118
hellaswag.val.3174,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,0.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
mmlu-high-school-computer-science.val.77,mistralai/mistral-7b-chat,1.0,3.78e-05,1.0,3.78e-05,1.0,5.67e-05,1.0,0.0001134,0.0,0.000146664,1.0,0.0019
hellaswag.val.7268,WizardLM/WizardLM-13B-V1.2,0.0,7.83e-05,0.0,5.220000000000001e-05,0.0,7.83e-05,0.0,0.0001566,0.0,0.000202536,1.0,0.00262
mmlu-professional-psychology.val.313,WizardLM/WizardLM-13B-V1.2,0.0,6.57e-05,1.0,4.380000000000001e-05,0.0,6.57e-05,1.0,0.0001314,0.0,0.0001699439999999,1.0,0.00223
hellaswag.val.6837,mistralai/mixtral-8x7b-chat,1.0,0.0001733999999999,0.0,5.780000000000001e-05,0.0,8.669999999999999e-05,1.0,0.0001733999999999,0.0,0.000224264,1.0,0.0029
grade-school-math.dev.5973,WizardLM/WizardLM-13B-V1.2,0.25,0.000147,0.25,0.0001038,0.25,0.000147,0.25,0.0002064,0.25,0.000274704,0.75,0.00647
arc-challenge.val.4,mistralai/mistral-7b-chat,1.0,2.02e-05,1.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.4102,mistralai/mistral-7b-chat,1.0,5.420000000000001e-05,1.0,5.420000000000001e-05,1.0,8.13e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00275
mmlu-high-school-psychology.val.52,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
hellaswag.val.7337,mistralai/mistral-7b-chat,0.0,4.520000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,1.0,0.00227
winogrande.dev.1253,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,0.0,3.5696000000000005e-05,1.0,0.00051
hellaswag.val.9856,mistralai/mistral-7b-chat,1.0,5.160000000000001e-05,1.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00262
grade-school-math.dev.5584,meta/code-llama-instruct-34b-chat,0.25,0.000377912,0.25,0.000105,0.25,0.0001785,0.5,0.0002646,0.25,0.000377912,0.5,0.00765
mmlu-philosophy.val.191,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
hellaswag.val.5552,mistralai/mixtral-8x7b-chat,0.0,0.0001386,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,1.0,0.00232
winogrande.dev.802,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.7248e-05,1.0,0.0005
mmlu-high-school-biology.val.154,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-professional-law.val.673,mistralai/mistral-7b-chat,0.0,5.480000000000001e-05,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,0.0,0.00278
hellaswag.val.7217,mistralai/mixtral-8x7b-chat,1.0,0.0001614,1.0,5.380000000000001e-05,1.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,0.0,0.0027
mmlu-professional-law.val.1122,WizardLM/WizardLM-13B-V1.2,0.0,0.0001364999999999,0.0,9.1e-05,0.0,0.0001364999999999,0.0,0.0002729999999999,0.0,0.00035308,0.0,0.00456
grade-school-math.dev.155,mistralai/mixtral-8x7b-chat,0.25,0.0002874,0.75,7.300000000000001e-05,0.25,0.0001683,0.25,0.0002874,0.25,0.000331352,0.5,0.00719
mmlu-professional-law.val.899,mistralai/mistral-7b-chat,0.0,5.94e-05,0.0,5.94e-05,0.0,8.91e-05,0.0,0.0001782,0.0,0.000230472,1.0,0.00298
mmlu-astronomy.val.52,mistralai/mixtral-8x7b-chat,1.0,6.720000000000001e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
hellaswag.val.8555,mistralai/mistral-7b-chat,0.0,4.720000000000001e-05,0.0,4.720000000000001e-05,0.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
hellaswag.val.8484,mistralai/mixtral-8x7b-chat,0.0,0.0001434,0.0,4.780000000000001e-05,0.0,7.17e-05,0.0,0.0001434,0.0,0.0001854639999999,1.0,0.0024
mmlu-business-ethics.val.64,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
mmlu-professional-law.val.1049,mistralai/mistral-7b-chat,1.0,5.9e-05,1.0,5.9e-05,0.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,0.0,0.00296
mmlu-conceptual-physics.val.8,mistralai/mixtral-8x7b-chat,1.0,3.96e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
mmlu-professional-law.val.952,WizardLM/WizardLM-13B-V1.2,0.0,8.31e-05,1.0,5.5400000000000005e-05,0.0,8.31e-05,1.0,0.0001656,0.0,0.000214952,1.0,0.00278
mmlu-sociology.val.133,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-miscellaneous.val.201,mistralai/mistral-7b-chat,0.0,1.24e-05,0.0,1.24e-05,0.0,1.86e-05,1.0,3.72e-05,0.0,4.8112e-05,1.0,0.0006299999999999
hellaswag.val.2325,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
mmlu-clinical-knowledge.val.198,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.1918,WizardLM/WizardLM-13B-V1.2,0.0,4.32e-05,0.0,2.9e-05,0.0,4.32e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00146
mmlu-professional-law.val.1377,WizardLM/WizardLM-13B-V1.2,0.0,7.47e-05,0.0,4.980000000000001e-05,0.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,0.0,0.0025
grade-school-math.dev.1812,WizardLM/WizardLM-13B-V1.2,0.75,0.0001404,0.25,6.900000000000001e-05,0.75,0.0001404,0.75,0.0002285999999999,0.75,0.0002716,0.5,0.00681
mmlu-international-law.val.50,mistralai/mixtral-8x7b-chat,1.0,6.6e-05,0.0,2.2e-05,1.0,3.3e-05,1.0,6.6e-05,0.0,8.536000000000001e-05,1.0,0.00114
hellaswag.val.2514,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.06e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
mmlu-miscellaneous.val.330,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,0.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
mmlu-professional-law.val.683,WizardLM/WizardLM-13B-V1.2,1.0,8.94e-05,0.0,5.9600000000000005e-05,1.0,8.94e-05,1.0,0.0001788,0.0,0.0002312479999999,1.0,0.00299
hellaswag.val.870,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.447,mistralai/mixtral-8x7b-chat,1.0,6.659999999999999e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
mmlu-high-school-european-history.val.137,WizardLM/WizardLM-13B-V1.2,1.0,0.0001064999999999,1.0,7.1e-05,1.0,0.0001064999999999,1.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
hellaswag.val.7586,WizardLM/WizardLM-13B-V1.2,0.0,8.34e-05,0.0,5.580000000000001e-05,0.0,8.34e-05,0.0,0.0001674,0.0,0.0002165039999999,1.0,0.0028
mmlu-conceptual-physics.val.180,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
mmlu-world-religions.val.151,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-miscellaneous.val.655,mistralai/mixtral-8x7b-chat,1.0,4.56e-05,1.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.8470,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.391,WizardLM/WizardLM-13B-V1.2,0.75,0.000144,0.25,6.560000000000001e-05,0.75,0.000144,0.25,0.0002201999999999,0.25,0.00026384,0.75,0.00723
mmlu-professional-law.val.817,WizardLM/WizardLM-13B-V1.2,0.0,7.86e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
hellaswag.val.4281,mistralai/mistral-7b-chat,1.0,4.56e-05,1.0,4.56e-05,1.0,6.809999999999999e-05,1.0,0.0001368,1.0,0.000176928,1.0,0.00232
mmlu-high-school-psychology.val.122,mistralai/mistral-7b-chat,1.0,2.8600000000000004e-05,1.0,2.8600000000000004e-05,1.0,4.29e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00147
mmlu-high-school-us-history.val.59,mistralai/mixtral-8x7b-chat,0.0,0.0002633999999999,0.0,8.78e-05,0.0,0.0001316999999999,0.0,0.0002633999999999,0.0,0.000340664,1.0,0.0043999999999999
mmlu-professional-law.val.96,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
grade-school-math.dev.683,WizardLM/WizardLM-13B-V1.2,0.75,0.0001605,0.25,6.86e-05,0.75,0.0001605,0.5,0.0002309999999999,0.25,0.000262288,0.5,0.0063
mmlu-human-aging.val.146,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-college-chemistry.val.99,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-sociology.val.137,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
grade-school-math.dev.5486,meta/code-llama-instruct-34b-chat,0.75,0.0003298,0.75,9.18e-05,0.5,0.0001539,0.75,0.0002676,0.75,0.0003298,0.75,0.0077
mmlu-professional-law.val.1269,WizardLM/WizardLM-13B-V1.2,0.0,0.0001004999999999,0.0,6.7e-05,0.0,0.0001004999999999,0.0,0.0002009999999999,0.0,0.00025996,1.0,0.00336
hellaswag.val.8324,mistralai/mistral-7b-chat,1.0,4.100000000000001e-05,1.0,4.100000000000001e-05,1.0,6.149999999999999e-05,1.0,0.0001229999999999,1.0,0.0001590799999999,1.0,0.00209
grade-school-math.dev.1534,meta/code-llama-instruct-34b-chat,0.25,0.000392656,0.25,0.0001036,0.25,0.0001220999999999,0.75,0.0002423999999999,0.25,0.000392656,0.75,0.00729
hellaswag.val.6200,mistralai/mistral-7b-chat,0.0,4.84e-05,0.0,4.84e-05,0.0,7.23e-05,1.0,0.0001452,0.0,0.000187792,1.0,0.00243
grade-school-math.dev.1704,mistralai/mistral-7b-chat,0.5,8.74e-05,0.5,8.74e-05,0.5,0.0001587,0.5,0.0002795999999999,0.25,0.000415936,0.75,0.00797
mmlu-philosophy.val.233,mistralai/mixtral-8x7b-chat,1.0,6.24e-05,1.0,2.08e-05,0.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-professional-law.val.1272,WizardLM/WizardLM-13B-V1.2,0.0,9.42e-05,0.0,6.280000000000001e-05,0.0,9.42e-05,1.0,0.0001884,0.0,0.000243664,1.0,0.00315
mmlu-security-studies.val.134,mistralai/mistral-7b-chat,1.0,3.5000000000000004e-05,1.0,3.5000000000000004e-05,1.0,5.25e-05,1.0,0.000105,0.0,0.0001357999999999,1.0,0.00176
grade-school-math.dev.4083,WizardLM/WizardLM-13B-V1.2,0.25,0.000153,0.25,9.9e-05,0.25,0.000153,0.25,0.000279,0.25,0.000332904,0.75,0.01023
mmlu-professional-law.val.1241,WizardLM/WizardLM-13B-V1.2,0.0,7.59e-05,0.0,5.06e-05,0.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
mmlu-moral-scenarios.val.307,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,1.0,4.11e-05,1.0,8.22e-05,0.0,0.000106312,1.0,0.00141
mmlu-high-school-psychology.val.195,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-high-school-psychology.val.352,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-college-computer-science.val.52,WizardLM/WizardLM-13B-V1.2,1.0,5.34e-05,0.0,3.5600000000000005e-05,1.0,5.34e-05,1.0,0.0001068,0.0,0.0001381279999999,1.0,0.00179
grade-school-math.dev.2528,WizardLM/WizardLM-13B-V1.2,0.75,0.0001409999999999,0.25,7.66e-05,0.75,0.0001409999999999,0.75,0.000222,0.25,0.0002747039999999,0.75,0.007
hellaswag.val.8239,mistralai/mixtral-8x7b-chat,0.0,0.0001584,0.0,5.280000000000001e-05,0.0,7.89e-05,0.0,0.0001584,0.0,0.000204864,1.0,0.00265
hellaswag.val.3450,WizardLM/WizardLM-13B-V1.2,0.0,7.859999999999999e-05,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
mmlu-clinical-knowledge.val.170,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.6941,meta/code-llama-instruct-34b-chat,0.75,0.000336784,0.25,9.02e-05,0.75,0.0001227,0.5,0.0002111999999999,0.75,0.000336784,0.75,0.00646
mmlu-moral-scenarios.val.88,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
mmlu-astronomy.val.7,mistralai/mixtral-8x7b-chat,0.0,7.5e-05,0.0,2.5e-05,1.0,3.75e-05,0.0,7.5e-05,0.0,9.7e-05,1.0,0.00126
mmlu-professional-psychology.val.7,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
arc-challenge.test.1081,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,1.0,6.9064e-05,1.0,0.0009
grade-school-math.dev.3221,meta/code-llama-instruct-34b-chat,0.25,0.000286344,0.25,0.0001078,0.5,0.0001422,0.25,0.0002075999999999,0.25,0.000286344,0.75,0.00697
mmlu-professional-law.val.955,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,0.0,0.0013599999999999
hellaswag.val.9575,WizardLM/WizardLM-13B-V1.2,0.0,8.669999999999998e-05,0.0,5.800000000000001e-05,0.0,8.669999999999998e-05,1.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
mmlu-high-school-psychology.val.544,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-international-law.val.94,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.7353,WizardLM/WizardLM-13B-V1.2,0.25,0.0001532999999999,0.25,9.86e-05,0.25,0.0001532999999999,0.25,0.0002975999999999,0.25,0.000329024,0.75,0.0098
hellaswag.val.7070,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,1.0,5.680000000000001e-05,0.0,8.52e-05,1.0,0.0001704,1.0,0.0002203839999999,1.0,0.00288
hellaswag.val.1835,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.6893,WizardLM/WizardLM-13B-V1.2,0.75,0.0001413,0.25,5.58e-05,0.75,0.0001413,0.25,0.000195,0.75,0.000334456,0.75,0.0066599999999999
consensus_summary.dev.71,mistralai/mistral-7b-chat,0.75,6.36e-05,0.75,6.36e-05,0.75,0.0001014,0.75,0.0001889999999999,0.75,0.000280136,0.75,0.00758
mmlu-professional-accounting.val.243,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
hellaswag.val.6731,WizardLM/WizardLM-13B-V1.2,0.0,7.02e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
hellaswag.val.694,WizardLM/WizardLM-13B-V1.2,1.0,3e-05,1.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00104
hellaswag.val.9992,WizardLM/WizardLM-13B-V1.2,1.0,7.92e-05,1.0,5.280000000000001e-05,1.0,7.92e-05,1.0,0.0001584,1.0,0.000204864,1.0,0.00268
hellaswag.val.8869,mistralai/mixtral-8x7b-chat,1.0,0.0001728,1.0,5.76e-05,1.0,8.64e-05,1.0,0.0001728,1.0,0.0002234879999999,1.0,0.00292
grade-school-math.dev.5128,WizardLM/WizardLM-13B-V1.2,0.75,0.0001598999999999,0.25,8.300000000000001e-05,0.75,0.0001598999999999,0.75,0.0002705999999999,0.25,0.0003127279999999,0.75,0.00766
grade-school-math.dev.7103,WizardLM/WizardLM-13B-V1.2,0.25,0.0001532999999999,0.25,9.32e-05,0.25,0.0001532999999999,0.75,0.0002663999999999,0.25,0.000342216,0.75,0.00659
arc-challenge.test.39,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
grade-school-math.dev.895,mistralai/mixtral-8x7b-chat,0.25,0.0002892,0.25,0.0001054,0.75,0.0001785,0.25,0.0002892,0.75,0.000351528,0.75,0.00838
mmlu-professional-law.val.1362,WizardLM/WizardLM-13B-V1.2,0.0,6.51e-05,0.0,4.340000000000001e-05,0.0,6.51e-05,0.0,0.0001302,0.0,0.0001683919999999,0.0,0.00218
mmlu-marketing.val.209,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-high-school-psychology.val.290,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00092
hellaswag.val.6417,mistralai/mistral-7b-chat,0.0,4.8200000000000006e-05,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
mmlu-professional-law.val.1526,mistralai/mixtral-8x7b-chat,0.0,0.0001524,1.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,0.0,0.00255
hellaswag.val.2360,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.67e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-us-foreign-policy.val.46,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,1.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.5588,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-high-school-computer-science.val.60,mistralai/mistral-7b-chat,0.0,1.6000000000000003e-05,0.0,1.6000000000000003e-05,1.0,2.4e-05,1.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
mmlu-high-school-european-history.val.113,mistralai/mixtral-8x7b-chat,1.0,0.0002033999999999,0.0,6.780000000000001e-05,1.0,0.0001016999999999,1.0,0.0002033999999999,0.0,0.000263064,1.0,0.0034
hellaswag.val.8950,mistralai/mistral-7b-chat,0.0,4.600000000000001e-05,0.0,4.600000000000001e-05,0.0,6.9e-05,0.0,0.000138,0.0,0.0001784799999999,1.0,0.00234
arc-challenge.test.1034,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.5409,mistralai/mixtral-8x7b-chat,1.0,0.0001662,1.0,5.5400000000000005e-05,1.0,8.31e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00281
mmlu-moral-scenarios.val.112,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.23e-05,0.0,8.46e-05,0.0,0.000109416,0.0,0.00145
mmlu-high-school-geography.val.39,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.7263,WizardLM/WizardLM-13B-V1.2,0.0,8.58e-05,0.0,5.720000000000001e-05,0.0,8.58e-05,0.0,0.0001716,0.0,0.000221936,1.0,0.00287
mmlu-formal-logic.val.67,mistralai/mistral-7b-chat,1.0,3e-05,1.0,3e-05,1.0,4.5e-05,0.0,9e-05,0.0,0.0001164,0.0,0.00151
mmlu-medical-genetics.val.94,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-moral-scenarios.val.785,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.00141
mmlu-professional-law.val.953,WizardLM/WizardLM-13B-V1.2,0.0,0.0001397999999999,0.0,9.32e-05,0.0,0.0001397999999999,0.0,0.0002795999999999,0.0,0.000361616,0.0,0.00467
grade-school-math.dev.5980,mistralai/mistral-7b-chat,0.25,7.520000000000001e-05,0.25,7.520000000000001e-05,0.75,0.0001305,0.75,0.0002375999999999,0.75,0.000299536,0.75,0.00526
mmlu-college-computer-science.val.58,mistralai/mixtral-8x7b-chat,0.0,8.4e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.00141
hellaswag.val.9680,mistralai/mistral-7b-chat,1.0,4.7e-05,1.0,4.7e-05,1.0,7.049999999999999e-05,0.0,0.0001409999999999,1.0,0.0001823599999999,1.0,0.00239
hellaswag.val.9899,mistralai/mistral-7b-chat,0.0,5.300000000000001e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
grade-school-math.dev.7368,mistralai/mistral-7b-chat,0.0,6.720000000000001e-05,0.0,6.720000000000001e-05,0.75,0.0001623,0.25,0.0002862,0.25,0.0002467679999999,0.75,0.00705
hellaswag.val.238,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,1.0,6e-05,1.0,7.76e-05,1.0,0.00101
hellaswag.val.6480,mistralai/mistral-7b-chat,0.0,5.44e-05,0.0,5.44e-05,0.0,8.16e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00276
grade-school-math.dev.746,mistralai/mixtral-8x7b-chat,0.75,0.0002568,0.25,8.02e-05,0.75,0.000159,0.75,0.0002568,0.25,0.0005137119999999,0.75,0.00703
mmlu-business-ethics.val.70,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,0.0,4.98e-05,0.0,6.4408e-05,0.0,0.0008399999999999
mmlu-moral-scenarios.val.656,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00139
hellaswag.val.2357,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,0.0,8.0704e-05,1.0,0.00108
hellaswag.val.5085,mistralai/mixtral-8x7b-chat,1.0,0.0001848,1.0,6.159999999999999e-05,1.0,9.24e-05,1.0,0.0001848,1.0,0.000239008,1.0,0.00309
grade-school-math.dev.2424,meta/code-llama-instruct-34b-chat,0.25,0.000339888,0.25,9.68e-05,0.25,0.0001428,0.75,0.0002706,0.25,0.000339888,0.5,0.00717
grade-school-math.dev.6107,mistralai/mistral-7b-chat,0.25,7.8e-05,0.25,7.8e-05,0.75,0.0001508999999999,0.25,0.000213,0.75,0.000370152,0.75,0.0081199999999999
mmlu-moral-disputes.val.241,mistralai/mistral-7b-chat,0.0,1.4e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
grade-school-math.dev.4299,mistralai/mistral-7b-chat,0.25,0.0001008,0.25,0.0001008,0.25,0.0002058,0.25,0.0004307999999999,0.25,0.000450856,1.0,0.018
mmlu-sociology.val.7,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,0.0,0.00104
mbpp.dev.405,mistralai/mistral-7b-chat,0.0,7.000000000000001e-05,0.0,7.000000000000001e-05,0.0,0.0001220999999999,0.0,3.6e-05,0.0,0.000198656,1.0,0.00986
hellaswag.val.5627,mistralai/mistral-7b-chat,1.0,5.84e-05,1.0,5.84e-05,1.0,8.76e-05,1.0,0.0001752,1.0,0.000226592,1.0,0.00293
mmlu-high-school-biology.val.32,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mtbench-math.dev.9,WizardLM/WizardLM-13B-V1.2,1.0,0.0001808999999999,0.8,9.52e-05,1.0,0.0001808999999999,1.0,0.0003863999999999,1.0,0.0004656,1.0,0.02105
winogrande.dev.766,mistralai/mixtral-8x7b-chat,0.0,3.3e-05,0.0,1.1e-05,0.0,1.65e-05,0.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00059
mmlu-international-law.val.92,mistralai/mistral-7b-chat,0.0,2.4800000000000003e-05,0.0,2.4800000000000003e-05,1.0,3.72e-05,1.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
mmlu-high-school-us-history.val.54,WizardLM/WizardLM-13B-V1.2,0.0,6.989999999999999e-05,1.0,4.660000000000001e-05,0.0,6.989999999999999e-05,1.0,0.0001397999999999,0.0,0.000180808,1.0,0.00234
mmlu-business-ethics.val.7,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
hellaswag.val.3974,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00264
grade-school-math.dev.5145,meta/code-llama-instruct-34b-chat,0.75,0.000404296,0.75,9.7e-05,0.75,0.0002045999999999,0.25,0.0003497999999999,0.75,0.000404296,0.75,0.01215
grade-school-math.dev.6166,mistralai/mistral-7b-chat,0.25,9.7e-05,0.25,9.7e-05,0.25,0.0001818,0.75,0.0002994,0.25,0.0003049679999999,0.5,0.0083699999999999
mmlu-high-school-statistics.val.24,mistralai/mistral-7b-chat,0.0,3.2600000000000006e-05,0.0,3.2600000000000006e-05,0.0,4.89e-05,0.0,9.78e-05,0.0,0.0001264879999999,1.0,0.00167
mtbench.dev.28,mistralai/mistral-7b-chat,0.7,0.0001208,0.7,0.0001208,0.4,0.0003063,0.9,0.000525,0.8,0.001001816,1.0,0.04296
mmlu-professional-law.val.1125,WizardLM/WizardLM-13B-V1.2,0.0,9.78e-05,0.0,6.52e-05,0.0,9.78e-05,1.0,0.0001956,0.0,0.0002529759999999,1.0,0.00327
mmlu-high-school-biology.val.83,mistralai/mixtral-8x7b-chat,1.0,8.4e-05,1.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
mmlu-professional-law.val.829,mistralai/mistral-7b-chat,0.0,4.2600000000000005e-05,0.0,4.2600000000000005e-05,0.0,6.39e-05,1.0,0.0001278,0.0,0.000165288,1.0,0.00214
winogrande.dev.246,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00051
mmlu-human-sexuality.val.92,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
hellaswag.val.9830,mistralai/mistral-7b-chat,0.0,5.24e-05,0.0,5.24e-05,0.0,7.86e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00263
grade-school-math.dev.5041,mistralai/mixtral-8x7b-chat,0.25,0.0003,0.25,0.0001134,0.25,0.0002028,0.25,0.0003,0.25,0.000326696,0.75,0.01055
bias_detection.dev.52,mistralai/mistral-7b-chat,0.0,5.28e-05,0.0,5.28e-05,0.0,9.69e-05,0.0,0.0001649999999999,0.0,0.000224264,0.0,0.00761
hellaswag.val.5459,mistralai/mixtral-8x7b-chat,1.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,1.0,0.00264
mmlu-moral-scenarios.val.308,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
winogrande.dev.214,mistralai/mistral-7b-chat,1.0,1.06e-05,1.0,1.06e-05,1.0,1.56e-05,1.0,3.18e-05,0.0,4.0352e-05,1.0,0.00054
grade-school-math.dev.2267,mistralai/mistral-7b-chat,0.25,0.0001222,0.25,0.0001222,0.75,0.0001851,0.25,0.0004284,0.75,0.00039576,0.75,0.00984
winogrande.dev.196,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,1.0,2.82e-05,0.0,3.5696000000000005e-05,0.0,0.00051
mmlu-management.val.86,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
hellaswag.val.7825,mistralai/mixtral-8x7b-chat,0.0,0.0001709999999999,0.0,5.7e-05,0.0,8.519999999999998e-05,0.0,0.0001709999999999,0.0,0.00022116,1.0,0.00286
mmlu-professional-law.val.1387,WizardLM/WizardLM-13B-V1.2,0.0,0.0001026,0.0,6.84e-05,0.0,0.0001026,0.0,0.0002052,0.0,0.000265392,0.0,0.00343
hellaswag.val.2013,mistralai/mixtral-8x7b-chat,1.0,7.740000000000001e-05,0.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
mmlu-international-law.val.60,mistralai/mistral-7b-chat,1.0,2.1600000000000003e-05,1.0,2.1600000000000003e-05,1.0,3.21e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00112
grade-school-math.dev.4803,WizardLM/WizardLM-13B-V1.2,0.25,0.0001656,0.0,9.880000000000002e-05,0.25,0.0001656,0.25,0.000261,0.25,0.000358512,0.25,0.00925
mmlu-professional-law.val.1061,WizardLM/WizardLM-13B-V1.2,1.0,0.0001076999999999,0.0,7.18e-05,1.0,0.0001076999999999,0.0,0.0002153999999999,0.0,0.0002785839999999,1.0,0.0036
mmlu-high-school-us-history.val.26,mistralai/mixtral-8x7b-chat,1.0,0.0001889999999999,1.0,6.3e-05,1.0,9.45e-05,1.0,0.0001889999999999,0.0,0.00024444,1.0,0.00316
mmlu-professional-law.val.181,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
winogrande.dev.945,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,0.0,1.5e-05,0.0,3e-05,1.0,3.880000000000001e-05,0.0,0.00051
mmlu-medical-genetics.val.52,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-professional-law.val.739,mistralai/mistral-7b-chat,0.0,4.520000000000001e-05,0.0,4.520000000000001e-05,0.0,6.780000000000001e-05,0.0,0.0001356,0.0,0.000175376,0.0,0.00227
hellaswag.val.5422,mistralai/mixtral-8x7b-chat,0.0,0.0001356,0.0,4.520000000000001e-05,0.0,6.75e-05,0.0,0.0001356,0.0,0.000175376,0.0,0.0023
grade-school-math.dev.7210,mistralai/mistral-7b-chat,0.25,8.640000000000001e-05,0.25,8.640000000000001e-05,0.5,0.0001482,0.25,0.0002172,0.25,0.000317384,0.75,0.00845
winogrande.dev.513,mistralai/mistral-7b-chat,1.0,1.1e-05,1.0,1.1e-05,0.0,1.65e-05,0.0,3.3e-05,1.0,4.2680000000000005e-05,0.0,0.00059
hellaswag.val.5384,mistralai/mixtral-8x7b-chat,0.0,0.0001326,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,0.0,0.00222
mmlu-high-school-mathematics.val.51,mistralai/mixtral-8x7b-chat,0.0,0.0001026,0.0,3.4200000000000005e-05,0.0,5.13e-05,0.0,0.0001026,0.0,0.000132696,0.0,0.00172
mmlu-professional-medicine.val.39,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,1.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.613,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
mmlu-electrical-engineering.val.23,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
mmlu-electrical-engineering.val.96,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,1.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,0.0,0.00091
hellaswag.val.722,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-high-school-mathematics.val.56,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.16e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-high-school-psychology.val.414,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
hellaswag.val.5626,mistralai/mixtral-8x7b-chat,0.0,0.0001919999999999,0.0,6.4e-05,0.0,9.569999999999998e-05,0.0,0.0001919999999999,0.0,0.00024832,1.0,0.00321
mmlu-marketing.val.38,mistralai/mistral-7b-chat,0.0,1.8800000000000003e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
hellaswag.val.9188,WizardLM/WizardLM-13B-V1.2,1.0,6.479999999999999e-05,0.0,4.340000000000001e-05,1.0,6.479999999999999e-05,1.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
mmlu-philosophy.val.49,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-philosophy.val.285,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-anatomy.val.94,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-psychology.val.71,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
hellaswag.val.3814,mistralai/mixtral-8x7b-chat,1.0,0.0001602,0.0,5.34e-05,0.0,8.01e-05,1.0,0.0001602,0.0,0.000207192,1.0,0.00271
mmlu-professional-law.val.501,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00232
hellaswag.val.5544,mistralai/mixtral-8x7b-chat,0.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.7418,mistralai/mistral-7b-chat,0.25,8.44e-05,0.25,8.44e-05,0.25,0.0001208999999999,0.25,0.0002496,0.25,0.000263064,0.75,0.00749
hellaswag.val.9493,mistralai/mixtral-8x7b-chat,1.0,0.000177,0.0,5.9e-05,1.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00299
grade-school-math.dev.7064,mistralai/mistral-7b-chat,0.25,7.7e-05,0.25,7.7e-05,0.75,0.000135,0.75,0.0002586,0.75,0.000295656,0.5,0.00808
winogrande.dev.978,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,0.0,1.53e-05,0.0,3.06e-05,1.0,3.9576e-05,1.0,0.00055
hellaswag.val.1985,mistralai/mistral-7b-chat,0.0,1.8e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-abstract-algebra.val.80,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00105
bias_detection.dev.68,mistralai/mistral-7b-chat,0.0,4.9e-05,0.0,4.9e-05,0.0,8.549999999999999e-05,0.0,0.0001583999999999,0.0,0.000250648,0.0,0.0073
grade-school-math.dev.7036,mistralai/mixtral-8x7b-chat,0.5,0.0002676,0.75,7.48e-05,0.5,0.0001629,0.5,0.0002676,0.5,0.000277032,0.5,0.00726
mmlu-professional-psychology.val.392,mistralai/mixtral-8x7b-chat,1.0,7.08e-05,0.0,2.36e-05,0.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
mmlu-professional-law.val.1328,WizardLM/WizardLM-13B-V1.2,0.0,6.72e-05,1.0,4.480000000000001e-05,0.0,6.72e-05,0.0,0.0001344,0.0,0.0001738239999999,1.0,0.00225
mmlu-miscellaneous.val.32,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-professional-law.val.269,WizardLM/WizardLM-13B-V1.2,1.0,9.69e-05,0.0,6.46e-05,1.0,9.69e-05,1.0,0.0001938,0.0,0.000250648,1.0,0.00324
hellaswag.val.3327,mistralai/mistral-7b-chat,0.0,5.76e-05,0.0,5.76e-05,0.0,8.609999999999999e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
hellaswag.val.5607,mistralai/mixtral-8x7b-chat,1.0,0.0001152,1.0,3.8400000000000005e-05,1.0,5.76e-05,1.0,0.0001152,1.0,0.0001489919999999,1.0,0.00196
mmlu-logical-fallacies.val.100,mistralai/mixtral-8x7b-chat,0.0,8.58e-05,1.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00147
grade-school-math.dev.6803,WizardLM/WizardLM-13B-V1.2,0.75,0.000141,0.75,8.779999999999999e-05,0.75,0.000141,0.75,0.0002724,0.75,0.000349976,0.75,0.0075999999999999
grade-school-math.dev.6125,WizardLM/WizardLM-13B-V1.2,0.5,0.0001761,0.25,0.0001162,0.5,0.0001761,0.75,0.0002874,0.25,0.00039576,0.75,0.0093099999999999
grade-school-math.dev.591,mistralai/mistral-7b-chat,0.75,9.92e-05,0.75,9.92e-05,0.25,0.0001574999999999,0.75,0.0002934,0.25,0.000309624,0.75,0.00977
hellaswag.val.5750,mistralai/mistral-7b-chat,1.0,5e-05,1.0,5e-05,0.0,7.5e-05,1.0,0.00015,1.0,0.000194,1.0,0.00251
mmlu-high-school-psychology.val.234,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.803,mistralai/mixtral-8x7b-chat,0.0,5.76e-05,1.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,1.0,7.4496e-05,1.0,0.001
hellaswag.val.4501,WizardLM/WizardLM-13B-V1.2,0.0,7.53e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00255
grade-school-math.dev.5431,WizardLM/WizardLM-13B-V1.2,0.75,0.0001746,0.25,9.6e-05,0.75,0.0001746,0.25,0.0002837999999999,0.75,0.000384896,0.75,0.0108
mmlu-professional-law.val.763,WizardLM/WizardLM-13B-V1.2,1.0,6.54e-05,0.0,4.36e-05,1.0,6.54e-05,1.0,0.0001308,0.0,0.000169168,1.0,0.00219
grade-school-math.dev.3455,mistralai/mistral-7b-chat,0.75,7.38e-05,0.75,7.38e-05,0.5,0.000123,0.25,0.0002333999999999,0.75,0.00032592,0.5,0.00503
mmlu-elementary-mathematics.val.175,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-professional-psychology.val.70,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,1.0,3.15e-05,0.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
hellaswag.val.636,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,0.0,0.00124
mmlu-business-ethics.val.94,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,0.0,0.00085
hellaswag.val.8499,mistralai/mistral-7b-chat,0.0,5.34e-05,0.0,5.34e-05,0.0,7.979999999999999e-05,0.0,0.0001602,0.0,0.000207192,0.0,0.00268
hellaswag.val.3530,WizardLM/WizardLM-13B-V1.2,0.0,8.280000000000001e-05,0.0,5.520000000000001e-05,0.0,8.280000000000001e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
mmlu-electrical-engineering.val.87,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,0.0,0.00094
hellaswag.val.5649,mistralai/mixtral-8x7b-chat,1.0,0.0001578,0.0,5.260000000000001e-05,0.0,7.89e-05,1.0,0.0001578,0.0,0.000204088,0.0,0.00264
hellaswag.val.2277,mistralai/mistral-7b-chat,1.0,1.7800000000000002e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,1.0,6.9064e-05,1.0,0.00093
mmlu-clinical-knowledge.val.252,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
hellaswag.val.1808,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.42e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.586,mistralai/mixtral-8x7b-chat,0.0,6.06e-05,0.0,2.02e-05,0.0,3e-05,0.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.6687,mistralai/mistral-7b-chat,0.0,5.080000000000001e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
grade-school-math.dev.6150,mistralai/mistral-7b-chat,0.75,0.000106,0.75,0.000106,0.25,0.0001713,0.5,0.0003462,0.75,0.00028712,0.75,0.00754
mmlu-astronomy.val.37,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-astronomy.val.104,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,0.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
winogrande.dev.818,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,1.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00053
hellaswag.val.1550,WizardLM/WizardLM-13B-V1.2,0.0,6.149999999999999e-05,0.0,4.100000000000001e-05,0.0,6.149999999999999e-05,0.0,0.0001229999999999,0.0,0.0001590799999999,1.0,0.00206
mmlu-nutrition.val.279,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00088
mmlu-college-medicine.val.98,mistralai/mixtral-8x7b-chat,1.0,8.04e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
grade-school-math.dev.3151,WizardLM/WizardLM-13B-V1.2,0.25,0.0002105999999999,0.25,9.94e-05,0.25,0.0002105999999999,0.25,0.0002993999999999,0.25,0.000436888,0.5,0.02373
hellaswag.val.2538,mistralai/mistral-7b-chat,1.0,2.62e-05,1.0,2.62e-05,0.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.0013499999999999
abstract2title.test.72,mistralai/mixtral-8x7b-chat,1.0,0.000267,1.0,8.78e-05,1.0,0.0001307999999999,1.0,0.000267,1.0,0.000339112,1.0,0.0051
hellaswag.val.7571,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00256
mmlu-high-school-physics.val.132,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.693,mistralai/mixtral-8x7b-chat,0.75,0.0001997999999999,0.25,5.560000000000001e-05,0.75,0.0001278,0.75,0.0001997999999999,0.25,0.000215728,0.5,0.00572
mmlu-elementary-mathematics.val.368,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mtbench-math.dev.12,meta/code-llama-instruct-34b-chat,0.1,0.000198656,0.1,7.16e-05,0.1,0.0002505,0.1,0.0002298,0.1,0.000198656,1.0,0.0151499999999999
mmlu-professional-law.val.798,WizardLM/WizardLM-13B-V1.2,1.0,0.0001628999999999,0.0,0.0001086,1.0,0.0001628999999999,0.0,0.0003257999999999,0.0,0.000421368,1.0,0.0054399999999999
grade-school-math.dev.7371,WizardLM/WizardLM-13B-V1.2,0.25,0.0001965,0.25,9.62e-05,0.25,0.0001965,0.25,0.0003467999999999,0.25,0.000371704,0.5,0.01158
grade-school-math.dev.4504,WizardLM/WizardLM-13B-V1.2,0.25,0.0001437,0.25,8.32e-05,0.25,0.0001437,0.25,0.0002766,0.25,0.000336008,0.75,0.00896
bias_detection.dev.213,mistralai/mistral-7b-chat,0.0,5.1e-05,0.0,5.1e-05,0.0,0.0001044,0.0,0.0001716,0.0,0.000237456,1.0,0.00885
arc-challenge.test.729,WizardLM/WizardLM-13B-V1.2,1.0,4.05e-05,1.0,2.6800000000000004e-05,1.0,4.05e-05,1.0,8.1e-05,1.0,0.0001047599999999,1.0,0.00136
hellaswag.val.9509,mistralai/mixtral-8x7b-chat,0.0,0.0001446,1.0,4.8200000000000006e-05,1.0,7.230000000000001e-05,0.0,0.0001446,1.0,0.000187016,1.0,0.00245
grade-school-math.dev.4537,WizardLM/WizardLM-13B-V1.2,0.25,0.000159,0.75,6.66e-05,0.25,0.000159,0.25,0.0002232,0.5,0.0003189359999999,0.5,0.0060199999999999
mmlu-professional-law.val.1270,WizardLM/WizardLM-13B-V1.2,0.0,5.61e-05,1.0,3.74e-05,0.0,5.61e-05,0.0,0.0001122,0.0,0.000145112,0.0,0.00188
mmlu-us-foreign-policy.val.50,mistralai/mixtral-8x7b-chat,1.0,8.46e-05,1.0,2.82e-05,1.0,4.23e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
abstract2title.test.142,mistralai/mixtral-8x7b-chat,1.0,0.0001662,1.0,5.28e-05,1.0,8.34e-05,1.0,0.0001662,1.0,0.000210296,1.0,0.0033
winogrande.dev.164,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,1.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,0.0,0.00052
mmlu-high-school-us-history.val.179,mistralai/mixtral-8x7b-chat,1.0,0.0002129999999999,0.0,7.1e-05,0.0,0.0001064999999999,1.0,0.0002129999999999,0.0,0.00027548,1.0,0.00356
grade-school-math.dev.2716,WizardLM/WizardLM-13B-V1.2,0.75,0.0001508999999999,0.25,0.000103,0.75,0.0001508999999999,0.25,0.0002219999999999,0.25,0.000241336,0.75,0.0065699999999999
hellaswag.val.8305,WizardLM/WizardLM-13B-V1.2,0.0,7.589999999999999e-05,0.0,5.080000000000001e-05,0.0,7.589999999999999e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
hellaswag.val.480,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
hellaswag.val.9084,mistralai/mixtral-8x7b-chat,1.0,0.0001386,0.0,4.6200000000000005e-05,0.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00232
mmlu-human-aging.val.9,mistralai/mixtral-8x7b-chat,1.0,6e-05,1.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
hellaswag.val.1625,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-professional-medicine.val.90,mistralai/mixtral-8x7b-chat,1.0,0.0001698,0.0,5.660000000000001e-05,0.0,8.49e-05,1.0,0.0001698,0.0,0.000219608,1.0,0.00284
mbpp.dev.153,mistralai/mistral-7b-chat,1.0,3.180000000000001e-05,1.0,3.180000000000001e-05,1.0,6.51e-05,1.0,0.0001272,1.0,0.000110968,1.0,0.00741
mmlu-professional-law.val.1082,mistralai/mistral-7b-chat,1.0,5.62e-05,1.0,5.62e-05,0.0,8.43e-05,1.0,0.0001686,0.0,0.000218056,1.0,0.00282
mmlu-high-school-psychology.val.410,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.0014
hellaswag.val.1153,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,0.0,0.0009299999999999
mmlu-professional-law.val.754,mistralai/mistral-7b-chat,0.0,5.280000000000001e-05,0.0,5.280000000000001e-05,1.0,7.92e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00265
mmlu-virology.val.14,mistralai/mistral-7b-chat,1.0,1.36e-05,1.0,1.36e-05,0.0,2.04e-05,0.0,4.08e-05,0.0,5.2768e-05,1.0,0.00072
grade-school-math.dev.1931,WizardLM/WizardLM-13B-V1.2,0.5,0.0002039999999999,0.25,0.0001326,0.5,0.0002039999999999,0.25,0.0003635999999999,0.25,0.0004229199999999,0.5,0.01256
hellaswag.val.476,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,0.0,5.16e-05,0.0,6.673599999999999e-05,0.0,0.00087
grade-school-math.dev.5359,WizardLM/WizardLM-13B-V1.2,0.75,0.0001593,0.75,0.0001074,0.75,0.0001593,0.25,0.0002652,0.25,0.000320488,0.75,0.00818
hellaswag.val.2446,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-moral-scenarios.val.799,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
hellaswag.val.3602,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,0.0,8.76e-05,0.0,0.0001752,0.0,0.000226592,1.0,0.00293
mmlu-professional-law.val.861,mistralai/mistral-7b-chat,1.0,3.68e-05,1.0,3.68e-05,0.0,5.52e-05,0.0,0.0001104,0.0,0.000142784,0.0,0.00185
mmlu-professional-law.val.658,mistralai/mistral-7b-chat,0.0,3.4000000000000007e-05,0.0,3.4000000000000007e-05,1.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,0.0,0.00171
grade-school-math.dev.4672,WizardLM/WizardLM-13B-V1.2,0.25,0.0001704,0.25,8.32e-05,0.25,0.0001704,0.75,0.0002982,0.25,0.000352304,0.5,0.01006
hellaswag.val.9355,mistralai/mixtral-8x7b-chat,1.0,0.0001572,0.0,5.24e-05,1.0,7.86e-05,1.0,0.0001572,0.0,0.000203312,1.0,0.00263
grade-school-math.dev.6020,mistralai/mistral-7b-chat,0.25,0.0001034,0.25,0.0001034,0.75,0.000168,0.25,0.000285,0.25,0.00031428,0.75,0.00872
mmlu-conceptual-physics.val.133,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.2940,mistralai/mistral-7b-chat,0.75,0.0001096,0.75,0.0001096,0.75,0.0002022,0.75,0.0002898,0.25,0.000404296,0.75,0.01266
mmlu-world-religions.val.44,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,0.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
mmlu-computer-security.val.61,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,0.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
mmlu-high-school-psychology.val.187,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.3822,mistralai/mixtral-8x7b-chat,1.0,0.0001338,0.0,4.460000000000001e-05,1.0,6.659999999999999e-05,1.0,0.0001338,0.0,0.000173048,1.0,0.00224
hellaswag.val.19,WizardLM/WizardLM-13B-V1.2,0.0,4.2e-05,0.0,2.82e-05,0.0,4.2e-05,1.0,8.46e-05,0.0,0.000109416,1.0,0.00142
mmlu-professional-law.val.995,WizardLM/WizardLM-13B-V1.2,0.0,0.0001104,1.0,7.36e-05,0.0,0.0001104,1.0,0.0002201999999999,0.0,0.000285568,1.0,0.00369
mmlu-high-school-macroeconomics.val.352,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,0.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
mmlu-human-aging.val.151,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
grade-school-math.dev.2025,WizardLM/WizardLM-13B-V1.2,0.25,0.0001461,0.5,7.680000000000001e-05,0.25,0.0001461,0.75,0.0002586,0.75,0.000307296,0.5,0.00718
mmlu-miscellaneous.val.62,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
hellaswag.val.8334,mistralai/mistral-7b-chat,0.0,5.84e-05,0.0,5.84e-05,0.0,8.76e-05,1.0,0.0001752,0.0,0.000226592,1.0,0.00293
hellaswag.val.6815,mistralai/mixtral-8x7b-chat,0.0,0.0001506,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00252
mmlu-high-school-psychology.val.123,mistralai/mistral-7b-chat,0.0,3.520000000000001e-05,0.0,3.520000000000001e-05,1.0,5.28e-05,1.0,0.0001055999999999,0.0,0.000136576,1.0,0.00177
grade-school-math.dev.1337,meta/code-llama-instruct-34b-chat,0.25,0.000418264,0.25,0.000124,0.75,0.0001529999999999,0.25,0.000237,0.25,0.000418264,0.75,0.00857
grade-school-math.dev.1124,mistralai/mixtral-8x7b-chat,0.5,0.0002346,0.75,0.000103,0.75,0.0002045999999999,0.5,0.0002346,0.5,0.000432232,0.5,0.0092199999999999
grade-school-math.dev.1964,mistralai/mistral-7b-chat,0.5,5.66e-05,0.5,5.66e-05,0.75,0.0001124999999999,0.25,0.0001901999999999,0.75,0.000247544,0.75,0.00519
winogrande.dev.319,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,0.0,1.44e-05,0.0,2.94e-05,0.0,3.7248e-05,0.0,0.00053
hellaswag.val.8936,mistralai/mixtral-8x7b-chat,1.0,0.0001512,1.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,1.0,0.000195552,1.0,0.00256
mmlu-high-school-macroeconomics.val.284,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,0.0,0.00123
mmlu-electrical-engineering.val.143,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.4865,WizardLM/WizardLM-13B-V1.2,0.25,0.0002301,0.25,0.0001156,0.25,0.0002301,1.0,0.000198,0.25,0.000373256,0.75,0.01299
grade-school-math.dev.2124,WizardLM/WizardLM-13B-V1.2,0.5,0.0002034,0.25,7.42e-05,0.5,0.0002034,0.5,0.0002964,0.5,0.000281688,0.5,0.00658
grade-school-math.dev.2567,WizardLM/WizardLM-13B-V1.2,0.5,0.0001671,0.25,7.000000000000001e-05,0.5,0.0001671,0.25,0.000276,0.75,0.0003686,0.75,0.00998
hellaswag.val.5921,WizardLM/WizardLM-13B-V1.2,0.0,6.539999999999999e-05,0.0,4.380000000000001e-05,0.0,6.539999999999999e-05,1.0,0.0001314,0.0,0.0001699439999999,0.0,0.00223
hellaswag.val.585,mistralai/mixtral-8x7b-chat,1.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.1396,WizardLM/WizardLM-13B-V1.2,1.0,3.93e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
hellaswag.val.529,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-miscellaneous.val.371,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.3000,mistralai/mistral-7b-chat,0.75,8.7e-05,0.75,8.7e-05,0.25,0.0001529999999999,0.75,0.0002148,0.25,0.000347648,0.75,0.00537
mmlu-abstract-algebra.val.52,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,0.0,5.16e-05,0.0,6.751200000000001e-05,0.0,0.00091
hellaswag.val.7158,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.0027
grade-school-math.dev.885,WizardLM/WizardLM-13B-V1.2,0.5,0.0001598999999999,0.25,9.96e-05,0.5,0.0001598999999999,0.75,0.0002226,0.5,0.00035308,0.5,0.00754
mmlu-conceptual-physics.val.68,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00081
mmlu-high-school-european-history.val.73,WizardLM/WizardLM-13B-V1.2,0.0,0.0001496999999999,0.0,9.98e-05,0.0,0.0001496999999999,1.0,0.0002993999999999,0.0,0.000387224,1.0,0.0049999999999999
hellaswag.val.4264,mistralai/mistral-7b-chat,0.0,3.7000000000000005e-05,0.0,3.7000000000000005e-05,0.0,5.55e-05,1.0,0.000111,0.0,0.00014356,1.0,0.00189
mmlu-clinical-knowledge.val.105,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-miscellaneous.val.476,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.1850,WizardLM/WizardLM-13B-V1.2,0.0,3.8400000000000005e-05,0.0,2.58e-05,0.0,3.8400000000000005e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
hellaswag.val.6930,mistralai/mistral-7b-chat,0.0,4.9000000000000005e-05,0.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00249
mmlu-us-foreign-policy.val.48,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
grade-school-math.dev.4514,mistralai/mistral-7b-chat,0.75,8.82e-05,0.75,8.82e-05,0.75,0.000159,0.25,0.0002424,0.75,0.00031428,0.75,0.00678
hellaswag.val.8407,mistralai/mixtral-8x7b-chat,0.0,0.0001494,0.0,4.980000000000001e-05,0.0,7.47e-05,0.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
mmlu-professional-law.val.662,WizardLM/WizardLM-13B-V1.2,0.0,6.45e-05,0.0,4.3e-05,0.0,6.45e-05,0.0,0.000129,0.0,0.00016684,1.0,0.00216
hellaswag.val.2081,mistralai/mistral-7b-chat,1.0,1.8e-05,1.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,0.0,0.00091
consensus_summary.dev.244,mistralai/mixtral-8x7b-chat,0.75,0.0001331999999999,0.0,5.0400000000000005e-05,1.0,6.48e-05,0.75,0.0001331999999999,0.75,0.000227368,0.0,0.00294
hellaswag.val.7973,mistralai/mixtral-8x7b-chat,1.0,0.0001697999999999,1.0,5.680000000000001e-05,1.0,8.52e-05,1.0,0.0001697999999999,1.0,0.0002203839999999,1.0,0.00288
mmlu-logical-fallacies.val.11,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,1.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.00113
consensus_summary.dev.122,mistralai/mixtral-8x7b-chat,0.75,0.0001883999999999,0.75,6.440000000000001e-05,0.75,9.48e-05,0.75,0.0001883999999999,0.75,0.000315056,0.75,0.00621
bias_detection.dev.28,mistralai/mistral-7b-chat,0.0,6.6e-05,0.0,6.6e-05,0.0,0.0001163999999999,0.0,0.0001758,0.0,0.000243664,0.0,0.0108399999999999
hellaswag.val.3903,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00295
mmlu-clinical-knowledge.val.64,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
mmlu-professional-law.val.387,WizardLM/WizardLM-13B-V1.2,1.0,0.0001121999999999,0.0,7.48e-05,1.0,0.0001121999999999,1.0,0.0002243999999999,0.0,0.000290224,1.0,0.00375
hellaswag.val.1932,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,1.0,7.9152e-05,1.0,0.00103
hellaswag.val.6456,WizardLM/WizardLM-13B-V1.2,0.0,7.8e-05,0.0,5.2e-05,0.0,7.8e-05,0.0,0.000156,0.0,0.00020176,1.0,0.00264
mmlu-high-school-government-and-politics.val.133,WizardLM/WizardLM-13B-V1.2,1.0,3.9e-05,0.0,2.6e-05,1.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
winogrande.dev.604,mistralai/mistral-7b-chat,0.0,1.12e-05,0.0,1.12e-05,0.0,1.6800000000000002e-05,0.0,3.3600000000000004e-05,0.0,4.3456000000000005e-05,1.0,0.0006
winogrande.dev.318,mistralai/mixtral-8x7b-chat,1.0,3.4800000000000006e-05,1.0,1.16e-05,1.0,1.7100000000000002e-05,1.0,3.4800000000000006e-05,1.0,4.500800000000001e-05,1.0,0.0005899999999999
hellaswag.val.9852,mistralai/mixtral-8x7b-chat,0.0,0.0001463999999999,0.0,4.880000000000001e-05,0.0,7.319999999999999e-05,0.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
winogrande.dev.657,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,1.0,0.00052
abstract2title.test.193,mistralai/mixtral-8x7b-chat,1.0,0.0002148,1.0,7.04e-05,1.0,0.0001122,1.0,0.0002148,1.0,0.000266944,1.0,0.00446
mmlu-college-biology.val.34,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00113
mmlu-medical-genetics.val.62,mistralai/mixtral-8x7b-chat,0.0,6e-05,0.0,2e-05,1.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00104
mmlu-econometrics.val.5,mistralai/mixtral-8x7b-chat,0.0,8.94e-05,1.0,2.9800000000000003e-05,1.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.0015
hellaswag.val.3469,mistralai/mixtral-8x7b-chat,1.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00232
mmlu-college-biology.val.8,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.1403,mistralai/mistral-7b-chat,0.25,0.0001036,0.25,0.0001036,0.25,0.0001893,0.25,0.0002466,0.25,0.000429904,0.5,0.01424
arc-challenge.test.404,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,0.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-professional-law.val.228,WizardLM/WizardLM-13B-V1.2,1.0,6.09e-05,0.0,4.06e-05,1.0,6.09e-05,1.0,0.0001217999999999,0.0,0.000157528,1.0,0.00204
grade-school-math.dev.6542,WizardLM/WizardLM-13B-V1.2,0.25,0.0002174999999999,0.25,9.780000000000002e-05,0.25,0.0002174999999999,0.5,0.0002952,0.25,0.000346872,0.75,0.0103699999999999
mmlu-high-school-statistics.val.85,mistralai/mistral-7b-chat,0.0,2.36e-05,0.0,2.36e-05,1.0,3.54e-05,1.0,7.08e-05,0.0,9.1568e-05,1.0,0.00119
hellaswag.val.8838,mistralai/mixtral-8x7b-chat,1.0,0.0001476,1.0,4.920000000000001e-05,1.0,7.38e-05,1.0,0.0001476,1.0,0.0001908959999999,1.0,0.00247
mmlu-professional-law.val.1166,mistralai/mixtral-8x7b-chat,1.0,0.0001284,0.0,4.280000000000001e-05,1.0,6.42e-05,1.0,0.0001284,0.0,0.000166064,0.0,0.00215
grade-school-math.dev.1433,WizardLM/WizardLM-13B-V1.2,0.75,0.0001695,0.25,8.460000000000001e-05,0.75,0.0001695,0.25,0.0002718,0.25,0.000227368,0.5,0.00671
hellaswag.val.3707,mistralai/mistral-7b-chat,0.0,4.340000000000001e-05,0.0,4.340000000000001e-05,0.0,6.479999999999999e-05,0.0,0.0001302,0.0,0.0001683919999999,1.0,0.00221
mmlu-elementary-mathematics.val.213,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
grade-school-math.dev.6451,WizardLM/WizardLM-13B-V1.2,0.25,0.0001442999999999,0.5,8.5e-05,0.25,0.0001442999999999,0.5,0.0002448,0.75,0.000339888,0.75,0.00857
mmlu-professional-law.val.579,WizardLM/WizardLM-13B-V1.2,0.0,9.06e-05,1.0,6.04e-05,0.0,9.06e-05,1.0,0.0001812,0.0,0.000234352,1.0,0.00303
mmlu-high-school-government-and-politics.val.100,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,1.0,8.759999999999999e-05,0.0,0.000113296,1.0,0.00147
consensus_summary.dev.35,mistralai/mixtral-8x7b-chat,0.75,0.000186,0.75,6.400000000000001e-05,0.75,0.0001076999999999,0.75,0.000186,0.75,0.000250648,1.0,0.00238
hellaswag.val.63,WizardLM/WizardLM-13B-V1.2,1.0,3.12e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-international-law.val.102,mistralai/mixtral-8x7b-chat,1.0,6e-05,1.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00104
mmlu-moral-scenarios.val.700,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,0.0,4.32e-05,0.0,8.64e-05,0.0,0.000111744,0.0,0.00145
hellaswag.val.6165,mistralai/mixtral-8x7b-chat,1.0,0.0001224,1.0,4.080000000000001e-05,1.0,6.09e-05,1.0,0.0001224,0.0,0.000158304,1.0,0.00208
hellaswag.val.6006,mistralai/mistral-7b-chat,0.0,5.360000000000001e-05,0.0,5.360000000000001e-05,0.0,8.04e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-professional-psychology.val.381,mistralai/mistral-7b-chat,1.0,2.24e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-professional-psychology.val.451,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00124
winogrande.dev.1059,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,0.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00048
mmlu-astronomy.val.10,mistralai/mixtral-8x7b-chat,0.0,7.62e-05,0.0,2.54e-05,1.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
hellaswag.val.9608,mistralai/mixtral-8x7b-chat,0.0,0.0001686,1.0,5.62e-05,1.0,8.43e-05,0.0,0.0001686,1.0,0.000218056,1.0,0.00285
mmlu-security-studies.val.72,WizardLM/WizardLM-13B-V1.2,0.0,8.37e-05,0.0,5.580000000000001e-05,0.0,8.37e-05,1.0,0.0001674,0.0,0.0002165039999999,0.0,0.0028
mmlu-professional-medicine.val.214,mistralai/mixtral-8x7b-chat,1.0,0.0001188,0.0,3.960000000000001e-05,0.0,5.94e-05,1.0,0.0001188,0.0,0.000153648,1.0,0.00202
mmlu-professional-law.val.674,WizardLM/WizardLM-13B-V1.2,1.0,6.96e-05,1.0,4.64e-05,1.0,6.96e-05,0.0,0.0001392,0.0,0.000180032,0.0,0.00233
arc-challenge.test.756,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,0.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,0.0,0.00074
grade-school-math.dev.3489,mistralai/mistral-7b-chat,0.25,8.060000000000001e-05,0.25,8.060000000000001e-05,0.25,0.0001527,0.25,0.0002316,0.25,0.000281688,0.25,0.00738
mmlu-world-religions.val.137,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,1.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
mmlu-human-aging.val.8,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-clinical-knowledge.val.71,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.1716,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-professional-psychology.val.276,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,1.0,3.45e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-moral-scenarios.val.24,mistralai/mistral-7b-chat,0.0,2.7600000000000003e-05,0.0,2.7600000000000003e-05,1.0,4.14e-05,0.0,8.28e-05,0.0,0.000107088,1.0,0.00142
mmlu-professional-law.val.694,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00088
mmlu-international-law.val.68,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,0.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
grade-school-math.dev.2143,WizardLM/WizardLM-13B-V1.2,0.75,0.0001641,0.75,9.000000000000002e-05,0.75,0.0001641,0.25,0.0002448,0.25,0.00037248,0.75,0.0065699999999999
hellaswag.val.8355,mistralai/mistral-7b-chat,1.0,5e-05,1.0,5e-05,1.0,7.5e-05,1.0,0.00015,1.0,0.000194,1.0,0.00254
mmlu-high-school-mathematics.val.243,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-professional-law.val.1341,WizardLM/WizardLM-13B-V1.2,0.0,6.63e-05,0.0,4.420000000000001e-05,0.0,6.63e-05,0.0,0.0001326,0.0,0.000171496,0.0,0.00222
mmlu-professional-law.val.1504,WizardLM/WizardLM-13B-V1.2,0.0,0.0001508999999999,1.0,0.0001005999999999,0.0,0.0001508999999999,1.0,0.0003017999999999,0.0,0.000390328,1.0,0.0050399999999999
hellaswag.val.3163,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
mmlu-professional-law.val.42,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.8614,mistralai/mistral-7b-chat,0.0,4.94e-05,0.0,4.94e-05,1.0,7.41e-05,0.0,0.0001482,0.0,0.000191672,1.0,0.00248
grade-school-math.dev.4248,mistralai/mistral-7b-chat,0.75,7.86e-05,0.75,7.86e-05,0.75,0.0001521,0.25,0.000249,0.75,0.000301864,0.75,0.00762
mmlu-moral-disputes.val.191,mistralai/mistral-7b-chat,0.0,1.64e-05,0.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
consensus_summary.dev.305,mistralai/mixtral-8x7b-chat,0.75,0.0002076,0.75,8.36e-05,0.75,0.0001119,0.75,0.0002076,0.75,0.00030652,0.75,0.00607
mmlu-jurisprudence.val.9,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-professional-law.val.747,WizardLM/WizardLM-13B-V1.2,1.0,0.0001029,0.0,6.86e-05,1.0,0.0001029,1.0,0.0002058,0.0,0.0002661679999999,0.0,0.00344
mmlu-human-sexuality.val.26,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,1.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,1.0,7.604800000000001e-05,1.0,0.00102
mmlu-high-school-physics.val.104,mistralai/mixtral-8x7b-chat,0.0,9.42e-05,0.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
grade-school-math.dev.2867,WizardLM/WizardLM-13B-V1.2,0.5,0.0001782,0.25,0.00011,0.5,0.0001782,0.5,0.0003252,0.25,0.000358512,0.25,0.01544
hellaswag.val.1798,WizardLM/WizardLM-13B-V1.2,1.0,3.81e-05,1.0,2.54e-05,1.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00131
mmlu-sociology.val.120,mistralai/mistral-7b-chat,1.0,1.34e-05,1.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.0006799999999999
hellaswag.val.4188,mistralai/mistral-7b-chat,0.0,4.2600000000000005e-05,0.0,4.2600000000000005e-05,0.0,6.39e-05,0.0,0.0001278,0.0,0.000165288,1.0,0.00214
mmlu-professional-law.val.519,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-prehistory.val.208,mistralai/mistral-7b-chat,1.0,1.6800000000000002e-05,1.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.7008,mistralai/mixtral-8x7b-chat,0.0,0.0001614,0.0,5.380000000000001e-05,0.0,8.039999999999999e-05,0.0,0.0001614,0.0,0.000208744,1.0,0.0027
winogrande.dev.89,mistralai/mistral-7b-chat,1.0,9.8e-06,1.0,9.8e-06,0.0,1.47e-05,1.0,3e-05,1.0,3.880000000000001e-05,0.0,0.00054
mmlu-high-school-chemistry.val.42,mistralai/mixtral-8x7b-chat,0.0,6.48e-05,0.0,2.1600000000000003e-05,1.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,0.0,0.00109
mmlu-professional-law.val.568,WizardLM/WizardLM-13B-V1.2,0.0,7.35e-05,1.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-moral-scenarios.val.66,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.93e-05,0.0,7.86e-05,0.0,0.000101656,0.0,0.00132
grade-school-math.dev.4366,mistralai/mistral-7b-chat,0.5,7.6e-05,0.5,7.6e-05,0.5,0.0001422,0.5,0.0002657999999999,0.25,0.000269272,0.75,0.0067899999999999
mmlu-miscellaneous.val.571,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
mmlu-professional-accounting.val.3,mistralai/mistral-7b-chat,1.0,2.42e-05,1.0,2.42e-05,1.0,3.63e-05,0.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
grade-school-math.dev.7377,WizardLM/WizardLM-13B-V1.2,0.75,0.0002066999999999,0.25,0.0001012,0.75,0.0002066999999999,0.25,0.00033,0.25,0.0003492,0.75,0.01014
mmlu-professional-law.val.636,WizardLM/WizardLM-13B-V1.2,1.0,9.93e-05,0.0,6.62e-05,1.0,9.93e-05,0.0,0.0001986,0.0,0.0002568559999999,0.0,0.00332
mmlu-high-school-geography.val.168,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
mbpp.dev.327,mistralai/mistral-7b-chat,0.0,4.3200000000000007e-05,0.0,4.3200000000000007e-05,1.0,6.42e-05,1.0,0.0001038,1.0,0.000132696,1.0,0.00523
grade-school-math.dev.4892,WizardLM/WizardLM-13B-V1.2,0.5,0.0001233,0.25,7.02e-05,0.5,0.0001233,0.75,0.0002772,0.25,0.00031816,0.5,0.0071299999999999
mmlu-professional-law.val.167,mistralai/mistral-7b-chat,0.0,3.78e-05,0.0,3.78e-05,0.0,5.67e-05,0.0,0.0001128,0.0,0.000146664,0.0,0.0019
arc-challenge.val.47,mistralai/mistral-7b-chat,0.0,1.24e-05,0.0,1.24e-05,0.0,1.86e-05,1.0,3.72e-05,0.0,4.8112e-05,1.0,0.0006299999999999
hellaswag.val.3871,mistralai/mixtral-8x7b-chat,0.0,0.0001661999999999,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001661999999999,0.0,0.000215728,1.0,0.00282
hellaswag.val.4406,mistralai/mixtral-8x7b-chat,0.0,0.0001512,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
mmlu-moral-scenarios.val.598,mistralai/mistral-7b-chat,0.0,2.6600000000000003e-05,0.0,2.6600000000000003e-05,0.0,3.99e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00137
hellaswag.val.6925,mistralai/mixtral-8x7b-chat,0.0,0.00015,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,0.0,0.00251
mmlu-computer-security.val.38,mistralai/mixtral-8x7b-chat,0.0,7.740000000000001e-05,0.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
winogrande.dev.566,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,1.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
grade-school-math.dev.5450,mistralai/mistral-7b-chat,0.5,0.000101,0.5,0.000101,0.25,0.0002052,0.5,0.0002802,0.25,0.000329024,0.75,0.00814
mmlu-nutrition.val.153,mistralai/mixtral-8x7b-chat,1.0,0.000102,0.0,3.4000000000000007e-05,0.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
hellaswag.val.6613,mistralai/mixtral-8x7b-chat,0.0,0.0001757999999999,0.0,5.8800000000000006e-05,0.0,8.819999999999999e-05,0.0,0.0001757999999999,0.0,0.000228144,1.0,0.00295
grade-school-math.dev.1063,WizardLM/WizardLM-13B-V1.2,0.25,0.0001872,0.25,8.779999999999999e-05,0.25,0.0001872,0.25,0.00027,0.25,0.00030652,0.75,0.0092299999999999
grade-school-math.dev.4583,WizardLM/WizardLM-13B-V1.2,0.25,0.000192,0.75,0.000114,0.25,0.000192,0.25,0.0003306,0.25,0.000428352,0.75,0.01132
winogrande.dev.1100,mistralai/mixtral-8x7b-chat,0.0,2.8799999999999995e-05,0.0,9.6e-06,1.0,1.4399999999999998e-05,0.0,2.8799999999999995e-05,0.0,3.7248e-05,1.0,0.00049
grade-school-math.dev.3095,meta/code-llama-instruct-34b-chat,0.25,0.000456288,0.25,0.0001118,0.25,8.88e-05,0.75,0.0002573999999999,0.25,0.000456288,0.75,0.00857
grade-school-math.dev.4036,mistralai/mistral-7b-chat,0.75,8.88e-05,0.75,8.88e-05,0.75,0.0001269,0.75,0.0002106,0.25,0.00043456,0.75,0.00725
grade-school-math.dev.4932,WizardLM/WizardLM-13B-V1.2,0.5,0.0002145,0.25,0.0001038,0.5,0.0002145,0.5,0.000321,0.25,0.00049276,0.5,0.01005
mmlu-professional-law.val.1176,WizardLM/WizardLM-13B-V1.2,0.0,9.36e-05,1.0,6.24e-05,0.0,9.36e-05,1.0,0.0001865999999999,0.0,0.000242112,1.0,0.00313
arc-challenge.test.494,mistralai/mixtral-8x7b-chat,1.0,3.66e-05,0.0,1.22e-05,1.0,1.83e-05,1.0,3.66e-05,1.0,4.7336e-05,1.0,0.00065
mmlu-clinical-knowledge.val.119,mistralai/mixtral-8x7b-chat,1.0,6.9e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.0011899999999999
mmlu-high-school-psychology.val.420,mistralai/mixtral-8x7b-chat,0.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,0.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-conceptual-physics.val.171,mistralai/mistral-7b-chat,1.0,1.66e-05,1.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
winogrande.dev.554,mistralai/mixtral-8x7b-chat,1.0,2.94e-05,1.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.7248e-05,1.0,0.00053
grade-school-math.dev.5557,mistralai/mixtral-8x7b-chat,0.0,0.0002106,0.75,8.340000000000001e-05,0.75,0.0001386,0.0,0.0002106,0.75,0.000336008,0.75,0.00713
grade-school-math.dev.1714,mistralai/mistral-7b-chat,0.25,9.72e-05,0.25,9.72e-05,0.75,0.0001389,0.75,0.0001866,0.25,0.000312728,0.75,0.00612
grade-school-math.dev.1585,mistralai/mixtral-8x7b-chat,0.75,0.0002694,0.25,5.520000000000001e-05,0.25,0.0001010999999999,0.75,0.0002694,0.25,0.0002374559999999,0.75,0.00764
hellaswag.val.1841,WizardLM/WizardLM-13B-V1.2,0.0,3.72e-05,0.0,2.4800000000000003e-05,0.0,3.72e-05,0.0,7.44e-05,0.0,9.6224e-05,1.0,0.00125
mmlu-high-school-chemistry.val.180,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-professional-psychology.val.316,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-business-ethics.val.80,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,0.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.2778,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.9e-05,0.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-professional-psychology.val.2,mistralai/mistral-7b-chat,1.0,3e-05,1.0,3e-05,0.0,4.5e-05,1.0,9e-05,0.0,0.0001164,0.0,0.00151
mmlu-high-school-world-history.val.72,WizardLM/WizardLM-13B-V1.2,0.0,0.0001076999999999,0.0,7.18e-05,0.0,0.0001076999999999,1.0,0.0002153999999999,0.0,0.0002785839999999,1.0,0.0036
mmlu-professional-accounting.val.60,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
grade-school-math.dev.927,WizardLM/WizardLM-13B-V1.2,0.25,0.0001707,0.25,9.04e-05,0.25,0.0001707,1.0,0.0001962,0.25,0.000305744,0.5,0.00727
grade-school-math.dev.1022,meta/code-llama-instruct-34b-chat,0.75,0.000330576,0.25,9.12e-05,0.75,0.0001598999999999,0.25,0.0002646,0.75,0.000330576,0.75,0.00782
mmlu-international-law.val.40,mistralai/mistral-7b-chat,1.0,1.8800000000000003e-05,1.0,1.8800000000000003e-05,0.0,2.82e-05,1.0,5.64e-05,0.0,7.2944e-05,1.0,0.00095
grade-school-math.dev.3539,WizardLM/WizardLM-13B-V1.2,0.25,0.0001389,0.0,6.88e-05,0.25,0.0001389,0.75,0.0002004,0.75,0.0003127279999999,0.75,0.0062299999999999
hellaswag.val.2136,mistralai/mistral-7b-chat,0.0,2.88e-05,0.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
hellaswag.val.9259,WizardLM/WizardLM-13B-V1.2,0.0,7.769999999999999e-05,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.0026
mmlu-professional-law.val.46,WizardLM/WizardLM-13B-V1.2,0.0,0.000117,0.0,7.8e-05,0.0,0.000117,0.0,0.000234,0.0,0.00030264,0.0,0.00391
mmlu-professional-law.val.550,WizardLM/WizardLM-13B-V1.2,1.0,9.15e-05,1.0,6.1000000000000005e-05,1.0,9.15e-05,1.0,0.0001829999999999,0.0,0.00023668,1.0,0.00306
hellaswag.val.8981,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,1.0,0.00279
mmlu-international-law.val.63,mistralai/mixtral-8x7b-chat,1.0,9.18e-05,0.0,3.0600000000000005e-05,1.0,4.59e-05,1.0,9.18e-05,0.0,0.000118728,1.0,0.00154
grade-school-math.dev.1428,mistralai/mistral-7b-chat,0.25,0.0001055999999999,0.25,0.0001055999999999,0.5,0.0002073,0.5,0.0002814,0.75,0.000398864,0.75,0.01082
mmlu-college-physics.val.6,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
mmlu-conceptual-physics.val.113,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.00075
hellaswag.val.3716,mistralai/mixtral-8x7b-chat,1.0,0.0001842,1.0,6.14e-05,1.0,9.21e-05,1.0,0.0001842,1.0,0.000238232,1.0,0.00311
mmlu-philosophy.val.198,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,0.0,0.00084
mmlu-high-school-biology.val.93,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
grade-school-math.dev.2409,WizardLM/WizardLM-13B-V1.2,0.5,0.0001632,0.25,8.779999999999999e-05,0.5,0.0001632,0.75,0.0002975999999999,0.25,0.00036084,0.75,0.00946
mmlu-high-school-psychology.val.443,mistralai/mixtral-8x7b-chat,0.0,5.76e-05,0.0,1.92e-05,0.0,2.88e-05,0.0,5.76e-05,0.0,7.4496e-05,0.0,0.0009699999999999
mmlu-conceptual-physics.val.183,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
hellaswag.val.2902,mistralai/mistral-7b-chat,1.0,2.94e-05,1.0,2.94e-05,1.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
grade-school-math.dev.612,mistralai/mixtral-8x7b-chat,0.75,0.000261,0.75,7.680000000000001e-05,0.75,0.0001311,0.75,0.000261,0.75,0.00029876,0.75,0.00836
hellaswag.val.1952,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00113
grade-school-math.dev.5379,WizardLM/WizardLM-13B-V1.2,0.25,0.000126,0.5,9.000000000000002e-05,0.25,0.000126,0.5,0.0002538,0.0,0.00035308,0.75,0.00921
grade-school-math.dev.1193,mistralai/mistral-7b-chat,0.25,9.42e-05,0.25,9.42e-05,0.25,0.0001659,0.25,0.0002694,0.25,0.00036472,0.5,0.00877
grade-school-math.dev.5675,WizardLM/WizardLM-13B-V1.2,0.5,0.0001341,0.75,7.02e-05,0.5,0.0001341,1.0,0.0001728,0.5,0.00024832,0.5,0.00568
hellaswag.val.7392,mistralai/mixtral-8x7b-chat,1.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.099999999999999e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00275
hellaswag.val.4417,mistralai/mixtral-8x7b-chat,0.0,0.0001698,1.0,5.660000000000001e-05,1.0,8.49e-05,0.0,0.0001698,1.0,0.000219608,1.0,0.00287
mmlu-public-relations.val.49,mistralai/mistral-7b-chat,1.0,1.7e-05,1.0,1.7e-05,0.0,2.55e-05,0.0,5.1e-05,0.0,6.596e-05,0.0,0.00086
mmlu-elementary-mathematics.val.105,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,0.0,0.00105
mmlu-marketing.val.173,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
hellaswag.val.7856,mistralai/mixtral-8x7b-chat,0.0,0.0001422,0.0,4.74e-05,0.0,7.08e-05,0.0,0.0001422,0.0,0.000183912,1.0,0.00238
consensus_summary.dev.252,mistralai/mixtral-8x7b-chat,0.75,0.0001709999999999,1.0,5.960000000000001e-05,0.75,8.219999999999999e-05,0.75,0.0001709999999999,0.75,0.0002312479999999,1.0,0.0023
hellaswag.val.7798,mistralai/mistral-7b-chat,1.0,5.5e-05,1.0,5.5e-05,1.0,8.219999999999998e-05,1.0,0.0001649999999999,1.0,0.0002134,1.0,0.00279
grade-school-math.dev.5636,WizardLM/WizardLM-13B-V1.2,0.25,0.0001758,0.25,0.0001066,0.25,0.0001758,0.5,0.0002868,0.25,0.00037248,0.75,0.00801
winogrande.dev.217,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,1.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
mmlu-business-ethics.val.50,mistralai/mistral-7b-chat,1.0,2.64e-05,1.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
arc-challenge.val.202,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
grade-school-math.dev.4934,WizardLM/WizardLM-13B-V1.2,0.25,0.0001623,0.25,0.0001162,0.25,0.0001623,0.75,0.0002694,0.25,0.000328248,0.75,0.00993
grade-school-math.dev.4032,meta/code-llama-instruct-34b-chat,0.25,0.000398088,0.75,8.44e-05,0.75,0.0001446,0.75,0.0002327999999999,0.25,0.000398088,0.75,0.00795
mmlu-professional-accounting.val.22,mistralai/mistral-7b-chat,1.0,2.3800000000000003e-05,1.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
mmlu-high-school-world-history.val.183,mistralai/mixtral-8x7b-chat,1.0,0.0002292,0.0,7.64e-05,1.0,0.0001146,1.0,0.0002292,0.0,0.0002964319999999,1.0,0.00383
mmlu-prehistory.val.57,WizardLM/WizardLM-13B-V1.2,0.0,4.92e-05,0.0,3.2800000000000004e-05,0.0,4.92e-05,1.0,9.84e-05,0.0,0.0001272639999999,1.0,0.00165
mmlu-college-biology.val.63,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,1.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
grade-school-math.dev.6822,WizardLM/WizardLM-13B-V1.2,0.75,0.0001428,0.25,8.32e-05,0.75,0.0001428,0.75,0.0002478,0.75,0.000373256,0.75,0.01129
grade-school-math.dev.5823,mistralai/mistral-7b-chat,0.75,8.6e-05,0.75,8.6e-05,0.75,0.0001352999999999,0.75,0.0002657999999999,0.75,0.000329024,0.75,0.00593
mmlu-professional-law.val.436,WizardLM/WizardLM-13B-V1.2,0.0,0.0001247999999999,1.0,8.32e-05,0.0,0.0001247999999999,0.0,0.0002495999999999,0.0,0.000322816,0.0,0.0041699999999999
mmlu-professional-law.val.1415,WizardLM/WizardLM-13B-V1.2,1.0,4.56e-05,1.0,3.04e-05,1.0,4.56e-05,1.0,9.12e-05,0.0,0.000117952,1.0,0.00156
hellaswag.val.7594,mistralai/mixtral-8x7b-chat,0.0,0.0001446,0.0,4.8200000000000006e-05,0.0,7.230000000000001e-05,0.0,0.0001446,0.0,0.000187016,1.0,0.00245
hellaswag.val.430,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-prehistory.val.22,mistralai/mixtral-8x7b-chat,0.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
hellaswag.val.8217,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-conceptual-physics.val.173,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00096
mmlu-moral-scenarios.val.492,mistralai/mistral-7b-chat,0.0,3.08e-05,0.0,3.08e-05,0.0,4.6200000000000005e-05,0.0,9.24e-05,0.0,0.000119504,0.0,0.00155
mmlu-professional-law.val.958,mistralai/mistral-7b-chat,0.0,5.160000000000001e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,0.0,0.00259
mmlu-high-school-biology.val.225,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,1.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.00103
mmlu-international-law.val.8,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,1.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
hellaswag.val.2409,mistralai/mistral-7b-chat,1.0,1.94e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,1.0,7.5272e-05,1.0,0.00101
mmlu-high-school-microeconomics.val.156,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.5229,WizardLM/WizardLM-13B-V1.2,0.0,8.549999999999999e-05,0.0,5.7e-05,0.0,8.549999999999999e-05,0.0,0.0001709999999999,0.0,0.00022116,1.0,0.00289
grade-school-math.dev.62,mistralai/mistral-7b-chat,0.75,9.3e-05,0.75,9.3e-05,0.5,0.0001716,0.75,0.0002309999999999,0.25,0.000262288,0.5,0.00842
mmlu-professional-law.val.730,mistralai/mixtral-8x7b-chat,1.0,0.0001146,0.0,3.820000000000001e-05,1.0,5.73e-05,1.0,0.0001146,0.0,0.000148216,0.0,0.00192
grade-school-math.dev.2876,WizardLM/WizardLM-13B-V1.2,0.25,0.0001416,0.25,9.54e-05,0.25,0.0001416,0.75,0.0003054,0.25,0.000338336,0.5,0.00786
mmlu-professional-law.val.1256,mistralai/mistral-7b-chat,0.0,5.56e-05,0.0,5.56e-05,0.0,8.34e-05,0.0,0.0001668,0.0,0.000215728,0.0,0.00279
mmlu-professional-law.val.292,mistralai/mistral-7b-chat,1.0,3.64e-05,1.0,3.64e-05,0.0,5.46e-05,0.0,0.0001092,0.0,0.000141232,1.0,0.00183
mmlu-professional-law.val.975,WizardLM/WizardLM-13B-V1.2,0.0,9.42e-05,0.0,6.280000000000001e-05,0.0,9.42e-05,1.0,0.0001884,0.0,0.000243664,1.0,0.00315
grade-school-math.dev.2482,WizardLM/WizardLM-13B-V1.2,0.75,0.0001674,0.75,8.76e-05,0.75,0.0001674,0.75,0.0002802,0.75,0.000308072,0.75,0.009
mmlu-professional-psychology.val.524,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00097
hellaswag.val.7509,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.7e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00292
mmlu-public-relations.val.52,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.4775,WizardLM/WizardLM-13B-V1.2,0.25,0.0001481999999999,0.25,7.74e-05,0.25,0.0001481999999999,0.25,0.0002213999999999,0.25,0.00024056,0.75,0.00553
mmlu-professional-law.val.111,WizardLM/WizardLM-13B-V1.2,1.0,9.24e-05,0.0,6.159999999999999e-05,1.0,9.24e-05,0.0,0.0001848,0.0,0.000239008,1.0,0.00309
grade-school-math.dev.4849,mistralai/mistral-7b-chat,0.5,9.7e-05,0.5,9.7e-05,0.75,0.0002094,0.5,0.0003612,0.75,0.000354632,0.5,0.00842
grade-school-math.dev.4497,meta/code-llama-instruct-34b-chat,0.25,0.00032204,0.25,0.000539,0.25,0.0001404,0.75,0.0002316,0.25,0.00032204,0.75,0.00834
grade-school-math.dev.6495,mistralai/mistral-7b-chat,0.25,9.2e-05,0.25,9.2e-05,0.75,0.0001751999999999,0.25,0.0002898,0.25,0.000318936,0.75,0.01029
mmlu-miscellaneous.val.492,mistralai/mistral-7b-chat,0.0,1.84e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.0009299999999999
hellaswag.val.5482,mistralai/mistral-7b-chat,0.0,4.3e-05,0.0,4.3e-05,0.0,6.45e-05,0.0,0.000129,0.0,0.00016684,1.0,0.00216
mmlu-international-law.val.80,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,1.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
grade-school-math.dev.5009,mistralai/mixtral-8x7b-chat,0.25,0.0002052,0.25,5.5400000000000005e-05,0.75,0.0001416,0.25,0.0002052,0.75,0.000273928,0.5,0.00624
hellaswag.val.7511,mistralai/mixtral-8x7b-chat,1.0,0.0001422,1.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,1.0,0.000183912,1.0,0.00238
hellaswag.val.81,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-elementary-mathematics.val.189,mistralai/mistral-7b-chat,0.0,1.82e-05,0.0,1.82e-05,0.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.0009199999999999
hellaswag.val.6954,mistralai/mixtral-8x7b-chat,0.0,0.0001596,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.0027
hellaswag.val.4548,mistralai/mixtral-8x7b-chat,1.0,0.0001409999999999,1.0,4.7e-05,1.0,7.049999999999999e-05,1.0,0.0001409999999999,1.0,0.0001823599999999,1.0,0.00239
hellaswag.val.726,WizardLM/WizardLM-13B-V1.2,1.0,3.6e-05,0.0,2.4e-05,1.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,0.0,0.00121
mmlu-college-mathematics.val.38,mistralai/mistral-7b-chat,0.0,2.92e-05,0.0,2.92e-05,1.0,4.38e-05,0.0,8.759999999999999e-05,0.0,0.000113296,0.0,0.00147
mtbench.dev.5,mistralai/mistral-7b-chat,0.9,6.76e-05,0.9,6.76e-05,0.7,0.0003189,1.0,0.000429,0.7,0.000545528,1.0,0.02467
mmlu-high-school-microeconomics.val.70,mistralai/mistral-7b-chat,0.0,2.1600000000000003e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,0.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-virology.val.64,mistralai/mixtral-8x7b-chat,0.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,0.0,0.00096
winogrande.dev.327,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,0.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,1.0,0.00049
mmlu-professional-law.val.1430,mistralai/mistral-7b-chat,0.0,5.9600000000000005e-05,0.0,5.9600000000000005e-05,1.0,8.94e-05,0.0,0.0001788,0.0,0.0002312479999999,0.0,0.00299
grade-school-math.dev.2165,mistralai/mistral-7b-chat,0.25,7.960000000000001e-05,0.25,7.960000000000001e-05,0.25,0.0001266,0.75,0.0003065999999999,0.25,0.000296432,0.75,0.00935
mmlu-professional-law.val.423,WizardLM/WizardLM-13B-V1.2,0.0,7.199999999999999e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,0.0,0.00241
mmlu-miscellaneous.val.352,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.106,WizardLM/WizardLM-13B-V1.2,1.0,9.27e-05,0.0,6.18e-05,1.0,9.27e-05,0.0,0.0001853999999999,0.0,0.000239784,0.0,0.00313
hellaswag.val.1909,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00099
mmlu-marketing.val.183,mistralai/mistral-7b-chat,0.0,1.7e-05,0.0,1.7e-05,0.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-high-school-physics.val.7,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,0.0,0.00094
mmlu-professional-law.val.52,WizardLM/WizardLM-13B-V1.2,1.0,0.0001026,0.0,6.84e-05,1.0,0.0001026,0.0,0.0002052,0.0,0.000265392,1.0,0.00343
mmlu-professional-law.val.364,WizardLM/WizardLM-13B-V1.2,1.0,0.0001026,1.0,6.84e-05,1.0,0.0001026,1.0,0.0002045999999999,0.0,0.000265392,1.0,0.00343
grade-school-math.dev.688,mistralai/mistral-7b-chat,0.75,7.240000000000001e-05,0.75,7.240000000000001e-05,0.25,0.0001109999999999,0.75,0.000225,0.25,0.000211072,0.75,0.00487
mmlu-econometrics.val.48,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,1.0,0.00142
bias_detection.dev.239,meta/code-llama-instruct-34b-chat,0.0,0.000262288,0.0,6.220000000000001e-05,0.0,0.0001152,0.0,0.0002568,0.0,0.000262288,0.0,0.01164
grade-school-math.dev.1365,mistralai/mixtral-8x7b-chat,0.25,0.0002532,0.25,8.82e-05,0.25,0.0001773,0.25,0.0002532,0.25,0.000396536,0.75,0.0090499999999999
grade-school-math.dev.6403,mistralai/mistral-7b-chat,0.25,0.000102,0.25,0.000102,0.25,0.0002007,0.5,0.0003509999999999,0.25,0.00039964,0.75,0.01031
mmlu-college-computer-science.val.46,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,0.0,4.8e-05,0.0,6.285600000000001e-05,1.0,0.00082
grade-school-math.dev.4814,mistralai/mistral-7b-chat,0.25,8.760000000000002e-05,0.25,8.760000000000002e-05,0.25,0.0001827,0.25,0.0002232,0.25,0.000418264,0.75,0.00907
winogrande.dev.404,mistralai/mistral-7b-chat,1.0,1.24e-05,1.0,1.24e-05,0.0,1.86e-05,1.0,3.72e-05,1.0,4.8112e-05,1.0,0.00066
mmlu-miscellaneous.val.530,mistralai/mistral-7b-chat,0.0,1.46e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
mmlu-high-school-european-history.val.104,mistralai/mixtral-8x7b-chat,0.0,0.0002483999999999,0.0,8.280000000000001e-05,1.0,0.0001241999999999,0.0,0.0002483999999999,0.0,0.000321264,0.0,0.00415
mmlu-public-relations.val.96,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,0.0,0.0007199999999999
grade-school-math.dev.4350,WizardLM/WizardLM-13B-V1.2,0.25,0.0001607999999999,0.75,7.46e-05,0.25,0.0001607999999999,0.75,0.0002525999999999,0.75,0.000257632,0.5,0.00619
mmlu-prehistory.val.305,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,0.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00086
hellaswag.val.5629,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-high-school-biology.val.290,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,0.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00086
mmlu-professional-law.val.1266,mistralai/mixtral-8x7b-chat,0.0,0.0001812,0.0,6.04e-05,0.0,9.06e-05,0.0,0.0001812,0.0,0.000234352,1.0,0.00306
grade-school-math.dev.5152,WizardLM/WizardLM-13B-V1.2,0.25,0.0002091,0.75,0.0001024,0.25,0.0002091,0.5,0.0003276,0.25,0.000467152,0.0,0.00938
arc-challenge.test.836,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.3600000000000004e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-high-school-physics.val.14,mistralai/mixtral-8x7b-chat,0.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,0.0,6.54e-05,0.0,8.4584e-05,0.0,0.00113
mmlu-marketing.val.219,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
grade-school-math.dev.4691,WizardLM/WizardLM-13B-V1.2,0.5,0.0001893,0.25,8.560000000000001e-05,0.5,0.0001893,0.25,0.0002262,0.25,0.000401192,0.5,0.00798
consensus_summary.dev.32,mistralai/mixtral-8x7b-chat,0.75,0.0001986,0.25,6.2e-05,0.75,0.0001017,0.75,0.0001986,0.75,0.000262288,0.75,0.00496
hellaswag.val.619,mistralai/mistral-7b-chat,1.0,2.08e-05,1.0,2.08e-05,1.0,3.12e-05,1.0,6.24e-05,1.0,8.0704e-05,1.0,0.00108
grade-school-math.dev.1758,WizardLM/WizardLM-13B-V1.2,0.75,0.0001965,0.25,9.320000000000002e-05,0.75,0.0001965,0.75,0.0002879999999999,0.5,0.000355408,0.75,0.0102499999999999
mmlu-professional-law.val.298,WizardLM/WizardLM-13B-V1.2,0.0,0.0001121999999999,1.0,7.48e-05,0.0,0.0001121999999999,1.0,0.0002243999999999,0.0,0.000290224,1.0,0.00375
mmlu-professional-psychology.val.246,WizardLM/WizardLM-13B-V1.2,0.0,4.02e-05,0.0,2.68e-05,0.0,4.02e-05,0.0,8.04e-05,0.0,0.000103984,1.0,0.00135
mmlu-high-school-macroeconomics.val.154,mistralai/mistral-7b-chat,1.0,2.9800000000000003e-05,1.0,2.9800000000000003e-05,1.0,4.47e-05,1.0,8.94e-05,0.0,0.000115624,1.0,0.0015
hellaswag.val.2073,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.36e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
winogrande.dev.1011,mistralai/mistral-7b-chat,0.0,9.8e-06,0.0,9.8e-06,1.0,1.4699999999999998e-05,0.0,2.94e-05,0.0,3.8024e-05,1.0,0.0005
mmlu-miscellaneous.val.777,mistralai/mixtral-8x7b-chat,0.0,4.8e-05,0.0,1.6000000000000003e-05,0.0,2.4e-05,0.0,4.8e-05,0.0,6.208e-05,1.0,0.00081
grade-school-math.dev.2629,WizardLM/WizardLM-13B-V1.2,0.5,0.0001409999999999,0.75,9.06e-05,0.5,0.0001409999999999,0.5,0.000198,0.75,0.000284792,0.75,0.00722
hellaswag.val.7314,mistralai/mistral-7b-chat,0.0,5.080000000000001e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,0.0,0.00258
hellaswag.val.8301,mistralai/mistral-7b-chat,0.0,5.980000000000001e-05,0.0,5.980000000000001e-05,0.0,8.97e-05,1.0,0.0001794,0.0,0.000232024,1.0,0.003
mmlu-high-school-microeconomics.val.119,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.7175,mistralai/mistral-7b-chat,0.25,9.5e-05,0.25,9.5e-05,0.75,0.0001844999999999,0.25,0.0003329999999999,0.75,0.000429128,0.75,0.00911
grade-school-math.dev.2423,mistralai/mistral-7b-chat,0.25,0.0001388,0.25,0.0001388,0.5,0.0001397999999999,0.5,0.000303,0.5,0.000321264,0.5,0.00764
hellaswag.val.8271,WizardLM/WizardLM-13B-V1.2,0.0,6.18e-05,0.0,4.1200000000000005e-05,0.0,6.18e-05,0.0,0.0001236,0.0,0.000159856,1.0,0.00207
hellaswag.val.5030,mistralai/mistral-7b-chat,0.0,5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
hellaswag.val.1920,mistralai/mistral-7b-chat,1.0,3.3e-05,1.0,3.3e-05,0.0,4.92e-05,0.0,9.9e-05,0.0,0.00012804,1.0,0.00166
mmlu-security-studies.val.104,mistralai/mistral-7b-chat,1.0,2.46e-05,1.0,2.46e-05,0.0,3.69e-05,1.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.0012699999999999
hellaswag.val.3307,mistralai/mixtral-8x7b-chat,0.0,0.0001553999999999,0.0,5.1800000000000005e-05,0.0,7.769999999999999e-05,0.0,0.0001553999999999,0.0,0.000200984,1.0,0.00263
abstract2title.test.47,mistralai/mixtral-8x7b-chat,1.0,0.0001164,1.0,3.86e-05,1.0,5.97e-05,1.0,0.0001164,1.0,0.0001489919999999,1.0,0.00279
consensus_summary.dev.279,meta/code-llama-instruct-34b-chat,0.5,0.000211848,0.5,5.22e-05,0.5,0.0003183,0.5,0.0001578,0.5,0.000211848,0.5,0.00248
mmlu-astronomy.val.25,mistralai/mixtral-8x7b-chat,1.0,5.1e-05,1.0,1.7e-05,1.0,2.55e-05,1.0,5.1e-05,0.0,6.596e-05,1.0,0.00089
arc-challenge.test.723,mistralai/mixtral-8x7b-chat,1.0,4.98e-05,1.0,1.66e-05,0.0,2.49e-05,1.0,4.98e-05,1.0,6.4408e-05,1.0,0.0008399999999999
grade-school-math.dev.2902,WizardLM/WizardLM-13B-V1.2,0.75,0.0001574999999999,0.75,8.86e-05,0.75,0.0001574999999999,0.75,0.0002357999999999,0.75,0.000349976,0.75,0.00893
mmlu-miscellaneous.val.121,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-professional-medicine.val.229,WizardLM/WizardLM-13B-V1.2,0.0,6.269999999999999e-05,0.0,4.1800000000000006e-05,0.0,6.269999999999999e-05,1.0,0.0001253999999999,0.0,0.000162184,1.0,0.00213
grade-school-math.dev.5860,mistralai/mistral-7b-chat,0.25,9.6e-05,0.25,9.6e-05,0.25,0.0002081999999999,0.25,0.0003035999999999,0.25,0.000366272,0.75,0.01044
mmlu-high-school-macroeconomics.val.264,mistralai/mistral-7b-chat,0.0,2.0600000000000003e-05,0.0,2.0600000000000003e-05,1.0,3.09e-05,0.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.4292,mistralai/mistral-7b-chat,1.0,4.2600000000000005e-05,1.0,4.2600000000000005e-05,1.0,6.39e-05,1.0,0.0001278,1.0,0.000165288,1.0,0.00217
arc-challenge.test.1065,mistralai/mixtral-8x7b-chat,1.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,1.0,5.64e-05,1.0,7.2944e-05,1.0,0.00095
mmlu-philosophy.val.225,mistralai/mistral-7b-chat,1.0,1.3e-05,1.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
mmlu-professional-law.val.521,WizardLM/WizardLM-13B-V1.2,0.0,7.71e-05,1.0,5.14e-05,0.0,7.71e-05,0.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
mmlu-high-school-computer-science.val.64,mistralai/mistral-7b-chat,1.0,2.9e-05,1.0,2.9e-05,1.0,4.35e-05,1.0,8.7e-05,0.0,0.00011252,1.0,0.00146
grade-school-math.dev.1532,mistralai/mistral-7b-chat,0.75,8.5e-05,0.75,8.5e-05,0.5,0.0001833,0.5,0.0002928,0.75,0.000356184,0.5,0.00876
hellaswag.val.7491,WizardLM/WizardLM-13B-V1.2,0.0,8.999999999999999e-05,0.0,6e-05,0.0,8.999999999999999e-05,0.0,0.0001799999999999,0.0,0.0002328,0.0,0.00304
hellaswag.val.4441,mistralai/mistral-7b-chat,0.0,4.8e-05,0.0,4.8e-05,0.0,7.199999999999999e-05,0.0,0.0001439999999999,0.0,0.00018624,1.0,0.00241
mmlu-philosophy.val.222,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
mmlu-professional-law.val.770,WizardLM/WizardLM-13B-V1.2,0.0,8.219999999999999e-05,1.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00278
mbpp.dev.358,mistralai/mixtral-8x7b-chat,1.0,0.0002688,1.0,7.54e-05,1.0,0.0001575,1.0,0.0002688,1.0,0.00028324,1.0,0.00969
grade-school-math.dev.3234,meta/code-llama-instruct-34b-chat,0.5,0.0003104,0.75,8.14e-05,0.5,0.0001512,0.5,0.0002766,0.5,0.0003104,0.5,0.00662
grade-school-math.dev.6316,WizardLM/WizardLM-13B-V1.2,0.75,0.0001284,0.25,8.52e-05,0.75,0.0001284,0.75,0.0001841999999999,0.25,0.000296432,0.75,0.00688
mmlu-professional-law.val.811,WizardLM/WizardLM-13B-V1.2,0.0,0.0001002,0.0,6.68e-05,0.0,0.0001002,0.0,0.0002004,0.0,0.000259184,1.0,0.00335
mmlu-professional-law.val.1024,WizardLM/WizardLM-13B-V1.2,0.0,5.97e-05,0.0,3.980000000000001e-05,0.0,5.97e-05,1.0,0.0001193999999999,0.0,0.000154424,1.0,0.002
bias_detection.dev.156,mistralai/mistral-7b-chat,0.0,5.660000000000001e-05,0.0,5.660000000000001e-05,1.0,9.33e-05,1.0,0.0001788,0.0,0.0002304719999999,1.0,0.00978
mmlu-professional-law.val.1170,mistralai/mistral-7b-chat,0.0,6.56e-05,0.0,6.56e-05,1.0,9.84e-05,1.0,0.0001967999999999,0.0,0.000254528,1.0,0.00329
mmlu-clinical-knowledge.val.171,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
hellaswag.val.2557,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-miscellaneous.val.637,mistralai/mistral-7b-chat,1.0,1.48e-05,1.0,1.48e-05,1.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
hellaswag.val.10001,mistralai/mixtral-8x7b-chat,0.0,0.0001386,1.0,4.6200000000000005e-05,1.0,6.93e-05,0.0,0.0001386,1.0,0.000179256,1.0,0.00235
hellaswag.val.7378,WizardLM/WizardLM-13B-V1.2,0.0,8.13e-05,0.0,5.44e-05,0.0,8.13e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00273
mmlu-world-religions.val.72,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-professional-psychology.val.512,mistralai/mistral-7b-chat,0.0,1.5600000000000003e-05,0.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.5318,WizardLM/WizardLM-13B-V1.2,0.25,0.0001331999999999,0.5,8.32e-05,0.25,0.0001331999999999,0.75,0.0003083999999999,0.25,0.000330576,0.5,0.01057
mmlu-professional-accounting.val.156,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,1.0,3.81e-05,0.0,7.62e-05,0.0,9.8552e-05,1.0,0.00131
mmlu-high-school-psychology.val.53,mistralai/mixtral-8x7b-chat,1.0,4.26e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
mmlu-high-school-macroeconomics.val.134,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,0.0,0.0014
mmlu-security-studies.val.218,WizardLM/WizardLM-13B-V1.2,0.0,8.91e-05,0.0,5.94e-05,0.0,8.91e-05,1.0,0.0001782,0.0,0.000230472,1.0,0.00298
mmlu-high-school-biology.val.187,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,1.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
hellaswag.val.2904,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
grade-school-math.dev.1152,meta/code-llama-instruct-34b-chat,0.5,0.000255304,0.25,7.94e-05,0.75,0.0001376999999999,0.75,0.0002208,0.5,0.000255304,0.75,0.00668
grade-school-math.dev.3391,WizardLM/WizardLM-13B-V1.2,0.25,0.0002277,0.25,7.000000000000001e-05,0.25,0.0002277,0.25,0.0002394,0.25,0.0003949839999999,0.75,0.01077
mmlu-high-school-biology.val.62,mistralai/mistral-7b-chat,1.0,2e-05,1.0,2e-05,0.0,3e-05,0.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-professional-accounting.val.1,mistralai/mistral-7b-chat,1.0,2.56e-05,1.0,2.56e-05,1.0,3.84e-05,0.0,7.68e-05,0.0,9.9328e-05,0.0,0.00129
hellaswag.val.3830,WizardLM/WizardLM-13B-V1.2,0.0,7.74e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,1.0,0.0001548,0.0,0.000200208,1.0,0.00262
hellaswag.val.5636,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00279
arc-challenge.test.1136,mistralai/mistral-7b-chat,0.0,1.24e-05,0.0,1.24e-05,1.0,1.86e-05,1.0,3.72e-05,1.0,4.8112e-05,1.0,0.00066
arc-challenge.test.217,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.0008399999999999
mmlu-professional-psychology.val.314,WizardLM/WizardLM-13B-V1.2,1.0,4.5e-05,0.0,3e-05,1.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-clinical-knowledge.val.137,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
hellaswag.val.6856,mistralai/mistral-7b-chat,0.0,3.78e-05,0.0,3.78e-05,0.0,5.67e-05,0.0,0.0001134,0.0,0.000146664,1.0,0.0019299999999999
abstract2title.test.100,mistralai/mixtral-8x7b-chat,1.0,0.0001494,1.0,5e-05,1.0,7.38e-05,1.0,0.0001494,1.0,0.00018236,1.0,0.00306
mmlu-high-school-computer-science.val.70,mistralai/mistral-7b-chat,1.0,2.2600000000000004e-05,1.0,2.2600000000000004e-05,1.0,3.39e-05,0.0,6.72e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-formal-logic.val.38,mistralai/mistral-7b-chat,1.0,1.9e-05,1.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
grade-school-math.dev.3915,WizardLM/WizardLM-13B-V1.2,0.75,0.0001743,0.25,0.0001465999999999,0.75,0.0001743,0.25,0.0002729999999999,0.25,0.000354632,0.75,0.01063
winogrande.dev.1078,mistralai/mistral-7b-chat,0.0,9.4e-06,0.0,9.4e-06,1.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00048
hellaswag.val.5211,mistralai/mixtral-8x7b-chat,0.0,0.0001368,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001368,0.0,0.000176928,1.0,0.00229
hellaswag.val.9625,WizardLM/WizardLM-13B-V1.2,0.0,7.74e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,1.0,0.00259
hellaswag.val.9650,mistralai/mixtral-8x7b-chat,0.0,0.0001656,0.0,5.520000000000001e-05,0.0,8.25e-05,0.0,0.0001656,0.0,0.0002141759999999,1.0,0.0028
grade-school-math.dev.6613,mistralai/mixtral-8x7b-chat,0.25,0.0002304,0.25,8.1e-05,0.5,0.0001374,0.25,0.0002304,0.5,0.000318936,0.5,0.00892
grade-school-math.dev.7000,WizardLM/WizardLM-13B-V1.2,0.75,0.0001479,0.25,8.38e-05,0.75,0.0001479,0.75,0.0002274,0.5,0.000318936,0.5,0.0081199999999999
mmlu-professional-law.val.1056,WizardLM/WizardLM-13B-V1.2,0.0,0.0001185,0.0,7.900000000000001e-05,0.0,0.0001185,0.0,0.000237,0.0,0.00030652,1.0,0.00396
mmlu-college-biology.val.97,mistralai/mixtral-8x7b-chat,1.0,4.86e-05,1.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
hellaswag.val.6019,mistralai/mistral-7b-chat,1.0,4.720000000000001e-05,1.0,4.720000000000001e-05,1.0,7.08e-05,0.0,0.0001416,1.0,0.000183136,1.0,0.0024
grade-school-math.dev.729,WizardLM/WizardLM-13B-V1.2,0.75,0.0001685999999999,0.75,0.0001064,0.75,0.0001685999999999,0.75,0.0002615999999999,0.25,0.000351528,0.75,0.01081
hellaswag.val.5673,mistralai/mixtral-8x7b-chat,0.0,0.0001572,1.0,5.24e-05,1.0,7.829999999999999e-05,0.0,0.0001572,0.0,0.000203312,1.0,0.00266
grade-school-math.dev.3513,WizardLM/WizardLM-13B-V1.2,0.25,0.0001602,0.75,7.54e-05,0.25,0.0001602,0.75,0.0002376,0.75,0.000336008,0.75,0.0101
grade-school-math.dev.5407,WizardLM/WizardLM-13B-V1.2,0.75,0.0001487999999999,0.75,9.22e-05,0.75,0.0001487999999999,0.75,0.0002753999999999,0.25,0.000304968,0.5,0.00943
arc-challenge.val.244,mistralai/mixtral-8x7b-chat,1.0,4.74e-05,1.0,1.58e-05,0.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.00083
hellaswag.val.1289,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-professional-law.val.1300,WizardLM/WizardLM-13B-V1.2,0.0,0.0001083,0.0,7.219999999999999e-05,0.0,0.0001083,0.0,0.000216,0.0,0.000280136,0.0,0.00362
hellaswag.val.2807,mistralai/mistral-7b-chat,1.0,2.28e-05,1.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,1.0,8.846400000000001e-05,1.0,0.0011799999999999
hellaswag.val.9534,mistralai/mistral-7b-chat,0.0,4.720000000000001e-05,0.0,4.720000000000001e-05,1.0,7.08e-05,0.0,0.0001416,0.0,0.000183136,1.0,0.00237
mmlu-nutrition.val.127,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,0.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,1.0,0.00095
mmlu-college-biology.val.18,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-high-school-world-history.val.129,mistralai/mixtral-8x7b-chat,1.0,0.000285,1.0,9.5e-05,1.0,0.0001425,1.0,0.000285,0.0,0.0003686,1.0,0.0047599999999999
grade-school-math.dev.1202,WizardLM/WizardLM-13B-V1.2,0.25,0.0001994999999999,0.25,0.0001398,0.25,0.0001994999999999,0.25,0.0003197999999999,0.25,0.0006099359999999,0.75,0.01321
winogrande.dev.304,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,0.0,1.41e-05,0.0,2.82e-05,0.0,3.6472000000000006e-05,1.0,0.00051
grade-school-math.dev.1006,meta/code-llama-instruct-34b-chat,0.25,0.000449304,0.25,6.82e-05,0.25,0.0001923,0.75,0.0002004,0.25,0.000449304,0.75,0.00685
mmlu-econometrics.val.33,mistralai/mixtral-8x7b-chat,1.0,6.9e-05,0.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
mmlu-professional-law.val.331,WizardLM/WizardLM-13B-V1.2,0.0,7.35e-05,1.0,4.9000000000000005e-05,0.0,7.35e-05,0.0,0.000147,0.0,0.00019012,1.0,0.00246
mmlu-human-aging.val.53,mistralai/mistral-7b-chat,0.0,1.66e-05,0.0,1.66e-05,1.0,2.49e-05,1.0,4.98e-05,0.0,6.4408e-05,1.0,0.00087
grade-school-math.dev.1355,mistralai/mistral-7b-chat,0.5,7.12e-05,0.5,7.12e-05,0.5,0.0001325999999999,0.25,0.0002189999999999,0.75,0.00025996,0.5,0.0070799999999999
hellaswag.val.8173,mistralai/mixtral-8x7b-chat,1.0,0.0001548,1.0,5.160000000000001e-05,1.0,7.74e-05,1.0,0.0001548,1.0,0.000200208,1.0,0.00262
grade-school-math.dev.2160,mistralai/mistral-7b-chat,0.75,6.82e-05,0.75,6.82e-05,0.25,0.0001341,0.25,0.0002232,0.25,0.000266944,0.75,0.00719
grade-school-math.dev.6928,mistralai/mistral-7b-chat,0.75,9.82e-05,0.75,9.82e-05,0.5,0.0001476,0.75,0.0002934,0.25,0.00037636,0.5,0.00751
consensus_summary.dev.22,mistralai/mistral-7b-chat,0.75,5.4600000000000006e-05,0.75,5.4600000000000006e-05,0.75,0.0001017,0.75,0.0001896,0.75,0.000303416,0.75,0.00383
hellaswag.val.2670,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,0.0,3.24e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
winogrande.dev.712,mistralai/mistral-7b-chat,1.0,8.999999999999999e-06,1.0,8.999999999999999e-06,0.0,1.35e-05,1.0,2.7e-05,0.0,3.4920000000000004e-05,1.0,0.00049
mmlu-professional-law.val.224,WizardLM/WizardLM-13B-V1.2,0.0,7.56e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00253
winogrande.dev.913,mistralai/mixtral-8x7b-chat,0.0,3e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,1.0,0.00054
mmlu-professional-law.val.1347,WizardLM/WizardLM-13B-V1.2,1.0,8.91e-05,1.0,5.94e-05,1.0,8.91e-05,1.0,0.0001782,0.0,0.000230472,1.0,0.00298
hellaswag.val.1981,mistralai/mistral-7b-chat,0.0,3.08e-05,0.0,3.08e-05,0.0,4.6200000000000005e-05,0.0,9.24e-05,0.0,0.000119504,1.0,0.00155
mmlu-electrical-engineering.val.93,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,0.0,0.00115
mmlu-high-school-psychology.val.65,mistralai/mistral-7b-chat,1.0,1.32e-05,1.0,1.32e-05,1.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
grade-school-math.dev.2852,WizardLM/WizardLM-13B-V1.2,0.75,0.0002148,0.25,0.0001288,0.75,0.0002148,0.25,0.00042,0.75,0.000405848,0.75,0.01149
mmlu-college-computer-science.val.94,mistralai/mixtral-8x7b-chat,1.0,0.0001092,0.0,3.64e-05,0.0,5.46e-05,1.0,0.0001092,0.0,0.000141232,1.0,0.00183
mmlu-philosophy.val.96,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,0.0,1.98e-05,0.0,3.96e-05,0.0,5.1216000000000006e-05,0.0,0.00067
hellaswag.val.6274,mistralai/mixtral-8x7b-chat,1.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,1.0,0.0001439999999999,1.0,0.00018624,1.0,0.00241
arc-challenge.val.28,mistralai/mixtral-8x7b-chat,1.0,3.3e-05,1.0,1.1e-05,0.0,1.65e-05,1.0,3.3e-05,0.0,4.2680000000000005e-05,1.0,0.00056
grade-school-math.dev.2389,WizardLM/WizardLM-13B-V1.2,0.25,0.0002097,0.25,7.66e-05,0.25,0.0002097,0.75,0.0003792,0.25,0.0004462,0.75,0.01926
hellaswag.val.7254,mistralai/mistral-7b-chat,0.0,5.06e-05,0.0,5.06e-05,0.0,7.56e-05,0.0,0.0001518,0.0,0.000196328,1.0,0.00257
grade-school-math.dev.7170,WizardLM/WizardLM-13B-V1.2,0.75,0.0001479,0.25,7.400000000000001e-05,0.75,0.0001479,0.75,0.0002177999999999,0.25,0.000284016,0.5,0.00638
hellaswag.val.8944,mistralai/mixtral-8x7b-chat,0.0,0.0001632,0.0,5.44e-05,0.0,8.16e-05,0.0,0.0001632,0.0,0.000211072,1.0,0.00276
mmlu-high-school-psychology.val.456,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,1.0,2.1600000000000003e-05,1.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-world-religions.val.104,mistralai/mixtral-8x7b-chat,1.0,4.2e-05,0.0,1.4e-05,1.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00071
hellaswag.val.5762,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
mmlu-miscellaneous.val.130,mistralai/mistral-7b-chat,1.0,1.64e-05,1.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
mmlu-global-facts.val.77,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
mmlu-professional-psychology.val.195,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.00079
hellaswag.val.9079,mistralai/mixtral-8x7b-chat,0.0,0.0001643999999999,0.0,5.480000000000001e-05,0.0,8.219999999999999e-05,0.0,0.0001643999999999,0.0,0.000212624,1.0,0.00275
hellaswag.val.304,WizardLM/WizardLM-13B-V1.2,1.0,3.03e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.4032,mistralai/mistral-7b-chat,0.0,4.980000000000001e-05,0.0,4.980000000000001e-05,0.0,7.47e-05,1.0,0.0001494,0.0,0.0001932239999999,1.0,0.0025
hellaswag.val.4238,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,1.0,4.880000000000001e-05,1.0,7.289999999999998e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,1.0,0.00248
mmlu-virology.val.142,WizardLM/WizardLM-13B-V1.2,0.0,2.88e-05,1.0,1.92e-05,0.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.001
mmlu-moral-scenarios.val.362,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,0.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
hellaswag.val.6077,mistralai/mistral-7b-chat,0.0,6.080000000000001e-05,0.0,6.080000000000001e-05,0.0,9.09e-05,0.0,0.0001824,0.0,0.000235904,1.0,0.00305
mmlu-college-chemistry.val.46,mistralai/mixtral-8x7b-chat,1.0,6.12e-05,0.0,2.04e-05,0.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-professional-law.val.402,mistralai/mistral-7b-chat,0.0,5.160000000000001e-05,0.0,5.160000000000001e-05,0.0,7.74e-05,0.0,0.0001548,0.0,0.000200208,0.0,0.00259
grade-school-math.dev.5266,WizardLM/WizardLM-13B-V1.2,0.5,0.0001815,0.5,0.0001108,0.5,0.0001815,0.75,0.000288,0.5,0.000320488,0.5,0.00863
hellaswag.val.1942,mistralai/mistral-7b-chat,0.0,2.82e-05,0.0,2.82e-05,1.0,4.2e-05,0.0,8.46e-05,0.0,0.000109416,1.0,0.00142
winogrande.dev.57,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,0.0,3.9576e-05,1.0,0.00053
mmlu-moral-scenarios.val.874,mistralai/mistral-7b-chat,0.0,3.3e-05,0.0,3.3e-05,1.0,4.95e-05,1.0,9.9e-05,0.0,0.00012804,1.0,0.0016899999999999
mmlu-moral-scenarios.val.435,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00134
grade-school-math.dev.1549,mistralai/mistral-7b-chat,0.25,6.92e-05,0.25,6.92e-05,0.25,0.0001616999999999,0.5,0.0002916,0.25,0.000349976,0.75,0.01271
mmlu-high-school-european-history.val.151,mistralai/mixtral-8x7b-chat,1.0,0.000177,1.0,5.9e-05,0.0,8.85e-05,1.0,0.000177,0.0,0.0002289199999999,1.0,0.00299
arc-challenge.val.227,mistralai/mixtral-8x7b-chat,1.0,5.52e-05,0.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,0.0,7.139200000000001e-05,1.0,0.00096
hellaswag.val.3192,mistralai/mistral-7b-chat,1.0,3e-05,1.0,3e-05,1.0,4.5e-05,1.0,9e-05,1.0,0.0001164,1.0,0.00151
mmlu-philosophy.val.130,mistralai/mixtral-8x7b-chat,1.0,5.46e-05,1.0,1.82e-05,1.0,2.73e-05,1.0,5.46e-05,0.0,7.0616e-05,0.0,0.00095
mmlu-jurisprudence.val.91,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-high-school-biology.val.127,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,1.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
hellaswag.val.3759,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,0.0,0.0001614,0.0,0.000208744,0.0,0.0027
winogrande.dev.1173,mistralai/mistral-7b-chat,0.0,1.06e-05,0.0,1.06e-05,1.0,1.59e-05,0.0,3.18e-05,0.0,4.1128e-05,1.0,0.00057
mmlu-elementary-mathematics.val.266,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,0.0,4.32e-05,0.0,5.5872e-05,0.0,0.00073
mmlu-professional-law.val.144,WizardLM/WizardLM-13B-V1.2,0.0,0.0001029,0.0,6.86e-05,0.0,0.0001029,1.0,0.0002058,0.0,0.0002661679999999,1.0,0.00344
grade-school-math.dev.1766,mistralai/mixtral-8x7b-chat,0.5,0.0001949999999999,0.75,6.500000000000001e-05,0.5,0.0001298999999999,0.5,0.0001949999999999,0.25,0.000361616,0.75,0.0063
hellaswag.val.8552,WizardLM/WizardLM-13B-V1.2,0.0,8.52e-05,0.0,5.680000000000001e-05,0.0,8.52e-05,0.0,0.0001704,0.0,0.0002203839999999,1.0,0.00285
mmlu-professional-law.val.935,mistralai/mistral-7b-chat,0.0,6.0200000000000006e-05,0.0,6.0200000000000006e-05,1.0,9.03e-05,1.0,0.0001806,0.0,0.000233576,1.0,0.00302
hellaswag.val.2848,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,0.0,3.57e-05,0.0,7.2e-05,0.0,9.312e-05,0.0,0.00124
hellaswag.val.8233,mistralai/mixtral-8x7b-chat,0.0,0.0001824,0.0,6.080000000000001e-05,0.0,9.12e-05,0.0,0.0001824,0.0,0.000235904,0.0,0.00305
mmlu-professional-accounting.val.101,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,1.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.1892,mistralai/mistral-7b-chat,1.0,1.84e-05,1.0,1.84e-05,1.0,2.76e-05,1.0,5.52e-05,1.0,7.139200000000001e-05,1.0,0.00096
mmlu-high-school-statistics.val.100,mistralai/mixtral-8x7b-chat,0.0,8.82e-05,1.0,2.94e-05,0.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.0015099999999999
grade-school-math.dev.5577,mistralai/mistral-7b-chat,0.25,0.0001014,0.25,0.0001014,0.25,0.0001446,0.25,0.0002472,0.25,0.000421368,0.5,0.01013
mmlu-high-school-geography.val.78,mistralai/mistral-7b-chat,1.0,2.22e-05,1.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00115
consensus_summary.dev.0,mistralai/mixtral-8x7b-chat,0.75,0.0001524,0.75,6.300000000000001e-05,0.75,0.0001047,0.75,0.0001524,0.75,0.000228144,0.75,0.00421
mmlu-high-school-psychology.val.332,mistralai/mistral-7b-chat,1.0,1.5e-05,1.0,1.5e-05,0.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
hellaswag.val.8892,mistralai/mixtral-8x7b-chat,1.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
hellaswag.val.3220,mistralai/mixtral-8x7b-chat,1.0,9.06e-05,1.0,3.02e-05,1.0,4.5e-05,1.0,9.06e-05,0.0,0.000117176,1.0,0.00152
hellaswag.val.6734,mistralai/mixtral-8x7b-chat,1.0,0.0001512,1.0,5.0400000000000005e-05,1.0,7.529999999999999e-05,1.0,0.0001512,0.0,0.000195552,1.0,0.00256
grade-school-math.dev.80,WizardLM/WizardLM-13B-V1.2,0.75,0.0001553999999999,0.5,5.96e-05,0.75,0.0001553999999999,0.25,0.000255,0.25,0.00036084,0.75,0.00845
mbpp.dev.6,mistralai/mistral-7b-chat,0.0,5.6000000000000006e-05,0.0,5.6000000000000006e-05,0.0,0.0001035,0.0,0.000198,0.0,0.000203312,1.0,0.00963
mmlu-professional-law.val.1296,WizardLM/WizardLM-13B-V1.2,1.0,7.769999999999999e-05,1.0,5.2e-05,1.0,7.769999999999999e-05,1.0,0.0001553999999999,0.0,0.00020176,0.0,0.00261
mmlu-high-school-us-history.val.58,WizardLM/WizardLM-13B-V1.2,1.0,0.0001074,1.0,7.16e-05,1.0,0.0001074,1.0,0.0002148,0.0,0.000277808,1.0,0.00362
mmlu-marketing.val.105,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
hellaswag.val.7773,mistralai/mixtral-8x7b-chat,0.0,0.0001487999999999,0.0,4.9600000000000006e-05,0.0,7.439999999999999e-05,0.0,0.0001487999999999,0.0,0.000192448,1.0,0.00252
mmlu-college-chemistry.val.77,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
hellaswag.val.2622,mistralai/mistral-7b-chat,0.0,1.7599999999999998e-05,0.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mtbench.dev.6,mistralai/mistral-7b-chat,0.9,0.0001296,0.9,0.0001296,0.9,0.0002193,1.0,0.0004248,0.8,0.000494312,1.0,0.0288399999999999
mmlu-sociology.val.82,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
hellaswag.val.9149,mistralai/mistral-7b-chat,1.0,4.5e-05,1.0,4.5e-05,1.0,6.749999999999999e-05,1.0,0.0001349999999999,1.0,0.0001746,1.0,0.00229
hellaswag.val.347,mistralai/mixtral-8x7b-chat,0.0,8.159999999999999e-05,0.0,2.72e-05,0.0,4.08e-05,0.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.3232,WizardLM/WizardLM-13B-V1.2,0.0,3.8400000000000005e-05,0.0,2.58e-05,0.0,3.8400000000000005e-05,0.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
mmlu-high-school-world-history.val.100,mistralai/mixtral-8x7b-chat,1.0,0.000159,0.0,5.300000000000001e-05,1.0,7.95e-05,1.0,0.000159,0.0,0.00020564,1.0,0.00266
mbpp.dev.314,mistralai/mistral-7b-chat,0.0,3.92e-05,0.0,3.92e-05,1.0,6.900000000000001e-05,0.0,0.0001914,0.0,0.000121832,0.0,0.00892
hellaswag.val.4120,mistralai/mistral-7b-chat,1.0,5.12e-05,1.0,5.12e-05,1.0,7.680000000000001e-05,1.0,0.0001536,1.0,0.000198656,1.0,0.0026
arc-challenge.val.203,mistralai/mixtral-8x7b-chat,1.0,4.02e-05,0.0,1.34e-05,1.0,2.01e-05,1.0,4.02e-05,0.0,5.1992000000000006e-05,1.0,0.00071
grade-school-math.dev.1848,mistralai/mistral-7b-chat,0.25,8.32e-05,0.25,8.32e-05,0.25,0.0001149,0.75,0.0002375999999999,0.75,0.000318936,0.75,0.00701
mmlu-high-school-government-and-politics.val.11,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,0.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-moral-scenarios.val.769,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
hellaswag.val.3068,WizardLM/WizardLM-13B-V1.2,1.0,4.26e-05,0.0,2.84e-05,1.0,4.26e-05,1.0,8.52e-05,0.0,0.000110192,1.0,0.00146
hellaswag.val.7595,mistralai/mistral-7b-chat,1.0,4.880000000000001e-05,1.0,4.880000000000001e-05,1.0,7.319999999999999e-05,1.0,0.0001463999999999,1.0,0.0001893439999999,0.0,0.00245
hellaswag.val.2215,mistralai/mistral-7b-chat,0.0,2.44e-05,0.0,2.44e-05,0.0,3.66e-05,0.0,7.32e-05,0.0,9.4672e-05,1.0,0.00123
hellaswag.val.6882,mistralai/mixtral-8x7b-chat,1.0,0.0001476,0.0,4.920000000000001e-05,0.0,7.38e-05,1.0,0.0001476,0.0,0.0001908959999999,1.0,0.00247
hellaswag.val.8980,mistralai/mistral-7b-chat,0.0,5.420000000000001e-05,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
bias_detection.dev.122,mistralai/mistral-7b-chat,0.0,5.5e-05,0.0,5.5e-05,0.0,0.0001128,0.0,0.0001854,0.0,0.00023668,0.0,0.00731
hellaswag.val.6053,mistralai/mistral-7b-chat,0.0,4.7e-05,0.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00239
hellaswag.val.755,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,1.0,2.0600000000000003e-05,1.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00107
mmlu-professional-law.val.320,WizardLM/WizardLM-13B-V1.2,0.0,9.66e-05,0.0,6.44e-05,0.0,9.66e-05,0.0,0.0001932,0.0,0.000249872,1.0,0.00323
grade-school-math.dev.3418,mistralai/mistral-7b-chat,0.25,6.02e-05,0.25,6.02e-05,0.75,0.0001791,0.75,0.0002502,0.25,0.000331352,0.5,0.0100699999999999
mmlu-miscellaneous.val.505,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,0.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,0.0,0.00067
hellaswag.val.9497,mistralai/mixtral-8x7b-chat,0.0,0.0001746,0.0,5.8200000000000005e-05,0.0,8.730000000000001e-05,0.0,0.0001746,0.0,0.000225816,1.0,0.00295
mmlu-miscellaneous.val.2,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.943,WizardLM/WizardLM-13B-V1.2,0.0,7.62e-05,1.0,5.080000000000001e-05,0.0,7.62e-05,0.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
hellaswag.val.198,mistralai/mistral-7b-chat,0.0,2.34e-05,0.0,2.34e-05,1.0,3.51e-05,0.0,7.02e-05,0.0,9.0792e-05,1.0,0.00121
hellaswag.val.3270,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.23e-05,0.0,0.0001452,0.0,0.000187792,1.0,0.00246
mmlu-high-school-physics.val.74,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-high-school-us-history.val.120,WizardLM/WizardLM-13B-V1.2,0.0,0.0001137,0.0,7.58e-05,0.0,0.0001137,1.0,0.0002274,0.0,0.000294104,1.0,0.0038
hellaswag.val.6197,mistralai/mixtral-8x7b-chat,0.0,0.0001452,0.0,4.84e-05,0.0,7.26e-05,0.0,0.0001452,0.0,0.000187792,0.0,0.00243
hellaswag.val.4377,mistralai/mistral-7b-chat,0.0,5.44e-05,0.0,5.44e-05,1.0,8.13e-05,1.0,0.0001632,0.0,0.000211072,1.0,0.00276
mmlu-moral-disputes.val.130,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-college-physics.val.62,mistralai/mixtral-8x7b-chat,1.0,6.18e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
mmlu-high-school-us-history.val.137,mistralai/mixtral-8x7b-chat,1.0,0.0001974,1.0,6.58e-05,1.0,9.87e-05,1.0,0.0001974,0.0,0.000255304,1.0,0.0033
hellaswag.val.3085,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,1.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,0.0,0.00112
grade-school-math.dev.4051,WizardLM/WizardLM-13B-V1.2,0.75,0.0001484999999999,0.25,8.740000000000001e-05,0.75,0.0001484999999999,0.75,0.0002573999999999,0.25,0.000355408,0.75,0.0095599999999999
mmlu-moral-disputes.val.154,mistralai/mistral-7b-chat,1.0,1.92e-05,1.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
hellaswag.val.6514,WizardLM/WizardLM-13B-V1.2,0.0,7.5e-05,0.0,5e-05,0.0,7.5e-05,0.0,0.00015,0.0,0.000194,1.0,0.00254
hellaswag.val.2248,WizardLM/WizardLM-13B-V1.2,0.0,4.47e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.0015
grade-school-math.dev.6418,WizardLM/WizardLM-13B-V1.2,0.75,0.0001398,0.75,8.66e-05,0.75,0.0001398,0.75,0.000258,0.75,0.000307296,0.75,0.0063599999999999
hellaswag.val.9648,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
mmlu-human-aging.val.173,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.5590,mistralai/mixtral-8x7b-chat,0.75,0.0002676,0.25,8.78e-05,0.25,0.0001341,0.75,0.0002676,0.25,0.000390328,0.75,0.00853
grade-school-math.dev.3229,mistralai/mistral-7b-chat,0.75,7.42e-05,0.75,7.42e-05,0.75,0.000144,0.75,0.0002232,0.75,0.0002529759999999,0.75,0.00763
mmlu-marketing.val.193,WizardLM/WizardLM-13B-V1.2,0.0,3.09e-05,0.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.3722,mistralai/mixtral-8x7b-chat,0.0,0.0001602,1.0,5.34e-05,1.0,8.01e-05,0.0,0.0001602,1.0,0.000207192,1.0,0.00271
mmlu-security-studies.val.46,mistralai/mistral-7b-chat,0.0,3.4200000000000005e-05,0.0,3.4200000000000005e-05,1.0,5.13e-05,0.0,0.0001026,0.0,0.000132696,1.0,0.00172
arc-challenge.test.488,mistralai/mixtral-8x7b-chat,1.0,3.66e-05,0.0,1.22e-05,1.0,1.83e-05,1.0,3.66e-05,0.0,4.7336e-05,1.0,0.00065
hellaswag.val.2264,mistralai/mistral-7b-chat,1.0,2.74e-05,1.0,2.74e-05,1.0,4.08e-05,1.0,8.22e-05,1.0,0.000106312,1.0,0.00138
mmlu-high-school-biology.val.213,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,1.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-college-medicine.val.65,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-professional-psychology.val.284,mistralai/mistral-7b-chat,0.0,2.3800000000000003e-05,0.0,2.3800000000000003e-05,0.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
arc-challenge.test.551,mistralai/mixtral-8x7b-chat,1.0,4.6800000000000006e-05,0.0,1.5600000000000003e-05,0.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00079
grade-school-math.dev.2272,WizardLM/WizardLM-13B-V1.2,0.25,0.0001881,0.25,0.0001262,0.25,0.0001881,0.25,0.0003617999999999,0.25,0.0004462,0.75,0.01173
mmlu-abstract-algebra.val.94,mistralai/mixtral-8x7b-chat,0.0,5.8200000000000005e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
mmlu-professional-law.val.1355,WizardLM/WizardLM-13B-V1.2,0.0,7.71e-05,0.0,5.14e-05,0.0,7.71e-05,1.0,0.0001542,0.0,0.0001994319999999,1.0,0.00258
grade-school-math.dev.6063,WizardLM/WizardLM-13B-V1.2,0.75,0.0001503,0.25,8.36e-05,0.75,0.0001503,0.75,0.0002394,0.75,0.000334456,0.75,0.008
mmlu-virology.val.88,mistralai/mixtral-8x7b-chat,1.0,5.94e-05,0.0,1.98e-05,1.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
mmlu-professional-law.val.842,mistralai/mistral-7b-chat,1.0,4.1200000000000005e-05,1.0,4.1200000000000005e-05,0.0,6.18e-05,1.0,0.0001236,0.0,0.000159856,1.0,0.0021
mmlu-high-school-microeconomics.val.63,mistralai/mistral-7b-chat,1.0,1.7599999999999998e-05,1.0,1.7599999999999998e-05,1.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
hellaswag.val.2466,mistralai/mistral-7b-chat,1.0,2.1e-05,1.0,2.1e-05,1.0,3.12e-05,1.0,6.3e-05,1.0,8.148e-05,1.0,0.00109
grade-school-math.dev.1147,meta/code-llama-instruct-34b-chat,0.75,0.000396536,0.5,8.999999999999999e-05,0.75,0.0001451999999999,0.5,0.000312,0.75,0.000396536,0.5,0.00864
mmlu-professional-law.val.1169,WizardLM/WizardLM-13B-V1.2,0.0,9.78e-05,0.0,6.52e-05,0.0,9.78e-05,1.0,0.0001956,0.0,0.0002529759999999,1.0,0.00327
grade-school-math.dev.1325,WizardLM/WizardLM-13B-V1.2,0.75,0.0001286999999999,0.25,6.42e-05,0.75,0.0001286999999999,0.25,0.0001961999999999,0.25,0.000304968,0.75,0.00709
mmlu-professional-psychology.val.444,WizardLM/WizardLM-13B-V1.2,1.0,5.64e-05,0.0,3.7600000000000006e-05,1.0,5.64e-05,1.0,0.0001127999999999,0.0,0.000145888,1.0,0.00189
mmlu-professional-psychology.val.581,mistralai/mistral-7b-chat,0.0,2.2600000000000004e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
mmlu-sociology.val.104,mistralai/mixtral-8x7b-chat,1.0,7.68e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
hellaswag.val.6617,WizardLM/WizardLM-13B-V1.2,1.0,8.999999999999999e-05,1.0,6e-05,1.0,8.999999999999999e-05,1.0,0.0001799999999999,0.0,0.0002328,1.0,0.00304
mmlu-moral-scenarios.val.276,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,1.0,4.41e-05,1.0,8.82e-05,0.0,0.000114072,1.0,0.00148
winogrande.dev.671,mistralai/mistral-7b-chat,1.0,1.16e-05,1.0,1.16e-05,0.0,1.7400000000000003e-05,1.0,3.4800000000000006e-05,1.0,4.500800000000001e-05,1.0,0.00062
winogrande.dev.999,mistralai/mistral-7b-chat,1.0,1.02e-05,1.0,1.02e-05,1.0,1.56e-05,1.0,3.12e-05,0.0,4.0352e-05,1.0,0.00056
mmlu-moral-scenarios.val.718,mistralai/mistral-7b-chat,0.0,2.9800000000000003e-05,0.0,2.9800000000000003e-05,0.0,4.47e-05,0.0,8.94e-05,0.0,0.000115624,1.0,0.00153
grade-school-math.dev.6434,mistralai/mistral-7b-chat,0.25,0.0001028,0.25,0.0001028,0.75,0.0001365,0.75,0.0002556,0.75,0.000336784,0.75,0.00756
mmlu-professional-accounting.val.39,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,0.0,4.29e-05,0.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mmlu-world-religions.val.14,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
mmlu-prehistory.val.37,mistralai/mixtral-8x7b-chat,1.0,5.58e-05,0.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.346,mistralai/mixtral-8x7b-chat,0.25,0.0003564,0.25,9.5e-05,0.25,0.000195,0.25,0.0003564,0.25,0.000339888,0.75,0.01174
mmlu-high-school-macroeconomics.val.305,mistralai/mistral-7b-chat,0.0,1.62e-05,0.0,1.62e-05,1.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-moral-disputes.val.122,mistralai/mistral-7b-chat,0.0,1.44e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00076
mmlu-high-school-government-and-politics.val.173,mistralai/mistral-7b-chat,0.0,2.6e-05,0.0,2.6e-05,1.0,3.9e-05,1.0,7.8e-05,0.0,0.00010088,1.0,0.00131
mmlu-world-religions.val.105,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,0.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.6408,WizardLM/WizardLM-13B-V1.2,0.25,0.0001623,0.75,9.9e-05,0.25,0.0001623,0.25,0.0002609999999999,0.25,0.000340664,0.75,0.00967
grade-school-math.dev.6369,mistralai/mistral-7b-chat,0.75,8.400000000000001e-05,0.75,8.400000000000001e-05,0.25,0.000138,0.25,0.000255,0.25,0.000352304,0.75,0.008
hellaswag.val.277,WizardLM/WizardLM-13B-V1.2,0.0,3.6e-05,0.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
arc-challenge.test.809,mistralai/mistral-7b-chat,0.0,1.52e-05,0.0,1.52e-05,1.0,2.28e-05,1.0,4.56e-05,0.0,5.8976e-05,1.0,0.00077
grade-school-math.dev.1130,WizardLM/WizardLM-13B-V1.2,0.25,0.0002058,0.25,0.0001218,0.25,0.0002058,0.25,0.000384,0.25,0.000431456,0.5,0.01596
hellaswag.val.997,mistralai/mistral-7b-chat,1.0,1.94e-05,1.0,1.94e-05,1.0,2.88e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
grade-school-math.dev.3322,WizardLM/WizardLM-13B-V1.2,0.75,0.0001662,0.25,9.68e-05,0.75,0.0001662,0.75,0.000285,0.25,0.00031816,0.75,0.01222
hellaswag.val.4166,WizardLM/WizardLM-13B-V1.2,0.0,7.680000000000001e-05,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,0.0,0.0026
grade-school-math.dev.6104,WizardLM/WizardLM-13B-V1.2,0.25,0.0001386,0.25,7.76e-05,0.25,0.0001386,0.25,0.0002034,0.25,0.0003228159999999,0.75,0.00859
mmlu-professional-law.val.852,WizardLM/WizardLM-13B-V1.2,1.0,0.0001002,0.0,6.68e-05,1.0,0.0001002,1.0,0.0002004,0.0,0.000259184,1.0,0.00335
hellaswag.val.5992,WizardLM/WizardLM-13B-V1.2,1.0,7.56e-05,1.0,5.0400000000000005e-05,1.0,7.56e-05,1.0,0.0001512,1.0,0.000195552,1.0,0.00256
mmlu-moral-disputes.val.233,mistralai/mistral-7b-chat,0.0,2.68e-05,0.0,2.68e-05,0.0,4.02e-05,1.0,8.04e-05,0.0,0.000103984,1.0,0.00135
grade-school-math.dev.6467,WizardLM/WizardLM-13B-V1.2,0.25,0.0001779,0.25,9.26e-05,0.25,0.0001779,0.75,0.0002076,0.25,0.000396536,0.75,0.00962
grade-school-math.dev.5401,WizardLM/WizardLM-13B-V1.2,0.75,0.0001502999999999,0.25,7.620000000000001e-05,0.75,0.0001502999999999,0.5,0.0002538,0.25,0.0003298,0.75,0.00841
abstract2title.test.236,mistralai/mixtral-8x7b-chat,1.0,0.000177,1.0,5.78e-05,1.0,8.97e-05,1.0,0.000177,1.0,0.000218056,1.0,0.00336
hellaswag.val.4064,mistralai/mixtral-8x7b-chat,0.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.159999999999999e-05,0.0,0.0001638,0.0,0.0002118479999999,1.0,0.00274
grade-school-math.dev.5143,WizardLM/WizardLM-13B-V1.2,0.5,0.0001319999999999,0.25,5.84e-05,0.5,0.0001319999999999,0.25,0.0002087999999999,0.25,0.000230472,0.75,0.00537
grade-school-math.dev.2884,mistralai/mistral-7b-chat,0.25,7.620000000000001e-05,0.25,7.620000000000001e-05,0.25,0.0002096999999999,0.25,0.0002429999999999,0.75,0.00033756,0.75,0.01032
mmlu-high-school-psychology.val.435,mistralai/mixtral-8x7b-chat,1.0,4.5e-05,0.0,1.5e-05,1.0,2.25e-05,1.0,4.5e-05,0.0,5.8200000000000005e-05,1.0,0.0007599999999999
mmlu-professional-law.val.1163,mistralai/mistral-7b-chat,0.0,6.52e-05,0.0,6.52e-05,0.0,9.78e-05,1.0,0.0001956,0.0,0.0002529759999999,1.0,0.00327
hellaswag.val.1805,mistralai/mistral-7b-chat,0.0,2.08e-05,0.0,2.08e-05,0.0,3.12e-05,0.0,6.24e-05,0.0,8.0704e-05,1.0,0.00105
mmlu-moral-disputes.val.127,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,0.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
hellaswag.val.2262,WizardLM/WizardLM-13B-V1.2,1.0,3.03e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,1.0,0.00102
abstract2title.test.180,mistralai/mixtral-8x7b-chat,1.0,0.000135,1.0,4.4800000000000005e-05,1.0,7.11e-05,1.0,0.000135,1.0,0.000168392,1.0,0.00284
grade-school-math.dev.4990,WizardLM/WizardLM-13B-V1.2,0.25,0.0001923,0.0,0.0001112,0.25,0.0001923,0.75,0.0003846,0.75,0.000309624,0.5,0.00932
grade-school-math.dev.4288,mistralai/mistral-7b-chat,0.25,0.0005776,0.25,0.0005776,0.75,0.0001467,0.75,0.000231,0.75,0.000277032,0.75,0.00651
hellaswag.val.10010,mistralai/mistral-7b-chat,1.0,4.080000000000001e-05,1.0,4.080000000000001e-05,0.0,6.12e-05,1.0,0.0001224,1.0,0.000158304,1.0,0.00208
mmlu-high-school-geography.val.140,mistralai/mixtral-8x7b-chat,1.0,4.92e-05,0.0,1.64e-05,1.0,2.46e-05,1.0,4.92e-05,0.0,6.3632e-05,1.0,0.00083
grade-school-math.dev.7051,WizardLM/WizardLM-13B-V1.2,0.5,0.0001569,0.5,0.0001,0.5,0.0001569,0.5,0.0002508,0.5,0.00031428,0.75,0.0079499999999999
mmlu-high-school-world-history.val.138,mistralai/mixtral-8x7b-chat,1.0,0.0002028,0.0,6.76e-05,1.0,0.0001014,1.0,0.0002028,0.0,0.0002622879999999,1.0,0.00339
hellaswag.val.7117,mistralai/mistral-7b-chat,1.0,4.9000000000000005e-05,1.0,4.9000000000000005e-05,1.0,7.35e-05,1.0,0.000147,1.0,0.00019012,0.0,0.00249
mmlu-econometrics.val.96,mistralai/mixtral-8x7b-chat,1.0,0.0001026,1.0,3.4200000000000005e-05,1.0,5.13e-05,1.0,0.0001026,0.0,0.000132696,1.0,0.00172
hellaswag.val.2327,mistralai/mistral-7b-chat,1.0,2.6600000000000003e-05,1.0,2.6600000000000003e-05,0.0,3.96e-05,1.0,7.98e-05,0.0,0.000103208,1.0,0.00137
hellaswag.val.9328,mistralai/mixtral-8x7b-chat,0.0,0.000159,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00266
mmlu-virology.val.11,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,0.0,0.00085
mmlu-nutrition.val.90,mistralai/mixtral-8x7b-chat,0.0,7.14e-05,1.0,2.3800000000000003e-05,0.0,3.57e-05,0.0,7.14e-05,0.0,9.2344e-05,1.0,0.00123
mmlu-anatomy.val.29,mistralai/mixtral-8x7b-chat,0.0,9.42e-05,0.0,3.1400000000000004e-05,0.0,4.71e-05,0.0,9.42e-05,0.0,0.000121832,1.0,0.00158
arc-challenge.test.139,mistralai/mixtral-8x7b-chat,0.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00078
mbpp.dev.140,mistralai/mistral-7b-chat,0.0,3.96e-05,0.0,3.96e-05,0.0,4.92e-05,1.0,0.0001212,0.0,9.6224e-05,1.0,0.01201
mmlu-professional-law.val.593,WizardLM/WizardLM-13B-V1.2,0.0,5.37e-05,1.0,3.58e-05,0.0,5.37e-05,0.0,0.0001074,0.0,0.000138904,1.0,0.00183
hellaswag.val.3818,mistralai/mistral-7b-chat,0.0,5.380000000000001e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-moral-scenarios.val.731,mistralai/mistral-7b-chat,0.0,2.9e-05,0.0,2.9e-05,0.0,4.35e-05,0.0,8.7e-05,0.0,0.00011252,1.0,0.00149
hellaswag.val.8917,mistralai/mixtral-8x7b-chat,0.0,0.000156,1.0,5.2e-05,1.0,7.8e-05,0.0,0.000156,1.0,0.00020176,1.0,0.00264
mmlu-high-school-european-history.val.146,mistralai/mixtral-8x7b-chat,0.0,0.0002292,0.0,7.66e-05,0.0,0.0001149,0.0,0.0002292,0.0,0.000297208,0.0,0.00384
hellaswag.val.1143,mistralai/mistral-7b-chat,0.0,1.7800000000000002e-05,0.0,1.7800000000000002e-05,0.0,2.67e-05,0.0,5.34e-05,0.0,6.9064e-05,0.0,0.0009
arc-challenge.test.823,mistralai/mistral-7b-chat,0.0,2.24e-05,0.0,2.24e-05,1.0,3.33e-05,1.0,6.720000000000001e-05,0.0,8.6912e-05,1.0,0.00113
mmlu-moral-disputes.val.54,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,1.0,5.94e-05,0.0,7.682400000000001e-05,0.0,0.001
grade-school-math.dev.634,mistralai/mixtral-8x7b-chat,0.75,0.0002975999999999,0.5,9.8e-05,0.5,0.0001539,0.75,0.0002975999999999,0.75,0.000344544,0.75,0.00892
consensus_summary.dev.64,mistralai/mixtral-8x7b-chat,0.75,0.0001896,0.25,6.26e-05,0.75,0.0001257,0.75,0.0001896,0.0,0.000312728,0.0,0.0037099999999999
mmlu-moral-scenarios.val.437,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
grade-school-math.dev.2479,mistralai/mistral-7b-chat,0.75,7.98e-05,0.75,7.98e-05,0.75,0.0001584,0.25,0.000276,0.25,0.00041516,0.75,0.00804
mmlu-prehistory.val.105,mistralai/mixtral-8x7b-chat,1.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,1.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
hellaswag.val.8186,mistralai/mixtral-8x7b-chat,0.0,0.0001536,0.0,5.12e-05,0.0,7.680000000000001e-05,0.0,0.0001536,0.0,0.000198656,1.0,0.00257
hellaswag.val.2211,mistralai/mistral-7b-chat,0.0,2.58e-05,0.0,2.58e-05,0.0,3.8700000000000006e-05,0.0,7.740000000000001e-05,0.0,0.000100104,0.0,0.0013
mmlu-prehistory.val.96,mistralai/mixtral-8x7b-chat,1.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,1.0,6.42e-05,0.0,8.3032e-05,1.0,0.0011099999999999
mmlu-high-school-microeconomics.val.39,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,0.0,2.79e-05,0.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
mmlu-medical-genetics.val.58,mistralai/mistral-7b-chat,0.0,2.56e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00129
mmlu-conceptual-physics.val.229,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.8303,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,0.0,5.1000000000000006e-05,0.0,7.619999999999998e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00259
mbpp.dev.307,mistralai/mistral-7b-chat,0.0,3.8e-05,0.0,3.8e-05,0.0,7.47e-05,1.0,0.0001494,1.0,0.000124936,1.0,0.00675
mmlu-abstract-algebra.val.7,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00098
mmlu-high-school-statistics.val.163,mistralai/mistral-7b-chat,0.0,3.54e-05,0.0,3.54e-05,0.0,5.31e-05,1.0,0.0001062,0.0,0.000137352,1.0,0.00178
mmlu-high-school-macroeconomics.val.251,mistralai/mistral-7b-chat,1.0,2.04e-05,1.0,2.04e-05,1.0,3.06e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-professional-psychology.val.259,mistralai/mistral-7b-chat,0.0,2.94e-05,0.0,2.94e-05,0.0,4.41e-05,0.0,8.82e-05,0.0,0.000114072,1.0,0.00148
grade-school-math.dev.1144,WizardLM/WizardLM-13B-V1.2,0.25,0.0001635,0.25,0.0001062,0.25,0.0001635,0.25,0.0002904,0.25,0.00040352,0.75,0.01275
hellaswag.val.6492,mistralai/mixtral-8x7b-chat,0.0,0.0001386,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,1.0,0.00232
mmlu-high-school-macroeconomics.val.378,mistralai/mistral-7b-chat,1.0,2.3800000000000003e-05,1.0,2.3800000000000003e-05,1.0,3.57e-05,1.0,7.14e-05,0.0,9.2344e-05,1.0,0.0012
winogrande.dev.1241,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,1.0,4.0352e-05,1.0,0.00056
grade-school-math.dev.3578,mistralai/mixtral-8x7b-chat,0.75,0.0002357999999999,0.25,0.0001004,0.75,0.0001452,0.75,0.0002357999999999,0.75,0.000332128,0.75,0.00716
hellaswag.val.4203,WizardLM/WizardLM-13B-V1.2,0.0,8.25e-05,0.0,5.520000000000001e-05,0.0,8.25e-05,1.0,0.0001656,0.0,0.0002141759999999,1.0,0.00277
mmlu-professional-law.val.1462,WizardLM/WizardLM-13B-V1.2,1.0,8.699999999999999e-05,0.0,5.800000000000001e-05,1.0,8.699999999999999e-05,0.0,0.0001739999999999,0.0,0.00022504,1.0,0.00291
mmlu-international-law.val.97,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
winogrande.dev.1044,mistralai/mistral-7b-chat,1.0,1.04e-05,1.0,1.04e-05,0.0,1.56e-05,1.0,3.12e-05,1.0,4.0352e-05,1.0,0.00056
mmlu-high-school-world-history.val.146,WizardLM/WizardLM-13B-V1.2,1.0,0.0001233,1.0,8.22e-05,1.0,0.0001233,1.0,0.0002466,0.0,0.000318936,1.0,0.0041199999999999
mmlu-high-school-us-history.val.78,mistralai/mixtral-8x7b-chat,1.0,0.0001428,0.0,4.7600000000000005e-05,1.0,7.14e-05,1.0,0.0001428,0.0,0.000184688,1.0,0.00239
winogrande.dev.651,mistralai/mistral-7b-chat,0.0,1e-05,0.0,1e-05,1.0,1.5e-05,0.0,3e-05,0.0,3.880000000000001e-05,0.0,0.00054
hellaswag.val.4849,WizardLM/WizardLM-13B-V1.2,0.0,6.749999999999999e-05,0.0,4.5e-05,0.0,6.749999999999999e-05,0.0,0.0001349999999999,0.0,0.0001746,1.0,0.00226
mmlu-professional-law.val.709,WizardLM/WizardLM-13B-V1.2,0.0,9.84e-05,0.0,6.56e-05,0.0,9.84e-05,1.0,0.0001967999999999,0.0,0.000254528,1.0,0.00332
mmlu-formal-logic.val.34,mistralai/mixtral-8x7b-chat,1.0,5.28e-05,0.0,1.7599999999999998e-05,0.0,2.64e-05,1.0,5.28e-05,0.0,6.828800000000001e-05,1.0,0.00089
mmlu-professional-law.val.1174,mistralai/mistral-7b-chat,0.0,3.2200000000000003e-05,0.0,3.2200000000000003e-05,1.0,4.83e-05,0.0,9.66e-05,0.0,0.000124936,0.0,0.00162
mmlu-high-school-mathematics.val.91,mistralai/mistral-7b-chat,0.0,2.4e-05,0.0,2.4e-05,0.0,3.6e-05,0.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
mmlu-professional-law.val.597,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.649999999999999e-05,1.0,0.0001529999999999,0.0,0.00019788,0.0,0.00256
hellaswag.val.5575,mistralai/mixtral-8x7b-chat,0.0,0.0001728,0.0,5.76e-05,0.0,8.64e-05,0.0,0.0001728,0.0,0.0002234879999999,1.0,0.00289
hellaswag.val.4519,mistralai/mistral-7b-chat,1.0,5.380000000000001e-05,1.0,5.380000000000001e-05,1.0,8.07e-05,0.0,0.0001614,1.0,0.000208744,1.0,0.0027
grade-school-math.dev.4618,mistralai/mistral-7b-chat,0.75,8.060000000000001e-05,0.75,8.060000000000001e-05,0.5,0.0001752,0.25,0.0002556,0.5,0.000405072,0.5,0.00994
mmlu-jurisprudence.val.10,mistralai/mixtral-8x7b-chat,0.0,4.56e-05,0.0,1.52e-05,0.0,2.28e-05,0.0,4.56e-05,0.0,5.8976e-05,1.0,0.0008
mmlu-high-school-us-history.val.28,WizardLM/WizardLM-13B-V1.2,1.0,0.0001178999999999,1.0,7.86e-05,1.0,0.0001178999999999,1.0,0.0002357999999999,0.0,0.0003049679999999,1.0,0.00394
mmlu-logical-fallacies.val.92,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,1.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.00149
mmlu-human-aging.val.171,mistralai/mixtral-8x7b-chat,1.0,4.14e-05,1.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-international-law.val.12,mistralai/mistral-7b-chat,0.0,3.2200000000000003e-05,0.0,3.2200000000000003e-05,1.0,4.83e-05,1.0,9.66e-05,0.0,0.000124936,1.0,0.00162
mbpp.dev.301,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,0.0,0.0001631999999999,0.0,0.0002255999999999,0.0,0.0001544239999999,0.0,0.01592
grade-school-math.dev.6589,WizardLM/WizardLM-13B-V1.2,0.25,0.0001605,0.25,0.000109,0.25,0.0001605,0.75,0.000276,0.25,0.0003507519999999,0.75,0.01079
grade-school-math.dev.1638,meta/code-llama-instruct-34b-chat,0.25,0.000320488,0.25,0.0001372,0.75,0.0001392,0.75,0.0002808,0.25,0.000320488,0.75,0.01069
mmlu-prehistory.val.75,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,1.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-moral-scenarios.val.227,mistralai/mistral-7b-chat,0.0,3.02e-05,0.0,3.02e-05,1.0,4.53e-05,1.0,9.06e-05,0.0,0.000117176,0.0,0.00155
grade-school-math.dev.6596,meta/code-llama-instruct-34b-chat,0.25,0.00030652,0.25,9.04e-05,0.75,0.0001695,0.25,0.0002652,0.25,0.00030652,0.75,0.01125
hellaswag.val.2425,mistralai/mistral-7b-chat,1.0,2.7e-05,1.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00136
mmlu-high-school-government-and-politics.val.83,mistralai/mistral-7b-chat,0.0,2.1e-05,0.0,2.1e-05,0.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
hellaswag.val.5010,WizardLM/WizardLM-13B-V1.2,0.0,7.95e-05,0.0,5.300000000000001e-05,0.0,7.95e-05,0.0,0.000159,0.0,0.00020564,1.0,0.00269
mbpp.dev.316,mistralai/mistral-7b-chat,0.0,4.34e-05,0.0,4.34e-05,1.0,8.4e-05,1.0,0.0001824,1.0,0.000222712,1.0,0.00866
mmlu-professional-medicine.val.119,WizardLM/WizardLM-13B-V1.2,0.0,9.33e-05,0.0,6.22e-05,0.0,9.33e-05,1.0,0.0001866,0.0,0.000241336,1.0,0.00315
grade-school-math.dev.2203,mistralai/mistral-7b-chat,0.5,5.42e-05,0.5,5.42e-05,0.75,0.0001298999999999,0.75,0.0001997999999999,0.5,0.000212624,0.75,0.00513
mmlu-virology.val.137,mistralai/mixtral-8x7b-chat,0.0,4.92e-05,1.0,1.64e-05,0.0,2.46e-05,0.0,4.92e-05,0.0,6.3632e-05,0.0,0.00083
mmlu-sociology.val.105,mistralai/mixtral-8x7b-chat,0.0,5.04e-05,0.0,1.6800000000000002e-05,1.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-college-computer-science.val.6,mistralai/mistral-7b-chat,0.0,3.92e-05,0.0,3.92e-05,0.0,5.88e-05,0.0,0.0001176,0.0,0.000152096,1.0,0.00197
mmlu-professional-law.val.300,WizardLM/WizardLM-13B-V1.2,0.0,7.049999999999999e-05,0.0,4.7e-05,0.0,7.049999999999999e-05,1.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
mmlu-professional-law.val.134,WizardLM/WizardLM-13B-V1.2,0.0,6.21e-05,1.0,4.14e-05,0.0,6.21e-05,1.0,0.0001236,0.0,0.000160632,1.0,0.00208
hellaswag.val.2011,WizardLM/WizardLM-13B-V1.2,1.0,3.84e-05,0.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.9328e-05,1.0,0.00132
mmlu-marketing.val.163,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
hellaswag.val.41,WizardLM/WizardLM-13B-V1.2,0.0,4.56e-05,0.0,3.04e-05,0.0,4.56e-05,1.0,9.12e-05,0.0,0.000117952,1.0,0.00153
arc-challenge.test.352,mistralai/mixtral-8x7b-chat,0.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,0.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
grade-school-math.dev.5226,mistralai/mistral-7b-chat,0.25,9.44e-05,0.25,9.44e-05,0.75,0.0001704,0.5,0.0002646,0.25,0.00033368,0.75,0.007
mmlu-moral-scenarios.val.626,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,1.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00139
grade-school-math.dev.1727,mistralai/mistral-7b-chat,0.25,0.0001142,0.25,0.0001142,0.25,0.0001701,0.75,0.0004488,0.75,0.0003786879999999,0.75,0.00968
mmlu-professional-law.val.136,mistralai/mistral-7b-chat,0.0,4.280000000000001e-05,0.0,4.280000000000001e-05,1.0,6.42e-05,0.0,0.0001284,0.0,0.000166064,1.0,0.00215
mmlu-miscellaneous.val.713,mistralai/mixtral-8x7b-chat,1.0,3.9e-05,0.0,1.3e-05,1.0,1.95e-05,1.0,3.9e-05,0.0,5.044e-05,1.0,0.00066
mmlu-jurisprudence.val.53,mistralai/mixtral-8x7b-chat,1.0,7.259999999999999e-05,1.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00125
mmlu-anatomy.val.45,mistralai/mixtral-8x7b-chat,1.0,6.78e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,1.0,6.78e-05,0.0,8.768799999999999e-05,1.0,0.00114
hellaswag.val.5905,mistralai/mistral-7b-chat,1.0,5.7400000000000006e-05,1.0,5.7400000000000006e-05,1.0,8.61e-05,1.0,0.0001722,1.0,0.000222712,1.0,0.00288
hellaswag.val.3899,WizardLM/WizardLM-13B-V1.2,1.0,9.09e-05,0.0,6.06e-05,1.0,9.09e-05,0.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
mmlu-professional-law.val.1321,WizardLM/WizardLM-13B-V1.2,0.0,4.83e-05,0.0,3.2200000000000003e-05,0.0,4.83e-05,0.0,9.66e-05,0.0,0.000124936,1.0,0.00162
grade-school-math.dev.3584,WizardLM/WizardLM-13B-V1.2,0.75,0.0001304999999999,0.75,7.44e-05,0.75,0.0001304999999999,0.75,0.0002316,0.75,0.000305744,0.75,0.00643
hellaswag.val.6582,WizardLM/WizardLM-13B-V1.2,0.0,7.53e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,0.0,0.00255
mmlu-high-school-psychology.val.450,mistralai/mistral-7b-chat,1.0,1.4e-05,1.0,1.4e-05,0.0,2.1e-05,1.0,4.2e-05,0.0,5.432e-05,1.0,0.00074
mmlu-professional-law.val.1178,WizardLM/WizardLM-13B-V1.2,0.0,0.0001137,1.0,7.58e-05,0.0,0.0001137,1.0,0.0002274,0.0,0.000294104,1.0,0.0038
mmlu-professional-psychology.val.330,mistralai/mixtral-8x7b-chat,1.0,5.8200000000000005e-05,1.0,1.94e-05,1.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00101
mmlu-college-biology.val.135,mistralai/mixtral-8x7b-chat,1.0,9e-05,0.0,3e-05,0.0,4.5e-05,1.0,9e-05,0.0,0.0001164,1.0,0.00151
mmlu-professional-law.val.625,WizardLM/WizardLM-13B-V1.2,1.0,8.249999999999999e-05,0.0,5.5e-05,1.0,8.249999999999999e-05,0.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
mmlu-professional-law.val.1312,WizardLM/WizardLM-13B-V1.2,1.0,0.0001061999999999,1.0,7.08e-05,1.0,0.0001061999999999,1.0,0.0002123999999999,0.0,0.0002747039999999,1.0,0.00355
mmlu-professional-law.val.968,mistralai/mixtral-8x7b-chat,1.0,0.0001518,1.0,5.06e-05,0.0,7.59e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.6359,mistralai/mistral-7b-chat,0.25,5.96e-05,0.25,5.96e-05,0.25,0.0001376999999999,0.25,0.0002417999999999,0.25,0.000230472,0.75,0.00586
grade-school-math.dev.3053,WizardLM/WizardLM-13B-V1.2,0.5,0.0001764,0.75,8.440000000000002e-05,0.5,0.0001764,0.5,0.0002298,0.5,0.000339888,0.5,0.00861
mmlu-high-school-macroeconomics.val.361,mistralai/mistral-7b-chat,0.0,1.74e-05,0.0,1.74e-05,1.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.00091
mmlu-high-school-mathematics.val.104,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,0.0,6.659999999999999e-05,0.0,8.6136e-05,0.0,0.00112
mmlu-high-school-macroeconomics.val.122,mistralai/mistral-7b-chat,0.0,1.92e-05,0.0,1.92e-05,1.0,2.88e-05,1.0,5.76e-05,0.0,7.4496e-05,1.0,0.0009699999999999
mmlu-clinical-knowledge.val.161,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,0.0,0.00108
hellaswag.val.707,mistralai/mixtral-8x7b-chat,0.0,7.8e-05,0.0,2.6e-05,1.0,3.9e-05,0.0,7.8e-05,0.0,0.00010088,1.0,0.00131
winogrande.dev.528,mistralai/mistral-7b-chat,1.0,9.4e-06,1.0,9.4e-06,1.0,1.41e-05,1.0,2.82e-05,1.0,3.6472000000000006e-05,1.0,0.00051
mmlu-elementary-mathematics.val.264,mistralai/mistral-7b-chat,0.0,3e-05,0.0,3e-05,0.0,4.5e-05,0.0,9e-05,0.0,0.0001164,1.0,0.00151
grade-school-math.dev.2750,WizardLM/WizardLM-13B-V1.2,0.25,0.0002156999999999,0.25,0.0001268,0.25,0.0002156999999999,0.25,0.0003138,0.25,0.000412832,0.5,0.0186
mmlu-high-school-psychology.val.218,WizardLM/WizardLM-13B-V1.2,0.0,3.75e-05,0.0,2.5e-05,0.0,3.75e-05,1.0,7.5e-05,0.0,9.7e-05,0.0,0.00129
mmlu-high-school-biology.val.189,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
bias_detection.dev.62,mistralai/mistral-7b-chat,0.0,6.24e-05,0.0,6.24e-05,0.0,0.0001049999999999,1.0,0.0002165999999999,0.0,0.000259184,1.0,0.00631
mmlu-professional-law.val.1349,WizardLM/WizardLM-13B-V1.2,0.0,6.48e-05,1.0,4.3200000000000007e-05,0.0,6.48e-05,0.0,0.0001296,0.0,0.000167616,0.0,0.0022
hellaswag.val.2767,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.08e-05,0.0,8.22e-05,0.0,0.000106312,0.0,0.00138
mmlu-logical-fallacies.val.105,mistralai/mistral-7b-chat,0.0,1.5e-05,0.0,1.5e-05,1.0,2.25e-05,0.0,4.5e-05,0.0,5.8200000000000005e-05,0.0,0.0007599999999999
grade-school-math.dev.3808,WizardLM/WizardLM-13B-V1.2,0.75,0.0001836,0.5,0.0001062,0.75,0.0001836,0.75,0.0002837999999999,0.75,0.0003887759999999,0.5,0.0102
mtbench-math.dev.17,mistralai/mistral-7b-chat,0.4,5.640000000000001e-05,0.4,5.640000000000001e-05,0.1,0.0004098,0.4,0.0003396,1.0,0.000173048,1.0,0.01193
hellaswag.val.6508,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00275
mmlu-professional-psychology.val.212,mistralai/mixtral-8x7b-chat,1.0,5.04e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-law.val.1030,WizardLM/WizardLM-13B-V1.2,0.0,8.13e-05,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,0.0,0.00272
abstract2title.test.163,mistralai/mixtral-8x7b-chat,1.0,0.0002123999999999,1.0,7.04e-05,1.0,0.0001077,1.0,0.0002123999999999,1.0,0.000266944,1.0,0.00405
mmlu-astronomy.val.82,mistralai/mixtral-8x7b-chat,1.0,7.68e-05,1.0,2.56e-05,1.0,3.84e-05,1.0,7.68e-05,0.0,9.8552e-05,1.0,0.00129
arc-challenge.test.154,mistralai/mistral-7b-chat,0.0,1.36e-05,0.0,1.36e-05,0.0,2.04e-05,0.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
grade-school-math.dev.6502,mistralai/mistral-7b-chat,0.25,8.08e-05,0.25,8.08e-05,0.25,0.0001647,0.25,0.0002333999999999,0.25,0.000312728,0.5,0.0100699999999999
grade-school-math.dev.776,WizardLM/WizardLM-13B-V1.2,0.5,0.0001467,0.75,6.460000000000001e-05,0.5,0.0001467,0.5,0.0001902,0.25,0.000277808,0.5,0.00614
grade-school-math.dev.3595,mistralai/mistral-7b-chat,0.25,0.0001132,0.25,0.0001132,0.75,0.0001923,0.75,0.0002838,0.25,0.000498192,0.75,0.01246
hellaswag.val.8270,mistralai/mixtral-8x7b-chat,0.0,0.0001902,0.0,6.34e-05,0.0,9.51e-05,0.0,0.0001902,0.0,0.000245992,1.0,0.00318
hellaswag.val.6539,mistralai/mixtral-8x7b-chat,0.0,0.0001608,0.0,5.360000000000001e-05,0.0,8.01e-05,0.0,0.0001608,0.0,0.0002079679999999,1.0,0.00272
mmlu-professional-law.val.11,WizardLM/WizardLM-13B-V1.2,1.0,0.0001565999999999,0.0,0.0001043999999999,1.0,0.0001565999999999,1.0,0.0003131999999999,0.0,0.000405072,1.0,0.0052299999999999
mmlu-computer-security.val.99,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,0.0,2.13e-05,0.0,4.26e-05,0.0,5.5096e-05,0.0,0.0007199999999999
mmlu-professional-accounting.val.56,mistralai/mistral-7b-chat,0.0,2.8600000000000004e-05,0.0,2.8600000000000004e-05,1.0,4.26e-05,1.0,8.58e-05,0.0,0.000110968,1.0,0.00144
mbpp.dev.135,mistralai/mistral-7b-chat,0.0,4.240000000000001e-05,0.0,4.240000000000001e-05,0.0,7.02e-05,0.0,0.000177,0.0,0.000123384,0.0,0.00809
mmlu-college-medicine.val.100,mistralai/mistral-7b-chat,1.0,1.62e-05,1.0,1.62e-05,1.0,2.43e-05,1.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00082
mmlu-professional-law.val.836,mistralai/mistral-7b-chat,1.0,2.8e-05,1.0,2.8e-05,1.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.00141
grade-school-math.dev.1569,WizardLM/WizardLM-13B-V1.2,0.25,0.0001788,0.25,9.02e-05,0.25,0.0001788,0.75,0.0002808,0.25,0.000332128,0.75,0.01
mmlu-marketing.val.75,mistralai/mistral-7b-chat,1.0,1.54e-05,1.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00081
winogrande.dev.730,mistralai/mistral-7b-chat,1.0,9.6e-06,1.0,9.6e-06,1.0,1.4399999999999998e-05,1.0,2.8799999999999995e-05,1.0,3.7248e-05,1.0,0.00052
mmlu-professional-psychology.val.569,mistralai/mixtral-8x7b-chat,1.0,5.7e-05,0.0,1.9e-05,1.0,2.85e-05,1.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
mmlu-management.val.39,mistralai/mistral-7b-chat,0.0,1.38e-05,0.0,1.38e-05,0.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.00073
mmlu-high-school-european-history.val.32,WizardLM/WizardLM-13B-V1.2,0.0,0.0001319999999999,0.0,8.800000000000001e-05,0.0,0.0001319999999999,0.0,0.0002639999999999,0.0,0.00034144,0.0,0.00441
grade-school-math.dev.3693,meta/code-llama-instruct-34b-chat,0.75,0.00030652,0.25,8.58e-05,0.75,0.0001326,0.75,0.0002309999999999,0.75,0.00030652,0.75,0.00624
grade-school-math.dev.611,WizardLM/WizardLM-13B-V1.2,0.25,0.0001307999999999,0.25,8.740000000000001e-05,0.25,0.0001307999999999,0.75,0.0002316,0.25,0.00034144,0.75,0.00917
hellaswag.val.988,mistralai/mistral-7b-chat,1.0,2.32e-05,1.0,2.32e-05,1.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.0012
hellaswag.val.2302,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
mmlu-professional-accounting.val.137,WizardLM/WizardLM-13B-V1.2,0.0,2.94e-05,1.0,1.96e-05,0.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00102
grade-school-math.dev.1382,WizardLM/WizardLM-13B-V1.2,0.75,0.0001245,0.75,6.2e-05,0.75,0.0001245,0.75,0.0002189999999999,0.75,0.000265392,0.5,0.0059
mmlu-marketing.val.233,mistralai/mistral-7b-chat,0.0,1.58e-05,0.0,1.58e-05,0.0,2.37e-05,0.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
mmlu-moral-scenarios.val.778,mistralai/mistral-7b-chat,0.0,2.74e-05,0.0,2.74e-05,0.0,4.11e-05,0.0,8.22e-05,0.0,0.000106312,0.0,0.00138
grade-school-math.dev.3519,WizardLM/WizardLM-13B-V1.2,0.5,0.0001878,0.25,8.92e-05,0.5,0.0001878,0.25,0.000276,0.25,0.00031816,0.75,0.00847
grade-school-math.dev.3190,mistralai/mistral-7b-chat,0.5,9.94e-05,0.5,9.94e-05,0.25,0.0002183999999999,0.25,0.0002472,0.5,0.000406624,0.75,0.0078
mmlu-high-school-macroeconomics.val.381,mistralai/mixtral-8x7b-chat,1.0,5.88e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
winogrande.dev.412,mistralai/mistral-7b-chat,0.0,1.12e-05,0.0,1.12e-05,0.0,1.6800000000000002e-05,0.0,3.3600000000000004e-05,0.0,4.3456000000000005e-05,0.0,0.00057
hellaswag.val.4081,mistralai/mistral-7b-chat,0.0,5.080000000000001e-05,0.0,5.080000000000001e-05,0.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
mmlu-professional-accounting.val.58,WizardLM/WizardLM-13B-V1.2,0.0,5.1e-05,0.0,3.4000000000000007e-05,0.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
mmlu-high-school-statistics.val.146,mistralai/mistral-7b-chat,0.0,4.74e-05,0.0,4.74e-05,1.0,7.110000000000001e-05,1.0,0.0001422,0.0,0.000183912,1.0,0.00238
hellaswag.val.5893,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.28e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00281
mmlu-professional-law.val.135,WizardLM/WizardLM-13B-V1.2,0.0,7.02e-05,1.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00235
mmlu-jurisprudence.val.33,mistralai/mixtral-8x7b-chat,1.0,6.48e-05,0.0,2.1600000000000003e-05,0.0,3.24e-05,1.0,6.48e-05,0.0,8.380800000000001e-05,1.0,0.00109
mmlu-high-school-macroeconomics.val.101,mistralai/mixtral-8x7b-chat,0.0,5.4e-05,0.0,1.8e-05,0.0,2.7e-05,0.0,5.4e-05,0.0,6.984e-05,1.0,0.00091
mmlu-high-school-biology.val.7,mistralai/mistral-7b-chat,0.0,1.54e-05,0.0,1.54e-05,0.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
mmlu-high-school-world-history.val.180,mistralai/mixtral-8x7b-chat,1.0,0.0001818,1.0,6.06e-05,1.0,9.09e-05,1.0,0.0001818,0.0,0.0002351279999999,1.0,0.00304
hellaswag.val.1429,mistralai/mixtral-8x7b-chat,1.0,6.840000000000001e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.0011799999999999
mmlu-business-ethics.val.98,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,1.0,8.1e-05,0.0,0.0001047599999999,1.0,0.00139
grade-school-math.dev.4938,WizardLM/WizardLM-13B-V1.2,0.75,0.0001323,0.75,9.28e-05,0.75,0.0001323,0.25,0.0002496,0.25,0.000308848,0.5,0.00844
grade-school-math.dev.2063,WizardLM/WizardLM-13B-V1.2,0.25,0.0001899,0.25,8.979999999999999e-05,0.25,0.0001899,0.25,0.0002898,0.25,0.000367048,0.75,0.01077
mmlu-high-school-psychology.val.363,mistralai/mixtral-8x7b-chat,0.0,6.42e-05,0.0,2.14e-05,0.0,3.21e-05,0.0,6.42e-05,0.0,8.3032e-05,1.0,0.00108
mmlu-high-school-us-history.val.35,WizardLM/WizardLM-13B-V1.2,0.0,0.0001385999999999,0.0,9.24e-05,0.0,0.0001385999999999,0.0,0.0002771999999999,0.0,0.000358512,0.0,0.00466
grade-school-math.dev.3645,WizardLM/WizardLM-13B-V1.2,0.25,0.0002013,0.25,7.159999999999999e-05,0.25,0.0002013,0.25,0.0003828,0.25,0.000432232,0.25,0.01512
hellaswag.val.3166,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-medicine.val.154,mistralai/mixtral-8x7b-chat,1.0,0.0001062,1.0,3.54e-05,1.0,5.31e-05,1.0,0.0001062,0.0,0.000137352,1.0,0.00181
mmlu-jurisprudence.val.7,mistralai/mistral-7b-chat,1.0,1.96e-05,1.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
mmlu-econometrics.val.53,mistralai/mixtral-8x7b-chat,1.0,8.159999999999999e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
mmlu-virology.val.24,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-professional-law.val.1258,WizardLM/WizardLM-13B-V1.2,0.0,5.94e-05,1.0,3.960000000000001e-05,0.0,5.94e-05,0.0,0.0001188,0.0,0.000153648,1.0,0.00202
mmlu-professional-law.val.240,WizardLM/WizardLM-13B-V1.2,0.0,7.47e-05,1.0,4.980000000000001e-05,0.0,7.47e-05,1.0,0.0001487999999999,0.0,0.0001932239999999,1.0,0.0025
mmlu-high-school-macroeconomics.val.389,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,0.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
hellaswag.val.2036,mistralai/mistral-7b-chat,1.0,1.74e-05,1.0,1.74e-05,1.0,2.58e-05,1.0,5.22e-05,1.0,6.751200000000001e-05,0.0,0.0008799999999999
mmlu-clinical-knowledge.val.236,mistralai/mistral-7b-chat,0.0,1.48e-05,0.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.3226,WizardLM/WizardLM-13B-V1.2,0.5,0.0001553999999999,0.5,0.0001,0.5,0.0001553999999999,0.75,0.0002874,0.25,0.000323592,0.5,0.00953
hellaswag.val.7195,mistralai/mixtral-8x7b-chat,1.0,0.0001494,1.0,4.980000000000001e-05,1.0,7.47e-05,1.0,0.0001494,1.0,0.0001932239999999,1.0,0.00253
mmlu-miscellaneous.val.411,mistralai/mistral-7b-chat,0.0,2.22e-05,0.0,2.22e-05,0.0,3.33e-05,1.0,6.659999999999999e-05,0.0,8.6136e-05,1.0,0.00112
grade-school-math.dev.5899,mistralai/mixtral-8x7b-chat,0.25,0.000225,0.25,9.8e-05,0.75,0.0001482,0.25,0.000225,0.75,0.000318936,0.75,0.0085399999999999
hellaswag.val.4994,mistralai/mistral-7b-chat,0.0,5.72e-05,0.0,5.72e-05,0.0,8.61e-05,0.0,0.0001722,0.0,0.000222712,0.0,0.00288
grade-school-math.dev.5749,WizardLM/WizardLM-13B-V1.2,0.75,0.0001341,0.25,8.280000000000001e-05,0.75,0.0001341,0.25,0.000198,0.25,0.0002522,0.75,0.00527
hellaswag.val.1388,WizardLM/WizardLM-13B-V1.2,0.0,3.39e-05,0.0,2.2600000000000004e-05,0.0,3.39e-05,0.0,6.78e-05,0.0,8.768799999999999e-05,0.0,0.00114
hellaswag.val.5430,mistralai/mixtral-8x7b-chat,1.0,0.0001463999999999,0.0,4.880000000000001e-05,0.0,7.289999999999998e-05,1.0,0.0001463999999999,0.0,0.0001893439999999,1.0,0.00245
mmlu-professional-law.val.723,WizardLM/WizardLM-13B-V1.2,0.0,7.98e-05,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,0.0,0.00267
mmlu-business-ethics.val.60,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,0.0,3.4200000000000005e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
hellaswag.val.7740,mistralai/mixtral-8x7b-chat,1.0,0.0001475999999999,0.0,4.94e-05,0.0,7.379999999999999e-05,1.0,0.0001475999999999,0.0,0.000191672,1.0,0.00251
mmlu-high-school-psychology.val.492,mistralai/mistral-7b-chat,0.0,2.54e-05,0.0,2.54e-05,0.0,3.81e-05,1.0,7.62e-05,0.0,9.8552e-05,1.0,0.00128
mmlu-marketing.val.137,mistralai/mistral-7b-chat,0.0,1.94e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,1.0,5.8200000000000005e-05,0.0,7.5272e-05,0.0,0.00101
mmlu-elementary-mathematics.val.195,mistralai/mistral-7b-chat,0.0,1.9e-05,0.0,1.9e-05,0.0,2.85e-05,0.0,5.7e-05,0.0,7.372e-05,1.0,0.00096
grade-school-math.dev.3484,WizardLM/WizardLM-13B-V1.2,0.25,0.0001446,0.75,8.16e-05,0.25,0.0001446,0.75,0.0002034,0.25,0.000367824,0.75,0.01064
mmlu-high-school-world-history.val.219,WizardLM/WizardLM-13B-V1.2,1.0,0.0001238999999999,0.0,8.26e-05,1.0,0.0001238999999999,1.0,0.0002477999999999,0.0,0.000320488,1.0,0.00414
mmlu-professional-law.val.752,WizardLM/WizardLM-13B-V1.2,0.0,0.0001083,0.0,7.219999999999999e-05,0.0,0.0001083,1.0,0.0002166,0.0,0.000280136,1.0,0.00362
hellaswag.val.6761,mistralai/mixtral-8x7b-chat,1.0,0.0001524,0.0,5.080000000000001e-05,0.0,7.62e-05,1.0,0.0001524,0.0,0.0001971039999999,1.0,0.00255
grade-school-math.dev.306,meta/code-llama-instruct-34b-chat,0.25,0.00033756,0.25,8.980000000000001e-05,0.75,0.0001581,0.75,0.0002508,0.25,0.00033756,0.75,0.00766
mmlu-moral-scenarios.val.208,mistralai/mistral-7b-chat,0.0,2.8e-05,0.0,2.8e-05,0.0,4.2e-05,1.0,8.4e-05,0.0,0.00010864,1.0,0.0014399999999999
mmlu-high-school-macroeconomics.val.292,mistralai/mistral-7b-chat,0.0,1.6800000000000002e-05,0.0,1.6800000000000002e-05,0.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
mmlu-professional-law.val.613,mistralai/mistral-7b-chat,0.0,5.0400000000000005e-05,0.0,5.0400000000000005e-05,1.0,7.56e-05,0.0,0.0001512,0.0,0.000195552,1.0,0.00253
grade-school-math.dev.717,WizardLM/WizardLM-13B-V1.2,0.25,0.0001539,0.25,0.0001038,0.25,0.0001539,0.75,0.0002267999999999,0.5,0.000313504,0.75,0.00686
mmlu-miscellaneous.val.472,mistralai/mixtral-8x7b-chat,1.0,4.38e-05,0.0,1.46e-05,1.0,2.19e-05,1.0,4.38e-05,0.0,5.6648e-05,1.0,0.00074
grade-school-math.dev.6731,WizardLM/WizardLM-13B-V1.2,0.5,0.0001005,0.25,5.7e-05,0.5,0.0001005,0.25,0.0002058,0.5,0.000243664,0.5,0.00462
hellaswag.val.5850,WizardLM/WizardLM-13B-V1.2,0.0,6.69e-05,0.0,4.460000000000001e-05,0.0,6.69e-05,0.0,0.0001338,0.0,0.000173048,1.0,0.00227
mmlu-machine-learning.val.41,mistralai/mixtral-8x7b-chat,1.0,0.0001086,0.0,3.6200000000000006e-05,0.0,5.43e-05,1.0,0.0001086,0.0,0.0001404559999999,0.0,0.00182
hellaswag.val.543,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,1.0,3e-05,1.0,6e-05,0.0,7.76e-05,1.0,0.00101
mmlu-prehistory.val.187,WizardLM/WizardLM-13B-V1.2,1.0,4.77e-05,0.0,3.180000000000001e-05,1.0,4.77e-05,1.0,9.54e-05,0.0,0.000123384,1.0,0.00163
mmlu-philosophy.val.290,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,1.0,2.94e-05,1.0,5.88e-05,0.0,7.604800000000001e-05,1.0,0.00099
grade-school-math.dev.4794,WizardLM/WizardLM-13B-V1.2,0.25,0.0002136,0.75,0.0001412,0.25,0.0002136,0.75,0.0003576,0.25,0.000360064,0.75,0.01099
mmlu-jurisprudence.val.44,mistralai/mixtral-8x7b-chat,1.0,6.3e-05,0.0,2.1e-05,1.0,3.15e-05,1.0,6.3e-05,0.0,8.148e-05,1.0,0.00106
mmlu-philosophy.val.236,mistralai/mistral-7b-chat,0.0,1.98e-05,0.0,1.98e-05,0.0,2.97e-05,0.0,5.94e-05,0.0,7.682400000000001e-05,1.0,0.001
hellaswag.val.5483,WizardLM/WizardLM-13B-V1.2,1.0,8.789999999999998e-05,0.0,5.8800000000000006e-05,1.0,8.789999999999998e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
hellaswag.val.4992,mistralai/mixtral-8x7b-chat,0.0,0.0001428,1.0,4.7600000000000005e-05,1.0,7.14e-05,0.0,0.0001428,1.0,0.000184688,1.0,0.00242
mmlu-college-chemistry.val.98,mistralai/mixtral-8x7b-chat,0.0,5.64e-05,0.0,1.8800000000000003e-05,1.0,2.82e-05,0.0,5.64e-05,0.0,7.2944e-05,0.0,0.00095
mmlu-professional-law.val.767,mistralai/mistral-7b-chat,0.0,6.900000000000001e-05,0.0,6.900000000000001e-05,0.0,0.0001035,1.0,0.000207,0.0,0.00026772,1.0,0.00346
mmlu-moral-scenarios.val.201,mistralai/mistral-7b-chat,0.0,2.64e-05,0.0,2.64e-05,0.0,3.96e-05,1.0,7.92e-05,0.0,0.000102432,1.0,0.00133
hellaswag.val.4285,mistralai/mixtral-8x7b-chat,0.0,0.0001529999999999,1.0,5.1000000000000006e-05,1.0,7.649999999999999e-05,0.0,0.0001529999999999,1.0,0.00019788,0.0,0.00259
hellaswag.val.8312,mistralai/mixtral-8x7b-chat,0.0,0.0001506,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00252
hellaswag.val.8764,mistralai/mixtral-8x7b-chat,0.0,0.0001626,0.0,5.420000000000001e-05,0.0,8.13e-05,0.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
hellaswag.val.1554,WizardLM/WizardLM-13B-V1.2,1.0,4.65e-05,1.0,3.1e-05,1.0,4.65e-05,1.0,9.3e-05,0.0,0.00012028,1.0,0.00156
grade-school-math.dev.3213,mistralai/mistral-7b-chat,0.25,0.0001058,0.25,0.0001058,0.75,0.0001872,0.25,0.0002892,0.25,0.000365496,0.75,0.01119
hellaswag.val.6966,mistralai/mistral-7b-chat,1.0,5.360000000000001e-05,1.0,5.360000000000001e-05,1.0,8.04e-05,1.0,0.0001608,1.0,0.0002079679999999,1.0,0.00269
mmlu-professional-psychology.val.226,WizardLM/WizardLM-13B-V1.2,1.0,4.32e-05,0.0,2.88e-05,1.0,4.32e-05,1.0,8.64e-05,0.0,0.000111744,1.0,0.00145
hellaswag.val.3020,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,1.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
grade-school-math.dev.5900,mistralai/mistral-7b-chat,0.75,9.48e-05,0.75,9.48e-05,0.75,0.0001409999999999,0.75,0.0002297999999999,0.75,0.000300312,0.75,0.00681
hellaswag.val.6108,mistralai/mixtral-8x7b-chat,0.0,0.0001662,0.0,5.5400000000000005e-05,0.0,8.31e-05,0.0,0.0001662,0.0,0.000214952,0.0,0.00278
mbpp.dev.266,mistralai/mistral-7b-chat,0.0,5.72e-05,0.0,5.72e-05,0.0,7.739999999999998e-05,1.0,0.0001631999999999,0.0,0.00025996,1.0,0.00955
hellaswag.val.6517,mistralai/mistral-7b-chat,0.0,5.420000000000001e-05,0.0,5.420000000000001e-05,0.0,8.13e-05,1.0,0.0001626,0.0,0.0002102959999999,1.0,0.00272
consensus_summary.dev.239,mistralai/mistral-7b-chat,0.75,6.500000000000001e-05,0.75,6.500000000000001e-05,0.75,8.730000000000001e-05,0.75,0.0001926,0.75,0.00028712,1.0,0.00243
mmlu-professional-law.val.545,mistralai/mistral-7b-chat,1.0,5.260000000000001e-05,1.0,5.260000000000001e-05,0.0,7.89e-05,1.0,0.0001571999999999,0.0,0.000204088,1.0,0.00264
mbpp.dev.105,mistralai/mistral-7b-chat,1.0,6.18e-05,1.0,6.18e-05,1.0,0.0001098,1.0,0.0001404,1.0,0.000188568,1.0,0.009
mmlu-high-school-biology.val.222,mistralai/mixtral-8x7b-chat,0.0,4.86e-05,1.0,1.62e-05,0.0,2.43e-05,0.0,4.86e-05,0.0,6.285600000000001e-05,1.0,0.00085
hellaswag.val.8542,mistralai/mixtral-8x7b-chat,0.0,0.0001439999999999,1.0,4.8e-05,1.0,7.199999999999999e-05,0.0,0.0001439999999999,1.0,0.00018624,1.0,0.00244
grade-school-math.dev.6289,WizardLM/WizardLM-13B-V1.2,0.75,0.0001308,0.25,6.64e-05,0.75,0.0001308,0.75,0.000192,0.75,0.000268496,0.5,0.00575
mmlu-professional-law.val.986,mistralai/mistral-7b-chat,0.0,6.14e-05,0.0,6.14e-05,0.0,9.21e-05,1.0,0.0001842,0.0,0.000238232,1.0,0.00308
grade-school-math.dev.1285,mistralai/mixtral-8x7b-chat,0.75,0.0002045999999999,0.75,0.0001012,0.75,0.0001314,0.75,0.0002045999999999,0.75,0.000315056,0.5,0.00624
mmlu-miscellaneous.val.523,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,1.0,1.48e-05,1.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
mmlu-jurisprudence.val.17,mistralai/mistral-7b-chat,1.0,2.4e-05,1.0,2.4e-05,1.0,3.6e-05,1.0,7.2e-05,0.0,9.312e-05,1.0,0.00121
hellaswag.val.143,WizardLM/WizardLM-13B-V1.2,0.0,2.22e-05,0.0,1.48e-05,0.0,2.22e-05,0.0,4.44e-05,0.0,5.7424e-05,1.0,0.00075
grade-school-math.dev.3097,WizardLM/WizardLM-13B-V1.2,0.75,0.0001725,0.75,0.0001024,0.75,0.0001725,0.25,0.0003036,0.25,0.000353856,0.75,0.0078
mmlu-formal-logic.val.22,mistralai/mistral-7b-chat,0.0,3.02e-05,0.0,3.02e-05,0.0,4.53e-05,0.0,8.999999999999999e-05,0.0,0.000117176,0.0,0.00152
mmlu-high-school-psychology.val.361,mistralai/mixtral-8x7b-chat,1.0,7.740000000000001e-05,1.0,2.58e-05,1.0,3.8700000000000006e-05,1.0,7.740000000000001e-05,0.0,0.000100104,1.0,0.0013
hellaswag.val.8400,mistralai/mistral-7b-chat,0.0,5.8800000000000006e-05,0.0,5.8800000000000006e-05,0.0,8.789999999999998e-05,0.0,0.0001763999999999,0.0,0.000228144,1.0,0.00295
grade-school-math.dev.7422,mistralai/mistral-7b-chat,0.25,8.999999999999999e-05,0.25,8.999999999999999e-05,0.25,0.0001716,0.25,0.0002904,0.5,0.000523024,0.75,0.0096499999999999
mmlu-nutrition.val.198,meta/code-llama-instruct-34b-chat,0.0,0.000145112,1.0,3.74e-05,1.0,5.61e-05,1.0,0.0001122,0.0,0.000145112,1.0,0.00188
hellaswag.val.4893,WizardLM/WizardLM-13B-V1.2,0.0,8.07e-05,0.0,5.380000000000001e-05,0.0,8.07e-05,1.0,0.0001614,0.0,0.000208744,1.0,0.0027
mmlu-high-school-government-and-politics.val.74,mistralai/mistral-7b-chat,0.0,2.28e-05,0.0,2.28e-05,1.0,3.3900000000000004e-05,1.0,6.840000000000001e-05,0.0,8.846400000000001e-05,1.0,0.00115
grade-school-math.dev.3570,WizardLM/WizardLM-13B-V1.2,0.75,0.0001484999999999,0.25,5.9e-05,0.75,0.0001484999999999,0.5,0.0002597999999999,0.75,0.000299536,0.75,0.00715
mmlu-high-school-chemistry.val.11,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,0.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
arc-challenge.test.667,mistralai/mistral-7b-chat,1.0,1.5600000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,1.0,6.0528e-05,1.0,0.00082
mmlu-high-school-physics.val.28,mistralai/mixtral-8x7b-chat,1.0,0.000102,0.0,3.4000000000000007e-05,0.0,5.1e-05,1.0,0.000102,0.0,0.0001319199999999,1.0,0.00171
mmlu-security-studies.val.138,mistralai/mistral-7b-chat,1.0,3.0600000000000005e-05,1.0,3.0600000000000005e-05,1.0,4.59e-05,1.0,9.18e-05,0.0,0.000118728,1.0,0.00154
hellaswag.val.8245,WizardLM/WizardLM-13B-V1.2,1.0,6.659999999999999e-05,0.0,4.460000000000001e-05,1.0,6.659999999999999e-05,1.0,0.0001338,0.0,0.000173048,1.0,0.00227
grade-school-math.dev.822,WizardLM/WizardLM-13B-V1.2,0.25,0.0001809,0.25,8.92e-05,0.25,0.0001809,0.0,0.000258,0.75,0.000338336,0.75,0.00777
hellaswag.val.4319,mistralai/mixtral-8x7b-chat,1.0,0.0001542,1.0,5.14e-05,1.0,7.71e-05,1.0,0.0001542,1.0,0.0001994319999999,1.0,0.00261
hellaswag.val.4322,mistralai/mistral-7b-chat,0.0,4.56e-05,0.0,4.56e-05,0.0,6.84e-05,0.0,0.0001361999999999,0.0,0.000176928,1.0,0.00232
hellaswag.val.7369,WizardLM/WizardLM-13B-V1.2,0.0,6.93e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,0.0,0.0001386,0.0,0.000179256,0.0,0.00235
mmlu-high-school-psychology.val.140,mistralai/mixtral-8x7b-chat,1.0,4.32e-05,0.0,1.44e-05,1.0,2.16e-05,1.0,4.32e-05,0.0,5.5872e-05,1.0,0.00073
hellaswag.val.7456,mistralai/mixtral-8x7b-chat,0.0,0.0001409999999999,0.0,4.7e-05,0.0,7.049999999999999e-05,0.0,0.0001409999999999,0.0,0.0001823599999999,1.0,0.00236
grade-school-math.dev.7209,mistralai/mistral-7b-chat,0.25,0.000115,0.25,0.000115,0.25,0.0001584,0.5,0.0002747999999999,0.25,0.000321264,0.75,0.01057
hellaswag.val.9470,WizardLM/WizardLM-13B-V1.2,1.0,8.16e-05,1.0,5.44e-05,1.0,8.16e-05,1.0,0.0001632,1.0,0.000211072,1.0,0.00276
hellaswag.val.9228,mistralai/mistral-7b-chat,1.0,4.920000000000001e-05,1.0,4.920000000000001e-05,1.0,7.38e-05,1.0,0.0001476,1.0,0.0001908959999999,1.0,0.0025
hellaswag.val.9177,WizardLM/WizardLM-13B-V1.2,1.0,8.31e-05,1.0,5.5400000000000005e-05,1.0,8.31e-05,1.0,0.0001662,1.0,0.000214952,1.0,0.00281
mmlu-professional-law.val.1422,mistralai/mistral-7b-chat,0.0,5.64e-05,0.0,5.64e-05,1.0,8.46e-05,1.0,0.0001692,0.0,0.000218832,1.0,0.00283
mmlu-high-school-biology.val.292,mistralai/mixtral-8x7b-chat,0.0,6.720000000000001e-05,1.0,2.24e-05,0.0,3.3600000000000004e-05,0.0,6.720000000000001e-05,0.0,8.6912e-05,0.0,0.00116
grade-school-math.dev.3298,WizardLM/WizardLM-13B-V1.2,0.25,0.0002604,0.25,0.0001009999999999,0.25,0.0002604,0.25,0.000282,0.75,0.000382568,0.75,0.0102
grade-school-math.dev.3163,WizardLM/WizardLM-13B-V1.2,0.25,0.0001602,0.75,0.0001054,0.25,0.0001602,0.25,0.0002904,0.25,0.000412832,0.5,0.00706
hellaswag.val.9836,mistralai/mixtral-8x7b-chat,1.0,0.0001518,0.0,5.06e-05,0.0,7.56e-05,1.0,0.0001518,0.0,0.000196328,1.0,0.00254
grade-school-math.dev.6564,meta/code-llama-instruct-34b-chat,0.25,0.000343768,0.25,0.00058,0.25,0.0002034,0.25,0.0003149999999999,0.25,0.000343768,0.5,0.01099
hellaswag.val.5586,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.53e-05,0.0,0.00015,0.0,0.000194776,1.0,0.00252
hellaswag.val.7944,mistralai/mixtral-8x7b-chat,1.0,0.000117,1.0,3.9000000000000006e-05,1.0,5.85e-05,1.0,0.000117,1.0,0.0001513199999999,1.0,0.00199
grade-school-math.dev.209,mistralai/mixtral-8x7b-chat,0.75,0.0002423999999999,0.25,8.5e-05,0.5,0.0001194,0.75,0.0002423999999999,0.75,0.00026772,0.75,0.00562
mmlu-formal-logic.val.61,mistralai/mistral-7b-chat,0.0,4.6200000000000005e-05,0.0,4.6200000000000005e-05,0.0,6.93e-05,1.0,0.0001386,0.0,0.000179256,1.0,0.00232
arc-challenge.test.1064,mistralai/mixtral-8x7b-chat,1.0,6.54e-05,0.0,2.18e-05,0.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
grade-school-math.dev.2770,WizardLM/WizardLM-13B-V1.2,0.25,0.0001844999999999,0.25,0.0001058,0.25,0.0001844999999999,0.25,0.00024,0.25,0.000273152,0.25,0.00954
mmlu-moral-scenarios.val.121,mistralai/mixtral-8x7b-chat,1.0,8.28e-05,0.0,2.7600000000000003e-05,0.0,4.14e-05,1.0,8.28e-05,0.0,0.000107088,0.0,0.00139
mmlu-moral-scenarios.val.830,mistralai/mistral-7b-chat,0.0,2.78e-05,0.0,2.78e-05,0.0,4.17e-05,0.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014299999999999
mmlu-high-school-psychology.val.475,mistralai/mixtral-8x7b-chat,1.0,5.34e-05,0.0,1.7800000000000002e-05,1.0,2.67e-05,1.0,5.34e-05,0.0,6.9064e-05,1.0,0.00093
mmlu-high-school-psychology.val.226,mistralai/mistral-7b-chat,0.0,1.32e-05,0.0,1.32e-05,0.0,1.98e-05,1.0,3.96e-05,0.0,5.1216000000000006e-05,1.0,0.00067
grade-school-math.dev.2120,WizardLM/WizardLM-13B-V1.2,0.75,0.0001487999999999,0.75,9.7e-05,0.75,0.0001487999999999,0.75,0.000354,0.25,0.000301864,0.75,0.01165
grade-school-math.dev.2547,mistralai/mistral-7b-chat,0.75,6.400000000000001e-05,0.75,6.400000000000001e-05,0.75,0.0001307999999999,0.75,0.0002177999999999,0.75,0.000225816,0.5,0.00515
mmlu-professional-law.val.1386,WizardLM/WizardLM-13B-V1.2,1.0,0.0001182,0.0,7.88e-05,1.0,0.0001182,1.0,0.0002364,0.0,0.000305744,1.0,0.0039499999999999
mmlu-professional-law.val.410,mistralai/mistral-7b-chat,1.0,4.56e-05,1.0,4.56e-05,0.0,6.84e-05,1.0,0.0001368,0.0,0.000176928,1.0,0.00229
mmlu-jurisprudence.val.62,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,0.0,0.00091
mmlu-management.val.58,mistralai/mixtral-8x7b-chat,1.0,4.44e-05,0.0,1.48e-05,0.0,2.22e-05,1.0,4.44e-05,0.0,5.7424e-05,0.0,0.00078
mmlu-professional-psychology.val.218,mistralai/mistral-7b-chat,0.0,2.3e-05,0.0,2.3e-05,0.0,3.45e-05,1.0,6.9e-05,0.0,8.924e-05,1.0,0.00116
hellaswag.val.886,mistralai/mistral-7b-chat,0.0,3.24e-05,0.0,3.24e-05,0.0,4.86e-05,0.0,9.72e-05,0.0,0.000125712,1.0,0.00163
mmlu-professional-law.val.1232,mistralai/mistral-7b-chat,1.0,5.360000000000001e-05,1.0,5.360000000000001e-05,0.0,8.04e-05,1.0,0.0001608,0.0,0.0002079679999999,1.0,0.00269
mmlu-medical-genetics.val.99,mistralai/mixtral-8x7b-chat,1.0,5.22e-05,0.0,1.74e-05,0.0,2.61e-05,1.0,5.22e-05,0.0,6.751200000000001e-05,1.0,0.0008799999999999
mmlu-philosophy.val.42,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.0012
hellaswag.val.8579,mistralai/mixtral-8x7b-chat,1.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.159999999999999e-05,1.0,0.0001638,0.0,0.0002118479999999,1.0,0.00277
hellaswag.val.2290,WizardLM/WizardLM-13B-V1.2,0.0,3.69e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-moral-scenarios.val.420,mistralai/mistral-7b-chat,0.0,2.96e-05,0.0,2.96e-05,0.0,4.44e-05,0.0,8.879999999999999e-05,0.0,0.000114848,1.0,0.0015199999999999
mmlu-professional-law.val.367,mistralai/mistral-7b-chat,0.0,5.8200000000000005e-05,0.0,5.8200000000000005e-05,1.0,8.730000000000001e-05,1.0,0.0001746,0.0,0.000225816,1.0,0.00292
hellaswag.val.6401,mistralai/mixtral-8x7b-chat,1.0,0.0001649999999999,0.0,5.5e-05,0.0,8.219999999999998e-05,1.0,0.0001649999999999,0.0,0.0002134,1.0,0.00276
grade-school-math.dev.3870,mistralai/mixtral-8x7b-chat,1.0,0.0001877999999999,0.75,8.38e-05,0.75,0.0001619999999999,1.0,0.0001877999999999,0.25,0.00029488,0.75,0.00858
mmlu-moral-scenarios.val.863,mistralai/mistral-7b-chat,0.0,2.7e-05,0.0,2.7e-05,0.0,4.05e-05,0.0,8.1e-05,0.0,0.0001047599999999,0.0,0.00136
mmlu-miscellaneous.val.780,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,0.0,5.354400000000001e-05,1.0,0.0007
mmlu-high-school-mathematics.val.54,mistralai/mistral-7b-chat,0.0,3.1e-05,0.0,3.1e-05,0.0,4.65e-05,1.0,9.3e-05,0.0,0.00012028,1.0,0.00156
mmlu-professional-law.val.438,mistralai/mistral-7b-chat,0.0,4.860000000000001e-05,0.0,4.860000000000001e-05,0.0,7.29e-05,1.0,0.0001458,0.0,0.000188568,0.0,0.00244
winogrande.dev.953,mistralai/mistral-7b-chat,1.0,1.12e-05,1.0,1.12e-05,0.0,1.6800000000000002e-05,1.0,3.3600000000000004e-05,0.0,4.4232000000000006e-05,1.0,0.0006
hellaswag.val.5048,mistralai/mistral-7b-chat,0.0,5.520000000000001e-05,0.0,5.520000000000001e-05,0.0,8.25e-05,0.0,0.0001656,0.0,0.0002141759999999,0.0,0.0028
mmlu-professional-psychology.val.310,WizardLM/WizardLM-13B-V1.2,1.0,5.19e-05,0.0,3.460000000000001e-05,1.0,5.19e-05,0.0,0.0001038,0.0,0.0001342479999999,1.0,0.00174
mmlu-high-school-psychology.val.474,WizardLM/WizardLM-13B-V1.2,1.0,2.3400000000000003e-05,1.0,1.5600000000000003e-05,1.0,2.3400000000000003e-05,1.0,4.6800000000000006e-05,0.0,6.0528e-05,1.0,0.00079
winogrande.dev.474,mistralai/mistral-7b-chat,1.0,1e-05,1.0,1e-05,1.0,1.5e-05,1.0,3e-05,0.0,3.802400000000001e-05,1.0,0.00054
grade-school-math.dev.2633,mistralai/mistral-7b-chat,0.25,8.6e-05,0.25,8.6e-05,0.5,0.0001488,0.25,0.0002544,0.25,0.000316608,0.75,0.00762
hellaswag.val.8182,mistralai/mixtral-8x7b-chat,0.0,0.0001302,0.0,4.340000000000001e-05,0.0,6.51e-05,0.0,0.0001302,0.0,0.0001683919999999,1.0,0.00218
hellaswag.val.1133,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.18e-05,1.0,6.42e-05,1.0,8.3032e-05,1.0,0.0011099999999999
hellaswag.val.4130,mistralai/mixtral-8x7b-chat,0.0,0.0001608,1.0,5.360000000000001e-05,1.0,8.04e-05,0.0,0.0001608,1.0,0.0002079679999999,1.0,0.00272
mmlu-high-school-microeconomics.val.180,mistralai/mistral-7b-chat,0.0,1.86e-05,0.0,1.86e-05,1.0,2.79e-05,1.0,5.58e-05,0.0,7.2168e-05,1.0,0.00094
grade-school-math.dev.2667,WizardLM/WizardLM-13B-V1.2,0.5,0.0001941,0.25,0.000108,0.5,0.0001941,0.5,0.0003281999999999,0.25,0.000439992,0.5,0.0103299999999999
mmlu-prehistory.val.64,mistralai/mixtral-8x7b-chat,1.0,0.0001134,1.0,3.78e-05,1.0,5.67e-05,1.0,0.0001134,0.0,0.000146664,1.0,0.0019
mmlu-professional-law.val.1054,WizardLM/WizardLM-13B-V1.2,1.0,6e-05,0.0,4e-05,1.0,6e-05,1.0,0.00012,0.0,0.0001551999999999,1.0,0.00201
mmlu-college-chemistry.val.60,mistralai/mixtral-8x7b-chat,0.0,5.8200000000000005e-05,0.0,1.94e-05,0.0,2.9100000000000003e-05,0.0,5.8200000000000005e-05,0.0,7.5272e-05,1.0,0.00098
hellaswag.val.2801,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,0.0,0.00137
grade-school-math.dev.1469,mistralai/mistral-7b-chat,0.25,8.900000000000001e-05,0.25,8.900000000000001e-05,0.75,0.0001404,0.75,0.0001992,0.25,0.000269272,0.5,0.00745
grade-school-math.dev.3924,WizardLM/WizardLM-13B-V1.2,0.25,0.0002145,0.75,9.12e-05,0.25,0.0002145,0.75,0.000258,0.75,0.000379464,0.75,0.00828
mmlu-professional-law.val.424,WizardLM/WizardLM-13B-V1.2,1.0,9.18e-05,1.0,6.120000000000001e-05,1.0,9.18e-05,1.0,0.0001836,0.0,0.0002374559999999,1.0,0.0031
mmlu-professional-law.val.532,mistralai/mistral-7b-chat,0.0,5.62e-05,0.0,5.62e-05,1.0,8.43e-05,0.0,0.0001686,0.0,0.000218056,1.0,0.00282
arc-challenge.test.412,mistralai/mistral-7b-chat,1.0,1.38e-05,1.0,1.38e-05,1.0,2.07e-05,1.0,4.14e-05,1.0,5.354400000000001e-05,1.0,0.0007
mmlu-miscellaneous.val.334,mistralai/mixtral-8x7b-chat,1.0,4.08e-05,0.0,1.36e-05,1.0,2.04e-05,1.0,4.08e-05,0.0,5.2768e-05,1.0,0.00069
hellaswag.val.5708,mistralai/mistral-7b-chat,0.0,6e-05,0.0,6e-05,0.0,8.999999999999999e-05,0.0,0.0001799999999999,0.0,0.0002328,1.0,0.00301
mmlu-professional-law.val.690,WizardLM/WizardLM-13B-V1.2,0.0,0.0001343999999999,0.0,8.96e-05,0.0,0.0001343999999999,0.0,0.0002681999999999,0.0,0.000347648,1.0,0.00449
mmlu-formal-logic.val.103,mistralai/mistral-7b-chat,0.0,2.46e-05,0.0,2.46e-05,0.0,3.69e-05,0.0,7.379999999999999e-05,0.0,9.5448e-05,1.0,0.00124
mmlu-high-school-government-and-politics.val.164,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,1.0,3.93e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
grade-school-math.dev.5369,WizardLM/WizardLM-13B-V1.2,0.25,0.0002301,0.25,0.000112,0.25,0.0002301,0.5,0.0002856,0.25,0.000408952,0.75,0.01428
mmlu-miscellaneous.val.745,mistralai/mixtral-8x7b-chat,1.0,4.6200000000000005e-05,1.0,1.54e-05,1.0,2.31e-05,1.0,4.6200000000000005e-05,0.0,5.9752000000000007e-05,1.0,0.00078
grade-school-math.dev.2198,mistralai/mixtral-8x7b-chat,0.25,0.0003132,0.25,9.82e-05,0.25,0.0002016,0.25,0.0003132,0.25,0.000307296,0.5,0.01307
arc-challenge.val.128,mistralai/mistral-7b-chat,1.0,2.14e-05,1.0,2.14e-05,1.0,3.21e-05,1.0,6.42e-05,1.0,8.3032e-05,1.0,0.0011099999999999
mmlu-professional-law.val.1523,WizardLM/WizardLM-13B-V1.2,1.0,0.0001397999999999,0.0,9.32e-05,1.0,0.0001397999999999,1.0,0.0002795999999999,0.0,0.000361616,0.0,0.00467
hellaswag.val.7891,WizardLM/WizardLM-13B-V1.2,0.0,8.669999999999999e-05,1.0,5.780000000000001e-05,0.0,8.669999999999999e-05,0.0,0.0001733999999999,1.0,0.000224264,1.0,0.00293
hellaswag.val.8389,mistralai/mixtral-8x7b-chat,0.0,0.0001638,0.0,5.4600000000000006e-05,0.0,8.159999999999999e-05,0.0,0.0001638,0.0,0.0002118479999999,1.0,0.00277
grade-school-math.dev.2481,mistralai/mixtral-8x7b-chat,0.75,0.0002172,0.75,6.8e-05,0.75,0.0001317,0.75,0.0002172,0.25,0.00030264,0.75,0.00613
mmlu-college-biology.val.100,mistralai/mixtral-8x7b-chat,1.0,8.340000000000001e-05,0.0,2.78e-05,1.0,4.17e-05,1.0,8.340000000000001e-05,0.0,0.000107864,1.0,0.0014
mmlu-professional-law.val.934,mistralai/mistral-7b-chat,0.0,2e-05,0.0,2e-05,0.0,3e-05,1.0,6e-05,0.0,7.76e-05,0.0,0.00104
mmlu-moral-disputes.val.179,mistralai/mistral-7b-chat,0.0,1.72e-05,0.0,1.72e-05,0.0,2.58e-05,1.0,5.16e-05,0.0,6.673599999999999e-05,1.0,0.00087
mmlu-elementary-mathematics.val.161,mistralai/mixtral-8x7b-chat,1.0,6.36e-05,0.0,2.12e-05,1.0,3.18e-05,1.0,6.36e-05,0.0,8.2256e-05,1.0,0.00107
