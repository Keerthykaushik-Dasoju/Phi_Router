sample_id,phi_prediction,phi_correctness,phi_cost,mistralai/mistral-7b-chat_correctness,mistralai/mistral-7b-chat_cost,WizardLM/WizardLM-13B-V1.2_correctness,WizardLM/WizardLM-13B-V1.2_cost,mistralai/mixtral-8x7b-chat_correctness,mistralai/mixtral-8x7b-chat_cost,meta/code-llama-instruct-34b-chat_correctness,meta/code-llama-instruct-34b-chat_cost,gpt-4-1106-preview_correctness,gpt-4-1106-preview_cost
mmlu-professional-law.val.1247,meta/code-llama-instruct-34b-chat,0.0,0.000457064,0.0,0.0001178,1.0,0.0001766999999999,0.0,0.0003533999999999,0.0,0.000457064,1.0,0.0059
mmlu-international-law.val.89,gpt-4-1106-preview,1.0,0.00122,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.4617,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.5357,gpt-4-1106-preview,0.5,0.00626,0.25,8.68e-05,0.25,0.0001317,0.25,0.0002526,0.5,0.00030652,0.5,0.00626
hellaswag.val.2731,mistralai/mistral-7b-chat,0.0,2.72e-05,0.0,2.72e-05,1.0,4.08e-05,1.0,8.159999999999999e-05,0.0,0.000105536,1.0,0.00137
hellaswag.val.9797,mistralai/mistral-7b-chat,0.0,5.1000000000000006e-05,0.0,5.1000000000000006e-05,0.0,7.619999999999998e-05,0.0,0.0001529999999999,0.0,0.00019788,1.0,0.00256
mmlu-professional-law.val.570,mistralai/mistral-7b-chat,0.0,6.36e-05,0.0,6.36e-05,0.0,9.54e-05,0.0,0.0001908,0.0,0.000246768,1.0,0.00319
hellaswag.val.1836,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
hellaswag.val.2769,mistralai/mistral-7b-chat,1.0,1.86e-05,1.0,1.86e-05,0.0,2.79e-05,1.0,5.58e-05,1.0,7.2168e-05,1.0,0.00097
mmlu-professional-law.val.485,meta/code-llama-instruct-34b-chat,0.0,0.00014356,0.0,3.7000000000000005e-05,0.0,5.55e-05,0.0,0.000111,0.0,0.00014356,1.0,0.00186
hellaswag.val.2850,mistralai/mistral-7b-chat,0.0,2.18e-05,0.0,2.18e-05,1.0,3.27e-05,1.0,6.54e-05,0.0,8.4584e-05,1.0,0.0011
mmlu-business-ethics.val.54,mistralai/mistral-7b-chat,0.0,2.42e-05,0.0,2.42e-05,1.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,0.0,0.00122
bias_detection.dev.265,mistralai/mistral-7b-chat,0.0,6.54e-05,0.0,6.54e-05,0.0,0.0001085999999999,0.0,0.0001817999999999,0.0,0.000270048,0.0,0.01179
consensus_summary.dev.5,meta/code-llama-instruct-34b-chat,0.75,0.000335232,0.75,8.740000000000001e-05,0.75,0.0002274,0.75,0.0002136,0.75,0.000335232,0.75,0.00886
hellaswag.val.3051,mistralai/mistral-7b-chat,0.0,1.96e-05,0.0,1.96e-05,0.0,2.94e-05,0.0,5.88e-05,0.0,7.604800000000001e-05,0.0,0.00099
hellaswag.val.5313,mistralai/mistral-7b-chat,0.0,6.0200000000000006e-05,0.0,6.0200000000000006e-05,1.0,9.03e-05,0.0,0.0001806,0.0,0.000233576,1.0,0.00302
mmlu-miscellaneous.val.737,mistralai/mistral-7b-chat,0.0,1.42e-05,0.0,1.42e-05,1.0,2.13e-05,1.0,4.26e-05,0.0,5.5096e-05,1.0,0.0007199999999999
grade-school-math.dev.3702,meta/code-llama-instruct-34b-chat,0.25,0.000415936,0.25,0.0001055999999999,0.25,0.0001869,0.25,0.0003072,0.25,0.000415936,0.5,0.0102
hellaswag.val.6662,mistralai/mistral-7b-chat,1.0,4.64e-05,1.0,4.64e-05,1.0,6.96e-05,1.0,0.0001392,1.0,0.000180032,1.0,0.00233
grade-school-math.dev.5353,meta/code-llama-instruct-34b-chat,0.75,0.000294104,0.25,8.78e-05,0.25,0.0001311,0.25,0.0002286,0.75,0.000294104,0.75,0.00763
grade-school-math.dev.7313,meta/code-llama-instruct-34b-chat,0.75,0.0002669439999999,0.25,8.280000000000001e-05,0.25,0.0001539,0.25,0.0002838,0.75,0.0002669439999999,0.75,0.00835
mmlu-high-school-biology.val.90,gpt-4-1106-preview,1.0,0.00117,0.0,2.32e-05,0.0,3.48e-05,1.0,6.96e-05,0.0,9.0016e-05,1.0,0.00117
mmlu-professional-law.val.73,mistralai/mistral-7b-chat,0.0,3.8400000000000005e-05,0.0,3.8400000000000005e-05,0.0,5.76e-05,1.0,0.0001152,0.0,0.0001489919999999,1.0,0.00193
mmlu-business-ethics.val.77,gpt-4-1106-preview,1.0,0.0007999999999999,0.0,1.58e-05,1.0,2.37e-05,1.0,4.74e-05,0.0,6.1304e-05,1.0,0.0007999999999999
hellaswag.val.7889,mistralai/mistral-7b-chat,0.0,4.6800000000000006e-05,0.0,4.6800000000000006e-05,0.0,7.02e-05,0.0,0.0001404,0.0,0.000181584,1.0,0.00238
grade-school-math.dev.715,meta/code-llama-instruct-34b-chat,0.25,0.000284792,0.75,8.94e-05,0.75,0.0001578,0.75,0.0002808,0.25,0.000284792,0.75,0.00757
mmlu-jurisprudence.val.67,mistralai/mistral-7b-chat,1.0,2.0600000000000003e-05,1.0,2.0600000000000003e-05,0.0,3.09e-05,1.0,6.18e-05,0.0,7.992800000000001e-05,1.0,0.00104
hellaswag.val.2580,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,0.0,3.06e-05,0.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
grade-school-math.dev.5091,meta/code-llama-instruct-34b-chat,0.25,0.000383344,0.75,0.0001016,0.5,0.0001844999999999,0.25,0.0003012,0.25,0.000383344,0.75,0.01166
grade-school-math.dev.7398,meta/code-llama-instruct-34b-chat,0.25,0.000312728,0.25,8.340000000000001e-05,0.75,0.0001656,0.75,0.0002418,0.25,0.000312728,0.75,0.00753
hellaswag.val.8841,mistralai/mistral-7b-chat,0.0,5.3200000000000006e-05,0.0,5.3200000000000006e-05,0.0,7.98e-05,0.0,0.0001596,0.0,0.0002064159999999,1.0,0.0027
mmlu-college-mathematics.val.52,gpt-4-1106-preview,1.0,0.00122,0.0,2.42e-05,0.0,3.63e-05,1.0,7.259999999999999e-05,0.0,9.3896e-05,1.0,0.00122
mmlu-professional-law.val.1513,meta/code-llama-instruct-34b-chat,0.0,0.0001722719999999,0.0,4.44e-05,0.0,6.66e-05,0.0,0.0001332,0.0,0.0001722719999999,0.0,0.00223
hellaswag.val.6403,mistralai/mistral-7b-chat,0.0,5.260000000000001e-05,0.0,5.260000000000001e-05,0.0,7.859999999999999e-05,0.0,0.0001578,0.0,0.000204088,1.0,0.00267
grade-school-math.dev.1515,mistralai/mistral-7b-chat,0.5,6.900000000000001e-05,0.5,6.900000000000001e-05,0.75,0.0001293,0.25,0.0002021999999999,0.75,0.000250648,0.75,0.00579
hellaswag.val.8810,mistralai/mistral-7b-chat,1.0,5.5400000000000005e-05,1.0,5.5400000000000005e-05,1.0,8.31e-05,0.0,0.0001662,1.0,0.000214952,1.0,0.00281
mmlu-professional-law.val.1365,mistralai/mistral-7b-chat,1.0,4.380000000000001e-05,1.0,4.380000000000001e-05,0.0,6.57e-05,0.0,0.0001314,0.0,0.0001699439999999,0.0,0.0022
hellaswag.val.9743,mistralai/mistral-7b-chat,1.0,5.280000000000001e-05,1.0,5.280000000000001e-05,1.0,7.89e-05,1.0,0.0001584,0.0,0.000204864,1.0,0.00268
hellaswag.val.4227,mistralai/mistral-7b-chat,0.0,5.020000000000001e-05,0.0,5.020000000000001e-05,0.0,7.5e-05,0.0,0.0001506,0.0,0.000194776,1.0,0.00255
grade-school-math.dev.3650,gpt-4-1106-preview,0.75,0.0083,0.25,6.2e-05,0.25,0.0001416,0.5,0.0002694,0.5,0.000351528,0.75,0.0083
grade-school-math.dev.7183,gpt-4-1106-preview,0.75,0.00779,0.25,9.44e-05,0.25,0.0001353,0.25,0.000282,0.25,0.000339888,0.75,0.00779
grade-school-math.dev.2573,meta/code-llama-instruct-34b-chat,0.25,0.000585104,0.25,0.0001122,0.75,0.0001566,0.75,0.0002676,0.25,0.000585104,0.75,0.00777
hellaswag.val.1662,mistralai/mistral-7b-chat,0.0,2.02e-05,0.0,2.02e-05,1.0,3.03e-05,1.0,6.06e-05,0.0,7.8376e-05,0.0,0.00105
mmlu-miscellaneous.val.235,gpt-4-1106-preview,1.0,0.00085,0.0,1.6800000000000002e-05,1.0,2.52e-05,1.0,5.04e-05,0.0,6.5184e-05,1.0,0.00085
grade-school-math.dev.2161,gpt-4-1106-preview,0.5,0.0106,0.25,8.16e-05,0.25,0.0001842,0.25,0.0002988,0.25,0.000394984,0.5,0.0106
hellaswag.val.5410,mistralai/mistral-7b-chat,1.0,4.420000000000001e-05,1.0,4.420000000000001e-05,1.0,6.599999999999999e-05,0.0,0.0001326,1.0,0.000171496,1.0,0.00222
hellaswag.val.551,mistralai/mistral-7b-chat,0.0,2.62e-05,0.0,2.62e-05,0.0,3.9e-05,1.0,7.86e-05,0.0,0.000101656,1.0,0.00132
mmlu-high-school-geography.val.58,mistralai/mistral-7b-chat,0.0,2.04e-05,0.0,2.04e-05,1.0,3.03e-05,1.0,6.12e-05,0.0,7.9152e-05,1.0,0.00103
mmlu-professional-law.val.1203,meta/code-llama-instruct-34b-chat,0.0,0.000325144,0.0,8.38e-05,0.0,0.0001257,0.0,0.0002514,0.0,0.000325144,1.0,0.0042
hellaswag.val.867,mistralai/mistral-7b-chat,0.0,2.32e-05,0.0,2.32e-05,0.0,3.48e-05,0.0,6.96e-05,0.0,9.0016e-05,0.0,0.00117
